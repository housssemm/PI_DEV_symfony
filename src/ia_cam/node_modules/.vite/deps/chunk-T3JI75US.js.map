{
  "version": 3,
  "sources": ["../../../../tfjs-backend-webgpu/src/flags_webgpu.ts", "../../../../tfjs-backend-webgpu/src/adapter_info.ts", "../../../../tfjs-backend-webgpu/src/buffer_manager.ts", "../../../../tfjs-backend-webgpu/src/texture_manager.ts", "../../../../tfjs-backend-webgpu/src/shader_util.ts", "../../../../tfjs-backend-webgpu/src/webgpu_program.ts", "../../../../tfjs-backend-webgpu/src/webgpu_util.ts", "../../../../tfjs-backend-webgpu/src/backend_webgpu.ts", "../../../../tfjs-backend-webgpu/src/base.ts", "../../../../tfjs-backend-webgpu/src/binary_op_util.ts", "../../../../tfjs-backend-webgpu/src/unary_op_util.ts", "../../../../tfjs-backend-webgpu/src/activation_util.ts", "../../../../tfjs-backend-webgpu/src/matmul_packed_webgpu.ts", "../../../../tfjs-backend-webgpu/src/matmul_reduce_webgpu.ts", "../../../../tfjs-backend-webgpu/src/matmul_small_output_size_webgpu.ts", "../../../../tfjs-backend-webgpu/src/matmul_splitK_webgpu.ts", "../../../../tfjs-backend-webgpu/src/fill_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Fill.ts", "../../../../tfjs-backend-webgpu/src/kernels/Reshape.ts", "../../../../tfjs-backend-webgpu/src/kernels/BatchMatMul_impl.ts", "../../../../tfjs-backend-webgpu/src/kernels/_FusedMatMul.ts", "../../../../tfjs-backend-webgpu/src/binary_op_complex_webgpu.ts", "../../../../tfjs-backend-webgpu/src/binary_op_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Identity.ts", "../../../../tfjs-backend-webgpu/src/kernels/Complex.ts", "../../../../tfjs-backend-webgpu/src/unary_op_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernel_utils/kernel_funcs_utils.ts", "../../../../tfjs-backend-webgpu/src/kernel_utils/shared.ts", "../../../../tfjs-backend-webgpu/src/kernels/Abs.ts", "../../../../tfjs-backend-webgpu/src/kernels/Acos.ts", "../../../../tfjs-backend-webgpu/src/kernels/Acosh.ts", "../../../../tfjs-backend-webgpu/src/kernels/Add.ts", "../../../../tfjs-backend-webgpu/src/addn_packed_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/AddN.ts", "../../../../tfjs-backend-webgpu/src/transpose_shared_webgpu.ts", "../../../../tfjs-backend-webgpu/src/transpose_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Transpose.ts", "../../../../tfjs-backend-webgpu/src/reduce_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernel_utils/reduce.ts", "../../../../tfjs-backend-webgpu/src/kernels/All.ts", "../../../../tfjs-backend-webgpu/src/kernels/Any.ts", "../../../../tfjs-backend-webgpu/src/argminmax_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/ArgMax.ts", "../../../../tfjs-backend-webgpu/src/kernels/ArgMin.ts", "../../../../tfjs-backend-webgpu/src/kernels/Asin.ts", "../../../../tfjs-backend-webgpu/src/kernels/Asinh.ts", "../../../../tfjs-backend-webgpu/src/kernels/Atan.ts", "../../../../tfjs-backend-webgpu/src/kernels/Atan2.ts", "../../../../tfjs-backend-webgpu/src/kernels/Atanh.ts", "../../../../tfjs-backend-webgpu/src/pool_filtersizeone_webgpu.ts", "../../../../tfjs-backend-webgpu/src/pool_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Max.ts", "../../../../tfjs-backend-webgpu/src/kernels/Mean.ts", "../../../../tfjs-backend-webgpu/src/kernels/Pool_impl.ts", "../../../../tfjs-backend-webgpu/src/kernels/AvgPool.ts", "../../../../tfjs-backend-webgpu/src/kernels/AvgPool3D.ts", "../../../../tfjs-backend-webgpu/src/avg_pool_backprop_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/AvgPool3DGrad.ts", "../../../../tfjs-backend-webgpu/src/kernels/AvgPoolGrad.ts", "../../../../tfjs-backend-webgpu/src/kernels/BatchMatMul.ts", "../../../../tfjs-backend-webgpu/src/slice_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Slice.ts", "../../../../tfjs-backend-webgpu/src/kernels/BatchToSpaceND.ts", "../../../../tfjs-backend-webgpu/src/bincount_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Bincount.ts", "../../../../tfjs-backend-webgpu/src/broadcast_args_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/BroadcastArgs.ts", "../../../../tfjs-backend-webgpu/src/kernels/NotEqual.ts", "../../../../tfjs-backend-webgpu/src/kernels/Real.ts", "../../../../tfjs-backend-webgpu/src/kernel_utils/int.ts", "../../../../tfjs-backend-webgpu/src/kernels/Cast.ts", "../../../../tfjs-backend-webgpu/src/kernels/Ceil.ts", "../../../../tfjs-backend-webgpu/src/clip_vec4_webgpu.ts", "../../../../tfjs-backend-webgpu/src/clip_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/ClipByValue.ts", "../../../../tfjs-backend-webgpu/src/complex_abs_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/ComplexAbs.ts", "../../../../tfjs-backend-webgpu/src/concat_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Imag.ts", "../../../../tfjs-backend-webgpu/src/kernels/Concat_impl.ts", "../../../../tfjs-backend-webgpu/src/kernels/Concat.ts", "../../../../tfjs-backend-webgpu/src/conv2d_mm_webgpu.ts", "../../../../tfjs-backend-webgpu/src/conv2d_naive_webgpu.ts", "../../../../tfjs-backend-webgpu/src/im2col_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Conv2D_impl.ts", "../../../../tfjs-backend-webgpu/src/kernels/Conv2D.ts", "../../../../tfjs-backend-webgpu/src/conv_backprop_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Conv2DBackpropFilter.ts", "../../../../tfjs-backend-webgpu/src/conv_backprop_mm_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Conv2DBackpropInput.ts", "../../../../tfjs-backend-webgpu/src/conv3d_naive_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Conv3D.ts", "../../../../tfjs-backend-webgpu/src/kernels/Conv3DBackpropFilterV2.ts", "../../../../tfjs-backend-webgpu/src/kernels/Conv3DBackpropInputV2.ts", "../../../../tfjs-backend-webgpu/src/kernels/Cos.ts", "../../../../tfjs-backend-webgpu/src/kernels/Cosh.ts", "../../../../tfjs-backend-webgpu/src/crop_and_resize_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/CropAndResize.ts", "../../../../tfjs-backend-webgpu/src/cum_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Cum_impl.ts", "../../../../tfjs-backend-webgpu/src/kernels/Cumprod.ts", "../../../../tfjs-backend-webgpu/src/kernels/Cumsum.ts", "../../../../tfjs-backend-webgpu/src/kernels/DenseBincount.ts", "../../../../tfjs-backend-webgpu/src/depth_to_space_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/DepthToSpace.ts", "../../../../tfjs-backend-webgpu/src/depthwise_conv2d_nchw_shared_webgpu.ts", "../../../../tfjs-backend-webgpu/src/depthwise_conv2d_vec4_webgpu.ts", "../../../../tfjs-backend-webgpu/src/depthwise_conv2d_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/DepthwiseConv2dNative.ts", "../../../../tfjs-backend-webgpu/src/conv_backprop_depthwise_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/DepthwiseConv2dNativeBackpropFilter.ts", "../../../../tfjs-backend-webgpu/src/kernels/DepthwiseConv2dNativeBackpropInput.ts", "../../../../tfjs-backend-webgpu/src/diag_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Diag.ts", "../../../../tfjs-backend-webgpu/src/dilation_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Dilation2D.ts", "../../../../tfjs-backend-webgpu/src/dilation_backprop_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Dilation2DBackpropFilter.ts", "../../../../tfjs-backend-webgpu/src/kernels/Dilation2DBackpropInput.ts", "../../../../tfjs-backend-webgpu/src/draw_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Draw.ts", "../../../../tfjs-backend-webgpu/src/kernels/Multiply.ts", "../../../../tfjs-backend-webgpu/src/kernels/Sum.ts", "../../../../tfjs-backend-webgpu/src/kernels/Einsum.ts", "../../../../tfjs-backend-webgpu/src/kernels/Elu.ts", "../../../../tfjs-backend-webgpu/src/kernels/EluGrad.ts", "../../../../tfjs-backend-webgpu/src/kernels/Equal.ts", "../../../../tfjs-backend-webgpu/src/kernels/Erf.ts", "../../../../tfjs-backend-webgpu/src/kernels/Exp.ts", "../../../../tfjs-backend-webgpu/src/kernels/ExpandDims.ts", "../../../../tfjs-backend-webgpu/src/kernels/Expm1.ts", "../../../../tfjs-backend-webgpu/src/fft_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/FFT_impl.ts", "../../../../tfjs-backend-webgpu/src/kernels/FFT.ts", "../../../../tfjs-backend-webgpu/src/flip_left_right_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/FlipLeftRight.ts", "../../../../tfjs-backend-webgpu/src/kernels/Floor.ts", "../../../../tfjs-backend-webgpu/src/kernels/FloorDiv.ts", "../../../../tfjs-backend-webgpu/src/from_pixels_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/FromPixels.ts", "../../../../tfjs-backend-webgpu/src/batchnorm_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/FusedBatchNorm.ts", "../../../../tfjs-backend-webgpu/src/kernels/FusedConv2D.ts", "../../../../tfjs-backend-webgpu/src/kernels/FusedDepthwiseConv2D.ts", "../../../../tfjs-backend-webgpu/src/gather_nd_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/GatherNd.ts", "../../../../tfjs-backend-webgpu/src/gather_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/GatherV2.ts", "../../../../tfjs-backend-webgpu/src/kernels/Greater.ts", "../../../../tfjs-backend-webgpu/src/kernels/GreaterEqual.ts", "../../../../tfjs-backend-webgpu/src/kernels/IFFT.ts", "../../../../tfjs-backend-webgpu/src/kernels/IsFinite.ts", "../../../../tfjs-backend-webgpu/src/kernels/IsInf.ts", "../../../../tfjs-backend-webgpu/src/kernels/IsNaN.ts", "../../../../tfjs-backend-webgpu/src/kernels/LeakyRelu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Less.ts", "../../../../tfjs-backend-webgpu/src/kernels/LessEqual.ts", "../../../../tfjs-backend-webgpu/src/lin_space_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/LinSpace.ts", "../../../../tfjs-backend-webgpu/src/kernels/Log.ts", "../../../../tfjs-backend-webgpu/src/kernels/Log1p.ts", "../../../../tfjs-backend-webgpu/src/kernels/LogicalAnd.ts", "../../../../tfjs-backend-webgpu/src/kernels/LogicalNot.ts", "../../../../tfjs-backend-webgpu/src/kernels/LogicalOr.ts", "../../../../tfjs-backend-webgpu/src/lrn_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/LRN.ts", "../../../../tfjs-backend-webgpu/src/lrn_grad_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/LRNGrad.ts", "../../../../tfjs-backend-webgpu/src/kernels/Maximum.ts", "../../../../tfjs-backend-webgpu/src/kernels/MaxPool.ts", "../../../../tfjs-backend-webgpu/src/kernels/MaxPool3D.ts", "../../../../tfjs-backend-webgpu/src/max_pool_backprop_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/MaxPool3DGrad.ts", "../../../../tfjs-backend-webgpu/src/kernels/MaxPoolGrad.ts", "../../../../tfjs-backend-webgpu/src/kernels/MaxPoolWithArgmax.ts", "../../../../tfjs-backend-webgpu/src/kernels/Min.ts", "../../../../tfjs-backend-webgpu/src/kernels/Minimum.ts", "../../../../tfjs-backend-webgpu/src/mirror_pad_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/MirrorPad.ts", "../../../../tfjs-backend-webgpu/src/kernels/Mod.ts", "../../../../tfjs-backend-webgpu/src/multinomial_webgpu.ts", "../../../../tfjs-backend-webgpu/src/softmax_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Softmax.ts", "../../../../tfjs-backend-webgpu/src/kernels/Multinomial.ts", "../../../../tfjs-backend-webgpu/src/kernels/Neg.ts", "../../../../tfjs-backend-webgpu/src/kernels/NonMaxSuppressionV3.ts", "../../../../tfjs-backend-webgpu/src/kernels/NonMaxSuppressionV5.ts", "../../../../tfjs-backend-webgpu/src/onehot_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/OneHot.ts", "../../../../tfjs-backend-webgpu/src/kernels/ZerosLike.ts", "../../../../tfjs-backend-webgpu/src/kernels/OnesLike.ts", "../../../../tfjs-backend-webgpu/src/kernels/Pack.ts", "../../../../tfjs-backend-webgpu/src/pad_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/PadV2.ts", "../../../../tfjs-backend-webgpu/src/kernels/Pow.ts", "../../../../tfjs-backend-webgpu/src/kernels/Prelu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Prod.ts", "../../../../tfjs-backend-webgpu/src/kernels/Range.ts", "../../../../tfjs-backend-webgpu/src/kernels/RealDiv.ts", "../../../../tfjs-backend-webgpu/src/kernels/Reciprocal.ts", "../../../../tfjs-backend-webgpu/src/kernels/Relu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Relu6.ts", "../../../../tfjs-backend-webgpu/src/resize_bilinear_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/ResizeBilinear.ts", "../../../../tfjs-backend-webgpu/src/resize_bilinear_backprop_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/ResizeBilinearGrad.ts", "../../../../tfjs-backend-webgpu/src/resize_nearest_neighbor_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/ResizeNearestNeighbor.ts", "../../../../tfjs-backend-webgpu/src/resize_nearest_neighbor_backprop_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/ResizeNearestNeighborGrad.ts", "../../../../tfjs-backend-webgpu/src/reverse_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Reverse.ts", "../../../../tfjs-backend-webgpu/src/rotate_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/RotateWithOffset.ts", "../../../../tfjs-backend-webgpu/src/kernels/Round.ts", "../../../../tfjs-backend-webgpu/src/kernels/Rsqrt.ts", "../../../../tfjs-backend-webgpu/src/scatter_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/ScatterNd.ts", "../../../../tfjs-backend-webgpu/src/search_sorted_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/SearchSorted.ts", "../../../../tfjs-backend-webgpu/src/select_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Select.ts", "../../../../tfjs-backend-webgpu/src/kernels/Selu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Sigmoid.ts", "../../../../tfjs-backend-webgpu/src/kernels/Sign.ts", "../../../../tfjs-backend-webgpu/src/kernels/Sin.ts", "../../../../tfjs-backend-webgpu/src/kernels/Sinh.ts", "../../../../tfjs-backend-webgpu/src/kernels/Softplus.ts", "../../../../tfjs-backend-webgpu/src/space_to_batchND_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/SpaceToBatchND.ts", "../../../../tfjs-backend-webgpu/src/sparse_segment_reduce_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernel_utils/sparse_segment_reduce.ts", "../../../../tfjs-backend-webgpu/src/kernels/SparseSegmentMean.ts", "../../../../tfjs-backend-webgpu/src/kernels/SparseSegmentSum.ts", "../../../../tfjs-backend-webgpu/src/tile_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Tile.ts", "../../../../tfjs-backend-webgpu/src/kernels/SparseToDense.ts", "../../../../tfjs-backend-webgpu/src/kernels/SplitV.ts", "../../../../tfjs-backend-webgpu/src/kernels/Sqrt.ts", "../../../../tfjs-backend-webgpu/src/kernels/Square.ts", "../../../../tfjs-backend-webgpu/src/kernels/SquaredDifference.ts", "../../../../tfjs-backend-webgpu/src/kernels/Step.ts", "../../../../tfjs-backend-webgpu/src/strided_slice_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/StridedSlice.ts", "../../../../tfjs-backend-webgpu/src/kernels/StringNGrams.ts", "../../../../tfjs-backend-webgpu/src/kernels/Sub.ts", "../../../../tfjs-backend-webgpu/src/kernels/Tan.ts", "../../../../tfjs-backend-webgpu/src/kernels/Tanh.ts", "../../../../tfjs-backend-webgpu/src/kernels/TensorScatterUpdate.ts", "../../../../tfjs-backend-webgpu/src/top_k_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/TopK.ts", "../../../../tfjs-backend-webgpu/src/transform_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/Transform.ts", "../../../../tfjs-backend-webgpu/src/kernels/Unpack.ts", "../../../../tfjs-backend-webgpu/src/unsorted_segment_sum_webgpu.ts", "../../../../tfjs-backend-webgpu/src/kernels/UnsortedSegmentSum.ts", "../../../../tfjs-backend-webgpu/src/register_all_kernels.ts"],
  "sourcesContent": ["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from '@tensorflow/tfjs-core';\n\nconst ENV = env();\n\n/** The batched dispatching calls size in the device queue. */\nENV.registerFlag('WEBGPU_DEFERRED_SUBMIT_BATCH_SIZE', () => 15);\n\n/**\n * Whether we forward execution to the CPU backend if tensors are small and\n * reside on the CPU.\n */\nENV.registerFlag('WEBGPU_CPU_FORWARD', () => true);\n\n/**\n * This flag is used to test different types of matmul programs.\n *\n * See MatMulProgramType in webgpu_util.ts for a list of available values.\n */\nENV.registerFlag('WEBGPU_MATMUL_PROGRAM_TYPE', () => -1);\n\n/**\n * Whether to use conv2dTranspose_naive which directly implement the\n * conv2dTranspose logic rather than using a matmul to simulate.\n */\nENV.registerFlag('WEBGPU_USE_NAIVE_CONV2D_TRANSPOSE', () => true);\n\n/**\n * Whether we use low power GPU. Otherwise, a high performance GPU will be\n * requested.\n */\nENV.registerFlag('WEBGPU_USE_LOW_POWER_GPU', () => false);\n\n/**\n * Threshold for input tensor size that determines whether WebGPU backend will\n * delegate computation to CPU.\n *\n * Default value is 1000.\n */\nENV.registerFlag('WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD', () => 1000);\n\n/**\n * Whether to use a dummy canvas to make profiling tools like PIX work with\n * TFJS webgpu backend.\n */\nENV.registerFlag('WEBGPU_USE_PROFILE_TOOL', () => false);\n\n/**\n * Whether to use import API.\n */\nENV.registerFlag('WEBGPU_IMPORT_EXTERNAL_TEXTURE', () => true);\n\n/**\n * Whether to use conv2dNaive for debugging.\n */\nENV.registerFlag('WEBGPU_USE_NAIVE_CONV2D_DEBUG', () => false);\n\n/**\n * Threshold to increase dispatched workgroups for matmul. If too few workgroups\n * are dispatched, it means the hardware may be in low occupancy.\n * -1 means it's not set by the user. A default strategy will be applied.\n */\nENV.registerFlag(\n    'WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL', () => -1);\n\n/**\n * Whether we will run im2col as a separate shader for convolution.\n */\nENV.registerFlag('WEBGPU_CONV_SEPARATE_IM2COL_SHADER', () => false);\n\n/**\n * A string used to match shader key. If any matches, print the related shader.\n * Seperated by comma. 'all' to print all. 'binary' to print binary(add, mul,\n * etc.). 'unary,conv2d' to print both unary and conv2d.\n */\nENV.registerFlag('WEBGPU_PRINT_SHADER', () => '');\n\n/** Experimental flag, whether enter compile only phase. */\nENV.registerFlag('WEBGPU_ENGINE_COMPILE_ONLY', () => false);\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport class AdapterInfo {\n  private vendor: string;\n  private architecture: string;\n  public intelGPUGeneration: number;\n\n  constructor(adapterInfo: GPUAdapterInfo) {\n    if (adapterInfo) {\n      this.vendor = adapterInfo.vendor;\n      this.architecture = adapterInfo.architecture;\n      this.intelGPUGeneration = this.getIntelGPUGeneration();\n    }\n  }\n\n  private getIntelGPUGeneration() {\n    if (this.isIntel()) {\n      if (this.architecture.startsWith('gen')) {\n        return Number(this.architecture.match(/\\d+/));\n      } else if (this.architecture.startsWith('xe')) {\n        return 12;\n      }\n    }\n    return 0;\n  }\n\n  isIntel(): boolean {\n    return this.vendor === 'intel';\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport class BufferManager {\n  private numUsedBuffers = 0;\n  private numFreeBuffers = 0;\n  private freeBuffers: Map<string, GPUBuffer[]> = new Map();\n  private usedBuffers: Map<string, GPUBuffer[]> = new Map();\n\n  public numBytesUsed = 0;\n  public numBytesAllocated = 0;\n\n  constructor(private device: GPUDevice) {}\n\n  acquireBuffer(\n      size: number, usage: GPUBufferUsageFlags, mappedAtCreation = false,\n      reuse = true) {\n    let buffer;\n    const key = getBufferKey(size, usage);\n\n    if (reuse) {\n      if (!this.freeBuffers.has(key)) {\n        this.freeBuffers.set(key, []);\n      }\n\n      if (this.freeBuffers.get(key).length > 0) {\n        buffer = this.freeBuffers.get(key).pop();\n        this.numFreeBuffers--;\n      } else {\n        buffer = this.device.createBuffer({size, usage, mappedAtCreation});\n        this.numBytesAllocated += size;\n      }\n    } else {\n      buffer = this.device.createBuffer({size, usage, mappedAtCreation});\n      this.numBytesAllocated += size;\n    }\n\n    if (!this.usedBuffers.has(key)) {\n      this.usedBuffers.set(key, []);\n    }\n    this.usedBuffers.get(key).push(buffer);\n    this.numUsedBuffers++;\n    this.numBytesUsed += size;\n\n    return buffer;\n  }\n\n  releaseBuffer(buffer: GPUBuffer, reuse = true) {\n    if (this.freeBuffers.size === 0) {\n      return;\n    }\n\n    const size = buffer.size;\n    const usage = buffer.usage;\n\n    const key = getBufferKey(size, usage);\n    const bufferArray = this.usedBuffers.get(key);\n    const index = bufferArray.indexOf(buffer);\n    if (index < 0) {\n      throw new Error('Cannot find the buffer in buffer manager');\n    }\n    bufferArray[index] = bufferArray[bufferArray.length - 1];\n    bufferArray.pop();\n    this.numUsedBuffers--;\n    this.numBytesUsed -= size;\n\n    if (reuse) {\n      this.freeBuffers.get(key).push(buffer);\n      this.numFreeBuffers++;\n    } else {\n      buffer.destroy();\n      this.numBytesAllocated -= size;\n    }\n  }\n\n  getNumUsedBuffers(): number {\n    return this.numUsedBuffers;\n  }\n\n  getNumFreeBuffers(): number {\n    return this.numFreeBuffers;\n  }\n\n  dispose() {\n    this.freeBuffers.forEach((buffers, key) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.usedBuffers.forEach((buffers, key) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.freeBuffers = new Map();\n    this.usedBuffers = new Map();\n    this.numUsedBuffers = 0;\n    this.numFreeBuffers = 0;\n    this.numBytesUsed = 0;\n    this.numBytesAllocated = 0;\n  }\n}\n\nfunction getBufferKey(size: number, usage: GPUBufferUsageFlags) {\n  return `${size}_${usage}`;\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport class TextureManager {\n  private numUsedTextures = 0;\n  private numFreeTextures = 0;\n  private freeTextures: Map<string, GPUTexture[]> = new Map();\n  private usedTextures: Map<string, GPUTexture[]> = new Map();\n\n  public numBytesUsed = 0;\n  public numBytesAllocated = 0;\n\n  constructor(private device: GPUDevice) {}\n\n  acquireTexture(\n      width: number, height: number, format: GPUTextureFormat,\n      usage: GPUTextureUsageFlags) {\n    const bytesPerElement = getBytesPerElement(format);\n    const byteSize = width * height * bytesPerElement;\n    const key = getTextureKey(width, height, format, usage);\n    if (!this.freeTextures.has(key)) {\n      this.freeTextures.set(key, []);\n    }\n\n    if (!this.usedTextures.has(key)) {\n      this.usedTextures.set(key, []);\n    }\n\n    this.numBytesUsed += byteSize;\n    this.numUsedTextures++;\n\n    if (this.freeTextures.get(key).length > 0) {\n      this.numFreeTextures--;\n\n      const newTexture = this.freeTextures.get(key).shift();\n      this.usedTextures.get(key).push(newTexture);\n      return newTexture;\n    }\n\n    this.numBytesAllocated += byteSize;\n\n    const newTexture = this.device.createTexture({\n      size: [width, height],\n      format,\n      usage,\n    });\n    this.usedTextures.get(key).push(newTexture);\n\n    return newTexture;\n  }\n\n  releaseTexture(texture: GPUTexture) {\n    if (this.freeTextures.size === 0) {\n      return;\n    }\n\n    const width = texture.width;\n    const height = texture.height;\n    const format = texture.format;\n    const usage = texture.usage;\n\n    const key = getTextureKey(width, height, format, usage);\n    if (!this.freeTextures.has(key)) {\n      this.freeTextures.set(key, []);\n    }\n\n    this.freeTextures.get(key).push(texture);\n    this.numFreeTextures++;\n    this.numUsedTextures--;\n\n    const textureList = this.usedTextures.get(key);\n    const textureIndex = textureList.indexOf(texture);\n    if (textureIndex < 0) {\n      throw new Error(\n          'Cannot release a texture that was never provided by this ' +\n          'texture manager');\n    }\n    textureList.splice(textureIndex, 1);\n    const bytesPerElement = getBytesPerElement(format);\n    const byteSize = width * height * bytesPerElement;\n    this.numBytesUsed -= byteSize;\n  }\n\n  getNumUsedTextures(): number {\n    return this.numUsedTextures;\n  }\n\n  getNumFreeTextures(): number {\n    return this.numFreeTextures;\n  }\n\n  dispose() {\n    this.freeTextures.forEach((textures, key) => {\n      textures.forEach(texture => {\n        texture.destroy();\n      });\n    });\n\n    this.usedTextures.forEach((textures, key) => {\n      textures.forEach(texture => {\n        texture.destroy();\n      });\n    });\n\n    this.freeTextures = new Map();\n    this.usedTextures = new Map();\n    this.numUsedTextures = 0;\n    this.numFreeTextures = 0;\n    this.numBytesUsed = 0;\n    this.numBytesAllocated = 0;\n  }\n}\n\nfunction getTextureKey(\n    width: number, height: number, format: GPUTextureFormat,\n    usage: GPUTextureUsageFlags) {\n  return `${width}_${height}_${format}_${usage}`;\n}\n\nfunction getBytesPerElement(format: GPUTextureFormat) {\n  if (format === 'rgba8unorm') {\n    return 16;\n  } else {\n    throw new Error(`${format} is not supported!`);\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Generates WGSL that computes strides.\nexport function symbolicallyComputeStrides(\n    indicesArr: number[], variableName: string): string[] {\n  if (Math.max(...indicesArr) > 5) {\n    throw new Error('Cannot symbolically compute strides for rank > 6 tensor.');\n  }\n\n  const numCoords = indicesArr.length;\n  const indicesStr = 'xyzwuv';\n  const shape = indicesArr.map(d => `${variableName}.${indicesStr[d]}`);\n  const strides = new Array(numCoords - 1);\n  strides[numCoords - 2] = shape[numCoords - 1];\n  for (let i = numCoords - 3; i >= 0; --i) {\n    strides[i] = `(${strides[i + 1]} * ${shape[i + 1]})`;\n  }\n\n  return strides;\n}\n\nexport const atomicAddSnippet =\n    (ptr: string, v: string, type: 'int32'|'float32') => {\n      if (type === 'int32') {\n        return `atomicAdd(${ptr}, bitcast<i32>(${v}));`;\n      } else {\n        // atomicAdd only supports uint/int type. For float, we use\n        // atomicCompareExchangeWeak to simulate.\n        return `\n          {\n            var oldValue = 0;\n            loop {\n              let newValueF32 = bitcast<f32>(oldValue) + (${v});\n              let newValue = bitcast<i32>(newValueF32);\n              let res = atomicCompareExchangeWeak(${ptr}, oldValue, newValue);\n              if res.exchanged {\n                break;\n              }\n              oldValue = res.old_value;\n            }\n          }`;\n      }\n    };\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, DataTypeMap, env, Rank, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {symbolicallyComputeStrides} from './shader_util';\n\nexport enum PixelsOpType {\n  FROM_PIXELS,\n  DRAW\n}\n\nexport interface WebGPUProgram {\n  // Whether to use atomic built-in functions.\n  atomic?: boolean;\n  // dispatch specifies geometry of thread groups - derived from dispatchLayout.\n  dispatch: [number, number, number];\n  // dispatchLayout enumerates how tensor dimensions are distributed among\n  // dispatch x,y,z dimensions.\n  dispatchLayout: {x: number[], y?: number[], z?: number[]};\n  // By default, the output data component is 1.\n  outputComponent?: number;\n  outputShape: number[];\n  pixelsOpType?: PixelsOpType;\n  // The unique key to distinguish different shader source code.\n  shaderKey: string;\n  // Whether to use output size for bounds checking.\n  size?: boolean;\n  uniforms?: string;\n  variableNames: string[];\n  // Describe each variable's component and must have one-one mapping with\n  // variableNames. If not set, all variables component will be same with output\n  // component member.\n  variableComponents?: number[];\n  // workgroupSize.x * workgroupSize.y * workgroupSize.z = the number of threads\n  // in a thread group. Individual dimensions determines thread layout within\n  // the group.\n  workgroupSize: [number, number, number];\n  // Size of register cache in one dimension (assumes square cache).\n  // Each thread writes to workPerThread * workPerThread locations in the output\n  // buffer.\n  workPerThread?: number;\n  pipeline?: GPUComputePipeline|Promise<GPUComputePipeline>;\n  getUserCode: () => string;\n}\n\nexport const compileProgram =\n    (device: GPUDevice, program: WebGPUProgram, inputsData: InputInfo[],\n     output: TensorInfo, parallelCompilation: boolean): GPUComputePipeline|\n    Promise<GPUComputePipeline> => {\n      const outputData = {dtype: output.dtype, shape: output.shape};\n      const source = makeShader(inputsData, outputData, program);\n      const module = device.createShaderModule(\n          {code: source, label: program.constructor.name});\n\n      let printShaderString = env().get('WEBGPU_PRINT_SHADER') as string;\n      if (printShaderString !== '') {\n        printShaderString = printShaderString.toLowerCase();\n        const printShaderArray = printShaderString.split(',');\n        if (printShaderString === 'all' ||\n            printShaderArray.some(\n                item => program.shaderKey.toLowerCase().includes(item))) {\n          console.group(program.shaderKey);\n          console.debug(source);\n          console.groupEnd();\n        }\n      }\n\n      if (parallelCompilation) {\n        return device.createComputePipelineAsync({\n          compute: {module, entryPoint: '_start'},\n          label: program.constructor.name,\n          layout: 'auto'\n        });\n      } else {\n        return device.createComputePipeline({\n          compute: {module, entryPoint: '_start'},\n          label: program.constructor.name,\n          layout: 'auto'\n        });\n      }\n    };\n\nexport const typeSnippet = (component: number, type = 'f32') => {\n  switch (component) {\n    case 1:\n      return `${type}`;\n    case 2:\n      return `vec2<${type}>`;\n    case 3:\n      return `vec3<${type}>`;\n    case 4:\n      return `vec4<${type}>`;\n    default:\n      throw new Error(`${component}-component ${type} is not supported.`);\n  }\n};\n\nexport function getCoordsDataType(rank: number): string {\n  if (rank <= 1) {\n    return 'i32';\n  } else if (rank === 2) {\n    return `vec2<i32>`;\n  } else if (rank === 3) {\n    return `vec3<i32>`;\n  } else if (rank === 4) {\n    return `vec4<i32>`;\n  } else if (rank === 5) {\n    return `vec5`;\n  } else if (rank === 6) {\n    return `vec6`;\n  } else {\n    throw Error(`GPU for rank ${rank} is not yet supported`);\n  }\n}\n\nexport function getCoordsXYZ(index: number): string {\n  if (index === 0) {\n    return 'x';\n  } else if (index === 1) {\n    return 'y';\n  } else if (index === 2) {\n    return 'z';\n  } else if (index === 3) {\n    return 'w';\n  } else if (index === 4) {\n    return 'u';\n  } else if (index === 5) {\n    return 'v';\n  } else {\n    throw Error(`Index ${index} is not yet supported`);\n  }\n}\n\nexport function getMainHeaderString(): string;\nexport function getMainHeaderString(index: string): string;\nexport function getMainHeaderString(...params: string[]): string {\n  let snippet: string;\n  switch (params.length) {\n    case 0:\n      snippet = `\n        fn main()\n      `;\n      break;\n    case 1:\n      snippet = `\n        fn main(${params[0]} : i32)\n      `;\n      break;\n    default:\n      throw Error('Unreachable');\n  }\n  return snippet;\n}\n\nexport function getStartHeaderString(\n    useGlobalIndex: boolean, program: WebGPUProgram): string {\n  let snippet: string;\n  snippet = `\n     ${getWorkgroupSizeString(program)}\n      fn _start(@builtin(local_invocation_id) LocalId : vec3<u32>,\n                @builtin(global_invocation_id) GlobalId : vec3<u32>,\n                @builtin(local_invocation_index) LocalIndex: u32,\n                @builtin(workgroup_id) WorkgroupId : vec3<u32>,\n                @builtin(num_workgroups) NumWorkgroups : vec3<u32>) {\n        localId = LocalId;\n        localIndex = LocalIndex;\n        globalId = GlobalId;\n        numWorkgroups = NumWorkgroups;\n        workgroupId = WorkgroupId;\n        ${useGlobalIndex ? `main(getGlobalIndex());` : `main();`};\n      }\n    `;\n  return snippet;\n}\n\nexport function getWorkgroupSizeString(program: WebGPUProgram): string {\n  return `\n  @compute @workgroup_size(${program.workgroupSize[0]}, ${\n      program.workgroupSize[1]}, ${program.workgroupSize[2]})\n`;\n}\n\nfunction makeShader(\n    inputInfo: InputInfo[], outputData: {dtype: DataType, shape: number[]},\n    program: WebGPUProgram): string {\n  const prefixSnippets: string[] = [];\n  const flatWorkgroupSize = program.workgroupSize[0] *\n      program.workgroupSize[1] * program.workgroupSize[2];\n  program.outputComponent =\n      program.outputComponent ? program.outputComponent : 1;\n  prefixSnippets.push(`\n\n      var<private> localId: vec3<u32>;\n      var<private> localIndex: u32;\n      var<private> globalId: vec3<u32>;\n      var<private> numWorkgroups: vec3<u32>;\n      var<private> workgroupId: vec3<u32>;\n\n      // Only used when the y/z dimension of workgroup size is 1.\n      fn getGlobalIndex() -> i32 {\n        ${\n      isFlatDispatch(program) ?\n          `  return i32(globalId.x);` :\n          `  return i32((workgroupId.z * numWorkgroups.x * numWorkgroups.y +\n                workgroupId.y * numWorkgroups.x + workgroupId.x) * ${\n              flatWorkgroupSize}u +\n                localIndex);\n        `}\n      }\n    `);\n\n  if (program.pixelsOpType != null) {\n    const inoutSnippet = program.pixelsOpType === PixelsOpType.FROM_PIXELS ?\n        `@group(0) @binding(0) var<storage, read_write> result: array<${\n            dataTypeToGPUType(outputData.dtype, program.outputComponent)}>;` :\n        `@group(0) @binding(1) var<storage, read> inBuf : array<${\n            dataTypeToGPUType(inputInfo[0].dtype, program.outputComponent)}>;`;\n    const outShapeStridesType =\n        outputData.shape.length === 3 ? 'vec2<i32>' : 'i32';\n    prefixSnippets.push(`\n        struct Uniform {\n          outShapeStrides : ${outShapeStridesType},\n          size            : i32,\n          numChannels     : i32,\n          alpha           : f32,\n        };\n\n        ${inoutSnippet}\n        @group(0) @binding(2) var<uniform> uniforms: Uniform;\n      `);\n    const useGlobalIndex = isFlatDispatchLayout(program);\n    return [\n      commonSnippet,\n      prefixSnippets.join('\\n'),\n      getCoordsFromIndexSnippet(outputData.shape),\n      program.getUserCode(),\n      getStartHeaderString(useGlobalIndex, program),\n    ].join('\\n');\n  }\n\n  let stridesLength: number;\n  let stridesDataType: string;\n  let uniformDeclaration = 'struct Uniforms { NAN : f32, INFINITY : f32, ';\n  program.variableNames.forEach((x, i) => {\n    const perDataType = getCoordsDataType(inputInfo[i].shape.length);\n    uniformDeclaration +=\n        `${x.charAt(0).toLowerCase() + x.slice(1)}Shape : ${perDataType}, `;\n    stridesLength = inputInfo[i].shape.length - 1;\n    stridesDataType = getCoordsDataType(stridesLength);\n    uniformDeclaration +=\n        `${x.charAt(0).toLowerCase() + x.slice(1)}ShapeStrides: ${\n            stridesDataType}, `;\n  });\n  const outputDataType = getCoordsDataType(outputData.shape.length);\n  uniformDeclaration += `outShape : ${outputDataType}, `;\n  stridesLength = outputData.shape.length - 1;\n  stridesDataType = getCoordsDataType(stridesLength);\n  uniformDeclaration += `\n         outShapeStrides: ${stridesDataType}, `;\n\n  if (program.size) {\n    uniformDeclaration += 'size : i32, ';\n  }\n\n  if (program.uniforms) {\n    uniformDeclaration += program.uniforms;\n  }\n  uniformDeclaration += '};';\n  uniformDeclaration = insertAlignment(uniformDeclaration);\n\n  prefixSnippets.push(uniformDeclaration);\n\n  // Output buffer.\n  if (program.atomic) {\n    prefixSnippets.push(`\n      @group(0) @binding(0) var<storage, read_write> result: array<atomic<i32>>;\n    `);\n  } else {\n    prefixSnippets.push(`\n      @group(0) @binding(0) var<storage, read_write> result: array<${\n        dataTypeToGPUType(outputData.dtype, program.outputComponent)}>;\n    `);\n  }\n  program.variableNames.forEach((x, i) => {\n    prefixSnippets.push(`\n      @group(0) @binding(${1 + i}) var<storage, read> ${x}: array<${\n        program.variableComponents ?\n            dataTypeToGPUType(\n                inputInfo[i].dtype, program.variableComponents[i]) :\n            dataTypeToGPUType(inputInfo[i].dtype, program.outputComponent)}>;\n        `);\n  });\n\n  if (uniformDeclaration !== '') {\n    prefixSnippets.push(`\n      @group(0) @binding(${\n        1 + program.variableNames.length}) var<uniform> uniforms: Uniforms;\n      `);\n  }\n\n  const coordsSnippet =\n      getOutputCoordsSnippet(outputData.shape, program.dispatchLayout);\n\n  const sources = [\n    commonSnippet, prefixSnippets.join('\\n') + isInfSnippet,\n    getCoordsFromIndexSnippet(outputData.shape), coordsSnippet,\n    getOutputIndexFromCoordsSnippet(outputData.shape.length)\n  ];\n  if (!program.atomic) {\n    sources.push(setOutputSnippet(\n        outputData.shape, outputData.dtype, program.outputComponent));\n  }\n\n  program.variableNames.forEach((x, i) => {\n    sources.push(`${getCoordsFromIndexSnippet(inputInfo[i].shape, x)}`);\n  });\n\n  const inputSnippet =\n      inputInfo\n          .map(\n              (x, i) => getInputSnippet(\n                  x, outputData.shape,\n                  program.variableComponents ? program.variableComponents[i] :\n                                               program.outputComponent,\n                  program.dispatchLayout.x.length === outputData.shape.length))\n          .join('\\n');\n  sources.push(inputSnippet);\n  sources.push(program.getUserCode());\n  const useGlobalIndex = isFlatDispatchLayout(program);\n  sources.push(getStartHeaderString(useGlobalIndex, program));\n  const source = sources.join('\\n');\n  return source;\n}\n\nexport function makeShaderKey<R extends Rank>(\n    program: WebGPUProgram, inputsData: InputInfo[],\n    output: TensorInfo): string {\n  let key = program.shaderKey;\n  if (program.pixelsOpType != null) {\n    return key;\n  }\n\n  const shapes: number[][] = [];\n  const types: Array<keyof DataTypeMap> = [];\n  inputsData.forEach(element => {\n    shapes.push(element.shape);\n    types.push(element.dtype);\n  });\n  shapes.push(output.shape);\n  types.push(output.dtype);\n\n  const broadcastDims =\n      inputsData.map(d => backend_util.getBroadcastDims(d.shape, output.shape));\n  const inputShapesEqualsOutShape =\n      inputsData.map(d => util.arraysEqual(d.shape, output.shape)).join('_');\n  const broadcastDimsKey = broadcastDims.map(d => d.join('_')).join(';');\n\n  const flatDispatchString = isFlatDispatch(program) ? 'flatDispatch' : '';\n\n  key += '_' + (program.workgroupSize ? program.workgroupSize.join(',') : '') +\n      shapes.map(shape => shape.length).join(',') + types.join(',') +\n      program.variableNames.join(',') + broadcastDimsKey +\n      inputShapesEqualsOutShape + flatDispatchString;\n\n  return key;\n}\n\nconst commonSnippet = `\n  struct vec5 {x: i32, y: i32, z: i32, w: i32, u: i32};\n  struct vec6 {x: i32, y: i32, z: i32, w: i32, u: i32, v: i32};\n\n  // Checks whether coordinates lie within the bounds of the shape.\n  fn coordsInBounds2D(coord : vec2<i32>, shape : vec2<i32>) -> bool {\n    return all(coord >= vec2<i32>(0)) && all(coord < shape);\n  }\n  fn coordsInBounds3D(coord : vec3<i32>, shape : vec3<i32>) -> bool {\n    return all(coord >= vec3<i32>(0)) && all(coord < shape);\n  }\n  fn coordsInBounds4D(coord : vec4<i32>, shape : vec4<i32>) -> bool {\n    return all(coord >= vec4<i32>(0)) && all(coord < shape);\n  }\n\n  fn getIndexFromCoords1D(coord : i32, shape : i32) -> i32 {\n    return coord;\n  }\n  fn getIndexFromCoords2D(coords : vec2<i32>, shape : vec2<i32>) -> i32 {\n    return dot(coords, vec2<i32>(shape.y, 1));\n  }\n  fn getIndexFromCoords3D(coords : vec3<i32>, shape : vec3<i32>) -> i32 {\n    return dot(coords, vec3<i32>(shape.y * shape.z, shape.z, 1));\n  }\n  fn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n    return dot(coords, vec4<i32>(\n        shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n  }\n  fn getIndexFromCoords5D(coords : vec5, shape : vec5) -> i32 {\n    let shapeStrides: vec5 = vec5(shape.y * shape.z * shape.w * shape.u, shape.z * shape.w * shape.u, shape.w * shape.u, shape.u, 1);\n    return coords.x*shapeStrides.x + coords.y*shapeStrides.y + coords.z*shapeStrides.z + coords.w*shapeStrides.w + coords.u*shapeStrides.u;\n  }\n  fn getIndexFromCoords6D(coords : vec6, shape : vec6) -> i32 {\n    let shapeStrides: vec6 = vec6(shape.y * shape.z * shape.w * shape.u * shape.v, shape.z * shape.w * shape.u * shape.v, shape.w * shape.u * shape.v, shape.u * shape.v, shape.v, 1);\n    return coords.x*shapeStrides.x + coords.y*shapeStrides.y + coords.z*shapeStrides.z + coords.w*shapeStrides.w + coords.u*shapeStrides.u + coords.v*shapeStrides.v;\n  }\n\n  // NaN defination in IEEE 754-1985 is :\n  //   - sign = either 0 or 1.\n  //   - biased exponent = all 1 bits.\n  //   - fraction = anything except all 0 bits (since all 0 bits represents infinity).\n  // https://en.wikipedia.org/wiki/IEEE_754-1985#Representation_of_non-numbers\n  fn isnan(val: f32) -> bool {\n    let floatToUint: u32 = bitcast<u32>(val);\n    return (floatToUint & 0x7fffffffu) > 0x7f800000u;\n  }\n  fn isnanVec4(val : vec4<f32>) -> vec4<bool> {\n    let floatToUint: vec4<u32> = bitcast<vec4<u32>>(val);\n    return (floatToUint & vec4<u32>(0x7fffffffu)) > vec4<u32>(0x7f800000u);\n  }\n`;\n\nconst isInfSnippet = `\n  fn isinf(val: f32) -> bool {\n    return abs(val) == uniforms.INFINITY;\n  }\n`;\n\ntype InputInfo = {\n  dtype: DataType; shape: number[]; name: string;\n};\n\n/**\n * Derives logical coordinates from a flat index. Performs integer division\n * with each stride and decrements the index until the index equals the final\n * dimension coordinate.\n */\nexport function getCoordsFromIndexSnippet(shape: number[], name = ''): string {\n  const rank = shape.length;\n  const funcName = name !== '' ?\n      `get${name.charAt(0).toUpperCase() + name.slice(1)}CoordsFromIndex` :\n      'getCoordsFromIndex';\n  const stridesName = name !== '' ?\n      `${name.charAt(0).toLowerCase() + name.slice(1)}ShapeStrides` :\n      `outShapeStrides`;\n\n  if (rank <= 1) {\n    return `fn ${funcName}(index : i32) -> i32 { return index; }`;\n  }\n\n  const strides = util.computeStrides(shape);\n  const dtype = getCoordsDataType(rank);\n\n  const coords: string[] = [];\n  for (let i = 0; i < rank; i++) {\n    coords.push(`d${i}`);\n  }\n\n  if (strides.length === 1) {\n    return `    fn ${funcName}(index : i32) -> vec2<i32> {\n      let d0 = index / uniforms.${\n        stridesName}; let d1 = index - d0 * uniforms.${stridesName};\n      return vec2<i32>(d0, d1);\n    }`;\n  }\n  let snippet;\n  snippet = 'var index2 = index;' +\n      strides\n          .map((_, i) => {\n            const line1 = `let ${coords[i]} = index2 / uniforms.${\n                stridesName}.${getCoordsXYZ(i)}`;\n            const line2 = i === strides.length - 1 ?\n                `let ${coords[i + 1]} = index2 - ${coords[i]} * uniforms.${\n                    stridesName}.${getCoordsXYZ(i)}` :\n                `index2 = index2 - ${coords[i]} * uniforms.${stridesName}.${\n                    getCoordsXYZ(i)}`;\n            return `${line1}; ${line2};`;\n          })\n          .join('');\n\n  return `\n    fn ${funcName}(index : i32) -> ${dtype} {\n      ${snippet}\n      return ${dtype}(${coords.join(',')});\n    }\n  `;\n}\n\nfunction getInputAtCoordsSnippet(\n    inputInfo: InputInfo, component: number): string {\n  const texName = inputInfo.name;\n  const rank = inputInfo.shape.length;\n  const type = getCoordsDataType(rank);\n  const funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n  const dims = ['d0', 'd1', 'd2', 'd3', 'd4', 'd5'].slice(0, rank);\n  const inputs = dims.map(d => `${d} : i32`).join(', ');\n\n  if (rank < 1) {\n    return `\n      fn ${funcName}() -> ${typeSnippet(component)} {\n        return ${typeSnippet(component)}(${texName}[0]);\n      }\n    `;\n  }\n\n  const shapeStr =\n      `uniforms.${texName.charAt(0).toLowerCase() + texName.slice(1)}Shape`;\n  let rankStr = `${rank}D`;\n  if (rank === 0) {\n    rankStr = '1D';\n  }\n\n  return `\n    fn ${funcName}(${inputs}) -> ${typeSnippet(component)} {\n      return ${typeSnippet(component)}(${texName}[getIndexFromCoords${\n      rankStr}(${type}(${dims.join(',')}),\n        ${shapeStr})${component === 1 ? '' : ` / ${component}`}]);\n    }\n   `;\n}\n\nfunction getInputByOutputSnippet(\n    inputInfo: InputInfo, outShape: number[], component: number,\n    isFlatDispatchLayout: boolean): string {\n  const texName = inputInfo.name;\n  const texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);\n\n  const funcName = 'get' + texFuncSnippet + 'ByOutput';\n\n  const inRank = inputInfo.shape.length;\n  const outRank = outShape.length;\n  const type = getCoordsDataType(outRank);\n\n  // If the inShape equals the outShape and the dispatch layout is flat, we can\n  // directly use |gl_GlobalInvocationID.x| as the index and don't need coords\n  // conversion between these two shapes.\n  if (util.arraysEqual(inputInfo.shape, outShape) && isFlatDispatchLayout) {\n    return `\n    fn ${funcName}Index(globalIndex : i32) -> ${typeSnippet(component)} {\n      return ${typeSnippet(component)}(${texName}[globalIndex]);\n    }\n\n    fn ${funcName}Coords(coords : ${type}) -> ${typeSnippet(component)} {\n      return ${typeSnippet(component)}(${texName}[${\n        outRank > 1 ? 'getOutputIndexFromCoords(coords)' :\n                      'coords'}${component === 1 ? '' : ` / ${component}`}]);\n    }\n    `;\n  }\n\n  const broadcastDims =\n      backend_util.getBroadcastDims(inputInfo.shape, outShape);\n  const rankDiff = outRank - inRank;\n\n  let coordsSnippet = '';\n\n  if (inRank === 0) {\n    return `\n    fn ${funcName}Index(globalIndex : i32) -> ${typeSnippet(component)}{\n      return get${texFuncSnippet}();\n    }\n\n    fn ${funcName}Coords(coords : ${type}) -> ${typeSnippet(component)}{\n      return get${texFuncSnippet}();\n    }\n  `;\n  } else {\n    if (outRank < 2 && broadcastDims.length >= 1) {\n      coordsSnippet = 'coords = 0;';\n    } else {\n      coordsSnippet =\n          broadcastDims.map(d => `coords.${getCoordsXYZ(d + rankDiff)} = 0;`)\n              .join('\\n');\n    }\n  }\n\n  let unpackedCoordsSnippet = '';\n  if (outRank < 2 && inRank > 0) {\n    unpackedCoordsSnippet = 'coords';\n  } else {\n    if (outRank > 1) {\n      const coordsType = getCoordsDataType(inRank);\n      const coordsValues =\n          inputInfo.shape.map((s, i) => `coords.${getCoordsXYZ(i + rankDiff)}`)\n              .join(', ');\n      unpackedCoordsSnippet = `${coordsType}(${coordsValues})`;\n    } else {\n      unpackedCoordsSnippet = 'coords';\n    }\n  }\n\n  const shapeStr =\n      `uniforms.${texName.charAt(0).toLowerCase() + texName.slice(1)}Shape`;\n  const rankStr = `${inRank}D`;\n\n  return `\n  fn ${funcName}Index(globalIndex : i32) -> ${typeSnippet(component)} {\n    var coords = getCoordsFromIndex(globalIndex);\n    ${coordsSnippet}\n    return ${typeSnippet(component)}(${texName}[getIndexFromCoords${rankStr}(${\n      unpackedCoordsSnippet}, ${shapeStr})${\n      component === 1 ? '' : ` / ${component}`}]);\n  }\n\n  fn ${funcName}Coords(coordsIn : ${type}) -> ${typeSnippet(component)} {\n    var coords = coordsIn;\n    ${coordsSnippet}\n    return ${typeSnippet(component)}(${texName}[getIndexFromCoords${rankStr}(${\n      unpackedCoordsSnippet}, ${shapeStr})${\n      component === 1 ? '' : ` / ${component}`}]);\n  }\n`;\n}\n\nfunction getInputSnippet(\n    inputInfo: InputInfo, outShape: number[], component: number,\n    isFlatDispatchLayout: boolean): string {\n  let res = getInputAtCoordsSnippet(inputInfo, component);\n\n  const inShape = inputInfo.shape;\n  if (inShape.length <= outShape.length) {\n    res += getInputByOutputSnippet(\n        inputInfo, outShape, component, isFlatDispatchLayout);\n  }\n\n  return res;\n}\n\n/**\n * Generates getOutputCoords() function that computes output coordinates\n * from dispatch geometry to reduce arithmetic.\n */\nfunction getOutputCoordsSnippet(\n    outShape: number[],\n    dispatchLayout: {x: number[], y?: number[], z?: number[]}): string {\n  const {x, y = [], z = []} = dispatchLayout;\n\n  const outRank = outShape.length;\n  const rank = x.length + y.length + z.length;\n  // getOutputCoords is only meaningful when the output rank is same with\n  // dispatch layout rank.\n  if (rank !== outRank) {\n    return '';\n  }\n\n  if (x.length === outRank) {\n    const dtype = getCoordsDataType(outRank);\n    const snippet = `fn getOutputCoords() -> ${dtype}{\n    let globalIndex = getGlobalIndex();\n    return getCoordsFromIndex(globalIndex);\n  }\n  `;\n    return snippet;\n  }\n\n  let gatherDimensionsStr = '';\n  const dims = [x, y, z];\n\n  for (let i = 0; i < dims.length; i++) {\n    const arr = dims[i];\n\n    if (arr.length === 0) {\n      continue;\n    }\n\n    if (arr.length === 1) {\n      gatherDimensionsStr += `let d${arr[0]} = i32(globalId[${i}]);`;\n    } else {\n      const strides = symbolicallyComputeStrides(arr, 'uniforms.outShape');\n      gatherDimensionsStr += `var index${i} = i32(globalId[${i}]);`;\n      for (let j = 0; j < strides.length; j++) {\n        gatherDimensionsStr += `let d${arr[j]} = index${i} / ${strides[j]};`;\n\n        if (j === strides.length - 1) {\n          gatherDimensionsStr += `let d${arr[j + 1]} = ` +\n              `index${i} - d${arr[j]} * ${strides[j]};`;\n        } else {\n          gatherDimensionsStr +=\n              `index${i} = index${i} - d${arr[j]} * ${strides[j]};`;\n        }\n      }\n    }\n  }\n\n  const dimensions = [];\n  for (let i = 0; i < rank; i++) {\n    dimensions.push(`d${i}`);\n  }\n\n  const dtype = getCoordsDataType(rank);\n  let snippet = `fn getOutputCoords() -> ${dtype} {\n  ${gatherDimensionsStr}\n`;\n  if (dimensions.length === 0) {\n    snippet += `return ${dtype}(0); }`;\n  } else {\n    snippet += `return ${dtype}(${dimensions.join(',')}); }`;\n  }\n\n  return snippet;\n}\n\nfunction getOutputIndexFromCoordsSnippet(outRank: number) {\n  let snippet = '';\n  switch (outRank) {\n    case 0:\n    case 1:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : i32) -> i32 {\n          return coords;\n        }\n        `;\n      break;\n    case 2:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec2<i32>) -> i32 {\n          return dot(coords, vec2<i32>(uniforms.outShapeStrides, 1));\n        }\n        `;\n      break;\n    case 3:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec3<i32>) -> i32 {\n          return dot(coords, vec3<i32>(uniforms.outShapeStrides.x, uniforms.outShapeStrides.y, 1));\n        }\n        `;\n      break;\n    case 4:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n          return dot(coords, vec4<i32>(\n            uniforms.outShapeStrides.x, uniforms.outShapeStrides.y, uniforms.outShapeStrides.z, 1));\n        }\n        `;\n      break;\n    case 5:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec5) -> i32 {\n          return coords.x * uniforms.outShapeStrides.x +\n              coords.y * uniforms.outShapeStrides.y +\n              coords.z * uniforms.outShapeStrides.z +\n              coords.w * uniforms.outShapeStrides.w +\n              coords.u;\n        }\n        `;\n      break;\n    case 6:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec6) -> i32 {\n          return coords.x * uniforms.outShapeStrides.x +\n              coords.y * uniforms.outShapeStrides.y +\n              coords.z * uniforms.outShapeStrides.z +\n              coords.w * uniforms.outShapeStrides.w +\n              coords.u * uniforms.outShapeStrides.u +\n              coords.v;\n        }\n        `;\n      break;\n    default:\n      util.assert(false, () => `Unsupported ${outRank}D shape`);\n      break;\n  }\n  return snippet;\n}\n\nfunction isFlatDispatch(program: WebGPUProgram): boolean {\n  return program.dispatch[1] === 1 && program.dispatch[2] === 1;\n}\n\nexport function dataTypeToGPUType(type: DataType, component = 1) {\n  if (type === 'float32') {\n    return typeSnippet(component, 'f32');\n  } else if (type === 'int32' || type === 'bool') {\n    return typeSnippet(component, 'i32');\n  }\n  throw new Error(`type ${type} is not supported.`);\n}\n\nfunction setOutputSnippet(\n    outShape: number[], outBufferType: DataType, component: number): string {\n  const outRank = outShape.length;\n  const gpuType = dataTypeToGPUType(outBufferType, component);\n  let snippet =\n      `fn setOutputAtIndex(flatIndex : i32, value : ${typeSnippet(component)}) {\n      result[flatIndex] = ${gpuType}(value);\n    }\n\n    fn setOutputAtIndexI32(flatIndex : i32, value : ${\n          typeSnippet(component, 'i32')}) {\n      result[flatIndex] = ${gpuType}(value);\n    }\n    `;\n  if (outRank >= 2) {\n    const dims = ['d0', 'd1', 'd2', 'd3', 'd4', 'd5'].slice(0, outRank);\n    const type = getCoordsDataType(outRank);\n\n    snippet += `\n      fn setOutputAtCoords(${dims.map(d => `${d} : i32`).join(', ')}, value : ${\n        typeSnippet(component)}) {\n        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));\n        setOutputAtIndex(flatIndex${\n        component === 1 ? '' : ` / ${component}`}, value);\n      }\n      fn setOutputAtCoordsI32(${\n        dims.map(d => `${d} : i32`).join(', ')}, value : ${\n        typeSnippet(component, 'i32')}) {\n        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));\n        setOutputAtIndexI32(flatIndex${\n        component === 1 ? '' : ` / ${component}`}, value);\n      }\n    `;\n  }\n\n  return snippet;\n}\n\nfunction insertAlignment(uniformShader: string) {\n  // insert alignment when current pattern is vec5 or vec6\n  const curInsertRe = /(\\w+)\\s*:\\s*vec(5|6)/g;\n  uniformShader = uniformShader.replace(curInsertRe, (match) => {\n    return '@align(16) ' + match;\n  });\n\n  // insert alignment when previous pattern is vec5 or vec6\n  const preInsertRe = /vec(5|6)\\s*,\\s*(\\w+)/g;\n  uniformShader = uniformShader.replace(preInsertRe, (_, p1, p2) => {\n    return `vec${p1}, @align(16) ${p2}`;\n  });\n  return uniformShader;\n}\nfunction isFlatDispatchLayout(program: WebGPUProgram): boolean {\n  if (program.dispatchLayout.hasOwnProperty('y') &&\n      program.dispatchLayout.y.length !== 0) {\n    return false;\n  }\n  if (program.dispatchLayout.hasOwnProperty('z') &&\n      program.dispatchLayout.z.length !== 0) {\n    return false;\n  }\n  return true;\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {DataType, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nconst arrayProduct = (arr: number[]) => {\n  let product = 1;\n  for (let i = 0; i < arr.length; i++) {\n    product *= arr[i];\n  }\n  return product;\n};\n\nexport function tilesFitEvenlyIntoShape(\n    tileSize: number[], shape: number[]): boolean {\n  if (tileSize.length !== shape.length) {\n    throw new Error(\n        `Cannot compute whether rank ${tileSize.length}` +\n        ` tiles fit evenly into rank ${shape.length} shape` +\n        ` - ranks must match.`);\n  }\n  return shape.every(\n      (dim: number, dimIdx: number) => dim % tileSize[dimIdx] === 0);\n}\n\n// Computes dispatch geometry based on layout of output dimensions and\n// workgroupSize.\nexport function computeDispatch(\n    layout: {x: number[], y?: number[], z?: number[]}, outputShape: number[],\n    workgroupSize: [number, number, number] = [1, 1, 1],\n    elementsPerThread: [number, number, number] =\n        [1, 1, 1]): [number, number, number] {\n  const [dispatchX, dispatchY, dispatchZ] = [\n    Math.ceil(\n        arrayProduct(layout.x.map(d => outputShape[d])) /\n        (workgroupSize[0] * elementsPerThread[0])),\n    layout.y ? Math.ceil(\n                   arrayProduct(layout.y.map(d => outputShape[d])) /\n                   (workgroupSize[1] * elementsPerThread[1])) :\n               1,\n    layout.z ? Math.ceil(\n                   arrayProduct(layout.z.map(d => outputShape[d])) /\n                   (workgroupSize[2] * elementsPerThread[2])) :\n               1\n  ];\n  return [dispatchX, dispatchY, dispatchZ];\n}\n\nexport type WorkgroupInfo = {\n  workgroupSize: [number, number, number],\n  elementsPerThread: [number, number, number],\n};\n\nexport function computeWorkgroupInfoForMatMul(\n    dimAOuter: number, dimInner: number, dimBOuter: number,\n    transposeA = false): WorkgroupInfo {\n  // These are experimental values. Usually, we need to adjust the work group\n  // size based on the input shapes to improve the EU occupancy.\n  // TODO: WebGPU limits the maximum allowed shared memory size as 16K. To make\n  // sure it doesn't exceed this limitations. Temporarily reduce the work group\n  // size to [8, 8, 1] and the work per thread size is [4, 4, 1]. But we should\n  // revisit it and find the balance between work group size and work per thread\n  // size.\n  const workgroupSize: [number, number, number] = [8, 8, 1];\n  const elementsPerThread: [number, number, number] = [4, 4, 1];\n\n  if (!transposeA) {\n    if (dimAOuter <= 8) {\n      elementsPerThread[1] = 1;\n    }\n\n    if (dimInner <= 16 && dimBOuter <= 16) {\n      workgroupSize[0] = 4;\n    }\n  }\n\n  return {workgroupSize, elementsPerThread};\n}\n\nexport function computeWorkgroupSizeForConv2d(\n    layout: {x: number[], y?: number[], z?: number[]}, outputShape: number[],\n    isVec4 = false): [number, number, number] {\n  if (isVec4) {\n    return [8, 8, 1];\n  }\n\n  const dim0 = arrayProduct(layout.x.map(d => outputShape[d]));\n  const dim1 = arrayProduct(layout.y.map(d => outputShape[d]));\n  // TODO(jiajia.qin@intel.com): More fine tune based on outputShape.\n  // These are experimental values. Usually, we need to adjust the work group\n  // size based on the output shape. For example, when one dimension is smaller\n  // than 4, it will be wasteful if we assign a larger size for this dimension,\n  // which results lots of threads doing useless work and reduces parallelism\n  // of hardware threads. But it is always a balance between work group size\n  // and shared memory. If one dimension is too small, such as 1, shared memory\n  // will won't be fully utilized.\n  if (dim0 <= 4) {\n    return [4, 16, 1];\n  }\n  if (dim1 <= 4) {\n    return [16, 4, 1];\n  }\n\n  return [16, 16, 1];\n}\n\nexport function computeWorkPerThreadForConv2d(\n    layout: {x: number[], y?: number[], z?: number[]}, outputShape: number[],\n    isVec4 = false): [number, number, number] {\n  if (isVec4) {\n    return [4, 4, 1];\n  }\n\n  const dim0 = arrayProduct(layout.x.map(d => outputShape[d]));\n  const dim1 = arrayProduct(layout.y.map(d => outputShape[d]));\n  // TODO(jiajia.qin@intel.com): More fine tune based on outputShape.\n  // The following conditions correspond to the values set in\n  // computeWorkgroupSizeForConv2d.\n  if (dim0 <= 4) {\n    return [1, 2, 1];\n  }\n  if (dim1 <= 4) {\n    return [2, 1, 1];\n  }\n\n  return [2, 2, 1];\n}\n\nexport function flatDispatchLayout(shape: number[]) {\n  return {x: shape.map((d, i) => i)};\n}\n\nexport function GPUBytesPerElement(dtype: DataType): number {\n  if (dtype === 'float32' || dtype === 'int32' || dtype === 'bool' ||\n      dtype === 'string') {\n    return 4;\n  } else if (dtype === 'complex64') {\n    return 8;\n  } else {\n    throw new Error(`Unknown dtype ${dtype}`);\n  }\n}\n\nexport function isWebGPUSupported(): boolean {\n  return !!(typeof globalThis !== 'undefined' && (globalThis.navigator)\n    && (globalThis.navigator.gpu));\n}\n\nexport function assertNotComplex(\n    tensor: TensorInfo|TensorInfo[], opName: string): void {\n  if (!Array.isArray(tensor)) {\n    tensor = [tensor];\n  }\n  tensor.forEach(t => {\n    if (t != null) {\n      util.assert(\n          t.dtype !== 'complex64',\n          () => `${opName} does not support complex64 tensors ` +\n              'in the WebGPU backend.');\n    }\n  });\n}\n\nexport enum MatMulProgramType {\n  MatMulReduceProgram,\n  MatMulSplitKProgram,\n  MatMulSmallOutputSizeProgram,\n  MatMulPackedProgram,\n  MatMulMax\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport './flags_webgpu';\n\nimport {backend_util, BackendValues, buffer, DataStorage, DataType, engine, env, GPUData, KernelBackend, Rank, RecursiveArray, ShapeMap, Tensor, TensorBuffer, TensorInfo, TimingInfo, TypedArray, util, WebGPUData} from '@tensorflow/tfjs-core';\n\nimport {AdapterInfo} from './adapter_info';\nimport {BufferManager} from './buffer_manager';\nimport {TextureManager} from './texture_manager';\nimport * as webgpu_program from './webgpu_program';\nimport * as webgpu_util from './webgpu_util';\n\nexport interface WebGPUMemoryInfo extends backend_util.MemoryInfo {\n  numBytesInGPU: number;\n  numBytesAllocatedInGPU: number;\n  unreliable: boolean;\n}\n\ntype TensorData = {\n  values: BackendValues,\n  dtype: DataType,\n  shape: number[],\n  refCount: number,\n  resource?: GPUBuffer|GPUTexture|GPUExternalTexture,\n  // external is true means we use the resource provided by users directly\n  // (without a copy), so users should be responsible for its release.\n  external?: boolean,\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensorInfos field.\n  complexTensorInfos?: {real: TensorInfo, imag: TensorInfo}\n};\n\ninterface DataId {}\n\nexport type WebGPUKernelInfo = {\n  name: string,\n  query: Promise<number>,\n};\n\nexport type TimerNode = RecursiveArray<WebGPUKernelInfo>|WebGPUKernelInfo;\n\nexport interface WebGPUTimingInfo extends TimingInfo {\n  uploadWaitMs: number;\n  downloadWaitMs: number;\n}\n\ntype ProgramUniform = Array<{type: string; data: number[]}>;\n\n// Empirically determined constant used to determine size threshold for handing\n// off execution to the CPU.\nconst CPU_HANDOFF_SIZE_THRESHOLD =\n    env().getNumber('WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD');\n\n// Reshape dispatch, not to exceed device limits.\nconst reshapeDispatch =\n    (device: GPUDevice,\n     program: webgpu_program.WebGPUProgram): [number, number, number] => {\n      const MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE =\n          device.limits.maxComputeWorkgroupsPerDimension;\n      const layout = program['dispatchLayout'];\n      const dispatch = program['dispatch'];\n      if (dispatch.every((d) => d <= MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE)) {\n        return dispatch;\n      }\n\n      util.assert(\n          dispatch[0] > MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE &&\n              layout.y === undefined && layout.z === undefined,\n          () => 'Dispatch size exceeds WebGPU limits in Y or Z dimension.');\n\n      let dispatchAverage = Math.ceil(Math.sqrt(dispatch[0]));\n      if (dispatchAverage > MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE) {\n        dispatchAverage = Math.ceil(Math.cbrt(dispatch[0]));\n        util.assert(\n            dispatchAverage <= MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE,\n            () => 'Total dispatch size exceeds WebGPU maximum.');\n        return [dispatchAverage, dispatchAverage, dispatchAverage];\n      } else {\n        return [dispatchAverage, dispatchAverage, 1];\n      }\n    };\n\nexport class WebGPUBackend extends KernelBackend {\n  bufferManager: BufferManager;\n  adapterInfo: AdapterInfo;\n  device: GPUDevice;\n  queue: GPUQueue;\n  tensorMap: DataStorage<TensorData>;\n  textureManager: TextureManager;\n  thresholdToIncreaseWorkgroups: number;\n\n  private activeTimers: TimerNode[];\n  private commandEncoder: GPUCommandEncoder;\n  private computePassEncoder: GPUComputePassEncoder;\n  private commandQueueOwnedIds = new WeakSet<DataId>();\n  private dispatchCountInPass = 0;\n  private disposed = false;\n  private downloadWaitMs = 0;\n  private dummyCanvas: HTMLCanvasElement;\n  private dummyContext: GPUCanvasContext;\n  private tensorDataPendingDisposal: DataId[] = [];\n  private static nextDataId = 0;\n  private pipelineCache:\n      {[key: string]: GPUComputePipeline|Promise<GPUComputePipeline>};\n  private programTimersStack: TimerNode[];\n  private queryResolveBuffer: GPUBuffer = null;\n  private querySet: GPUQuerySet = null;\n  private querySetCount = 2;\n  private stagingPendingDisposal: GPUBuffer[] = [];\n  private supportTimestampQuery: boolean;\n  private uniformPendingDisposal: GPUBuffer[] = [];\n  private uploadWaitMs = 0;\n  private hasReadSyncWarned = false;\n  private hasTimestampQueryWarned = false;\n\n  private nextDataId(): number {\n    return WebGPUBackend.nextDataId++;\n  }\n\n  constructor(device: GPUDevice, adapterInfo?: GPUAdapterInfo) {\n    super();\n    if (!webgpu_util.isWebGPUSupported()) {\n      throw new Error('WebGPU is not supported on this device');\n    }\n    this.pipelineCache = {};\n    this.device = device;\n    this.queue = device.queue;\n    this.commandEncoder = null;\n    this.computePassEncoder = null;\n    this.adapterInfo = new AdapterInfo(adapterInfo);\n    this.supportTimestampQuery = this.device.features.has('timestamp-query');\n    this.thresholdToIncreaseWorkgroups =\n        this.adapterInfo.intelGPUGeneration >= 12 ? 16 : 8;\n\n    this.bufferManager = new BufferManager(this.device);\n    this.textureManager = new TextureManager(this.device);\n    this.tensorMap = new DataStorage(this, engine());\n\n    // Profiling tools like PIX needs this dummy canvas to\n    // trigger capturing a frame.\n    if (env().getBool('WEBGPU_USE_PROFILE_TOOL')) {\n      this.dummyCanvas = document.createElement('canvas');\n      this.dummyCanvas.width = 1;\n      this.dummyCanvas.height = 1;\n\n      this.dummyContext = this.dummyCanvas.getContext('webgpu');\n      this.dummyContext.configure({\n        device,\n        format: 'bgra8unorm',\n      });\n\n      document.body.appendChild(this.dummyCanvas);\n    }\n  }\n\n  override floatPrecision(): 32 {\n    return 32;\n  }\n\n  /**\n   * Dispose the memory if the dataId has 0 refCount. Return true if the memory\n   * is released or delayed in this backend, false if there are still\n   * references.\n   * @param dataId\n   * @oaram force Optional, remove the data regardless of refCount\n   */\n  override disposeData(dataId: DataId, force = false): boolean {\n    // No-op if already disposed.\n    if (!this.tensorMap.has(dataId)) {\n      return true;\n    }\n\n    const tensorData = this.tensorMap.get(dataId);\n    if (force) {\n      tensorData.refCount = 0;\n    } else {\n      tensorData.refCount--;\n    }\n\n    if (tensorData.refCount > 0) {\n      return false;\n    }\n\n    if (tensorData.complexTensorInfos != null) {\n      this.disposeData(tensorData.complexTensorInfos.real.dataId);\n      this.disposeData(tensorData.complexTensorInfos.imag.dataId);\n    }\n\n    if (this.commandQueueOwnedIds.has(dataId)) {\n      this.tensorDataPendingDisposal.push(dataId);\n      return true;\n    }\n\n    this.releaseResource(dataId);\n    this.tensorMap.delete(dataId);\n\n    return true;\n  }\n\n  override memory(): WebGPUMemoryInfo {\n    return {\n      numBytesInGPU: this.bufferManager.numBytesUsed,\n      numBytesAllocatedInGPU: this.bufferManager.numBytesAllocated,\n      unreliable: false\n    } as WebGPUMemoryInfo;\n  }\n\n  private releaseResource(dataId: DataId) {\n    const tensorData = this.tensorMap.get(dataId);\n    if (!tensorData || !tensorData.resource) {\n      return;\n    }\n\n    // If tensor's resource is from external, do not release.\n    if (tensorData.external) {\n      tensorData.resource = null;\n      return;\n    }\n    if (tensorData.resource instanceof GPUBuffer) {\n      this.bufferManager.releaseBuffer(tensorData.resource);\n    } else if (tensorData.resource instanceof GPUTexture) {\n      this.textureManager.releaseTexture(tensorData.resource);\n    }\n    tensorData.resource = null;\n  }\n\n  /** Return refCount of a `TensorData`. */\n  override refCount(dataId: DataId): number {\n    if (this.tensorMap.has(dataId)) {\n      const tensorData = this.tensorMap.get(dataId);\n      return tensorData.refCount;\n    }\n    return 0;\n  }\n\n  /** Increase refCount of a `TensorData`. */\n  override incRef(dataId: DataId): void {\n    const tensorData = this.tensorMap.get(dataId);\n    tensorData.refCount++;\n  }\n\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId: DataId): void {\n    if (this.tensorMap.has(dataId)) {\n      const tensorData = this.tensorMap.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n\n  override write(values: BackendValues, shape: number[], dtype: DataType):\n      DataId {\n    if (dtype === 'complex64' && values != null) {\n      throw new Error(\n          `Cannot write to a complex64 dtype. ` +\n          `Please use tf.complex(real, imag).`);\n    }\n    const dataId = {id: this.nextDataId()};\n    this.tensorMap.set(dataId, {dtype, shape, values, refCount: 1});\n    return dataId;\n  }\n\n  override move(\n      dataId: DataId, values: BackendValues, shape: number[], dtype: DataType,\n      refCount: number): void {\n    if (dtype === 'complex64') {\n      throw new Error(\n          `Cannot write to a complex64 dtype. ` +\n          `Please use tf.complex(real, imag).`);\n    }\n    this.tensorMap.set(dataId, {dtype, shape, values, refCount});\n  }\n\n  submitQueue() {\n    this.queue.submit([this.commandEncoder.finish()]);\n    this.commandEncoder = null;\n    this.dispatchCountInPass = 0;\n\n    this.commandQueueOwnedIds = new WeakSet<DataId>();\n\n    this.tensorDataPendingDisposal.forEach(d => {\n      this.releaseResource(d);\n      this.tensorMap.delete(d);\n    });\n\n    this.uniformPendingDisposal.forEach(\n        b => this.bufferManager.releaseBuffer(b));\n    this.stagingPendingDisposal.forEach(\n        b => this.bufferManager.releaseBuffer(b, false));\n\n    this.tensorDataPendingDisposal = [];\n    this.uniformPendingDisposal = [];\n    this.stagingPendingDisposal = [];\n  }\n\n  ensureCommandEncoderReady() {\n    if (!this.commandEncoder) {\n      this.commandEncoder = this.device.createCommandEncoder();\n    }\n  }\n\n  endComputePassEncoder() {\n    if (this.computePassEncoder) {\n      this.computePassEncoder.end();\n      this.computePassEncoder = null;\n    }\n  }\n\n  // Check if parallel compilation is done.\n  async checkCompileCompletionAsync() {\n    let pipelines: GPUComputePipeline[];\n    try {\n      pipelines = await Promise.all(Object.values(this.pipelineCache));\n    } catch (e) {\n      // TODO: Add test case to catch this exception.\n      throw new Error(e.message);\n    }\n    Object.keys(this.pipelineCache).map((key, i) => {\n      this.pipelineCache[key] = pipelines[i];\n    });\n  }\n\n  public async getBufferData(buffer: GPUBuffer): Promise<ArrayBuffer> {\n    if (env().getBool('WEBGPU_ENGINE_COMPILE_ONLY')) {\n      console.warn(\n          'The data may be invalid since WEBGPU_ENGINE_COMPILE_ONLY is true, this can only be called when WEBGPU_ENGINE_COMPILE_ONLY is false');\n      return null;\n    }\n    const size = buffer.size;\n    const stagingBuffer = this.bufferManager.acquireBuffer(\n        size, GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ);\n    this.ensureCommandEncoderReady();\n    this.endComputePassEncoder();\n    this.commandEncoder.copyBufferToBuffer(buffer, 0, stagingBuffer, 0, size);\n    this.submitQueue();\n\n    await stagingBuffer.mapAsync(GPUMapMode.READ);\n    const values = stagingBuffer.getMappedRange().slice(0);\n\n    stagingBuffer.unmap();\n    if (stagingBuffer != null) {\n      this.bufferManager.releaseBuffer(stagingBuffer);\n    }\n\n    // Need to get texture from swapChain to enable profiling tool\n    // to capture a frame\n    if (env().getBool('WEBGPU_USE_PROFILE_TOOL')) {\n      util.assert(\n          this.dummyContext !== undefined,\n          () => `Fail to get context for profiling tool`);\n      this.dummyContext.getCurrentTexture();\n    }\n\n    return values;\n  }\n\n  private convertAndCacheOnCPU(dataId: DataId, data: BackendValues):\n      BackendValues {\n    const tensorData = this.tensorMap.get(dataId);\n    tensorData.values = data;\n    return tensorData.values;\n  }\n\n  override readSync(dataId: object): BackendValues {\n    const tensorData = this.tensorMap.get(dataId);\n    const {values, complexTensorInfos} = tensorData;\n\n    if (values != null || tensorData.dtype === 'string') {\n      return values;\n    }\n\n    if (tensorData.dtype === 'complex64') {\n      const realValues =\n          this.readSync(complexTensorInfos.real.dataId) as Float32Array;\n      const imagValues =\n          this.readSync(complexTensorInfos.imag.dataId) as Float32Array;\n      const complexVals = util.convertBackendValuesAndArrayBuffer(\n          backend_util.mergeRealAndImagArrays(realValues, imagValues).buffer,\n          'float32');\n      this.convertAndCacheOnCPU(dataId, complexVals);\n      return complexVals;\n    }\n\n    if (!this.hasReadSyncWarned) {\n      this.hasReadSyncWarned = true;\n      console.warn(\n          `The performance of synchronously reading data from GPU to CPU is ` +\n          `poor on the webgpu backend, please use asynchronous APIs instead.`);\n    }\n\n    const alphaModes: GPUCanvasAlphaMode[] = ['opaque', 'premultiplied'];\n\n    const buffer = tensorData.resource as GPUBuffer;\n    const bufferSize = buffer.size;\n    util.assert(\n        bufferSize % 4 === 0,\n        () => 'Because there is 4 bytes for ' +\n            'one pixel, buffer size must be multiple of 4.');\n    const pixelsSize = bufferSize / 4;\n    const valsGPU = new ArrayBuffer(bufferSize);\n    // TODO: adjust the reading window size according the `bufferSize`.\n    const canvasWidth = 256, canvasHeight = 256;\n    const stagingDeviceStorage: OffscreenCanvas[] =\n        alphaModes.map(_ => new OffscreenCanvas(canvasWidth, canvasHeight));\n    const stagingHostStorage = new OffscreenCanvas(canvasWidth, canvasHeight);\n\n    this.endComputePassEncoder();\n    stagingDeviceStorage\n        .map((storage, index) => {\n          const context = storage.getContext('webgpu');\n          // TODO: use rgba8unorm format when this format is supported on Mac.\n          // https://bugs.chromium.org/p/chromium/issues/detail?id=1298618\n          context.configure({\n            device: this.device,\n            format: 'bgra8unorm',\n            usage: GPUTextureUsage.COPY_DST,\n            alphaMode: alphaModes[index],\n          });\n          return context.getCurrentTexture();\n        })\n        .map((texture, index) => {\n          const bytesPerRow = canvasWidth * 4;\n          const readDataGPUToCPU =\n              (width: number, height: number, offset: number) => {\n                this.ensureCommandEncoderReady();\n                this.commandEncoder.copyBufferToTexture(\n                    {\n                      buffer,\n                      bytesPerRow,\n                      offset,\n                    },\n                    {\n                      texture,\n                    },\n                    {\n                      width,\n                      height,\n                    });\n                this.submitQueue();\n\n                const context = stagingHostStorage.getContext('2d', {\n                  willReadFrequently: true,\n                });\n                context.clearRect(0, 0, width, height);\n                context.drawImage(stagingDeviceStorage[index], 0, 0);\n                const stagingValues =\n                    context.getImageData(0, 0, width, height).data;\n                const alphaMode = alphaModes[index];\n                const span =\n                    new Uint8ClampedArray(valsGPU, offset, width * height * 4);\n                for (let k = 0; k < span.length; k += 4) {\n                  if (alphaMode === 'premultiplied') {\n                    span[k + 3] = stagingValues[k + 3];\n                  } else {\n                    const value = stagingValues[k];\n                    span[k] = stagingValues[k + 2];\n                    span[k + 1] = stagingValues[k + 1];\n                    span[k + 2] = value;\n                  }\n                }\n              };\n\n          const fullyReadCount =\n              Math.floor(pixelsSize / (canvasWidth * canvasHeight));\n          let width = canvasWidth, height = canvasHeight, offset = 0;\n          for (let i = 0; i < fullyReadCount; i++) {\n            // Read the buffer data, which fully fill the whole canvas.\n            readDataGPUToCPU(width, height, offset);\n            offset += canvasWidth * canvasHeight * 4;\n          }\n\n          const remainSize = pixelsSize % (canvasWidth * canvasHeight);\n          height = Math.floor(remainSize / canvasWidth);\n          if (height > 0) {\n            // Read the buffer data, which fully fill certain rows of canvas.\n            readDataGPUToCPU(width, height, offset);\n            offset += height * (canvasWidth * 4);\n          }\n\n          width = remainSize % canvasWidth;\n          if (width > 0) {\n            // Read the buffer data, which not fully fill one row of canvas.\n            readDataGPUToCPU(width, 1, offset);\n          }\n        });\n\n    const vals =\n        util.convertBackendValuesAndArrayBuffer(valsGPU, tensorData.dtype);\n    this.convertAndCacheOnCPU(dataId, vals);\n    return vals;\n  }\n\n  override async read(dataId: object): Promise<BackendValues> {\n    if (!this.tensorMap.has(dataId)) {\n      throw new Error(`Tensor ${dataId} was not registered!`);\n    }\n    const tensorData = this.tensorMap.get(dataId);\n\n    const {values} = tensorData;\n\n    if (values != null) {\n      return values;\n    }\n\n    // Download the values from the GPU.\n    let vals: BackendValues;\n    if (tensorData.dtype === 'complex64') {\n      const ps = await Promise.all([\n        this.read(tensorData.complexTensorInfos.real.dataId),\n        this.read(tensorData.complexTensorInfos.imag.dataId)\n      ]);\n\n      const realValues = ps[0];\n      const imagValues = ps[1];\n      vals = backend_util.mergeRealAndImagArrays(\n          realValues as Float32Array, imagValues as Float32Array);\n    } else {\n      const data = await this.getBufferData(tensorData.resource as GPUBuffer);\n      vals = util.convertBackendValuesAndArrayBuffer(data, tensorData.dtype);\n    }\n    this.convertAndCacheOnCPU(dataId, vals);\n    return vals;\n  }\n\n  // The source GPUBuffer and destination GPUBuffer have the same size and\n  // usage.\n  private copyBuffer(srcBuffer: GPUBuffer) {\n    const size = srcBuffer.size;\n    const usage = srcBuffer.usage;\n    const dstBuffer = this.bufferManager.acquireBuffer(size, usage);\n    this.ensureCommandEncoderReady();\n    this.endComputePassEncoder();\n    this.commandEncoder.copyBufferToBuffer(srcBuffer, 0, dstBuffer, 0, size);\n    this.submitQueue();\n    return dstBuffer;\n  }\n\n  /**\n   * Create a TF.js tensor out of an existing WebGPU buffer.\n   */\n  override createTensorFromGPUData(\n      webGPUData: WebGPUData, shape: number[], dtype: DataType): Tensor {\n    let buffer = webGPUData.buffer;\n    if (dtype === 'complex64') {\n      throw new Error(`Cannot write to a complex64 dtype. `);\n    }\n    const dataId = {id: this.nextDataId()};\n    this.tensorMap.set(dataId, {\n      dtype,\n      shape,\n      values: null,\n      refCount: 1,\n      external: webGPUData.zeroCopy\n    });\n    const tensorData = this.tensorMap.get(dataId);\n    const size = webgpu_util.GPUBytesPerElement(tensorData.dtype) *\n        util.sizeFromShape(tensorData.shape);\n    if (webGPUData.buffer.size < size) {\n      throw new Error(`GPUBuffer size(${\n          webGPUData.buffer.size}) is smaller than tensor size(${size})!`);\n    } else if (\n        (webGPUData.buffer.usage &\n         (GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC)) !==\n        (GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC)) {\n      throw new Error(\n          'GPUBuffer.usage should include GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC!');\n    }\n\n    // Do buffer copy by default.\n    if (webGPUData.zeroCopy !== true) {\n      buffer = this.copyBuffer(buffer);\n    }\n    tensorData.resource = buffer;\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this);\n  }\n\n  /**\n   * Read tensor to a new GPUBuffer.\n   * @param dataId The source tensor.\n   */\n  override readToGPU(dataId: DataId): GPUData {\n    const srcTensorData = this.tensorMap.get(dataId);\n    const {values, dtype, shape, resource} = srcTensorData;\n\n    if (dtype === 'complex64') {\n      throw new Error('Does not support reading buffer for complex64 dtype.');\n    }\n\n    if (resource == null) {\n      if (values != null) {\n        throw new Error('Data is not on GPU but on CPU.');\n      } else {\n        throw new Error('There is no data on GPU or CPU.');\n      }\n    }\n\n    const srcBuffer = resource as GPUBuffer;\n    const size = srcBuffer.size;\n    const usage = srcBuffer.usage;\n    const buffer = this.bufferManager.acquireBuffer(size, usage);\n    this.ensureCommandEncoderReady();\n    this.endComputePassEncoder();\n    this.commandEncoder.copyBufferToBuffer(\n        resource as GPUBuffer, 0, buffer, 0, size);\n    this.submitQueue();\n\n    const tensorInfo = this.makeTensorInfo(shape, dtype);\n    // Make engine track this tensor, so that we can dispose it later.\n    const tensorRef = engine().makeTensorFromTensorInfo(tensorInfo);\n\n    const tensorData = this.tensorMap.get(tensorInfo.dataId);\n    tensorData.resource = buffer;\n\n    return {tensorRef, buffer};\n  }\n\n  bufferSync<R extends Rank, D extends DataType>(t: TensorInfo):\n      TensorBuffer<R, D> {\n    const data = this.readSync(t.dataId);\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        const strings = (data as Uint8Array[]).map(d => util.decodeString(d));\n        return buffer(t.shape as ShapeMap[R], t.dtype, strings) as\n            TensorBuffer<R, D>;\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return buffer(t.shape as ShapeMap[R], t.dtype, data as TypedArray) as\n        TensorBuffer<R, D>;\n  }\n\n  override async time(f: () => void): Promise<WebGPUTimingInfo> {\n    if (!this.supportTimestampQuery && !this.hasTimestampQueryWarned) {\n      console.warn(\n          `This device doesn't support timestamp-query extension. ` +\n          `Start Chrome browser with flag ` +\n          `--enable-dawn-features=allow_unsafe_apis to try it again. ` +\n          `Otherwise, zero will be shown for the kernel time when profiling ` +\n          `mode is enabled.`);\n      this.hasTimestampQueryWarned = true;\n    }\n\n    const oldActiveTimers = this.activeTimers;\n    const newActiveTimers: TimerNode[] = [];\n\n    let outerMostTime = false;\n    if (this.programTimersStack == null) {\n      this.programTimersStack = newActiveTimers;\n      outerMostTime = true;\n    } else {\n      this.activeTimers.push(newActiveTimers);\n    }\n    this.activeTimers = newActiveTimers;\n\n    f();\n\n    const flattenedActiveTimerQueries =\n        util.flatten(this.activeTimers.map((d: WebGPUKernelInfo) => d.query))\n            .filter(d => d != null);\n    const flattenedActiveTimerNames =\n        util.flatten(this.activeTimers.map((d: WebGPUKernelInfo) => d.name))\n            .filter(d => d != null);\n\n    this.activeTimers = oldActiveTimers;\n\n    if (outerMostTime) {\n      this.programTimersStack = null;\n    }\n    const res: WebGPUTimingInfo = {\n      uploadWaitMs: this.uploadWaitMs,\n      downloadWaitMs: this.downloadWaitMs,\n      kernelMs: null,\n      wallMs: null\n    };\n\n    const kernelMs = await Promise.all(flattenedActiveTimerQueries);\n    res['kernelMs'] = util.sum(kernelMs);\n    res['getExtraProfileInfo'] = () =>\n        kernelMs.map((d, i) => ({name: flattenedActiveTimerNames[i], ms: d}))\n            .map(d => `${d.name}: ${d.ms}`)\n            .join(', ');\n    this.uploadWaitMs = 0;\n    this.downloadWaitMs = 0;\n    return res;\n  }\n\n  makeTensorInfo(\n      shape: number[], dtype: DataType,\n      values?: BackendValues|string[]): TensorInfo {\n    if (dtype === 'string' && values != null && values.length > 0 &&\n        util.isString(values[0])) {\n      values = (values as unknown as string[]).map(d => util.encodeString(d));\n    }\n    const dataId = this.write(values as BackendValues, shape, dtype);\n    return {dataId, shape, dtype};\n  }\n\n  private tensorToBinding(tensor?: TensorInfo): GPUBindingResource {\n    if (!tensor) {\n      return null;\n    }\n\n    const tensorData = this.tensorMap.get(tensor.dataId);\n    const resource = tensorData.resource;\n\n    if (resource instanceof GPUBuffer) {\n      return {buffer: resource};\n    }\n    if (resource instanceof GPUTexture) {\n      return resource.createView();\n    }\n    // GPUExternalTexture\n    return resource;\n  }\n\n  uploadToGPU(dataId: DataId): void {\n    const tensorData = this.tensorMap.get(dataId);\n    // Already on the GPU.\n    if (tensorData.resource != null) {\n      return;\n    }\n\n    const size = webgpu_util.GPUBytesPerElement(tensorData.dtype) *\n        util.sizeFromShape(tensorData.shape);\n    let buffer;\n    const usage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC |\n        GPUBufferUsage.COPY_DST;\n    if (tensorData.values) {\n      buffer = this.bufferManager.acquireBuffer(size, usage, true);\n      if (buffer.mapState === 'unmapped') {\n        const stagingBuffer = this.bufferManager.acquireBuffer(\n            size, GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC, true,\n            false);\n        const arrayBuffer = stagingBuffer.getMappedRange();\n        if (tensorData.dtype === 'int32' || tensorData.dtype === 'bool') {\n          new Int32Array(arrayBuffer).set(tensorData.values as TypedArray);\n        } else {\n          new Float32Array(arrayBuffer).set(tensorData.values as Float32Array);\n        }\n        stagingBuffer.unmap();\n        this.ensureCommandEncoderReady();\n        this.endComputePassEncoder();\n        this.commandEncoder.copyBufferToBuffer(\n            stagingBuffer, 0, buffer, 0, size);\n\n        this.stagingPendingDisposal.push(stagingBuffer);\n      } else {\n        const arrayBuffer = buffer.getMappedRange();\n        if (tensorData.dtype === 'int32' || tensorData.dtype === 'bool') {\n          new Int32Array(arrayBuffer).set(tensorData.values as TypedArray);\n        } else {\n          new Float32Array(arrayBuffer).set(tensorData.values as Float32Array);\n        }\n        buffer.unmap();\n      }\n\n      // Once uploaded, don't store the values on cpu.\n      tensorData.values = null;\n    } else {\n      buffer = this.bufferManager.acquireBuffer(size, usage);\n    }\n    tensorData.resource = buffer;\n  }\n\n  private makeUniforms(programUniform: ProgramUniform): GPUBindingResource {\n    let currentOffset = 0;\n    let preLength = 0;\n    const offsets: number[] = [];\n    let maxAlignmentOfField = 1;\n    programUniform.forEach((d) => {\n      if (d.data.length === 0) {\n        d.data = [1];\n      }\n      // https://www.w3.org/TR/WGSL/#alignof\n      let baseAlignment: number;\n      switch (d.data.length) {\n        case 1:\n          baseAlignment = 4;\n          break;\n        case 2:\n          baseAlignment = 8;\n          break;\n        case 3:\n          baseAlignment = 16;\n          break;\n        case 4:\n          baseAlignment = 16;\n          break;\n        case 5:\n          baseAlignment = 16;\n          break;\n        case 6:\n          baseAlignment = 16;\n          break;\n        default:\n          util.assert(false, () => `Unsupported ${d.data.length}D shape`);\n      }\n\n      if (preLength === 5 || preLength === 6) {\n        baseAlignment = 16;\n      }\n      if (baseAlignment > maxAlignmentOfField) {\n        maxAlignmentOfField = baseAlignment;\n      }\n      currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;\n      preLength = d.data.length;\n      offsets.push(currentOffset);\n      currentOffset += d.data.length * 4;\n    });\n\n    currentOffset =\n        Math.ceil(currentOffset / maxAlignmentOfField) * maxAlignmentOfField;\n    const arrayBuffer = new ArrayBuffer(currentOffset);\n    programUniform.forEach((d, i) => {\n      const offset = offsets[i];\n      if (d.type === 'int32') {\n        new Int32Array(arrayBuffer, offset, d.data.length).set(d.data);\n      } else if (d.type === 'uint32') {\n        new Uint32Array(arrayBuffer, offset, d.data.length).set(d.data);\n      } else {\n        new Float32Array(arrayBuffer, offset, d.data.length).set(d.data);\n      }\n    });\n\n    const uniformBuffer = this.bufferManager.acquireBuffer(\n        currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);\n    this.queue.writeBuffer(uniformBuffer, 0, arrayBuffer, 0, currentOffset);\n    this.uniformPendingDisposal.push(uniformBuffer);\n\n    return {offset: 0, size: currentOffset, buffer: uniformBuffer};\n  }\n\n  public runWebGPUProgram(\n      program: webgpu_program.WebGPUProgram, inputs: TensorInfo[],\n      outputDtype: DataType, programDefinedUniform?: ProgramUniform,\n      output?: TensorInfo): TensorInfo {\n    if (!output) {\n      output = this.makeTensorInfo(program.outputShape, outputDtype);\n    }\n    if (util.sizeFromShape(output.shape) === 0) {\n      // Short-circuit the computation since the result is empty (has 0 in its\n      // shape).\n      this.tensorMap.get(output.dataId).values =\n          util.getTypedArrayFromDType(output.dtype as 'float32', 0);\n      return output;\n    }\n    this.uploadToGPU(output.dataId);\n    program.dispatch = reshapeDispatch(this.device, program);\n\n    const inputsData = inputs.map((input: TensorInfo, i: number) => {\n      if (input.dtype === 'complex64') {\n        throw new Error(\n            `GPGPUProgram does not support complex64 input. For complex64 ` +\n            `dtypes, please separate the program into real and imaginary ` +\n            `parts.`);\n      }\n      this.uploadToGPU(input.dataId);\n\n      return {\n        // Returning dtype from tensorMap because it reflects dtype\n        // of underlying buffer, rather than abstract dtype.\n        dtype: this.tensorMap.get(input.dataId).dtype,\n        shape: input.shape,\n        name: program.variableNames[i]\n      };\n    });\n\n    program.shaderKey =\n        webgpu_program.makeShaderKey(program, inputsData, output);\n\n    const parallelCompilation = env().getBool('WEBGPU_ENGINE_COMPILE_ONLY');\n    if (!(program.shaderKey in this.pipelineCache)) {\n      this.pipelineCache[program.shaderKey] = webgpu_program.compileProgram(\n          this.device, program, inputsData, output, parallelCompilation);\n    }\n    program.pipeline = this.pipelineCache[program.shaderKey];\n\n    if (!parallelCompilation) {\n      this.recordAndSubmit(program, output, inputs, programDefinedUniform);\n    }\n    return output;\n  }\n\n  private recordAndSubmit(\n      program: webgpu_program.WebGPUProgram, output: TensorInfo,\n      inputs: TensorInfo[], programDefinedUniform?: ProgramUniform) {\n    if (program.pipeline instanceof Promise) {\n      throw new Error(\n          'Please call checkCompileCompletionAsync to ensure parallel compilation is done!');\n    }\n    // There are six kinds of uniforms: NAN, INFINITY, shapes, shape strides,\n    // program size, program defined uniforms.\n    let programUniform: ProgramUniform = [];\n    let bufferShapes: number[][] = [];\n    const uniformsType = 'int32';\n    if (program.pixelsOpType == null) {\n      programUniform.push(\n          {type: 'float32', data: [NaN]}, {type: 'float32', data: [Infinity]});\n      bufferShapes = inputs.concat(output).map(d => d.shape);\n      const uniformsType = 'int32';\n      bufferShapes.map(d => {\n        programUniform.push({type: uniformsType, data: d});\n        const strides = util.computeStrides(d);\n        programUniform.push({type: uniformsType, data: strides});\n      });\n    } else {\n      const strides = util.computeStrides(output.shape);\n      programUniform.push({type: uniformsType, data: strides});\n    }\n    if (program.size) {\n      const size = util.sizeFromShape(program.outputShape);\n      programUniform.push({\n        type: uniformsType,\n        data: [program.outputComponent ? size / program.outputComponent : size]\n      });\n    }\n\n    if (programDefinedUniform) {\n      programUniform = [...programUniform, ...programDefinedUniform];\n    }\n    const bindings = [\n      this.tensorToBinding(output), ...inputs.map(t => this.tensorToBinding(t)),\n      this.makeUniforms(programUniform)\n    ];\n\n    inputs.forEach(input => {\n      this.commandQueueOwnedIds.add(input.dataId);\n    });\n    this.commandQueueOwnedIds.add(output.dataId);\n\n    const bindGroup = this.device.createBindGroup({\n      layout: program.pipeline.getBindGroupLayout(0),\n      entries: bindings.map((b, i) => ({binding: i, resource: b})),\n    });\n\n    const shouldTimeProgram = this.activeTimers != null;\n    this.ensureCommandEncoderReady();\n\n    const computePassDescriptor: GPUComputePassDescriptor = {};\n    if (shouldTimeProgram && this.supportTimestampQuery) {\n      this.endComputePassEncoder();\n      if (this.querySet == null) {\n        this.querySet = this.device.createQuerySet({\n          type: 'timestamp',\n          count: this.querySetCount,\n        });\n      }\n      computePassDescriptor.timestampWrites = {\n        querySet: this.querySet,\n        beginningOfPassWriteIndex: 0,\n        endOfPassWriteIndex: 1,\n      };\n      this.computePassEncoder =\n          this.commandEncoder.beginComputePass(computePassDescriptor);\n    } else if (!this.computePassEncoder) {\n      this.computePassEncoder =\n          this.commandEncoder.beginComputePass(computePassDescriptor);\n    }\n\n    this.computePassEncoder.setPipeline(program.pipeline);\n    this.computePassEncoder.setBindGroup(0, bindGroup);\n    this.computePassEncoder.dispatchWorkgroups(\n        program.dispatch[0], program.dispatch[1], program.dispatch[2]);\n    this.dispatchCountInPass++;\n\n    if (shouldTimeProgram ||\n        env().get('WEBGPU_DEFERRED_SUBMIT_BATCH_SIZE') as\n            number <= this.dispatchCountInPass ||\n        program.pixelsOpType === webgpu_program.PixelsOpType.DRAW) {\n      this.endComputePassEncoder();\n      if (shouldTimeProgram) {\n        this.activeTimers.push(\n            {name: program.constructor.name, query: this.getQueryTime()});\n      } else {\n        this.submitQueue();\n      }\n    }\n  }\n\n  async getQueryTime(): Promise<number> {\n    if (!this.supportTimestampQuery) {\n      return 0;\n    }\n\n    if (this.queryResolveBuffer == null) {\n      this.queryResolveBuffer = this.bufferManager.acquireBuffer(\n          this.querySetCount * 8,\n          GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST |\n              GPUBufferUsage.QUERY_RESOLVE);\n    }\n    this.commandEncoder.resolveQuerySet(\n        this.querySet, 0, this.querySetCount, this.queryResolveBuffer, 0);\n\n    const queryStagingBuffer = this.bufferManager.acquireBuffer(\n        this.querySetCount * 8,\n        GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);\n\n    this.commandEncoder.copyBufferToBuffer(\n        this.queryResolveBuffer, 0, queryStagingBuffer, 0,\n        this.querySetCount * 8);\n\n    this.submitQueue();\n\n    await queryStagingBuffer.mapAsync(GPUMapMode.READ);\n    const arrayBuffer = new BigUint64Array(queryStagingBuffer.getMappedRange());\n    const time = Number(arrayBuffer[1] - arrayBuffer[0]) / 1000000;\n    queryStagingBuffer.unmap();\n    this.bufferManager.releaseBuffer(queryStagingBuffer);\n    return time;\n  }\n\n  shouldExecuteOnCPU(\n      inputs: TensorInfo[],\n      sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD): boolean {\n    return env().getBool('WEBGPU_CPU_FORWARD') &&\n        inputs.every(\n            input => this.tensorMap.get(input.dataId).resource == null &&\n                util.sizeFromShape(input.shape) < sizeThreshold);\n  }\n\n  override numDataIds() {\n    return this.tensorMap.numDataIds() - this.tensorDataPendingDisposal.length;\n  }\n\n  override dispose() {\n    if (this.disposed) {\n      return;\n    }\n    if (this.querySet != null) {\n      this.querySet.destroy();\n    }\n    this.bufferManager.dispose();\n    this.textureManager.dispose();\n    this.disposed = true;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport './flags_webgpu';\n\nimport {env, registerBackend} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from './backend_webgpu';\nimport {isWebGPUSupported} from './webgpu_util';\n\nif (isWebGPUSupported()) {\n  registerBackend('webgpu', async () => {\n    const gpuDescriptor: GPURequestAdapterOptions = {\n      powerPreference: env().get('WEBGPU_USE_LOW_POWER_GPU') ?\n          'low-power' :\n          'high-performance'\n    };\n\n    const adapter = await navigator.gpu.requestAdapter(gpuDescriptor);\n    const deviceDescriptor: GPUDeviceDescriptor = {};\n\n    const requiredFeatures = [];\n    if (adapter.features.has('timestamp-query')) {\n      requiredFeatures.push('timestamp-query');\n    }\n    if (adapter.features.has('bgra8unorm-storage')) {\n      requiredFeatures.push(['bgra8unorm-storage']);\n    }\n    deviceDescriptor.requiredFeatures =\n        requiredFeatures as Iterable<GPUFeatureName>;\n\n    const adapterLimits = adapter.limits;\n    deviceDescriptor.requiredLimits = {\n      'maxComputeWorkgroupStorageSize':\n          adapterLimits.maxComputeWorkgroupStorageSize,\n      'maxComputeWorkgroupsPerDimension':\n          adapterLimits.maxComputeWorkgroupsPerDimension,\n      'maxStorageBufferBindingSize': adapterLimits.maxStorageBufferBindingSize,\n      'maxBufferSize': adapterLimits.maxBufferSize,\n      'maxComputeWorkgroupSizeX': adapterLimits.maxComputeWorkgroupSizeX,\n      'maxComputeInvocationsPerWorkgroup':\n          adapterLimits.maxComputeInvocationsPerWorkgroup,\n    };\n\n    const device: GPUDevice = await adapter.requestDevice(deviceDescriptor);\n    const adapterInfo =\n      'info' in adapter\n        ? adapter.info\n        : 'requestAdapterInfo' in adapter\n          // tslint:disable-next-line:no-any\n          ? await (adapter as any).requestAdapterInfo()\n          : undefined;\n    return new WebGPUBackend(device, adapterInfo);\n  }, 3 /*priority*/);\n}\n\n// Export webgpu utilities\nexport * from './webgpu';\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport enum BinaryOpType {\n  ADD,\n  ATAN2,\n  COMPLEX_MULTIPLY_IMAG,\n  COMPLEX_MULTIPLY_REAL,\n  DIV,\n  ELU_DER,\n  EQUAL,\n  FLOOR_DIV,\n  GREATER,\n  GREATER_EQUAL,\n  LESS,\n  LESS_EQUAL,\n  LOGICAL_AND,\n  LOGICAL_OR,\n  MAX,\n  MIN,\n  MOD,\n  MUL,\n  NOT_EQUAL,\n  POW,\n  PRELU,\n  SQUARED_DIFFERENCE,\n  SUB\n}\n\nconst ADD = 'let resultTemp = a + b;';\nconst ATAN2 = 'let resultTemp = atan2(a, b);';\n// (Ar + Ai)(Br + Bi) =\n// ArBr + ArBi + AiBr + AiBi = ArBr - AB + ArBi + AiBr\n// Yr = ArBr - AB\n// Yi = ArBi + AiBr\nconst COMPLEX_MULTIPLY_REAL = 'let resultTemp = areal * breal - aimag * bimag;';\nconst COMPLEX_MULTIPLY_IMAG = 'let resultTemp = areal * bimag + aimag * breal;';\nconst DIV = 'let resultTemp = a / b;';\nconst ELU_DER = 'let resultTemp = select(a * (b + 1.0), a, b >= b - b);';\nconst EQUAL = `\n  let zero = sign(a) * 0 + 0;\n  let one = sign(b) * 0 + 1;\n  let resultTemp = select(zero, one, a == b);\n`;\nconst FLOOR_DIV = `\n  let remainder =\n      select(a % b, round(a % b), (round(a) == a) & (round(b) == b));\n  let quotient = (a - remainder) / b;\n  let resultTemp =\n      round(select(quotient, quotient - 1, sign(remainder) == -sign(b)));\n`;\nconst GREATER = `\n  let zero = sign(a) * 0 + 0;\n  let one = sign(b) * 0 + 1;\n  let resultTemp = select(zero, one, a > b);\n`;\nconst GREATER_EQUAL = `\n  let zero = sign(a) * 0 + 0;\n  let one = sign(b) * 0 + 1;\n  let resultTemp = select(zero, one, a >= b);\n`;\nconst LESS = `\n  let zero = sign(a) * 0 + 0;\n  let one = sign(b) * 0 + 1;\n  let resultTemp = select(zero, one, a < b);\n`;\nconst LESS_EQUAL = `\n  let zero = sign(a) * 0 + 0;\n  let one = sign(b) * 0 + 1;\n  let resultTemp = select(zero, one, a <= b);\n`;\nconst LOGICAL_AND = 'return f32(a >= 1.0 && b >= 1.0);';\nconst LOGICAL_AND_VEC4 = `return (vec4<f32>(a >= vec4<f32>(1.0)) *\n  vec4<f32>(b >= vec4<f32>(1.0)));`;\nconst LOGICAL_OR = 'return f32(a >= 1.0 || b >= 1.0);';\nconst LOGICAL_OR_VEC4 = `return min(vec4<f32>(a >= vec4<f32>(1.0)) +\n  vec4<f32>(b >= vec4<f32>(1.0)), vec4<f32>(1.0));`;\nconst MAX = 'let resultTemp = max(a, b);';\nconst MIN = 'let resultTemp = min(a, b);';\nconst MOD = `\n  let isNaN = b == 0.;\n  var resultTemp = a % b;\n  resultTemp = select((resultTemp + b) % b, resultTemp,\n      (a < 0. && b < 0.) || (a >= 0. && b > 0.));\n`;\nconst MOD_VEC4 = `\n  let isNaN = !vec4<bool>(b);\n  var resultTemp = vec4<f32>(a % b);\n  if (!((a[0] < 0. && b[0] < 0.) || (a[0] >= 0. && b[0] > 0.))) {\n    resultTemp[0] = (resultTemp[0] + b[0]) % b[0];\n  }\n  if (!((a[1] < 0. && b[1] < 0.) || (a[1] >= 0. && b[1] > 0.))) {\n    resultTemp[1] = (resultTemp[1] + b[1]) % b[1];\n  }\n  if (!((a[2] < 0. && b[2] < 0.) || (a[2] >= 0. && b[2] > 0.))) {\n    resultTemp[2] = (resultTemp[2] + b[2]) % b[2];\n  }\n  if (!((a[3] < 0. && b[3] < 0.) || (a[3] >= 0. && b[3] > 0.))) {\n    resultTemp[3] = (resultTemp[3] + b[3]) % b[3];\n  }\n`;\nconst MUL = 'let resultTemp = a * b;';\nconst NOT_EQUAL = `\n  var resultTemp = f32(a != b);\n  let valueForNaN = 1.0;\n`;\nconst NOT_EQUAL_VEC4 = `\n  var resultTemp = vec4<f32>(a != b);\n  let valueForNaN = 1.0;\n`;\n\nconst POW = `\n  let isNaN = a < 0.0 && floor(b) < b;\n  if (b == 0.0) {\n    return 1.0;\n  }\n  var resultTemp = select(sign(a) * pow(abs(a), b), pow(abs(a), b),\n      round(abs(b) % 2.0) != 1.0);\n`;\nconst POW_VEC4 = `\n  let isModRound1Bool = vec4<i32>(round(abs(b) % vec4<f32>(2.0))) == vec4<i32>(1);\n  let isModRound1 = vec4<f32>(isModRound1Bool);\n  let multiplier = sign(a) * isModRound1 + (vec4<f32>(1.0) - isModRound1);\n  var resultTemp = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  let isExpZero = b == vec4<f32>(0.0);\n  if (isExpZero.r) {\n    resultTemp.r = 1.0;\n  }\n  if (isExpZero.g) {\n    resultTemp.g = 1.0;\n  }\n  if (isExpZero.b) {\n    resultTemp.b = 1.0;\n  }\n  if (isExpZero.a) {\n    resultTemp.a = 1.0;\n  }\n  let isNaN = (a < vec4<f32>(0.0)) & (floor(b) < b);\n`;\n\nconst PRELU = `if (a < 0.0) { return b * a; }  return a;`;\nconst PRELU_VEC4 = `\n  let aLessThanZero = vec4<f32>(a < vec4<f32>(0.0));\n  return (aLessThanZero * (b * a)) + ((vec4<f32>(1.0) - aLessThanZero) * a);\n`;\nconst SQUARED_DIFFERENCE = 'let resultTemp = (a - b) * (a - b);';\nconst SUB = 'let resultTemp = a - b;';\n\nexport function getBinaryOpString(\n    type: BinaryOpType, useVec4?: boolean): string {\n  let doOpSnippet: string;\n\n  // Ops with NaN check\n  do {\n    switch (type) {\n      case BinaryOpType.ATAN2:\n        doOpSnippet = ATAN2;\n        break;\n      case BinaryOpType.MAX:\n        doOpSnippet = MAX;\n        break;\n      case BinaryOpType.MIN:\n        doOpSnippet = MIN;\n        break;\n      case BinaryOpType.MOD:\n        doOpSnippet = useVec4 ? MOD_VEC4 : MOD;\n        break;\n      case BinaryOpType.NOT_EQUAL:\n        doOpSnippet = useVec4 ? NOT_EQUAL_VEC4 : NOT_EQUAL;\n        break;\n      case BinaryOpType.POW:\n        doOpSnippet = useVec4 ? POW_VEC4 : POW;\n        break;\n      default:\n        continue;\n    }\n\n    let isNaN: string;\n    let dTypeN: string;\n    let boolN: string;\n    if (useVec4) {\n      isNaN = 'isnanVec4';\n      dTypeN = 'vec4<f32>';\n      boolN = 'vec4<bool>';\n    } else {\n      isNaN = 'isnan';\n      dTypeN = 'f32';\n      boolN = 'bool';\n    }\n\n    return `\n      let aIsNaN = ${isNaN}(a);\n      let aPostLegalization = select(a, ${dTypeN}(42), aIsNaN);\n      let bIsNaN = ${isNaN}(b);\n      let bPostLegalization = select(b, ${dTypeN}(42), bIsNaN);\n      let isNaN = false;\n      let valueForNaN = uniforms.NAN;\n      {\n        let a = aPostLegalization;\n        let b = bPostLegalization;\n        ${doOpSnippet}\n        return select(\n            resultTemp, ${dTypeN}(valueForNaN),\n            ${boolN}(isNaN) | aIsNaN | bIsNaN);\n      }\n    `;\n  } while (false);\n\n  // Ops without NaN check\n  switch (type) {\n    case BinaryOpType.ADD:\n      doOpSnippet = ADD;\n      break;\n    case BinaryOpType.COMPLEX_MULTIPLY_IMAG:\n      doOpSnippet = COMPLEX_MULTIPLY_IMAG;\n      break;\n    case BinaryOpType.COMPLEX_MULTIPLY_REAL:\n      doOpSnippet = COMPLEX_MULTIPLY_REAL;\n      break;\n    case BinaryOpType.DIV:\n      doOpSnippet = DIV;\n      break;\n    case BinaryOpType.ELU_DER:\n      doOpSnippet = ELU_DER;\n      break;\n    case BinaryOpType.EQUAL:\n      doOpSnippet = EQUAL;\n      break;\n    case BinaryOpType.FLOOR_DIV:\n      doOpSnippet = FLOOR_DIV;\n      break;\n    case BinaryOpType.GREATER:\n      doOpSnippet = GREATER;\n      break;\n    case BinaryOpType.GREATER_EQUAL:\n      doOpSnippet = GREATER_EQUAL;\n      break;\n    case BinaryOpType.LESS:\n      doOpSnippet = LESS;\n      break;\n    case BinaryOpType.LESS_EQUAL:\n      doOpSnippet = LESS_EQUAL;\n      break;\n    case BinaryOpType.LOGICAL_AND:\n      return useVec4 ? LOGICAL_AND_VEC4 : LOGICAL_AND;\n    case BinaryOpType.LOGICAL_OR:\n      return useVec4 ? LOGICAL_OR_VEC4 : LOGICAL_OR;\n    case BinaryOpType.MUL:\n      doOpSnippet = MUL;\n      break;\n    case BinaryOpType.PRELU:\n      return useVec4 ? PRELU_VEC4 : PRELU;\n    case BinaryOpType.SQUARED_DIFFERENCE:\n      doOpSnippet = SQUARED_DIFFERENCE;\n      break;\n    case BinaryOpType.SUB:\n      doOpSnippet = SUB;\n      break;\n    default:\n      // throw new Error(`BinaryType ${type} is not implemented!`);\n  }\n  return `\n    ${doOpSnippet}\n    return resultTemp;\n  `;\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nexport enum UnaryOpType {\n  ABS,\n  ACOS,\n  ACOSH,\n  ASIN,\n  ASINH,\n  ATAN,\n  ATANH,\n  CEIL,\n  COS,\n  COSH,\n  ELU,\n  ERF,\n  EXP,\n  EXPM1,\n  FLOOR,\n  IS_FINITE,\n  IS_INF,\n  IS_NAN,\n  LINEAR,\n  LOG,\n  LOG1P,\n  LOGICAL_NOT,\n  NEG,\n  RELU,\n  RELU6,\n  LEAKYRELU,\n  RECIPROCAL,\n  ROUND,\n  RSQRT,\n  SELU,\n  SIGMOID,\n  SIGN,\n  SIN,\n  SINH,\n  SOFTPLUS,\n  SQRT,\n  SQUARE,\n  STEP,\n  TAN,\n  TANH,\n  TO_INT\n}\n\nconst ABS = `return abs(a);`;\nconst ACOS = `\n  if (abs(a) > 1.) {\n    return uniforms.NAN;\n  }\n  return acos(a);\n`;\nconst ACOSH = `\n  if (a < 1.) {\n    return uniforms.NAN;\n  }\n  return acosh(a);\n`;\nconst ASIN = `\n  if (abs(a) > 1.) {\n    return uniforms.NAN;\n  }\n  return asin(a);\n`;\nconst ASINH = `return asinh(a);`;\nconst ATAN = `\n  if (isnan(a)) {\n    return uniforms.NAN;\n  }\n  return atan(a);\n`;\nconst ATANH = `\n  if (abs(a) > 1.) {\n    return uniforms.NAN;\n  }\n  if (a == 1.) {\n    return uniforms.INFINITY;\n  }\n  if (a == -1.) {\n    return -uniforms.INFINITY;\n  }\n  return atanh(a);\n`;\nconst CEIL = `return ceil(a);`;\nconst COS = `return cos(a);`;\nconst COSH = `\n  let e2x = exp(-a);\n  return (e2x + 1.0 / e2x) / 2.0;\n`;\nconst EXPM1 = `return exp(a) - 1.0;`;\nconst ELU = `if (a >= 0.0) { return a; }  return (exp(a) - 1.0);`;\nconst ELU_VEC4 = `\n  var resFloat = exp(a) - vec4<f32>(1.0);\n  if (a.r >= 0.0) {\n    resFloat.r = a.r;\n  }\n  if (a.g >= 0.0) {\n    resFloat.g = a.g;\n  }\n  if (a.b >= 0.0) {\n    resFloat.b = a.b;\n  }\n  if (a.a >= 0.0) {\n    resFloat.a = a.a;\n  }\n  return resFloat;\n`;\nconst ERF = `\n  // Error function is calculated approximately with elementary function.\n  // See \"Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables\", Abramowitz and Stegun.\n  let p = ${backend_util.ERF_P};\n  let a1 = ${backend_util.ERF_A1};\n  let a2 = ${backend_util.ERF_A2};\n  let a3 = ${backend_util.ERF_A3};\n  let a4 = ${backend_util.ERF_A4};\n  let a5 = ${backend_util.ERF_A5};\n\n  let sign = sign(a);\n  let absA = abs(a);\n  let t = 1.0 / (1.0 + p * absA);\n  return sign * (1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * exp(-absA * absA));\n`;\nconst EXP = `return exp(a);`;\nconst FLOOR = `return floor(a);`;\nconst IS_FINITE = `return f32(!isnan(a) && !isinf(a));`;\nconst IS_INF = `return f32(isinf(a));`;\nconst IS_NAN = `return f32(isnan(a));`;\nconst LINEAR = `return a;`;\nconst LOG = `if (a < 0.0) { return uniforms.NAN; }\n  return log(a);`;\nconst LOG1P = `\n  if (isnan(a)) { return a; }\n  return log(1.0 + a);\n`;\nconst LOGICAL_NOT = `return f32(!(a >= 1.0));`;\nconst NEG = `return -a;`;\nconst LEAKYRELU = `if (a < 0.0) { return uniforms.alpha * a; } return a;`;\nconst LEAKYRELU_VEC4 = `\n  let aLessThanZero = vec4<f32>(a < vec4<f32>(0.0));\n  return (aLessThanZero * (uniforms.alpha * a)) + ((vec4<f32>(1.0) - aLessThanZero) * a);\n`;\nconst RECIPROCAL = `return 1.0 / a;`;\nconst RELU = `return select(a, 0.0, a < 0.0);`;\nconst RELU6 = 'return clamp(a, 0.0, 6.0);';\nconst RELU6_VEC4 =\n    'return clamp(a, vec4<f32>(0.0, 0.0, 0.0, 0.0), vec4<f32>(6.0, 6.0, 6.0, 6.0));';\nconst RELU_VEC4 = `\n  return select(a, vec4<f32>(0.0), a < vec4<f32>(0.0));\n`;\nconst ROUND = `return round(a);`;\nconst RSQRT = `return inverseSqrt(a);`;\n// Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n// See: https://arxiv.org/abs/1706.02515\nconst SELU = `\n  if (a >= 0.0) {\n    return ${backend_util.SELU_SCALE} * a;\n  } else {\n    return ${backend_util.SELU_SCALEALPHA} * (exp(a) - 1.0);\n  }\n`;\nconst SIGMOID = `return 1.0 / (1.0 + exp(-1.0 * a));`;\nconst SIGN = `return sign(a);`;\nconst SIN = `return sin(a);`;\nconst SINH = `\n  let e2x = exp(a);\n  return (e2x - 1.0 / e2x) / 2.0;\n`;\nconst SOFTPLUS = `\n  let epsilon = 1.1920928955078125e-7;\n  let threshold = log(epsilon) + 2.0;\n\n  let too_large = a > -threshold;\n  let too_small = a < threshold;\n  let exp_a = exp(a);\n\n  if (too_large) {\n    return a;\n  } else if (too_small) {\n    return exp_a;\n  } else {\n    return log(exp_a + 1.0);\n  }\n`;\nconst SQRT = `return sqrt(a);`;\nconst SQUARE = `return a * a;`;\nconst STEP = `\n  if (isnan(a)) {\n    return a;\n  }\n\n  return select(uniforms.stepAlpha, 1.0, a > 0.0);\n`;\nconst TAN = `return tan(a);`;\nconst TANH = `\n  let e2x = exp(-2.0 * abs(a));\n  return sign(a) * (1.0 - e2x) / (1.0 + e2x);\n`;\nconst TO_INT = `return f32(i32((a)));`;\n\nexport function getUnaryOpString(type: UnaryOpType, useVec4?: boolean): string {\n  switch (type) {\n    case UnaryOpType.ABS:\n      return ABS;\n    case UnaryOpType.ACOS:\n      return ACOS;\n    case UnaryOpType.ACOSH:\n      return ACOSH;\n    case UnaryOpType.ASIN:\n      return ASIN;\n    case UnaryOpType.ASINH:\n      return ASINH;\n    case UnaryOpType.ATAN:\n      return ATAN;\n    case UnaryOpType.ATANH:\n      return ATANH;\n    case UnaryOpType.COS:\n      return COS;\n    case UnaryOpType.COSH:\n      return COSH;\n    case UnaryOpType.CEIL:\n      return CEIL;\n    case UnaryOpType.ELU:\n      return useVec4 ? ELU_VEC4 : ELU;\n    case UnaryOpType.ERF:\n      return ERF;\n    case UnaryOpType.EXP:\n      return EXP;\n    case UnaryOpType.EXPM1:\n      return EXPM1;\n    case UnaryOpType.FLOOR:\n      return FLOOR;\n    case UnaryOpType.IS_FINITE:\n      return IS_FINITE;\n    case UnaryOpType.IS_INF:\n      return IS_INF;\n    case UnaryOpType.IS_NAN:\n      return IS_NAN;\n    case UnaryOpType.LINEAR:\n      return LINEAR;\n    case UnaryOpType.LOG:\n      return LOG;\n    case UnaryOpType.LOG1P:\n      return LOG1P;\n    case UnaryOpType.LOGICAL_NOT:\n      return LOGICAL_NOT;\n    case UnaryOpType.NEG:\n      return NEG;\n    case UnaryOpType.LEAKYRELU:\n      return useVec4 ? LEAKYRELU_VEC4 : LEAKYRELU;\n    case UnaryOpType.RECIPROCAL:\n      return RECIPROCAL;\n    case UnaryOpType.RELU:\n      return useVec4 ? RELU_VEC4 : RELU;\n    case UnaryOpType.RELU6:\n      return useVec4 ? RELU6_VEC4 : RELU6;\n    case UnaryOpType.ROUND:\n      return ROUND;\n    case UnaryOpType.RSQRT:\n      return RSQRT;\n    case UnaryOpType.SELU:\n      return SELU;\n    case UnaryOpType.SIGMOID:\n      return SIGMOID;\n    case UnaryOpType.SIGN:\n      return SIGN;\n    case UnaryOpType.SIN:\n      return SIN;\n    case UnaryOpType.SINH:\n      return SINH;\n    case UnaryOpType.SOFTPLUS:\n      return SOFTPLUS;\n    case UnaryOpType.SQRT:\n      return SQRT;\n    case UnaryOpType.SQUARE:\n      return SQUARE;\n    case UnaryOpType.STEP:\n      return STEP;\n    case UnaryOpType.TAN:\n      return TAN;\n    case UnaryOpType.TANH:\n      return TANH;\n    case UnaryOpType.TO_INT:\n      return TO_INT;\n\n    default:\n      throw new Error(`BinaryType ${type} is not implemented!`);\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType, getBinaryOpString} from './binary_op_util';\nimport {getUnaryOpString, UnaryOpType} from './unary_op_util';\nimport {typeSnippet} from './webgpu_program';\n\nexport function activationFnSnippet(\n    activation: backend_util.Activation, hasPreluActivationWeights = false,\n    packed = false, coordsLength = 3): string {\n  if (activation === null) {\n    return '';\n  }\n\n  let activationOpSnippet = '';\n  if (activation === 'linear') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.LINEAR);\n  } else if (activation === 'relu') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.RELU, packed);\n  } else if (activation === 'elu') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.ELU, packed);\n  } else if (activation === 'relu6') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.RELU6, packed);\n  } else if (activation === 'prelu') {\n    activationOpSnippet = getBinaryOpString(BinaryOpType.PRELU, packed);\n  } else if (activation === 'sigmoid') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.SIGMOID, packed);\n  } else if (activation === 'leakyrelu') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.LEAKYRELU, packed);\n  } else {\n    throw new Error(`Activation ${\n        activation} has not been implemented for the WebGPU backend.`);\n  }\n  const elementSize = packed ? 4 : 1;\n  const dataType = typeSnippet(elementSize);\n  let activationFnSnippet = '';\n  if (hasPreluActivationWeights) {\n    activationFnSnippet = `\n      fn activation(a : ${dataType}, coords : vec${coordsLength}<i32>) -> ${\n        dataType} {\n        let b = getPreluActivationWeightsByOutputCoords(coords);\n        ${activationOpSnippet}\n      }`;\n  } else {\n    activationFnSnippet = `\n      fn activation(a : ${dataType}, coords : vec${coordsLength}<i32>) -> ${\n        dataType} {\n        ${activationOpSnippet}\n      }`;\n  }\n  return activationFnSnippet;\n}\n\nexport function biasActivationSnippet(\n    hasBias: boolean, activation: backend_util.Activation): string {\n  return `\n      ${hasBias ? 'value = value + getBiasByOutputCoords(coords);' : ''}\n      ${activation ? 'value = activation(value, coords);' : ''}\n      `;\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, typeSnippet, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, computeWorkgroupInfoForMatMul} from './webgpu_util';\n\nexport function matMulReadFnSource(\n    transposeA: boolean, transposeB: boolean, fitAOuter = false,\n    fitBOuter = false, fitInner = false, component = 1) {\n  util.assert(\n      transposeA && component === 1 || !transposeA,\n      () => `transposeA ${transposeA} is not compatible with component size ${\n          component}`);\n  const sampleA = `\n      ${\n      transposeA ? `value = getA(batch, col, row);` :\n                   `value = getA(batch, row, col);`}\n\n    `;\n  const sampleB = transposeB ? `value = getB(batch, col, row);` :\n                               `value = getB(batch, row, col);`;\n\n  return `\n  fn mm_readA(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {\n    var value = ${typeSnippet(component)}(0.0);\n    ${\n      fitAOuter && fitInner ?\n          sampleA :\n          `\n    ${\n              transposeA ?\n                  `if(row < uniforms.dimAOuter && col < uniforms.dimInner)` :\n                  `if(row < uniforms.aShape[1] && col < uniforms.aShape[2])`}\n    {\n      ${sampleA}\n    }\n    `}\n    return value;\n  }\n\n  fn mm_readB(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {\n    var value = ${typeSnippet(component)}(0.0);\n    ${sampleB}\n    return value;\n  }\n  `;\n}\n\nexport function matMulReadWriteFnSource(\n    hasBias: boolean, activation: backend_util.Activation, transposeA: boolean,\n    transposeB: boolean, fitAOuter = false, fitBOuter = false, fitInner = false,\n    component = 1) {\n  return `\n  ${\n      matMulReadFnSource(\n          transposeA, transposeB, fitAOuter, fitBOuter, fitInner, component)}\n  fn mm_write(batch: i32, row: i32, col: i32, valueIn: ${\n      typeSnippet(component)}) {\n    ${\n      fitAOuter && fitBOuter ?\n          '' :\n          'if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)'}\n    {\n      var value = valueIn;\n      let coords = vec3<i32>(batch, row, col);\n      ${biasActivationSnippet(hasBias, activation)}\n      setOutputAtCoords(coords[0], coords[1], coords[2], value);\n    }\n  }\n  `;\n}\n\nconst writeDataToSubAVec4Snippet =\n    (transpose: boolean, innerElementSize: number) => {\n      if (transpose) {\n        return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          kStart + inputRow,\n          globalRowStart + inputCol * ${innerElementSize});\n        `;\n\n      } else {\n        return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          globalRow + innerRow,\n          kStart + inputCol * ${innerElementSize});\n        `;\n      }\n    };\n\nconst calculateResultSnippet =\n    (transposeA: boolean, innerElementSize: number, rowPerThread: number,\n     tileInner: number) => {\n      if (transposeA) {\n        return `\n      for (var k = 0; k < ${tileInner}; k++) {\n        let BCached0 = mm_Bsub[k][tileCol];\n        let ACached0 = mm_Asub[k][localRow];\n        for (var i = 0; i < ${rowPerThread}; i++) {\n          acc[i] = fma(BCached0, vec4<f32>(ACached0[i]), acc[i]);\n        }\n      }`;\n      } else {\n        let bCachedStr = '';\n        let accStr = '';\n        for (let i = 0; i < innerElementSize; i++) {\n          bCachedStr += `let BCached${i} = mm_Bsub[k * ${innerElementSize} + ${\n              i}][tileCol];`;\n          accStr +=\n              `acc[i] = fma(BCached${i}, vec4<f32>(ACached[${i}]), acc[i]);`;\n        }\n        return `\n      for (var k = 0; k < ${tileInner / innerElementSize}; k++) {\n        ${bCachedStr}\n        for (var i = 0; i < ${rowPerThread}; i++) {\n          let ACached = mm_Asub[tileRow + i][k];\n          ${accStr}\n        }\n      }`;\n      }\n    };\n\nexport function makeMatMulPackedVec4Source(\n    workPerThread: number[], workgroupSize: [number, number, number],\n    transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n    broadcastBatch = false): string {\n  const tileAOuter = workgroupSize[1] * workPerThread[1];\n  const tileBOuter = workgroupSize[0] * workPerThread[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  const innerElementSize = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  util.assert(\n      ((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n       (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n          tileAWidth % workgroupSize[0] === 0 &&\n          tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4,\n      () => `If transposeA ${transposeA} is true, innerElementSize ${\n          innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n          Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n      tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${\n          workgroupSize[0]}. tileInner ${\n          tileInner} must be divisible by workgroupSize[1] ${\n          workgroupSize[1]}. colPerThread ${workPerThread[0]} must be 4.`);\n  return `\n  var<workgroup> mm_Asub : array<array<vec${innerElementSize}<f32>, ${\n      tileAWidth / innerElementSize}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<vec4<f32>, ${\n      tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\n  ${main()} {\n    let localRow = i32(localId.y);\n    let tileRow = localRow * ${rowPerThread};\n    let tileCol = i32(localId.x);\n\n    let globalRow = i32(globalId.y) * ${rowPerThread};\n    let globalCol = i32(globalId.x) * ${colPerThread};\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    let batchA = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};\n    let batchB = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n    let numTiles = ${\n      splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :\n               `(uniforms.dimInner - 1) / ${tileInner} + 1`};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc: array<vec4<f32>, ${rowPerThread}>;\n\n    // Loop over shared dimension.\n    let tileRowB = localRow * ${rowPerThreadB};\n    for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n            let inputRow = tileRow + innerRow;\n            let inputCol = tileCol;\n            ${writeDataToSubAVec4Snippet(transposeA, innerElementSize)}\n        }\n\n        // Load one tile of B into local memory.\n        for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {\n            let inputRow = tileRowB + innerRow;\n            let inputCol = tileCol;\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB, kStart + inputRow, globalCol);\n        }\n        kStart = kStart + ${tileInner};\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        ${\n      calculateResultSnippet(\n          transposeA, innerElementSize, rowPerThread, tileInner)}\n        workgroupBarrier();\n    }\n\n    for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n    }\n  }`;\n}\n\nconst writeDataToSubASnippet = (transpose: boolean) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          kStart + inputRow,\n          globalRowStart + inputCol);\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          globalRowStart + inputRow,\n          kStart + inputCol);\n        `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) => {\n  return transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' :\n\n                      'let ACached = mm_Asub[tileRow + innerRow][k];';\n};\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport function makeMatMulPackedSource(\n    workPerThread: number[], workgroupSize: [number, number, number],\n    transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n    sequentialAccessByThreads = false, broadcastBatch = false): string {\n  const tileAOuter = workPerThread[1] * workgroupSize[1];\n  const tileBOuter = workPerThread[0] * workgroupSize[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  util.assert(\n      tileAHight % workgroupSize[1] === 0 &&\n          tileAWidth % workgroupSize[0] === 0 &&\n          tileInner % workgroupSize[1] === 0,\n      () => `tileAHight ${tileAHight} must be divisible by workgroupSize[1]${\n          workgroupSize[1]}, tileAWidth ${\n          tileAWidth} must be divisible by workgroupSize[0]${\n          workgroupSize[0]}, tileInner ${\n          tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);\n  const rowPerThreadA = tileAHight / workgroupSize[1];\n  const colPerThreadA = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  const matmulSnippet = sequentialAccessByThreads ?\n      `\n      let localRow = i32(localId.y);\n      let localCol = i32(localId.x);\n      let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n      let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        for (var inputRow = localRow; inputRow < ${\n          tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n          for (var inputCol = localCol; inputCol < ${\n          tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n            ${writeDataToSubASnippet(transposeA)}\n          }\n        }\n        // Load one tile of B into local memory.\n        for (var inputRow = localRow; inputRow < ${\n          tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n              for (var inputCol = localCol; inputCol < ${\n          tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\n              kStart + inputRow,\n              globalColStart + inputCol);\n          }\n        }\n        kStart = kStart + ${tileInner};\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        var BCached : array<f32, ${colPerThread}>;\n        for (var k = 0; k < ${tileInner}; k++) {\n          for (var inner = 0; inner < ${colPerThread}; inner++) {\n            BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n          }\n          for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n            let ACached = ${\n          transposeA ?\n              `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` :\n              `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}\n            for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n              acc[innerRow][innerCol] =\n                  fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\n            }\n          }\n        }\n        workgroupBarrier();\n      }\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n          mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n        }\n      }\n      ` :\n      `\n  let tileRow = i32(localId.y) * ${rowPerThread};\n  let tileCol = i32(localId.x) * ${colPerThread};\n\n  let globalRow = i32(globalId.y) * ${rowPerThread};\n  let globalCol = i32(globalId.x) * ${colPerThread};\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let tileRowA = i32(localId.y) * ${rowPerThreadA};\n  let tileColA = i32(localId.x) * ${colPerThreadA};\n  let tileRowB = i32(localId.y) * ${rowPerThreadB};\n  // Loop over shared dimension.\n  for (var t = 0; t < numTiles; t++) {\n    // Load one tile of A into local memory.\n    for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow++) {\n      for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol++) {\n        let inputRow = tileRowA + innerRow;\n        let inputCol = tileColA + innerCol;\n        ${writeDataToSubASnippet(transposeA)}\n      }\n    }\n\n    // Load one tile of B into local memory.\n    for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {\n      for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n        let inputRow = tileRowB + innerRow;\n        let inputCol = tileCol + innerCol;\n        mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\n          kStart + inputRow,\n          globalCol + innerCol);\n      }\n    }\n    kStart = kStart + ${tileInner};\n    workgroupBarrier();\n\n    // Compute acc values for a single thread.\n    var BCached : array<f32, ${colPerThread}>;\n    for (var k = 0; k < ${tileInner}; k++) {\n      for (var inner = 0; inner < ${colPerThread}; inner++) {\n        BCached[inner] = mm_Bsub[k][tileCol + inner];\n      }\n\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        ${readDataFromSubASnippet(transposeA)}\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          acc[innerRow][innerCol] =\n              fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\n        }\n      }\n    }\n\n    workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n    for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n      mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n          acc[innerRow][innerCol]);\n    }\n  }\n  `;\n\n  return `\n    var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHight}>;\n    var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;\n\n    ${main()} {\n      let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n      let batchA = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};\n      let batchB = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};\n      let numTiles = ${\n      splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :\n               `(uniforms.dimInner - 1) / ${tileInner} + 1`};\n      var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n      var acc : array<array<f32, ${colPerThread}>, ${rowPerThread}>;\n\n      // Without this initialization strange values show up in acc.\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          acc[innerRow][innerCol] = 0.0;\n        }\n      }\n      ${matmulSnippet}\n    }\n  `;\n}\n\nconst readVectorASnippet = (transpose: boolean) => {\n  return transpose ? `\n      mm_readA(batchA, colA, globalRow),\n      mm_readA(batchA, colA + 1, globalRow),\n      mm_readA(batchA, colA + 2, globalRow),\n      mm_readA(batchA, colA + 3, globalRow)\n  ` :\n                     `\n      mm_readA(batchA, globalRow, colA),\n      mm_readA(batchA, globalRow, colA + 1),\n      mm_readA(batchA, globalRow, colA + 2),\n      mm_readA(batchA, globalRow, colA + 3)\n  `;\n};\n\nexport function makeVectorMatrixProductSource(\n    workgroupSize: [number, number, number], transposeA = false): string {\n  util.assert(\n      workgroupSize[1] === 1 && workgroupSize[2] === 1,\n      () => `A linear work group size is required. But got ${workgroupSize}.`);\n  const tileSize = workgroupSize[0] * 4;\n  return `\n    var<workgroup> mm_Asub : array<vec4<f32>, ${workgroupSize[0]}>;\n\n    ${main()} {\n      let tileCol = i32(localId.x);\n      let globalCol = i32(globalId.x);\n      let globalRow = i32(globalId.y);\n\n      let numTiles = (uniforms.dimInner - 1) / ${tileSize} + 1;\n      let batch = i32(globalId.z);\n      let batchA = batch % uniforms.aShape[0];\n      let batchB = batch % uniforms.bShape[0];\n      // Without this initialization strange values show up in acc.\n      var acc = 0.0;\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        let colA = t * ${tileSize} + tileCol * 4;\n        mm_Asub[tileCol] = vec4<f32>(${readVectorASnippet(transposeA)});\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        for (var k = 0; k < ${tileSize / 4}; k++) {\n          let rowB = t * ${tileSize} + k * 4;\n          let BCached = vec4<f32>(mm_readB(batchB, rowB, globalCol),\n                              mm_readB(batchB, rowB + 1, globalCol),\n                              mm_readB(batchB, rowB + 2, globalCol),\n                              mm_readB(batchB, rowB + 3, globalCol));\n\n          let ACached = mm_Asub[k];\n          acc = acc + dot(ACached, BCached);\n        }\n\n        workgroupBarrier();\n      }\n\n      mm_write(batch, globalRow, globalCol, acc);\n    }\n  `;\n}\n\nexport class MatMulPackedProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number];\n  elementsPerThread: [number, number, number];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  fitAOuter: boolean;\n  fitBOuter: boolean;\n  fitInner: boolean;\n  tileInner: number;\n  isVectorA: boolean;\n  isVec4: boolean;\n  outputComponent: number;\n  private sequentialAccessByThreads: boolean;\n\n  constructor(\n      aShape: [number, number, number], outputShape: [number, number, number],\n      transposeA = false, transposeB = false, bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null,\n      sequentialAccessByThreads = false) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [2], y: [1], z: [0]};\n    const dimInner = transposeA ? aShape[1] : aShape[2];\n    this.isVec4 = ((dimInner % 4 === 0 && !transposeA) ||\n                   (outputShape[1] % 4 === 0 && transposeA)) &&\n        outputShape[2] % 4 === 0 && !transposeB;\n    this.outputComponent = this.isVec4 ? 4 : 1;\n    this.isVectorA = outputShape[1] === 1 && !transposeA;\n\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.elementsPerThread = [1, 1, 1];\n      this.workgroupSize = [32, 1, 1];\n    } else {\n      const workgroupInfo = computeWorkgroupInfoForMatMul(\n          outputShape[1], dimInner, outputShape[2], transposeA);\n      this.workgroupSize = workgroupInfo.workgroupSize;\n      this.elementsPerThread = workgroupInfo.elementsPerThread;\n    }\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        this.elementsPerThread);\n\n    const addBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.sequentialAccessByThreads = sequentialAccessByThreads;\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    [this.fitAOuter, this.fitBOuter, this.fitInner] =\n        this.getShapeFit(outputShape[1], outputShape[2], dimInner);\n    this.shaderKey = `matMulPacked_${this.elementsPerThread}_${transposeA}_${\n        transposeB}_${this.activation}_${this.fitAOuter}_${this.fitBOuter}_${\n        this.fitInner}_${this.isVec4}_${this.isVectorA}_${\n        this.sequentialAccessByThreads}`;\n  }\n\n  getShapeFit(dimAOuter: number, dimBOuter: number, dimInner: number):\n      boolean[] {\n    const tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];\n    const tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];\n\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.tileInner = this.workgroupSize[0] * 4;\n    } else {\n      this.tileInner = tileBOuter;\n    }\n\n    const fitAOuter = dimAOuter % tileAOuter === 0;\n    const fitBOuter = dimBOuter % tileBOuter === 0;\n    const fitInner = dimInner % this.tileInner === 0;\n    return [fitAOuter, fitBOuter, fitInner];\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${\n        activationFnSnippet(\n            this.activation, this.hasPreluActivationWeights, this.isVec4)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation,\n            false /* transposeA is implemented in makeMatMulPackedSource */,\n            this.transposeB, this.fitAOuter, this.fitBOuter, this.fitInner,\n            this.isVec4 ? 4 : 1)}\n      ${\n        this.isVec4 ?\n            makeMatMulPackedVec4Source(\n                this.elementsPerThread, this.workgroupSize, this.transposeA,\n                this.tileInner, false, null, true) :\n            (this.isVectorA ? makeVectorMatrixProductSource(\n                                  this.workgroupSize, this.transposeA) :\n                              makeMatMulPackedSource(\n                                  this.elementsPerThread, this.workgroupSize,\n                                  this.transposeA, this.tileInner, false, null,\n                                  this.sequentialAccessByThreads, true))}\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet} from './activation_util';\nimport {matMulReadWriteFnSource} from './matmul_packed_webgpu';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport function makeMatMulReduceSource(workgroupSizeX: number): string {\n  return `\n    var<workgroup> sumValues : array<f32, ${workgroupSizeX}>;\n    ${main()} {\n      let coords = getOutputCoords();\n      let batch = coords[0];\n      let batchA = batch % uniforms.aShape[0];\n      let batchB = batch % uniforms.bShape[0];\n      let row = coords[1];\n      let col = coords[2];\n      var sum = 0.0;\n      let Length = uniforms.dimInner;\n      for (var k = i32(localId.x); k < Length; k = k + ${workgroupSizeX}) {\n        let dataA = mm_readA(batchA, row, k);\n        let dataB = mm_readB(batchB, k, col);\n        sum = sum + dataA * dataB;\n      }\n      sumValues[localId.x] = sum;\n      workgroupBarrier();\n\n      for(var currentSize = ${workgroupSizeX / 2}u; currentSize > 1u;\n          currentSize = currentSize / 2u) {\n        if (localId.x < currentSize)\n        {\n          sumValues[localId.x] = sumValues[localId.x] + sumValues[localId.x + currentSize];\n        }\n        workgroupBarrier();\n      }\n\n      if (localId.x == 0u) {\n        sum = sumValues[0] + sumValues[1];\n        mm_write(batch, row, col, sum);\n      }\n    }\n  `;\n}\n\nexport class MatMulReduceProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n\n  constructor(\n      outputShape: [number, number, number], transposeA = false,\n      transposeB = false, bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [], y: [1, 2], z: [0]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    const addBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    this.shaderKey =\n        `matMulReduce_${this.activation}_${transposeA}_${transposeB}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation, this.transposeA, this.transposeB)}\n      ${makeMatMulReduceSource(this.workgroupSize[0])}\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\nimport {activationFnSnippet} from './activation_util';\nimport {matMulReadWriteFnSource} from './matmul_packed_webgpu';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\n\nexport function makeMatMulSmallOutputSizeSource(\n    workgroupSize: [number, number, number]): string {\n  const tileAOuter = workgroupSize[1];\n  const tileBOuter = workgroupSize[0];\n  const tileInner = tileAOuter > tileBOuter ? tileAOuter : tileBOuter;\n  return `\n  var<workgroup> mm_Asub : array<array<f32, ${tileInner}>, ${tileAOuter}>;\n  var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;\n\n  // If the output size is small for matrix multiplication, avoid to use vec4\n  // and handle some elements per thread to optimally utilize the ALU.\n  // Read data from global memory to registers firstly, then store them into\n  // shared memory, so it is instruction-Level parallelism for arithmetic\n  // operations and others handle IO operations between barrier api, makes ALU\n  // and load/store units work simultaneously, could improves the performance.\n  ${main()} {\n    let tileRow = i32(localId.y);\n    let tileCol = i32(localId.x);\n    let globalRow = i32(globalId.y);\n    let globalCol = i32(globalId.x);\n    let batch = i32(globalId.z);\n    let batchA = batch % uniforms.aShape[0];\n    let batchB = batch % uniforms.bShape[0];\n\n    // uniforms.dimInner should be greater than 0.\n    let numTiles = (uniforms.dimInner - 1) / ${tileInner} + 1;\n    var acc = 0.0;\n\n    var globalColA = tileCol;\n    var globalRowB = 0;\n    var regA = mm_readA(batchA, globalRow, globalColA);\n    var regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);\n    var regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);\n    globalColA = globalColA + ${tileInner};\n    globalRowB = globalRowB + ${tileInner};\n\n    for (var t = 0; t < numTiles; t = t + 1) {\n      mm_Asub[tileRow][tileCol] = regA;\n      mm_Bsub[2 * tileRow][tileCol] = regB0;\n      mm_Bsub[2 * tileRow + 1][tileCol] = regB1;\n\n      workgroupBarrier();\n\n      regA = mm_readA(batchA, globalRow, globalColA);\n      regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);\n      regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);\n      globalColA = globalColA + ${tileInner};\n      globalRowB = globalRowB + ${tileInner};\n\n      for (var k = 0; k < ${tileInner}; k = k + 1) {\n        acc = acc + mm_Asub[tileRow][k] * mm_Bsub[k][tileCol];\n      }\n      workgroupBarrier();\n    }\n\n    mm_write(batch, globalRow, globalCol, acc);\n  }\n  `;\n}\n\nexport class MatMulSmallOutputSizeProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number] = [16, 8, 1];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n\n  constructor(\n      aShape: [number, number, number], bShape: [number, number, number],\n      outputShape: [number, number, number], transposeA = false,\n      transposeB = false, bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null) {\n    this.outputShape = outputShape;\n\n    this.dispatchLayout = {x: [2], y: [1], z: [0]};\n    this.dispatch = [\n      Math.ceil(outputShape[2] / this.workgroupSize[0]),\n      Math.ceil(outputShape[1] / this.workgroupSize[1]), outputShape[0]\n    ];\n\n    const addBias = bias != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    this.shaderKey =\n        `matMulSmallOutputSize_${this.activation}_${transposeA}_${transposeB}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation, this.transposeA, this.transposeB)}\n      ${makeMatMulSmallOutputSizeSource(this.workgroupSize)}\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source, matMulReadFnSource} from './matmul_packed_webgpu';\nimport {atomicAddSnippet} from './shader_util';\nimport {getMainHeaderString as main, typeSnippet, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class MatMulSplitKProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number] = [8, 8, 1];\n  elementsPerThread: [number, number, number];\n  transposeA: boolean;\n  transposeB: boolean;\n  atomic = true;\n  outputComponent: number;\n  splitedDimInner = 128;\n\n  constructor(\n      outputShape: [number, number, number], dimInner: number,\n      transposeA = false, transposeB = false) {\n    util.assert(\n        outputShape[0] === 1,\n        () => 'MatMulSplitKProgram only supports batch = 1.');\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [2], y: [1], z: [0, 3]};\n    const isVec4 = (transposeA && this.outputShape[1] % 4 === 0 ||\n                    !transposeA && dimInner % 4 === 0) &&\n        this.outputShape[2] % 4 === 0;\n    this.elementsPerThread = [4, 4, this.splitedDimInner];\n    this.outputComponent = isVec4 ? 4 : 1;\n    if (!isVec4) {\n      if (this.outputShape[1] < 16) {\n        this.elementsPerThread[1] = 1;\n      }\n      if (this.outputShape[2] < 16) {\n        this.elementsPerThread[0] = 1;\n      }\n    }\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout,\n        [\n          this.outputShape[0], this.outputShape[1], this.outputShape[2],\n          dimInner\n        ],\n        this.workgroupSize, this.elementsPerThread);\n\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.shaderKey = `matMulSplitK_${transposeA}_${transposeB}_${\n        this.elementsPerThread}_${this.outputComponent}`;\n  }\n\n  getUserCode(): string {\n    const component = this.outputComponent;\n    const userCode = `\n      ${\n        matMulReadFnSource(\n            false, this.transposeB, false, false, false, component)}\n      fn mm_write(batch: i32, row : i32, col : i32, value : ${\n        typeSnippet(component)}) {\n        if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n          let coords = vec3<i32>(batch, row, col);\n          let flatIndex = getOutputIndexFromCoords(coords);\n          // The problem is that we should initialize output to zero before using.\n          // Otherwise, the original value will be added to the result.\n          for (var i = 0; i < ${component}; i = i + 1) {\n            ${\n        atomicAddSnippet(\n            '&result[flatIndex + i]', `${component > 1 ? 'value[i]' : 'value'}`,\n            'float32')}\n          }\n        }\n      }\n      ${\n        component === 4 ? makeMatMulPackedVec4Source(\n                              this.elementsPerThread, this.workgroupSize,\n                              this.transposeA, 32, true, this.splitedDimInner) :\n                          makeMatMulPackedSource(\n                              this.elementsPerThread, this.workgroupSize,\n                              this.transposeA, 32, true, this.splitedDimInner)}\n    `;\n    return userCode;\n  }\n}\n\nexport class BiasActivationProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  uniforms = '';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  private addBias: boolean;\n  private activation: backend_util.Activation;\n  private hasPreluActivationWeights: boolean;\n\n  constructor(\n      outputShape: number[], bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.addBias = bias != null;\n    this.hasPreluActivationWeights = preluActivationWeights != null;\n    this.activation = activation;\n    if (this.addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (this.hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.shaderKey = `biasActivation_${activation}`;\n  }\n\n  getUserCode(): string {\n    return `\n    ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        var value = getXByOutputIndex(index);\n        ${biasActivationSnippet(this.addBias, this.activation)}\n        setOutputAtIndex(index, value);\n      }\n    }\n    `;\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class FillProgram implements WebGPUProgram {\n  variableNames: string[] = [];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'value : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'fill';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        setOutputAtIndex(index, uniforms.value);\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Fill, FillAttrs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {FillProgram} from '../fill_webgpu';\n\nexport function fill(args: {backend: WebGPUBackend, attrs: FillAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {shape, value} = attrs;\n  let {dtype} = attrs;\n\n  dtype = dtype || util.inferDtype(value);\n\n  if (dtype === 'string') {\n    // String type should be handled in CPU memory.\n    const values = util.getArrayFromDType(dtype, util.sizeFromShape(shape));\n    values.fill(value as string);\n    return backend.makeTensorInfo(shape, dtype, values);\n  } else {\n    const program = new FillProgram(shape);\n    const uniformData = [{type: 'float32', data: [value as number]}];\n    return backend.runWebGPUProgram(program, [], dtype, uniformData);\n  }\n}\n\nexport const fillConfig: KernelConfig = {\n  kernelName: Fill,\n  backendName: 'webgpu',\n  kernelFunc: fill as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reshape, ReshapeAttrs, ReshapeInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nexport function reshape(\n    args: {inputs: ReshapeInputs, backend: WebGPUBackend, attrs: ReshapeAttrs}):\n    TensorInfo {\n  const {inputs, attrs} = args;\n  const {x} = inputs;\n  const {shape} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const $shape = util.inferFromImplicitShape(shape, xSize);\n  const $xSize = util.sizeFromShape($shape);\n\n  util.assert(\n      xSize === $xSize,\n      () => `The new shape (${$shape}) has ${$xSize} elements and the old ` +\n          `shape (${x.shape}) has ${xSize} elements. The new shape and old ` +\n          `shape must have the same number of elements.`);\n\n  // Backend needs to track refCount for the dataId for reshape op\n  args.backend.incRef(x.dataId);\n  return {dataId: x.dataId, shape: $shape, dtype: x.dtype};\n}\n\nexport const reshapeConfig: KernelConfig = {\n  kernelName: Reshape,\n  backendName: 'webgpu',\n  kernelFunc: reshape as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, broadcast_util, env, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {MatMulPackedProgram} from '../matmul_packed_webgpu';\nimport {MatMulReduceProgram} from '../matmul_reduce_webgpu';\nimport {MatMulSmallOutputSizeProgram} from '../matmul_small_output_size_webgpu';\nimport {BiasActivationProgram, MatMulSplitKProgram} from '../matmul_splitK_webgpu';\nimport {WebGPUProgram} from '../webgpu_program';\nimport {MatMulProgramType} from '../webgpu_util';\n\nimport {fill} from './Fill';\nimport {reshape} from './Reshape';\n\ntype BatchMatMulConfig = {\n  a: TensorInfo,\n  b: TensorInfo,\n  transposeA: boolean,\n  transposeB: boolean,\n  backend: WebGPUBackend,\n  bias?: TensorInfo,\n  preluActivationWeights?: TensorInfo,\n  leakyreluAlpha?: number,\n  activation?: backend_util.Activation\n};\n\nexport function batchMatMulImpl({\n  a,\n  b,\n  transposeA,\n  transposeB,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: BatchMatMulConfig): TensorInfo {\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(\n      a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape: [number, number, number] = transposeA ?\n      [batchDimA, innerShapeA, outerShapeA] :\n      [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape: [number, number, number] = transposeB ?\n      [batchDimB, outerShapeB, innerShapeB] :\n      [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n  const intermediates: TensorInfo[] = [a3d, b3d];\n\n  const batchDim = Math.max(batchDimA, batchDimB);\n\n  const inputs: TensorInfo[] = [a3d, b3d];\n  const dimensions = [\n    {type: 'int32', data: [outerShapeA]}, {type: 'int32', data: [outerShapeB]},\n    {type: 'int32', data: [innerShapeA]}\n  ];\n\n  let program: WebGPUProgram;\n  let out: TensorInfo;\n  const outputShape: [number, number, number] =\n      [batchDim, outerShapeA, outerShapeB];\n  let matmulProgramType = env().get('WEBGPU_MATMUL_PROGRAM_TYPE') as number;\n  if (matmulProgramType < 0) {\n    // Usually increasing workgroups is a good way to gain more performance for\n    // few workgroups by tiling 32x32 (default matmul algorithm). Currently,\n    // there are three ways to increase workgroups. 1) MatMulReduceProgram,\n    // which is used only when the output size is very small (128 for now). 2)\n    // MatMulSplitKProgram, increasing workgroups by spliting K. 3)\n    // MatMulSmallOutputSizeProgram, increasing workgroups by small tile size.\n    // For different devices, the minimum optimal workgroups may be different.\n    // So here we set a |thresholdToIncreaseWorkgroups| to indicate whether we\n    // need to increase workgroups. And the literal number is an empirical\n    // value.\n    const thresholdFlagValue =\n        env().getNumber('WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL');\n    const thresholdToIncreaseWorkgroups = thresholdFlagValue > 0 ?\n        thresholdFlagValue :\n        backend.thresholdToIncreaseWorkgroups;\n    const workgroupsBy32x32 =\n        batchDim * Math.ceil(outerShapeA / 32) * Math.ceil(outerShapeB / 32);\n    const hasFewWorkgroups =\n        workgroupsBy32x32 <= thresholdToIncreaseWorkgroups ||\n        (outerShapeA <= 8 &&\n         workgroupsBy32x32 <= thresholdToIncreaseWorkgroups * 2);\n    if (hasFewWorkgroups) {\n      if (batchDim * outerShapeA * outerShapeB <= 128) {\n        matmulProgramType = MatMulProgramType.MatMulReduceProgram;\n      } else if (batchDim === 1 && innerShapeB >= 2000) {\n        matmulProgramType = MatMulProgramType.MatMulSplitKProgram;\n      } else {\n        matmulProgramType = MatMulProgramType.MatMulSmallOutputSizeProgram;\n      }\n    } else {\n      matmulProgramType = MatMulProgramType.MatMulPackedProgram;\n    }\n  }\n\n  switch (matmulProgramType) {\n    case MatMulProgramType.MatMulReduceProgram:\n      program = new MatMulReduceProgram(\n          outputShape, transposeA, transposeB, bias, activation,\n          preluActivationWeights);\n      break;\n    case MatMulProgramType.MatMulSplitKProgram: {\n      // The output buffer must be initailzed to zero before using since we\n      // use atomicAdd in MatMulSplitKProgram.\n      out = fill(\n          {backend, attrs: {shape: outputShape, value: 0, dtype: a.dtype}});\n      program = new MatMulSplitKProgram(\n          outputShape, innerShapeB, transposeA, transposeB);\n      if (bias || activation) {\n        out =\n            backend.runWebGPUProgram(program, inputs, a.dtype, dimensions, out);\n        const biasActivationProgram = new BiasActivationProgram(\n            out.shape, bias, activation, preluActivationWeights);\n        let uniformData = null;\n        const activationInputs: TensorInfo[] = [out];\n        if (bias) {\n          activationInputs.push(bias);\n        }\n        if (preluActivationWeights) {\n          activationInputs.push(preluActivationWeights);\n        }\n        if (activation === 'leakyrelu') {\n          uniformData = [{type: 'float32', data: [leakyreluAlpha]}];\n          biasActivationProgram.uniforms += ' alpha : f32,';\n        }\n        const outActivated = backend.runWebGPUProgram(\n            biasActivationProgram, activationInputs, out.dtype, uniformData);\n        intermediates.push(out);\n        const outReshaped = reshape(\n            {inputs: {x: outActivated}, backend, attrs: {shape: outShape}});\n        intermediates.push(outActivated);\n        for (const i of intermediates) {\n          backend.disposeData(i.dataId);\n        }\n        return outReshaped;\n      }\n      break;\n    }\n    case MatMulProgramType.MatMulSmallOutputSizeProgram:\n      program = new MatMulSmallOutputSizeProgram(\n          a3dShape, b3dShape, outputShape, transposeA, transposeB, bias,\n          activation, preluActivationWeights);\n      break;\n    case MatMulProgramType.MatMulPackedProgram:\n      // Experiments show that sequential access is more friendly for Intel\n      // GPUs.\n      const sequentialAccessByThreads = backend.adapterInfo.isIntel();\n      program = new MatMulPackedProgram(\n          a3dShape, outputShape, transposeA, transposeB, bias, activation,\n          preluActivationWeights, sequentialAccessByThreads);\n      break;\n    default:\n      throw new Error(`Unsupported MatMulProgramType ${matmulProgramType}.`);\n  }\n\n  if (bias) {\n    inputs.push(bias);\n  }\n  if (preluActivationWeights) {\n    inputs.push(preluActivationWeights);\n  }\n  if (activation === 'leakyrelu') {\n    dimensions.push({type: 'float32', data: [leakyreluAlpha]});\n    program.uniforms += ' alpha : f32,';\n  }\n  out = backend.runWebGPUProgram(program, inputs, a.dtype, dimensions, out);\n  const outReshaped =\n      reshape({inputs: {x: out}, backend, attrs: {shape: outShape}});\n  intermediates.push(out);\n  for (const i of intermediates) {\n    backend.disposeData(i.dataId);\n  }\n  return outReshaped;\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {batchMatMulImpl} from './BatchMatMul_impl';\n\nexport function _fusedMatMul(args: {\n  inputs: _FusedMatMulInputs,\n  attrs: _FusedMatMulAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b, bias, preluActivationWeights} = inputs;\n  const {transposeA, transposeB, activation, leakyreluAlpha} = attrs;\n\n  return batchMatMulImpl({\n    a,\n    b,\n    transposeA,\n    transposeB,\n    backend,\n    bias,\n    preluActivationWeights,\n    leakyreluAlpha,\n    activation\n  });\n}\n\nexport const _fusedMatMulConfig: KernelConfig = {\n  kernelName: _FusedMatMul,\n  backendName: 'webgpu',\n  kernelFunc: _fusedMatMul as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {BinaryOpType, getBinaryOpString} from './binary_op_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class BinaryOpComplexProgram implements WebGPUProgram {\n  variableNames = ['AReal', 'AImag', 'BReal', 'BImag'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [128, 1, 1];\n  op: BinaryOpType;\n  size = true;\n\n  constructor(op: BinaryOpType, aShape: number[], bShape: number[]) {\n    this.outputShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `binaryOpComplex_${op}`;\n    this.op = op;\n  }\n\n  getUserCode(): string {\n    const opStr = getBinaryOpString(this.op, false);\n    const userCode = `\n      fn binaryOpComplex(\n          areal : f32, aimag : f32, breal : f32, bimag : f32) -> f32 {\n        ${opStr}\n      }\n\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let areal = getARealByOutputIndex(index);\n          let aimag = getAImagByOutputIndex(index);\n          let breal = getBRealByOutputIndex(index);\n          let bimag = getBImagByOutputIndex(index);\n          setOutputAtIndex(index, binaryOpComplex(areal, aimag, breal, bimag));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType, getBinaryOpString} from './binary_op_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class BinaryOpProgram implements WebGPUProgram {\n  dispatch: [number, number, number];\n  dispatchLayout: {x: number[]};\n  outputComponent: number;\n  op: BinaryOpType;\n  outputShape: number[];\n  shaderKey: string;\n  size = true;\n  variableNames = ['A', 'B'];\n  workgroupSize: [number, number, number];\n  variableComponents: number[];\n\n  private lastDimensionSize: number;\n  private useSharedMemoryWithA: boolean;\n  private useSharedMemoryWithB: boolean;\n  private type: string;\n\n  constructor(op: BinaryOpType, aShape: number[], bShape: number[]) {\n    this.outputShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.op = op;\n\n    this.useSharedMemoryWithA =\n        aShape.length <= 1 && bShape.length > 1 && aShape[0] < 128;\n    this.useSharedMemoryWithB =\n        bShape.length <= 1 && aShape.length > 1 && bShape[0] < 128;\n\n    if (this.useSharedMemoryWithA || this.useSharedMemoryWithB) {\n      this.outputComponent = 1;\n      this.variableComponents = [1, 1];\n      // lastDimensionSize is used as sharedBuf array size, so can not be\n      // used as uniform.\n      this.lastDimensionSize =\n          this.useSharedMemoryWithB ? bShape[0] : aShape[0];\n      this.shaderKey = `binary_${op}_${this.lastDimensionSize}`;\n      this.type = 'shared';\n      // This is an experimental value when using shared memory.\n      // Note that the maximum of workgroup X dimension is 256.\n      this.workgroupSize = [256, 1, 1];\n    } else {\n      const aDivisibleBy4 =\n          aShape.length > 0 && aShape[aShape.length - 1] % 4 === 0;\n      const bDivisibleBy4 =\n          bShape.length > 0 && bShape[bShape.length - 1] % 4 === 0;\n      if (aDivisibleBy4 && bDivisibleBy4) {\n        this.outputComponent = 4;\n        this.variableComponents = [4, 4];\n      } else if (\n          (aDivisibleBy4 &&\n           (util.isScalarShape(bShape) || bShape[bShape.length - 1] === 1)) ||\n          (bDivisibleBy4 &&\n           (util.isScalarShape(aShape) || aShape[aShape.length - 1] === 1))) {\n        this.outputComponent = 4;\n        this.variableComponents = aDivisibleBy4 ? [4, 1] : [1, 4];\n      } else {\n        this.outputComponent = 1;\n        this.variableComponents = [1, 1];\n      }\n      this.type = 'nonshared';\n      this.shaderKey = `binary_${op}_${this.variableComponents}`;\n      // TODO(jiajia.qin@intel.com): Heuristically select a good work group\n      // size.\n      this.workgroupSize = [128, 1, 1];\n    }\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.outputComponent, 1, 1]);\n  }\n\n  getUserCode(): string {\n    let userCode;\n    const dType = this.outputComponent === 4 ? 'vec4<f32>' : 'f32';\n    const opFnStr = `\n    fn binaryOperation(a : ${dType}, b : ${dType}) -> ${dType} {\n      ${getBinaryOpString(this.op, this.outputComponent === 4)}\n    };\n    `;\n\n    if (this.type === 'shared') {\n      const sharedIndexSnippet = this.lastDimensionSize > 1 ?\n          `coords[${this.outputShape.length - 1}]` :\n          '0';\n      const accessDataSnippet = this.useSharedMemoryWithB ?\n          `let a = getAByOutputIndex(index);\n          let b = sharedBuf[${sharedIndexSnippet}];` :\n          `let a = sharedBuf[${sharedIndexSnippet}];\n          let b = getBByOutputIndex(index);`;\n      userCode = `\n        ${opFnStr}\n        var<workgroup> sharedBuf : array<f32, ${this.lastDimensionSize}>;\n        ${main('index')} {\n          // Fill in the shared memory buffer.\n          let localIndex = i32(localId.x);\n          if(localIndex < ${this.lastDimensionSize}) {\n            sharedBuf[localIndex] = f32(${\n          this.useSharedMemoryWithB ? 'B' : 'A'}[localIndex]);\n          }\n          workgroupBarrier();\n\n          if(index < uniforms.size) {\n            let coords = getCoordsFromIndex(index);\n            ${accessDataSnippet}\n            setOutputAtIndex(index, binaryOperation(a, b));\n          }\n        }\n        `;\n    } else {\n      userCode = `\n       ${opFnStr}\n       ${main('index')} {\n         if (index < uniforms.size) {\n           let coords = getCoordsFromIndex(index * ${this.outputComponent});\n           let a = ${dType}(getAByOutputCoords(coords));\n           let b = ${dType}(getBByOutputCoords(coords));\n           setOutputAtIndex(index, binaryOperation(a, b));\n         }\n       }\n       `;\n    }\n\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Identity, IdentityInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nexport function identity(\n    args: {inputs: IdentityInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs} = args;\n  const {x} = inputs;\n\n  args.backend.incRef(x.dataId);\n  return {dataId: x.dataId, shape: x.shape, dtype: x.dtype};\n}\n\nexport const identityConfig: KernelConfig = {\n  kernelName: Identity,\n  backendName: 'webgpu',\n  kernelFunc: identity as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Complex, ComplexInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\n\n/**\n * Complex tensors share data with their real and imaginary components. Complex\n * tensors' reference to the components is tracked by refCount on the individual\n * component. The refCounts are increased by the identity call.\n *\n * When a complex tensor is disposed, it will reduce the refCount on the\n * components by calling disposeData on each.\n */\nexport function complex(args: {inputs: ComplexInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {real, imag} = inputs;\n\n  const complexInfo = backend.makeTensorInfo(real.shape, 'complex64');\n  const complex = backend.tensorMap.get(complexInfo.dataId);\n\n  const realTensorInfo = identity({inputs: {x: real}, backend});\n\n  const imagTensorInfo = identity({inputs: {x: imag}, backend});\n\n  complex.complexTensorInfos = {real: realTensorInfo, imag: imagTensorInfo};\n\n  return complexInfo;\n}\n\nexport const complexConfig: KernelConfig = {\n  kernelName: Complex,\n  backendName: 'webgpu',\n  kernelFunc: complex as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getUnaryOpString, UnaryOpType} from './unary_op_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class UnaryOpProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A'];\n  workgroupSize: [number, number, number];\n  op: UnaryOpType;\n  uniforms?: string;\n  size = true;\n\n  constructor(outputShape: number[], op: UnaryOpType, uniforms = '') {\n    // TODO(jiajia.qin@intel.com): Heuristically select a good work group size.\n    const workgroupSizeX = 128;\n    this.workgroupSize = [workgroupSizeX, 1, 1];\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.op = op;\n    if (uniforms !== '') {\n      this.uniforms = uniforms;\n    }\n    this.shaderKey = `unary_${op}`;\n  }\n\n  getUserCode(): string {\n    return `\n      fn unaryOperation(a : f32) -> f32 {\n        ${getUnaryOpString(this.op, false)}\n      }\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let a = getAByOutputIndex(index);\n          setOutputAtIndex(index, unaryOperation(a));\n        }\n      }\n      `;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, KernelFunc, TensorInfo, TypedArray, UnaryInputs, upcastType} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {BinaryOpComplexProgram} from '../binary_op_complex_webgpu';\nimport {BinaryOpType} from '../binary_op_util';\nimport {BinaryOpProgram} from '../binary_op_webgpu';\nimport {complex} from '../kernels/Complex';\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\nimport {SimpleBinaryKernelImplCPU, SimpleUnaryKernelImplCPU} from './shared';\n\ntype UnaryKernelFuncConfig = {\n  opType: UnaryOpType,\n  cpuKernelImpl?: SimpleUnaryKernelImplCPU,\n  dtype?: DataType\n};\n\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param opType Op type to create `UnaryOpProgram`.\n * @param cpuKernelImpl Optional. Shared functionality from tfjs-backend-cpu, it\n *     will be involved when necessary.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function unaryKernelFunc(\n    {opType, cpuKernelImpl, dtype}: UnaryKernelFuncConfig): KernelFunc {\n  return ({inputs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    const webgpuBackend = backend as WebGPUBackend;\n\n    const $dtype = dtype || x.dtype;\n    if (webgpuBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {\n      const xData = webgpuBackend.tensorMap.get(x.dataId);\n      const outValues = cpuKernelImpl(xData.values as TypedArray, $dtype);\n      return webgpuBackend.makeTensorInfo(x.shape, $dtype, outValues);\n    }\n\n    const program: UnaryOpProgram = new UnaryOpProgram(x.shape, opType);\n    return webgpuBackend.runWebGPUProgram(program, [x], $dtype);\n  };\n}\n\ntype BinaryKernelFuncConfig = {\n  opType: BinaryOpType,\n  cpuKernelImpl?: SimpleBinaryKernelImplCPU,\n  supportsComplex?: boolean,\n  dtype?: DataType\n};\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param opType Op type to create `BinaryOpProgram`.\n * @param cpuKernelImpl Optional. Shared functionality from tfjs-backend-cpu, it\n *     will be involved when necessary.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc(\n    {opType, cpuKernelImpl, supportsComplex = false, dtype}:\n        BinaryKernelFuncConfig): KernelFunc {\n  return ({inputs, backend}) => {\n    const {a, b} = inputs as BinaryInputs;\n    const webgpuBackend = backend as WebGPUBackend;\n\n    if (supportsComplex && a.dtype === 'complex64') {\n      const aData = webgpuBackend.tensorMap.get(a.dataId);\n      const bData = webgpuBackend.tensorMap.get(b.dataId);\n      let real: TensorInfo, imag: TensorInfo;\n      if (opType !== BinaryOpType.MUL) {\n        [real, imag] = [\n          [aData.complexTensorInfos.real, bData.complexTensorInfos.real],\n          [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]\n        ].map(complexParts => {\n          const [aPart, bPart] = complexParts;\n\n          const aHandle = {\n            dataId: aPart.dataId,\n            dtype: aPart.dtype,\n            shape: a.shape\n          };\n          const bHandle = {\n            dataId: bPart.dataId,\n            dtype: bPart.dtype,\n            shape: b.shape\n          };\n\n          const program = new BinaryOpProgram(opType, a.shape, b.shape);\n          return webgpuBackend.runWebGPUProgram(\n              program, [aHandle, bHandle],\n              upcastType(aPart.dtype, bPart.dtype));\n        });\n      } else {\n        const realProgram = new BinaryOpComplexProgram(\n            BinaryOpType.COMPLEX_MULTIPLY_REAL, a.shape, b.shape);\n        const imagProgram = new BinaryOpComplexProgram(\n            BinaryOpType.COMPLEX_MULTIPLY_IMAG, a.shape, b.shape);\n\n        const inputs = [\n          {\n            dataId: aData.complexTensorInfos.real.dataId,\n            dtype: aData.complexTensorInfos.real.dtype,\n            shape: a.shape\n          },\n          {\n            dataId: aData.complexTensorInfos.imag.dataId,\n            dtype: aData.complexTensorInfos.imag.dtype,\n            shape: a.shape\n          },\n          {\n            dataId: bData.complexTensorInfos.real.dataId,\n            dtype: bData.complexTensorInfos.real.dtype,\n            shape: b.shape\n          },\n          {\n            dataId: bData.complexTensorInfos.imag.dataId,\n            dtype: bData.complexTensorInfos.imag.dtype,\n            shape: b.shape\n          }\n        ];\n\n        real = webgpuBackend.runWebGPUProgram(realProgram, inputs, 'float32');\n        imag = webgpuBackend.runWebGPUProgram(imagProgram, inputs, 'float32');\n      }\n\n      const complexOutput =\n          complex({inputs: {real, imag}, backend: webgpuBackend});\n\n      webgpuBackend.disposeData(real.dataId);\n      webgpuBackend.disposeData(imag.dataId);\n\n      // TODO: Implement CPU forwarding for complex inputs.\n\n      return complexOutput;\n    }\n\n    const $dtype = dtype || upcastType(a.dtype, b.dtype);\n    if ((a.dtype === 'string' || b.dtype === 'string' ||\n         webgpuBackend.shouldExecuteOnCPU([a, b])) &&\n        cpuKernelImpl != null) {\n      const aData = webgpuBackend.tensorMap.get(a.dataId).values as TypedArray;\n      const bData = webgpuBackend.tensorMap.get(b.dataId).values as TypedArray;\n      const decodedAVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(aData as any as Uint8Array[]) :\n          aData;\n      const decodedBVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(bData as any as Uint8Array[]) :\n          bData;\n      const [outValues, outShape] =\n          cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);\n\n      return webgpuBackend.makeTensorInfo(outShape, $dtype, outValues);\n    }\n    const program = new BinaryOpProgram(opType, a.shape, b.shape);\n    return webgpuBackend.runWebGPUProgram(program, [a, b], $dtype);\n  };\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Import shared functionality from tfjs-backend-cpu without triggering\n// side effects.\n// tslint:disable-next-line: no-imports-from-dist\nimport * as shared from '@tensorflow/tfjs-backend-cpu/dist/shared';\n// tslint:disable-next-line: no-imports-from-dist\nimport {SimpleBinaryKernelImpl} from '@tensorflow/tfjs-backend-cpu/dist/shared';\n// tslint:disable-next-line: no-imports-from-dist\nimport {SimpleUnaryImpl} from '@tensorflow/tfjs-backend-cpu/dist/utils/unary_types';\n\nexport type SimpleBinaryKernelImplCPU = SimpleBinaryKernelImpl;\nexport type SimpleUnaryKernelImplCPU = SimpleUnaryImpl;\nconst {\n  addImpl: addImplCPU,\n  castImpl: castImplCPU,\n  ceilImpl: ceilImplCPU,\n  concatImpl: concatImplCPU,\n  equalImpl: equalImplCPU,\n  expImpl: expImplCPU,\n  expm1Impl: expm1ImplCPU,\n  floorImpl: floorImplCPU,\n  floorDivImpl: floorDivImplCPU,\n  gatherNdImpl: gatherNdImplCPU,\n  gatherV2Impl: gatherV2ImplCPU,\n  greaterEqualImpl: greaterEqualImplCPU,\n  greaterImpl: greaterImplCPU,\n  lessEqualImpl: lessEqualImplCPU,\n  lessImpl: lessImplCPU,\n  logImpl: logImplCPU,\n  maxImpl: maxImplCPU,\n  maximumImpl: maximumImplCPU,\n  minimumImpl: minimumImplCPU,\n  multiplyImpl: multiplyImplCPU,\n  negImpl: negImplCPU,\n  notEqualImpl: notEqualImplCPU,\n  prodImpl: prodImplCPU,\n  rangeImpl: rangeImplCPU,\n  rsqrtImpl: rsqrtImplCPU,\n  scatterImpl: scatterImplCPU,\n  simpleAbsImpl: simpleAbsImplCPU,\n  sliceImpl: sliceImplCPU,\n  stridedSliceImpl: stridedSliceImplCPU,\n  stringNGramsImpl: stringNGramsImplCPU,\n  subImpl: subImplCPU,\n  tileImpl: tileImplCPU,\n  topKImpl: topKImplCPU,\n  transposeImpl: transposeImplCPU,\n  uniqueImpl: uniqueImplCPU,\n} = shared;\n\nexport {\n  addImplCPU,\n  castImplCPU,\n  ceilImplCPU,\n  concatImplCPU,\n  equalImplCPU,\n  expImplCPU,\n  expm1ImplCPU,\n  floorImplCPU,\n  floorDivImplCPU,\n  gatherNdImplCPU,\n  gatherV2ImplCPU,\n  greaterEqualImplCPU,\n  greaterImplCPU,\n  lessEqualImplCPU,\n  lessImplCPU,\n  logImplCPU,\n  maxImplCPU,\n  maximumImplCPU,\n  minimumImplCPU,\n  multiplyImplCPU,\n  prodImplCPU,\n  negImplCPU,\n  notEqualImplCPU,\n  scatterImplCPU,\n  simpleAbsImplCPU,\n  sliceImplCPU,\n  stridedSliceImplCPU,\n  stringNGramsImplCPU,\n  subImplCPU,\n  rangeImplCPU,\n  rsqrtImplCPU,\n  tileImplCPU,\n  topKImplCPU,\n  transposeImplCPU,\n  uniqueImplCPU,\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Abs, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {simpleAbsImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const abs =\n    unaryKernelFunc({opType: UnaryOpType.ABS, cpuKernelImpl: simpleAbsImplCPU});\n\nexport const absConfig: KernelConfig = {\n  kernelName: Abs,\n  backendName: 'webgpu',\n  kernelFunc: abs\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const acos = unaryKernelFunc({opType: UnaryOpType.ACOS});\n\nexport const acosConfig: KernelConfig = {\n  kernelName: Acos,\n  backendName: 'webgpu',\n  kernelFunc: acos\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const acosh = unaryKernelFunc({opType: UnaryOpType.ACOSH});\n\nexport const acoshConfig: KernelConfig = {\n  kernelName: Acosh,\n  backendName: 'webgpu',\n  kernelFunc: acosh\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {addImplCPU as cpuAdd} from '../kernel_utils/shared';\n\nexport const addKernelFunc = binaryKernelFunc(\n    {opType: BinaryOpType.ADD, cpuKernelImpl: cpuAdd, supportsComplex: true});\n\nexport const addConfig: KernelConfig = {\n  kernelName: Add,\n  backendName: 'webgpu',\n  kernelFunc: addKernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class AddNPackedProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[];\n  workPerThread = 1;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shapes: number[][]) {\n    this.outputShape = shapes[0];\n    this.variableNames = shapes.map((_, i) => `T${i}`);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n    this.shaderKey = 'addN';\n  }\n\n  getUserCode(): string {\n    const snippets: string[] = [];\n    // Get target elements from every input tensor.\n    this.variableNames.forEach(variable => {\n      snippets.push(`let v${variable} = get${variable}ByOutputCoords(coords);`);\n    });\n    // Calculate the sum of all elements.\n    const operation = this.variableNames\n                          .map(variable => {\n                            return `v${variable}`;\n                          })\n                          .join(' + ');\n\n    const userCode = `\n      ${main('index')} {\n        for (var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let flatIndex = index * ${this.workPerThread} + i;\n          if (flatIndex < uniforms.size) {\n            let coords = getCoordsFromIndex(flatIndex);\n            ${snippets.join('\\n        ')}\n            setOutputAtIndex(flatIndex, ${operation});\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AddN, AddNInputs, KernelConfig, KernelFunc, TensorInfo, upcastType} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {AddNPackedProgram} from '../addn_packed_webgpu';\nimport {identity} from './Identity';\n\nexport function addN(args: {inputs: AddNInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n\n  const tensors = inputs;\n  if (tensors.length === 1) {\n    return identity({inputs: {x: tensors[0]}, backend});\n  }\n\n  const dtype =\n      tensors.map(t => t.dtype).reduce((d1, d2) => upcastType(d1, d2));\n  const shapes = tensors.map(t => t.shape);\n  const program = new AddNPackedProgram(shapes);\n  return backend.runWebGPUProgram(program, tensors, dtype);\n}\n\nexport const addNConfig: KernelConfig = {\n  kernelName: AddN,\n  backendName: 'webgpu',\n  kernelFunc: addN as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport class TransposeSharedProgram implements WebGPUProgram {\n  variableNames = ['A'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[]};\n  dispatch: [number, number, number];\n  // Note that the maximum number of workgroup invocations by webgpu is 256.\n  workgroupSize: [number, number, number] = [16, 16, 1];\n\n  constructor(aShape: number[], newDim: number[]) {\n    const outputShape: number[] = new Array(aShape.length);\n    for (let i = 0; i < outputShape.length; i++) {\n      outputShape[i] = aShape[newDim[i]];\n    }\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [0], y: [1]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize, [1, 1, 1]);\n\n    this.shaderKey = 'transposeShared';\n  }\n\n  getUserCode(): string {\n    util.assert(\n        this.workgroupSize[0] === this.workgroupSize[1],\n        () => `Must be a square tile, current tile shape is ${\n            this.workgroupSize[0]} x ${this.workgroupSize[1]}`);\n    const tileSize = this.workgroupSize[0];\n    const userCode = `\n      var<workgroup> tile : array<array<f32, ${this.workgroupSize[0] + 1}>, ${\n        this.workgroupSize[0]}>;\n      ${main()} {\n        var x = i32(workgroupId.x) * ${tileSize} + i32(localId.x);\n        var y = i32(workgroupId.y) * ${tileSize} + i32(localId.y);\n        let width = uniforms.outShape[0];\n        let height = uniforms.outShape[1];\n        if (x < width && y < height) {\n          tile[localId.y][localId.x] = f32(A[y * width + x]);\n        }\n        workgroupBarrier();\n\n        x = i32(workgroupId.y) * ${tileSize} + i32(localId.x);\n        y = i32(workgroupId.x) * ${tileSize} + i32(localId.y);\n        if (x < height && y < width) {\n          setOutputAtIndex((y * height + x), tile[localId.x]\n            [localId.y]);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getCoordsXYZ, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class TransposeProgram implements WebGPUProgram {\n  variableNames = ['A'];\n  shaderKey: string;\n  outputShape: number[];\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workPerThread = 1;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  newDim: number[];\n  size = true;\n\n  constructor(aShape: number[], newDim: number[]) {\n    const outputShape: number[] = new Array(aShape.length);\n    for (let i = 0; i < outputShape.length; i++) {\n      outputShape[i] = aShape[newDim[i]];\n    }\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n\n    this.newDim = newDim;\n    this.shaderKey = `transpose_${newDim}`;\n  }\n\n  getUserCode(): string {\n    const dtype = getCoordsDataType(this.outputShape.length);\n    const switched = getSwitchedCoords(this.newDim);\n\n    const userCode = `\n      ${main('index')} {\n        for(var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let flatIndex = index * ${this.workPerThread} + i;\n          if(flatIndex < uniforms.size) {\n            let coords = getCoordsFromIndex(flatIndex);\n            setOutputAtIndex(flatIndex, A[getIndexFromCoords${\n        this.outputShape.length}D(\n              ${dtype}(${switched}), uniforms.aShape)]);\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\nexport function getSwitchedCoords(newDim: number[]): string {\n  const rank = newDim.length;\n  if (rank > 6) {\n    throw Error(`Transpose for rank ${rank} is not yet supported`);\n  }\n  const switchedCoords = new Array(rank);\n  for (let i = 0; i < newDim.length; i++) {\n    switchedCoords[newDim[i]] = `coords.${getCoordsXYZ(i)}`;\n  }\n\n  return switchedCoords.join();\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Transpose, TransposeAttrs, TransposeInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {transposeImplCPU as cpuTranspose} from '../kernel_utils/shared';\n\nimport {TransposeSharedProgram} from '../transpose_shared_webgpu';\nimport {TransposeProgram} from '../transpose_webgpu';\n\nexport function transpose(args: {\n  inputs: TransposeInputs,\n  attrs: TransposeAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {perm} = attrs;\n  const webgpuBackend = backend;\n\n  const xRank = x.shape.length;\n  const newShape: number[] = new Array(xRank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = x.shape[perm[i]];\n  }\n  if (backend.shouldExecuteOnCPU([x])) {\n    const xData = webgpuBackend.tensorMap.get(x.dataId);\n    const values = xData.values as TypedArray;\n    const outValues = cpuTranspose(values, x.shape, x.dtype, perm, newShape);\n    return backend.makeTensorInfo(newShape, x.dtype, outValues);\n  }\n  if (x.shape.length === 2 && util.arraysEqual(perm, [1, 0])) {\n    const program = new TransposeSharedProgram(x.shape, perm);\n    return webgpuBackend.runWebGPUProgram(program, [x], x.dtype);\n  }\n  const program = new TransposeProgram(x.shape, perm);\n  return webgpuBackend.runWebGPUProgram(program, [x], x.dtype);\n}\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'webgpu',\n  kernelFunc: transpose as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ReduceProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'reduceSize : i32,';\n  reduceType: 'all'|'any'|'max'|'mean'|'min'|'prod'|'sum';\n  inputShape: number[];\n  size = true;\n\n  constructor(\n      reduceInfo: backend_util.ReduceInfo,\n      reduceType: 'all'|'any'|'max'|'mean'|'min'|'prod'|'sum',\n      maxComputeWorkgroupSizeX: number) {\n    this.inputShape = [reduceInfo.batchSize, reduceInfo.inSize];\n    const [outputShape, ] =\n        backend_util.computeOutAndReduceShapes(this.inputShape, [1]);\n    this.outputShape = outputShape.length === 0 ? [1] : outputShape;\n    // If reduceSize |reduceInfo.inSize| is very large, the I/O accessing will\n    // become the bottleneck. Increasing workgroupSize can reduce the times of\n    // accessing global memory. The threshold value is just to make sure the\n    // reduceSize is large enough for a bigger workgroupSize.\n    if (reduceInfo.inSize >= 32768 && maxComputeWorkgroupSizeX >= 512) {\n      this.workgroupSize = [512, 1, 1];\n    } else if (reduceInfo.inSize >= 4096) {\n      this.workgroupSize = [256, 1, 1];\n    } else {\n      this.workgroupSize = [64, 1, 1];\n    }\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    // A work group only outputs a data, so we transfer [1, 1, 1] to compute\n    // dispatch size.\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);\n\n    this.reduceType = reduceType;\n    this.shaderKey = `reduce_${reduceType}`;\n  }\n\n  getUserCode(): string {\n    let reduceOp = ``;\n    let initValue = '0.0';\n    const workgroupSizeX = this.workgroupSize[0];\n    if (this.reduceType === 'min' || this.reduceType === 'max') {\n      reduceOp = `\n         if (isnan(candidate)) {\n          bestValue = uniforms.NAN;\n         } else if (!isnan(bestValue) && candidate ${\n          this.reduceType === 'min' ? '<' : '>'} bestValue)\n           {  bestValue = candidate; }`;\n      initValue = 'f32(x[offset])';\n    } else if (this.reduceType === 'sum' || this.reduceType === 'mean') {\n      reduceOp = ' bestValue = bestValue + candidate; ';\n    } else if (this.reduceType === 'prod') {\n      reduceOp = ' bestValue = bestValue * candidate; ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'all') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 && candidate >= 1.0); ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'any') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 || candidate >= 1.0); ';\n      initValue = '0.0';\n    }\n\n    const outputSnippet = this.reduceType === 'mean' ?\n        // tslint:disable-next-line:max-line-length\n        `setOutputAtIndex(outputIndex, bestValue / f32(uniforms.reduceSize));` :\n        `setOutputAtIndex(outputIndex, bestValue);`;\n\n    const sharedMemorySnippet = `\n         var<workgroup> xBestValues : array<f32, ${workgroupSizeX}>;\n       `;\n\n    const userCode = `\n       fn DIV_CEIL(a : u32, b : u32) -> u32 {\n        return ((a - 1u) / b + 1u);\n       }\n\n       ${sharedMemorySnippet}\n       fn getOffset(outputIndex : i32) -> i32 {\n         let outputCoords = getCoordsFromIndex(outputIndex);\n         let offset = ${\n        this.outputShape.length === 1 ?\n            'outputCoords' :\n            'outputCoords[0]'} * uniforms.reduceSize;\n          return offset;\n       }\n       ${main('index')} {\n         let outputIndex = index / ${workgroupSizeX};\n         let offset = getOffset(outputIndex);\n         var bestValue = ${initValue};\n         let Length = uniforms.reduceSize;\n         let WorkPerThread = DIV_CEIL(u32(Length), ${workgroupSizeX}u);\n         for (var k = i32(localId.x); k < Length && outputIndex < uniforms.size;\n             k = k + ${workgroupSizeX}) {\n           let candidate = f32(x[offset + k]);\n           ${reduceOp}\n         }\n         xBestValues[localId.x] = bestValue;\n         workgroupBarrier();\n\n         var reduceSize = min(u32(Length), ${workgroupSizeX}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (localId.x < currentSize) {\n            let candidate = xBestValues[localId.x + interval];\n            ${reduceOp}\n            xBestValues[localId.x] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (localId.x == 0u && outputIndex < uniforms.size) {\n          ${outputSnippet}\n        }\n       }\n     `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, sumOutType, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reshape} from '../kernels/Reshape';\nimport {transpose} from '../kernels/Transpose';\nimport {ReduceProgram} from '../reduce_webgpu';\n\nimport {maxImplCPU} from './shared';\nimport {prodImplCPU} from './shared';\n\ntype ReduceTypes = 'all'|'any'|'max'|'mean'|'min'|'prod'|'sum';\nconst RETURN_TYPES: {[key in ReduceTypes]?: DataType} = {\n  'mean': 'float32',\n  'all': 'bool',\n  'any': 'bool',\n};\n\nexport function reduce(\n    x: TensorInfo, axis: number|number[], keepDims: boolean,\n    reduceType: ReduceTypes, backend: WebGPUBackend): TensorInfo {\n  const xRank = x.shape.length;\n  const toDispose = [];\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n\n  let input = x;\n  if (permutedAxes != null) {\n    input = transpose({inputs: {x}, attrs: {perm: permutedAxes}, backend});\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n    toDispose.push(input);\n  }\n\n  backend_util.assertAxesAreInnerMostDims(reduceType, axes, xRank);\n\n  const [reduceOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(input.shape, axes);\n  let resOutShape = reduceOutShape;\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    resOutShape = backend_util.expandShapeToKeepDim(reduceOutShape, origAxes);\n  }\n\n  let res;\n  if ((reduceType === 'max' || reduceType === 'prod') &&\n      backend.shouldExecuteOnCPU([input])) {\n    const xVals = backend.tensorMap.get(input.dataId).values as TypedArray;\n    switch (reduceType) {\n      case 'max':\n        const outValues = maxImplCPU(\n            xVals, util.sizeFromShape(reduceShape), resOutShape, x.dtype);\n        res = backend.makeTensorInfo(resOutShape, x.dtype, outValues);\n        break;\n      case 'prod':\n        const {outVals, outShape, outDtype} =\n            prodImplCPU(input.shape, input.dtype, xVals, axes);\n        res = backend.makeTensorInfo(outShape, outDtype, outVals);\n        break;\n      default:\n        throw new Error(\n            `${reduceType} CPU implementation is not yet supported.`);\n    }\n  } else {\n    const inSize = util.sizeFromShape(reduceShape);\n    const xSize = util.sizeFromShape(input.shape);\n    const batchSize = xSize / inSize;\n\n    const reduceInfo = {windowSize: inSize, inSize, batchSize, outSize: 1};\n    const dtype = RETURN_TYPES[reduceType] || sumOutType(x.dtype);\n    const uniformData = [\n      {type: 'int32', data: [inSize]},\n    ];\n    const program = new ReduceProgram(\n        reduceInfo, reduceType, backend.device.limits.maxComputeWorkgroupSizeX);\n    const reduced =\n        backend.runWebGPUProgram(program, [input], dtype, uniformData);\n    toDispose.push(reduced);\n\n    res = reshape({inputs: {x: reduced}, attrs: {shape: resOutShape}, backend});\n  }\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n\n  return res;\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {All, AllAttrs, AllInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function all(\n    args: {inputs: AllInputs, attrs: AllAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {keepDims, axis} = attrs;\n\n  return reduce(x, axis, keepDims, 'all', backend);\n}\n\nexport const allConfig: KernelConfig = {\n  kernelName: All,\n  backendName: 'webgpu',\n  kernelFunc: all as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Any, AnyAttrs, AnyInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function any(\n    args: {inputs: AnyInputs, attrs: AnyAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {keepDims, axis} = attrs;\n\n  return reduce(x, axis, keepDims, 'any', backend);\n}\n\nexport const anyConfig: KernelConfig = {\n  kernelName: Any,\n  backendName: 'webgpu',\n  kernelFunc: any as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\nimport {getCoordsXYZ, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ArgMinMaxProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  variableNames = ['x'];\n  uniforms = 'infinityValue : f32,';\n  inputShape: number[];\n  reductionFactor: number;\n  op: string;\n  size = true;\n  private type: string;\n\n  constructor(inputShape: number[], axis: number, reduceType: 'min'|'max') {\n    const axes = [axis];\n\n    this.op = reduceType === 'min' ? '<' : '>';\n\n    // |outShape| is the shape with the removed axis\n    const [outputShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(inputShape, axes);\n\n    this.outputShape = outputShape.length === 0 ? [1] : outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    // The shared algorithm is mainly used for large reduce size. It fully\n    // utilizes the threads in one workgroup to do the reduction. However,\n    // when the reduce size is very small, it's better to use the plain\n    // algorithm to reduce the number of workgroups to speedup. The threthold\n    // can be further tuned.\n    if (util.sizeFromShape(reduceShape) < 32) {\n      this.type = 'plain';\n      this.dispatch = computeDispatch(\n          this.dispatchLayout, this.outputShape, this.workgroupSize);\n    } else {\n      this.type = 'shared';\n      // A work group only outputs a data, so we transfer [1, 1, 1] to compute\n      // dispatch size.\n      this.dispatch =\n          computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);\n    }\n\n    this.inputShape = inputShape;\n    this.shaderKey = `argMinMax_${this.op}_${this.type}`;\n  }\n\n  getUserCode(): string {\n    const workgroupSizeX = this.workgroupSize[0];\n    const getInputShapeLastDim = () => {\n      if (this.inputShape.length === 1) {\n        return 'uniforms.xShape';\n      } else {\n        return `uniforms.xShape.${getCoordsXYZ(this.inputShape.length - 1)}`;\n      }\n    };\n\n    const splitOutputCoords = () => {\n      let snippet = '';\n      if (this.outputShape.length === 1) {\n        if (this.inputShape.length !== 1) {\n          snippet += 'outputCoords,';\n        }\n      } else {\n        for (let i = 0; i < this.outputShape.length; i++) {\n          snippet += `outputCoords.${getCoordsXYZ(i)},`;\n        }\n      }\n      return snippet;\n    };\n\n    if (this.type === 'shared') {\n      const sharedMemorySnippet = `\n      var<workgroup> xBestIndices : array<i32, ${workgroupSizeX}>;\n      var<workgroup> xBestValues : array<f32, ${workgroupSizeX}>;\n    `;\n      const userCode = `\n      fn DIV_CEIL(a : u32, b : u32) -> u32 {\n        return ((a - 1u) / b + 1u);\n      }\n\n      ${sharedMemorySnippet}\n\n      ${main('index')} {\n        let outputIndex = index / ${workgroupSizeX};\n        let reduceLength = ${getInputShapeLastDim()};\n\n        var bestIndex = i32(localId.x);\n        var bestValue = uniforms.infinityValue;\n        let outputCoords = getCoordsFromIndex(outputIndex);\n        for (var k = i32(localId.x); k < reduceLength && outputIndex < uniforms.size;\n            k = k + ${workgroupSizeX}) {\n          let candidate = getX(${splitOutputCoords()} k);\n          if (!isnan(candidate) && candidate ${this.op} bestValue) {\n            bestValue = candidate;\n            bestIndex = k;\n          }\n        }\n        xBestValues[localId.x] = bestValue;\n        xBestIndices[localId.x] = bestIndex;\n        workgroupBarrier();\n\n        var reduceSize = min(u32(reduceLength), ${workgroupSizeX}u);\n        for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n            currentSize = reduceSize / 2u) {\n          let interval = DIV_CEIL(reduceSize, 2u);\n          if (localId.x < currentSize) {\n            let candidate = xBestValues[localId.x + interval];\n            if (candidate ${this.op} bestValue) {\n              bestValue = candidate;\n              xBestValues[localId.x] = bestValue;\n              xBestIndices[localId.x] = xBestIndices[localId.x + interval];\n            }\n          }\n          reduceSize = interval;\n          workgroupBarrier();\n        }\n\n        if (localId.x == 0u && outputIndex < uniforms.size) {\n          setOutputAtIndexI32(outputIndex, xBestIndices[localId.x]);\n        }\n      }\n    `;\n      return userCode;\n    } else {\n      const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let outputCoords = getCoordsFromIndex(index);\n          var bestIndex = 0;\n          var bestValue = getX(${splitOutputCoords()} 0);\n          let reduceLength = ${getInputShapeLastDim()};\n          for (var i = 1; i < reduceLength; i++) {\n            let candidate = getX(${splitOutputCoords()} i);\n            if (candidate ${this.op} bestValue) {\n              bestValue = candidate;\n              bestIndex = i;\n            }\n          }\n          setOutputAtIndexI32(index, bestIndex);\n        }\n      }\n      `;\n      return userCode;\n    }\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMax, ArgMaxAttrs, ArgMaxInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {ArgMinMaxProgram} from '../argminmax_webgpu';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {transpose} from './Transpose';\n\nexport function argMax(\n    args: {inputs: ArgMaxInputs, backend: WebGPUBackend, attrs: ArgMaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('argMax', [axes[0]], $x.shape.length);\n  const program = new ArgMinMaxProgram($x.shape, axes[0], 'max');\n  const uniformData = [{type: 'float32', data: [Number.NEGATIVE_INFINITY]}];\n  const out = backend.runWebGPUProgram(program, [$x], 'int32', uniformData);\n  intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));\n  return out;\n}\n\nexport const argMaxConfig: KernelConfig = {\n  kernelName: ArgMax,\n  backendName: 'webgpu',\n  kernelFunc: argMax as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMin, ArgMinAttrs, ArgMinInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {ArgMinMaxProgram} from '../argminmax_webgpu';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {transpose} from './Transpose';\n\nexport function argMin(\n    args: {inputs: ArgMinInputs, backend: WebGPUBackend, attrs: ArgMinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('argMin', [axes[0]], $x.shape.length);\n  const program = new ArgMinMaxProgram($x.shape, axes[0], 'min');\n  const uniformData = [{type: 'float32', data: [Number.POSITIVE_INFINITY]}];\n  const out = backend.runWebGPUProgram(program, [$x], 'int32', uniformData);\n  intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));\n  return out;\n}\n\nexport const argMinConfig: KernelConfig = {\n  kernelName: ArgMin,\n  backendName: 'webgpu',\n  kernelFunc: argMin as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asin, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const asin = unaryKernelFunc({opType: UnaryOpType.ASIN});\n\nexport const asinConfig: KernelConfig = {\n  kernelName: Asin,\n  backendName: 'webgpu',\n  kernelFunc: asin\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asinh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const asinh = unaryKernelFunc({opType: UnaryOpType.ASINH});\n\nexport const asinhConfig: KernelConfig = {\n  kernelName: Asinh,\n  backendName: 'webgpu',\n  kernelFunc: asinh\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const atan = unaryKernelFunc({opType: UnaryOpType.ATAN});\n\nexport const atanConfig: KernelConfig = {\n  kernelName: Atan,\n  backendName: 'webgpu',\n  kernelFunc: atan\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan2, KernelConfig} from '@tensorflow/tfjs-core';\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const atan2 = binaryKernelFunc({opType: BinaryOpType.ATAN2});\n\nexport const atan2Config: KernelConfig = {\n  kernelName: Atan2,\n  backendName: 'webgpu',\n  kernelFunc: atan2\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atanh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const atanh = unaryKernelFunc({opType: UnaryOpType.ATANH});\n\nexport const atanhConfig: KernelConfig = {\n  kernelName: Atanh,\n  backendName: 'webgpu',\n  kernelFunc: atanh\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class PoolWithFilterSizeEqualsOneProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = `strides : vec2<i32>,`;\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'poolWithFilterSizeEqualsOne';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let batch = coords[0];\n          let d = coords[3];\n\n          let xRCCorner = coords.yz * uniforms.strides;\n          let xRCorner = xRCCorner.x;\n          let xCCorner = xRCCorner.y;\n\n          let value = getX(batch, xRCorner, xCCorner, d);\n          setOutputAtIndex(index, value);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Pool2DProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms =\n      `strides : vec2<i32>, pads : vec2<i32>, dilations : vec2<i32>, convDims : vec2<i32>, filterDims : vec2<i32>,`;\n  // TODO(jiajia.qin@intel.com): Dynamically choose different workgroupSize for\n  // different output shapes.\n  workgroupSize: [number, number, number] = [128, 1, 1];\n  poolType: 'max'|'avg';\n  size = true;\n  computePositions: boolean;\n  flattenPositions: boolean;\n  includeBatchIndex: boolean;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, poolType: 'max'|'avg',\n      computePositions = false, flattenPositions = false,\n      includeBatchIndex = false) {\n    if (poolType === 'avg' && computePositions) {\n      throw new Error('Cannot compute positions for average pool.');\n    }\n\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.poolType = poolType;\n    this.computePositions = computePositions;\n    this.flattenPositions = flattenPositions;\n    this.includeBatchIndex = includeBatchIndex;\n    this.shaderKey = `pool2D_${poolType}_${computePositions}_${\n        flattenPositions}_${includeBatchIndex}`;\n  }\n\n  getUserCode(): string {\n    let updateSnippet: string;\n    if (this.poolType === 'avg') {\n      updateSnippet = `resultValue = resultValue + value; count = count + 1.0;`;\n    } else if (this.computePositions) {\n      const positionStr = this.flattenPositions ?\n          (this.includeBatchIndex ?\n               `((batch * uniforms.xShape[1] + xR) * uniforms.xShape[2] + xC) * uniforms.xShape[3] + d` :\n               `(xR * uniforms.xShape[2] + xC) * uniforms.xShape[3] + d`) :\n          `wR * uniforms.filterDims.y + wC`;\n      updateSnippet = `let currMaxValue = mix(value, maxValue, maxValueFound);\n      if (value >= currMaxValue) {\n        maxValue = value;\n        maxValueFound = 1.0;\n        maxPosition = ${positionStr};\n      }`;\n    } else {\n      updateSnippet = `resultValue = max(value, resultValue);`;\n    }\n\n    let returnValue = `resultValue`;\n    if (this.poolType === 'avg') {\n      returnValue = `resultValue / max(count, 1.0)`;\n    }\n\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n          let batch = coords[0];\n          let d = coords[3];\n          let xRCCorner = vec2<i32>(coords.yz) * uniforms.strides - uniforms.pads;\n          let xRCorner = xRCCorner.x;\n          let xCCorner = xRCCorner.y;\n\n          ${\n        this.computePositions ?\n            `var maxValue = 0.0;\n            var maxValueFound = 0.0;\n            var maxPosition = 0;` :\n            `var resultValue = ${\n                this.poolType === 'avg' ? '0.0' : '-1.0 / pow(10.0, -20.0)'};`}\n\n          var count = 0.0;\n          for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + uniforms.dilations.x) {\n            let xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= uniforms.convDims.x) {\n              continue;\n            }\n\n            for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + uniforms.dilations.y) {\n              let xC = xCCorner + wC;\n              if (xC < 0 || xC >= uniforms.convDims.y) {\n                continue;\n              }\n\n              let value = getX(batch, xR, xC, d);\n              ${updateSnippet}\n            }\n          }\n\n          ${\n        this.computePositions ? `setOutputAtIndexI32(index, maxPosition);` :\n                                `setOutputAtIndex(index, ${returnValue});`}\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\nexport class Pool3DProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms =\n      `strides : vec3<i32>, pads : vec3<i32>, convDims : vec3<i32>, filterDims : vec3<i32>,`;\n  workgroupSize: [number, number, number] = [128, 1, 1];\n  poolType: 'max'|'avg';\n  size = true;\n  computePositions: boolean;\n  flattenPositions: boolean;\n  includeBatchIndex: boolean;\n\n  constructor(\n      convInfo: backend_util.Conv3DInfo, poolType: 'max'|'avg',\n      computePositions = false, flattenPositions = false,\n      includeBatchIndex = false) {\n    if (poolType === 'avg' && computePositions) {\n      throw new Error('Cannot compute positions for average pool.');\n    }\n\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.poolType = poolType;\n    this.computePositions = computePositions;\n    this.flattenPositions = flattenPositions;\n    this.includeBatchIndex = includeBatchIndex;\n    this.shaderKey = `pool3D_${poolType}_${computePositions}_${\n        flattenPositions}_${includeBatchIndex}`;\n  }\n\n  getUserCode(): string {\n    let updateSnippet: string;\n    if (this.poolType === 'avg') {\n      updateSnippet = `resultValue += value; count += 1.0;`;\n    } else if (this.computePositions) {\n      const positionStr = this.flattenPositions ?\n          (this.includeBatchIndex ?\n               `(((batch * uniforms.xShape.y + xD) * uniforms.xShape.z + xR) * uniforms.xShape.w + xC) * uniforms.xShape.u + ch` :\n               `((xD * uniforms.xShape.z + xR) * uniforms.xShape.w + xC) * uniforms.xShape.u + ch`) :\n          `wD * uniforms.filterDims.y * uniforms.filterDims.y + wR * uniforms.filterDims.z + wC`;\n      updateSnippet = `let currMaxValue = mix(value, maxValue, maxValueFound);\n      if (value >= currMaxValue) {\n        maxValue = value;\n        maxValueFound = 1.0;\n        maxPosition = ${positionStr};\n      }`;\n    } else {\n      updateSnippet = `resultValue = max(value, resultValue);`;\n    }\n\n    let returnValue = `resultValue`;\n    if (this.poolType === 'avg') {\n      returnValue = `resultValue / max(count, 1.0)`;\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let batch = coords.x;\n          let ch = coords.u;\n\n          let xCorner = vec3<i32>(coords.y, coords.z, coords.w) * uniforms.strides - uniforms.pads;\n          let xDCorner = xCorner.x;\n          let xRCorner = xCorner.y;\n          let xCCorner = xCorner.z;\n\n          ${\n        this.computePositions ?\n            `var maxValue = 0.0;\n            var maxValueFound = 0.0;\n            var maxPosition = 0;` :\n            `var resultValue = ${\n                this.poolType === 'avg' ? '0.0' : '-1.0 / pow(10.0, -20.0)'};`}\n\n          var count = 0.0;\n          for (var wD = 0; wD < uniforms.filterDims.x; wD++) {\n            let xD = xDCorner + wD;\n            if (xD < 0 || xD >= uniforms.convDims.x) {\n              continue;\n            }\n\n            for (var wR = 0; wR < uniforms.filterDims.y; wR++) {\n              let xR = xRCorner + wR;\n              if (xR < 0 || xR >= uniforms.convDims.y) {\n                continue;\n              }\n\n              for (var wC = 0; wC < uniforms.filterDims.z; wC++) {\n                let xC = xCCorner + wC;\n                if (xC < 0 || xC >= uniforms.convDims.z) {\n                  continue;\n                }\n\n                let value = getX(batch, xD, xR, xC, ch);\n                ${updateSnippet}\n              }\n            }\n          }\n\n          ${\n        this.computePositions ? `setOutputAtIndexI32(index, maxPosition);` :\n                                `setOutputAtIndex(index, ${returnValue});`}\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function max(\n    args: {inputs: MaxInputs, backend: WebGPUBackend, attrs: MaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reductionIndices, keepDims} = attrs;\n\n  return reduce(x, reductionIndices, keepDims, 'max', backend);\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'webgpu',\n  kernelFunc: max as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Mean, MeanAttrs, MeanInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function mean(\n    args: {inputs: MeanInputs, attrs: MeanAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {keepDims, axis} = attrs;\n\n  return reduce(x, axis, keepDims, 'mean', backend);\n}\n\nexport const meanConfig: KernelConfig = {\n  kernelName: Mean,\n  backendName: 'webgpu',\n  kernelFunc: mean as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {PoolWithFilterSizeEqualsOneProgram} from '../pool_filtersizeone_webgpu';\nimport {Pool2DProgram} from '../pool_webgpu';\n\nimport {identity} from './Identity';\nimport {max} from './Max';\nimport {mean} from './Mean';\nimport {reshape} from './Reshape';\n\ntype PoolType = 'max'|'avg';\nexport function poolImpl(\n    x: TensorInfo, convInfo: backend_util.Conv2DInfo, poolType: PoolType,\n    backend: WebGPUBackend): TensorInfo {\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    return identity({inputs: {x}, backend});\n  }\n\n  if (convInfo.filterWidth === convInfo.inWidth &&\n      convInfo.filterHeight === convInfo.inHeight && convInfo.batchSize === 1 &&\n      convInfo.padInfo.type === 'VALID') {\n    const length = x.shape.length;\n    const reshapeX = reshape({\n      inputs: {x},\n      backend,\n      attrs: {\n        shape: [\n          x.shape[length - 3] * x.shape[length - 2] /* height * width */,\n          x.shape[length - 1] /* channel */\n        ]\n      }\n    });\n    let reduceX;\n    if (poolType === 'avg') {\n      reduceX = mean(\n          {inputs: {x: reshapeX}, backend, attrs: {axis: 0, keepDims: false}});\n    } else {\n      util.assert(poolType === 'max', () => `Invalid pool type ${poolType}`);\n      reduceX = max({\n        inputs: {x: reshapeX},\n        backend,\n        attrs: {reductionIndices: 0, keepDims: false}\n      });\n    }\n\n    const result = reshape(\n        {inputs: {x: reduceX}, backend, attrs: {shape: convInfo.outShape}});\n    backend.disposeData(reshapeX.dataId);\n    backend.disposeData(reduceX.dataId);\n    return result;\n  }\n\n  let program: Pool2DProgram|PoolWithFilterSizeEqualsOneProgram;\n  const dimensions =\n      [{type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}];\n  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1) {\n    program = new PoolWithFilterSizeEqualsOneProgram(convInfo);\n  } else {\n    if (poolType === 'avg') {\n      program = new Pool2DProgram(convInfo, 'avg');\n    } else {\n      util.assert(poolType === 'max', () => `Invalid pool type ${poolType}`);\n      program = new Pool2DProgram(convInfo, 'max');\n    }\n\n    dimensions.push(\n        {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]}, {\n          type: 'int32',\n          data: [convInfo.dilationHeight, convInfo.dilationWidth]\n        },\n        {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]}, {\n          type: 'int32',\n          data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]\n        });\n  }\n\n  return backend.runWebGPUProgram(program, [x], x.dtype, dimensions);\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPool, AvgPoolAttrs, AvgPoolInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {poolImpl} from './Pool_impl';\n\nexport function avgPool(\n    args: {inputs: AvgPoolInputs, backend: WebGPUBackend, attrs: AvgPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n\n  return poolImpl(x, convInfo, 'avg', backend);\n}\n\nexport const avgPoolConfig: KernelConfig = {\n  kernelName: AvgPool,\n  backendName: 'webgpu',\n  kernelFunc: avgPool as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPool3D, AvgPool3DAttrs, AvgPool3DInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Pool3DProgram} from '../pool_webgpu';\n\nexport function avgPool3D(args: {\n  inputs: AvgPool3DInputs,\n  backend: WebGPUBackend,\n  attrs: AvgPool3DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dataFormat, dimRoundingMode} = attrs;\n  const dilations: [number, number, number] = [1, 1, 1];\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode, dataFormat);\n  const avgPoolProgram = new Pool3DProgram(convInfo, 'avg');\n  const dimensions = [\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data:\n          [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]\n    },\n    {\n      type: 'int32',\n      data: [convInfo.inDepth, convInfo.inHeight, convInfo.inWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth, convInfo.effectiveFilterHeight,\n        convInfo.effectiveFilterWidth\n      ]\n    }\n  ];\n  return backend.runWebGPUProgram(avgPoolProgram, [x], x.dtype, dimensions);\n}\n\nexport const avgPool3DConfig: KernelConfig = {\n  kernelName: AvgPool3D,\n  backendName: 'webgpu',\n  kernelFunc: avgPool3D as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class AvgPool2DBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy'];\n  uniforms =\n      `strides : vec2<i32>, pads : vec2<i32>, dilations : vec2<i32>, filterDims : vec2<i32>,\n       outHeight : i32, outWidth : i32, avgMultiplier : f32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `avgPool2DBackprop`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords[0];\n        let d = coords[3];\n\n        let dyRCCorner = vec2<i32>(coords.yz) - uniforms.pads;\n        let dyRCorner = dyRCCorner.x;\n        let dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        for (var wR = 0; wR < uniforms.filterDims[0]; wR = wR + uniforms.dilations[0]) {\n          let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[0]);\n\n          if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n            continue;\n          }\n          let idyR = i32(dyR);\n\n          for (var wC = 0; wC < uniforms.filterDims[1]; wC = wC + uniforms.dilations[1]) {\n            let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[1]);\n\n            if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n              continue;\n            }\n            let idyC = i32(dyC);\n\n            let dyValue = getDy(batch, idyR, idyC, d);\n\n            dotProd = dotProd + dyValue * uniforms.avgMultiplier;\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n\nexport class AvgPool3DBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy'];\n  uniforms = `strides : vec3<i32>, pads : vec3<i32>, filterDims : vec3<i32>,\n       outDepth : i32, outHeight : i32, outWidth : i32, avgMultiplier : f32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv3DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `avgPool3DBackprop`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords.x;\n        let ch = coords.u;\n\n        let dyCorner = vec3<i32>(coords.y, coords.z, coords.w) - uniforms.pads;\n        let dyDCorner = dyCorner.x;\n        let dyRCorner = dyCorner.y;\n        let dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        for (var wD = 0; wD < uniforms.filterDims[0]; wD++) {\n          let dyD = f32(dyDCorner + wD) / f32(uniforms.strides[0]);\n\n          if (dyD < 0.0 || dyD >= f32(uniforms.outDepth) || fract(dyD) > 0.0) {\n            continue;\n          }\n          let idyD = i32(dyD);\n\n          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {\n            let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[1]);\n\n            if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n              continue;\n            }\n            let idyR = i32(dyR);\n\n            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {\n              let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[2]);\n\n              if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n                continue;\n              }\n              let idyC = i32(dyC);\n\n              let dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              dotProd += dyValue * uniforms.avgMultiplier;\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPool3DGrad, AvgPool3DGradAttrs, AvgPool3DGradInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {AvgPool3DBackpropProgram} from '../avg_pool_backprop_webgpu';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nexport function avgPool3DGrad(args: {\n  inputs: AvgPool3DGradInputs,\n  backend: WebGPUBackend,\n  attrs: AvgPool3DGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode);\n  const program = new AvgPool3DBackpropProgram(convInfo);\n  const avgMultiplier =\n      1 / (convInfo.filterDepth * convInfo.filterHeight * convInfo.filterWidth);\n  const uniformData = [\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth - 1 - convInfo.padInfo.front,\n        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,\n        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth, convInfo.effectiveFilterHeight,\n        convInfo.effectiveFilterWidth\n      ]\n    },\n    {type: 'int32', data: [convInfo.outDepth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'float32', data: [avgMultiplier]}\n  ];\n  return backend.runWebGPUProgram(program, [dy], x.dtype, uniformData);\n}\n\nexport const avgPool3DGradConfig: KernelConfig = {\n  kernelName: AvgPool3DGrad,\n  backendName: 'webgpu',\n  kernelFunc: avgPool3DGrad as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPoolGrad, AvgPoolGradAttrs, AvgPoolGradInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {AvgPool2DBackpropProgram} from '../avg_pool_backprop_webgpu';\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {assertNotComplex} from '../webgpu_util';\n\nexport function avgPoolGrad(args: {\n  inputs: AvgPoolGradInputs,\n  backend: WebGPUBackend,\n  attrs: AvgPoolGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  assertNotComplex([dy, input], 'avgPoolGrad');\n  const {filterSize, strides, pad} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad);\n  const program = new AvgPool2DBackpropProgram(convInfo);\n  const avgMultiplier = 1 / (convInfo.filterHeight * convInfo.filterWidth);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,\n        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]}, {\n      type: 'int32',\n      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]\n    },\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'float32', data: [avgMultiplier]}\n  ];\n  return backend.runWebGPUProgram(program, [dy], x.dtype, uniformData);\n}\n\nexport const avgPoolGradConfig: KernelConfig = {\n  kernelName: AvgPoolGrad,\n  backendName: 'webgpu',\n  kernelFunc: avgPoolGrad as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {batchMatMulImpl} from './BatchMatMul_impl';\n\nexport function batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  attrs: BatchMatMulAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  return batchMatMulImpl({a, b, transposeA, transposeB, backend});\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'webgpu',\n  kernelFunc: batchMatMul as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getCoordsXYZ, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SliceProgram implements WebGPUProgram {\n  variableNames = ['source'];\n  uniforms: string;\n  outputShape: number[];\n  shaderKey: string;\n  rank: number;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workPerThread = 1;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  start: number[];\n  size = true;\n\n  constructor(start: number[], destSize: number[]) {\n    this.outputShape = destSize;\n    this.rank = destSize.length;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n\n    this.start = start;\n    this.uniforms = `start : ${getCoordsDataType(start.length)}, `;\n    this.shaderKey = 'slice';\n  }\n\n  getUserCode(): string {\n    const dtype = getCoordsDataType(this.rank);\n    const sourceCoords = getCoords(this.rank);\n    let coordSum;\n    if (this.start.length === 1) {\n      coordSum = this.outputShape.map((_, i) => {\n        return `sourceLoc = uniforms.start + coords;`;\n      });\n    } else {\n      coordSum = this.outputShape.map((_, i) => {\n        return `sourceLoc.${coords[i]} = uniforms.start.${\n            getCoordsXYZ(i)} + coords.${coords[i]};`;\n      });\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          var sourceLoc : ${dtype};\n          let coords = getCoordsFromIndex(index);\n          ${coordSum.join('\\n')}\n          setOutputAtIndex(index, getSource(${sourceCoords}));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\nconst coords = ['x', 'y', 'z', 'w', 'u', 'v'];\n\nfunction getCoords(rank: number): string {\n  if (rank === 1) {\n    return 'sourceLoc';\n  } else if (rank <= 6) {\n    return coords.slice(0, rank).map(coord => `sourceLoc.${coord}`).join(',');\n  } else {\n    throw Error(`Slicing for rank ${rank} is not yet supported`);\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {sliceImplCPU} from '../kernel_utils/shared';\nimport {SliceProgram} from '../slice_webgpu';\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: WebGPUBackend, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {\n    const xTensorData = backend.tensorMap.get(x.dataId);\n    const outValues = sliceImplCPU(\n        xTensorData.values as TypedArray, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outValues);\n  }\n\n  if (util.sizeFromShape($size) === 0) {\n    return backend.makeTensorInfo($size, x.dtype, []);\n  }\n\n  // TODO(xing.xu): Add shadow slice support.\n  const program = new SliceProgram($begin, $size);\n  const uniformData = [{type: 'int32', data: $begin}];\n  return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'webgpu',\n  kernelFunc: slice as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BatchToSpaceND, BatchToSpaceNDAttrs, BatchToSpaceNDInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {transpose} from './Transpose';\n\nexport const batchToSpaceND = (args: {\n  inputs: BatchToSpaceNDInputs,\n  backend: WebGPUBackend,\n  attrs: BatchToSpaceNDAttrs\n}): TensorInfo => {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, crops} = attrs;\n\n  util.assert(\n      x.shape.length <= 4,\n      () => 'batchToSpaceND for rank > 4 with a WebGPU backend not ' +\n          'implemented yet');\n  const prod = blockShape.reduce((a, b) => a * b);\n\n  const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n  const permuted = backend_util.getPermuted(reshaped.length, blockShape.length);\n  const reshapedPermuted =\n      backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n  const sliceBeginCoords =\n      backend_util.getSliceBeginCoords(crops, blockShape.length);\n  const sliceSize =\n      backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n  const toDispose = [];\n\n  const reshapedIntermediate =\n      reshape({inputs: {x}, backend, attrs: {shape: reshaped}});\n  const transposedIntermediate = transpose(\n      {inputs: {x: reshapedIntermediate}, backend, attrs: {perm: permuted}});\n  const reshapedIntermediate2 = reshape({\n    inputs: {x: transposedIntermediate},\n    backend,\n    attrs: {shape: reshapedPermuted}\n  });\n  const sliced = slice({\n    inputs: {x: reshapedIntermediate2},\n    backend,\n    attrs: {begin: sliceBeginCoords, size: sliceSize}\n  });\n\n  toDispose.push(reshapedIntermediate);\n  toDispose.push(transposedIntermediate);\n  toDispose.push(reshapedIntermediate2);\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n\n  return sliced;\n};\n\nexport const batchToSpaceNDConfig: KernelConfig = {\n  kernelName: BatchToSpaceND,\n  backendName: 'webgpu',\n  kernelFunc: batchToSpaceND as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {atomicAddSnippet} from './shader_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nconst writeSnippet = `\n  fn bincount_write(index: i32, value: f32) {\n    ${atomicAddSnippet('&result[index]', 'value', 'float32')}\n  }\n`;\n\nconst binaryWriteSnippet = `\n  fn bincount_write(index: i32, value: f32) {\n    atomicStore(&result[index], bitcast<i32>(value));\n  }\n`;\n\nexport class BincountProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'binCountSize : i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  hasWeights = true;\n  binaryOutput = false;\n  rank: number;\n\n  constructor(\n      shape: [number]|[number, number], hasWeights: boolean,\n      binaryOutput = false) {\n    this.outputShape = shape;\n    this.rank = shape.length;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.binaryOutput = binaryOutput;\n    if (binaryOutput) {\n      this.atomic = false;\n    }\n    this.hasWeights = hasWeights;\n    if (this.hasWeights) {\n      this.variableNames.push('w');\n    }\n    this.shaderKey =\n        `bincount_${this.hasWeights}_${this.binaryOutput}_${this.rank}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${this.binaryOutput ? binaryWriteSnippet : writeSnippet}\n  ${main('index')} {\n    ${\n        this.rank === 1 ?\n            `if (index < uniforms.xShape) {\n      let indexVal = i32(getX(index));\n      if (indexVal < uniforms.binCountSize) {\n        let value = ${\n                this.binaryOutput ? 1. :\n                                    (this.hasWeights ? 'getW(index)' : '1.')};\n        bincount_write(indexVal, value);\n      }\n    }` :\n            `let coord = getCoordsFromIndex(index);\n    if (coordsInBounds2D(coord, uniforms.xShape)) {\n      let indexVal = i32(getX(coord[0], coord[1]));\n      if (indexVal < uniforms.binCountSize) {\n        let value = ${\n                this.binaryOutput ?\n                    1. :\n                    (this.hasWeights ? 'getW(coord[0], coord[1])' : '1.')};\n        bincount_write(coord.x * uniforms.binCountSize + indexVal, value);\n      }\n    }`}\n  }\n  `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Bincount, BincountAttrs, BincountInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {BincountProgram} from '../bincount_webgpu';\n\nimport {fill} from './Fill';\n\nexport function bincount(\n    args:\n        {inputs: BincountInputs, backend: WebGPUBackend, attrs: BincountAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, weights} = inputs;\n  const {size} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const weightsSize = util.sizeFromShape(weights.shape);\n  const hasWeights = weightsSize > 0;\n  const outputSize: [number] = [size];\n  const dtype = weights.dtype;\n\n  const output = fill({backend, attrs: {shape: outputSize, value: 0, dtype}});\n  const program = new BincountProgram([xSize], hasWeights);\n  const uniformData = [{type: 'int32', data: [size]}];\n  const bincountInputs: TensorInfo[] = hasWeights ? [x, weights] : [x];\n  const res = backend.runWebGPUProgram(\n      program, bincountInputs, dtype, uniformData, output);\n\n  return res;\n}\n\nexport const bincountConfig: KernelConfig = {\n  kernelName: Bincount,\n  backendName: 'webgpu',\n  kernelFunc: bincount as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class BroadcastArgsProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['s0', 's1'];\n  uniforms = 's0Size : i32, s1Size : i32, ';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shape: number) {\n    this.outputShape = [shape];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'broadcastArgs';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n  ${main('index')} {\n    if (index < uniforms.size) {\n      var s0 = 1.0;\n      var s1 = 1.0;\n      let indexS0 = index - uniforms.size + uniforms.s0Size;\n      let indexS1 = index - uniforms.size + uniforms.s1Size;\n      if (indexS0 >= 0) {\n        s0 = getS0(indexS0);\n      }\n      if (indexS1 >= 0) {\n        s1 = getS1(indexS1);\n      }\n\n      if (s0 == 1.0) {\n        setOutputAtIndex(index, s1);\n      } else if (s1 == 1.0) {\n        setOutputAtIndex(index, s0);\n      } else if (s0 != s1) {\n        setOutputAtIndex(index, uniforms.NAN);\n      } else {\n        setOutputAtIndex(index, s0);\n      }\n    }\n  }\n  `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BroadcastArgs, BroadcastArgsInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {BroadcastArgsProgram} from '../broadcast_args_webgpu';\n\nexport function broadcastArgs(args: {\n  inputs: BroadcastArgsInputs,\n  backend: WebGPUBackend,\n}): TensorInfo {\n  const {inputs, backend} = args;\n  const {s0, s1} = inputs;\n\n  if (backend.shouldExecuteOnCPU([s0, s1])) {\n    const s0TensorInfo = backend.tensorMap.get(s0.dataId);\n    const s1TensorInfo = backend.tensorMap.get(s1.dataId);\n    const s0Vals = s0TensorInfo.values as TypedArray;\n    const s1Vals = s1TensorInfo.values as TypedArray;\n    const broadcastShape = backend_util.assertAndGetBroadcastShape(\n        Array.from(s0Vals), Array.from(s1Vals));\n    return backend.makeTensorInfo(\n        [broadcastShape.length], 'int32', Int32Array.from(broadcastShape));\n  }\n\n  const s0Size = util.sizeFromShape(s0.shape);\n  const s1Size = util.sizeFromShape(s1.shape);\n  const outputSize = Math.max(s0Size, s1Size);\n\n  const program = new BroadcastArgsProgram(outputSize);\n  const uniformData =\n      [{type: 'int32', data: [s0Size]}, {type: 'int32', data: [s1Size]}];\n  return backend.runWebGPUProgram(program, [s0, s1], 'int32', uniformData);\n}\n\nexport const broadcastArgsConfig: KernelConfig = {\n  kernelName: BroadcastArgs,\n  backendName: 'webgpu',\n  kernelFunc: broadcastArgs as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {notEqualImplCPU as cpuNotEqual} from '../kernel_utils/shared';\n\nexport const notEqual = binaryKernelFunc({\n  opType: BinaryOpType.NOT_EQUAL,\n  dtype: 'bool',\n  cpuKernelImpl: cpuNotEqual\n});\n\nexport const notEqualConfig: KernelConfig = {\n  kernelName: NotEqual,\n  backendName: 'webgpu',\n  kernelFunc: notEqual\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Real, RealInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\n\nexport function real(args: {inputs: RealInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n  const inputData = backend.tensorMap.get(input.dataId);\n\n  return identity({inputs: {x: inputData.complexTensorInfos.real}, backend});\n}\n\nexport const realConfig: KernelConfig = {\n  kernelName: Real,\n  backendName: 'webgpu',\n  kernelFunc: real as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\nexport function int(input: TensorInfo, backend: WebGPUBackend): TensorInfo {\n  const program = new UnaryOpProgram(input.shape, UnaryOpType.TO_INT);\n  const output = backend.runWebGPUProgram(program, [input], 'int32');\n  return {dataId: output.dataId, shape: output.shape, dtype: output.dtype};\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport {BinaryInputs, Cast, CastAttrs, CastInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {castImplCPU} from '../kernel_utils/shared';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {notEqual} from './NotEqual';\nimport {real} from './Real';\n\nimport {int} from '../kernel_utils/int';\n\nexport function cast(\n    args: {inputs: CastInputs, backend: WebGPUBackend, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    // TODO: Import kernel function once zeros is modularized.\n    const zerosTensor = tf.zeros(x.shape);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensor}, backend});\n\n    zerosTensor.dispose();\n    backend.disposeData(floatX.dataId);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n    backend.disposeData(realPart.dataId);\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  if (backend.shouldExecuteOnCPU([x])) {\n    const values = backend.tensorMap.get(x.dataId).values as TypedArray;\n    const [resultShape, resultType, resultData] =\n        castImplCPU(values, x.shape, x.dtype, dtype);\n    return backend.makeTensorInfo(resultShape, resultType, resultData);\n  }\n\n  if (dtype === 'int32') {\n    return int(x, backend);\n  }\n\n  if (dtype === 'bool') {\n    const zerosTensorInfo = backend.makeTensorInfo(\n        [], 'bool', util.getTypedArrayFromDType('bool', 1));\n\n    const binaryInputs: BinaryInputs = {a: x, b: zerosTensorInfo};\n\n    const result = notEqual({inputs: binaryInputs, backend}) as TensorInfo;\n    backend.disposeData(zerosTensorInfo.dataId);\n    return result;\n  }\n\n  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'webgpu',\n  kernelFunc: cast as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Ceil, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {ceilImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const ceil =\n    unaryKernelFunc({opType: UnaryOpType.CEIL, cpuKernelImpl: ceilImplCPU});\n\nexport const ceilConfig: KernelConfig = {\n  kernelName: Ceil,\n  backendName: 'webgpu',\n  kernelFunc: ceil\n};\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ClipVec4Program implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  variableNames = ['A'];\n  uniforms = 'minVal : f32, maxVal : f32,';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workPerThread = 4;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  outputComponent = 4;\n  size = true;\n\n  constructor(outputShape: number[]) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n    this.shaderKey = 'clipVec4';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let value = getAByOutputIndex(index);\n          var clampedValue = clamp(\n              value, vec4<f32>(uniforms.minVal), vec4<f32>(uniforms.maxVal));\n          clampedValue = select(clampedValue, value, isnanVec4(value));\n          setOutputAtIndex(index, clampedValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ClipProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  variableNames = ['A'];\n  uniforms = 'minVal : f32, maxVal : f32,';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  minVal: number;\n  maxVal: number;\n  size = true;\n\n  constructor(outputShape: number[]) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'clip';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let value = getAByOutputIndex(index);\n          if (isnan(value)) {\n            setOutputAtIndex(index, value);\n            return;\n          }\n          setOutputAtIndex(index, clamp(value, uniforms.minVal, uniforms.maxVal));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ClipByValue, ClipByValueAttrs, ClipByValueInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {ClipVec4Program} from '../clip_vec4_webgpu';\nimport {ClipProgram} from '../clip_webgpu';\n\nexport function clipByValue(args: {\n  inputs: ClipByValueInputs,\n  backend: WebGPUBackend,\n  attrs: ClipByValueAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {clipValueMin, clipValueMax} = attrs;\n\n  let program: ClipProgram|ClipVec4Program;\n  const uniformData = [\n    {type: 'float32', data: [clipValueMin]},\n    {type: 'float32', data: [clipValueMax]}\n  ];\n  if (util.sizeFromShape(x.shape) % 4 === 0) {\n    program = new ClipVec4Program(x.shape);\n  } else {\n    program = new ClipProgram(x.shape);\n  }\n  return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n}\n\nexport const clipByValueConfig: KernelConfig = {\n  kernelName: ClipByValue,\n  backendName: 'webgpu',\n  kernelFunc: clipByValue as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ComplexAbsProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['real', 'imag'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'complexAbs';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let re = abs(getRealByOutputIndex(index));\n        let im = abs(getImagByOutputIndex(index));\n        let mx = max(re, im);\n\n        // The length function in wgsl may be not underflow-safe on some GPUs.\n        // So the safe solution is to ensure underflow-safety in all cases.\n        setOutputAtIndex(index, select(mx * length(vec2<f32>(1, min(re, im)/mx)), 0.0, mx == 0.0));\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ComplexAbs, ComplexAbsInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ComplexAbsProgram} from '../complex_abs_webgpu';\n\n// Returns a TensorInfo with the complex shape and the dataId of the\n// underlying part. We need to do this because a reshaped complex tensor is\n// not reflected in its parts.\nfunction makeComplexComponentTensorInfo(\n    complexTensor: TensorInfo, complexPart: TensorInfo): TensorInfo {\n  return {\n    dataId: complexPart.dataId,\n    dtype: complexPart.dtype,\n    shape: complexTensor.shape\n  };\n}\n\nexport function complexAbs(\n    args: {inputs: ComplexAbsInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  const xData = backend.tensorMap.get(x.dataId);\n\n  const program = new ComplexAbsProgram(x.shape);\n  const programInputs = [\n    makeComplexComponentTensorInfo(x, xData.complexTensorInfos.real),\n    makeComplexComponentTensorInfo(x, xData.complexTensorInfos.imag),\n  ];\n\n  return backend.runWebGPUProgram(\n      program, programInputs, programInputs[0].dtype);\n}\n\nexport const complexAbsConfig: KernelConfig = {\n  kernelName: ComplexAbs,\n  backendName: 'webgpu',\n  kernelFunc: complexAbs as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ConcatProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[];\n  uniforms = '';\n  workPerThread = 1;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  offsetLength: number;\n\n  constructor(shapes: Array<[number, number]>) {\n    this.outputShape =\n        backend_util.computeOutShape(shapes, 1 /* axis */) as [number, number];\n    this.variableNames = shapes.map((_, i) => `T${i}`);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n\n    this.offsetLength = shapes.length - 1;\n    for (let i = 0; i < this.offsetLength; i++) {\n      this.uniforms += `offset${i} : i32,`;\n    }\n    this.shaderKey = 'concat';\n  }\n\n  getUserCode(): string {\n    const snippets: string[] = [];\n    if (this.offsetLength > 0) {\n      snippets.push(\n          `if (yC < uniforms.offset0){ setOutputAtCoords(coords.x, coords.y, getT0(yR, yC)); }`);\n      for (let i = 1; i < this.offsetLength; i++) {\n        snippets.push(\n            `else if (yC < uniforms.offset${[i]}){ ` +\n            `setOutputAtCoords(coords.x, coords.y, getT${\n                i}(yR, yC - uniforms.offset${i - 1})); }`);\n      }\n      const lastIndex = this.offsetLength;\n      const lastShiftIndex = this.offsetLength - 1;\n      snippets.push(`else { setOutputAtCoords(coords.x, coords.y, getT${\n          lastIndex}(yR, yC - uniforms.offset${lastShiftIndex})); }`);\n    } else {\n      snippets.push(`setOutputAtCoords(coords.x, coords.y, getT0(yR, yC));`);\n    }\n\n    const userCode = `\n      ${main('index')} {\n        for(var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let flatIndex = index * ${this.workPerThread} + i;\n          if(flatIndex < uniforms.size) {\n            let coords = getCoordsFromIndex(flatIndex);\n            let yR = coords.x;\n            let yC = coords.y;\n\n            ${snippets.join('\\n        ')}\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Imag, ImagInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\n\nexport function imag(args: {inputs: ImagInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n  const inputData = backend.tensorMap.get(input.dataId);\n\n  return identity({inputs: {x: inputData.complexTensorInfos.imag}, backend});\n}\n\nexport const imagConfig: KernelConfig = {\n  kernelName: Imag,\n  backendName: 'webgpu',\n  kernelFunc: imag as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, ConcatInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ConcatProgram} from '../concat_webgpu';\nimport {concatImplCPU} from '../kernel_utils/shared';\n\nimport {complex} from './Complex';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concatImpl(\n    inputs: ConcatInputs, axis: number, backend: WebGPUBackend): TensorInfo {\n  const dtype = inputs[0].dtype;\n  if (dtype === 'complex64') {\n    const reals = inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concatImpl(reals, axis, backend);\n    const imagConcated = concatImpl(imags, axis, backend);\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeData(r.dataId));\n    imags.forEach(i => backend.disposeData(i.dataId));\n    backend.disposeData(realConcated.dataId);\n    backend.disposeData(imagConcated.dataId);\n\n    return result;\n  }\n\n  let runOnCpu = backend.shouldExecuteOnCPU(inputs);\n\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgpu doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (dtype === 'string') {\n    runOnCpu = true;\n  }\n\n  if (runOnCpu) {\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const tensors2D = inputs.map(t => {\n      const innerSize = util.sizeFromShape(t.shape.slice(axis));\n      const shape = [-1, innerSize];\n      return reshape({inputs: {x: t}, backend, attrs: {shape}});\n    });\n\n    const inputsValShapes = tensors2D.map(t => {\n      return {vals: backend.readSync(t.dataId), shape: t.shape};\n    });\n\n    // Concats 2d tensors along axis=1.\n    const outShape =\n        backend_util.computeOutShape(tensors2D.map(t => t.shape), 1 /* axis */);\n    const simplyConcat = tensors2D[0].shape[0] === 1;\n    const outVals =\n        concatImplCPU(inputsValShapes, outShape, dtype, simplyConcat);\n\n    const finalOutShape =\n        backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n\n    const outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);\n\n    tensors2D.forEach(t => backend.disposeData(t.dataId));\n\n    return outInfo;\n  }\n\n  // There is a storage buffer limitation in compute stage, one for output so\n  // the maximum for input is limits.maxStorageBuffersPerShaderStage - 1\n  const maxInputNum = backend.device.limits.maxStorageBuffersPerShaderStage - 1;\n  if (inputs.length > maxInputNum) {\n    const reducedInputs = [];\n    for (let i = 0; i < inputs.length; i += maxInputNum) {\n      const subArray = inputs.slice(i, i + maxInputNum);\n      reducedInputs.push(concatImpl(subArray, axis, backend));\n    }\n    const result = concatImpl(reducedInputs, axis, backend);\n\n    for (const i of reducedInputs) {\n      backend.disposeData(i.dataId);\n    }\n\n    return result;\n  }\n\n  const {tensors2D, outShape} = computeTensors2D(inputs, axis, backend);\n  const shapes = (tensors2D).map(t => t.shape as [number, number]);\n  const program = new ConcatProgram(shapes);\n\n  const uniformData: Array<{type: string; data: number[]}> = [];\n  const offsets: number[] = new Array(shapes.length - 1);\n  if (offsets.length > 0) {\n    offsets[0] = shapes[0][1];\n    uniformData.push({type: 'int32', data: [offsets[0]]});\n    for (let i = 1; i < offsets.length; i++) {\n      offsets[i] = offsets[i - 1] + shapes[i][1];\n      uniformData.push({type: 'int32', data: [offsets[i]]});\n    }\n  }\n\n  const res = backend.runWebGPUProgram(\n      program, tensors2D, tensors2D[0].dtype, uniformData);\n  tensors2D.forEach(r => backend.disposeData(r.dataId));\n\n  const reshapedResult =\n      reshape({inputs: {x: res}, backend, attrs: {shape: outShape}});\n  backend.disposeData(res.dataId);\n  return reshapedResult;\n}\n\nfunction computeTensors2D(\n    inputs: ConcatInputs, axis: number, backend: WebGPUBackend) {\n  const outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n  const tensors2D = inputs.map(t => reshape({\n                                 inputs: {x: t},\n                                 backend,\n                                 attrs: {\n                                   shape: [\n                                     util.sizeFromShape(t.shape.slice(0, axis)),\n                                     util.sizeFromShape(t.shape.slice(axis))\n                                   ]\n                                 }\n                               }));\n\n  return {tensors2D, outShape};\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Concat, ConcatAttrs, ConcatInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {concatImpl} from './Concat_impl';\nimport {identity} from './Identity';\n\nexport function concat(\n    args: {inputs: ConcatInputs, attrs: ConcatAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n\n  const shapes = inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n\n  const outShape =\n      backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return identity({inputs: {x: $inputs[0]}, backend});\n  }\n\n  return concatImpl($inputs, $axis, backend);\n}\n\nexport const concatConfig: KernelConfig = {\n  kernelName: Concat,\n  backendName: 'webgpu',\n  kernelFunc: concat as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\nimport {typeSnippet, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, computeWorkgroupSizeForConv2d, computeWorkPerThreadForConv2d} from './webgpu_util';\n\nfunction conv2dCommonSnippet(\n    isChannelsLast: boolean, fitAOuter: boolean, fitBOuter: boolean,\n    fitInner: boolean, addBias = false,\n    activation: backend_util.Activation = null,\n    hasPreluActivationWeights = false, innerElementSizeX = 4,\n    innerElementSizeW = 4, innerElementSize = 4) {\n  const getXSnippet = (innerElementSize: number) => {\n    switch (innerElementSize) {\n      case 1:\n        return 'resData = f32(x[xIndex]);';\n      case 3:\n        return 'resData = vec3<f32>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);';\n      case 4:\n        return 'resData = vec4<f32>(x[xIndex / 4]);';\n      default:\n        throw new Error(\n            `innerElementSize ${innerElementSize} is not supported.`);\n    }\n  };\n  const getWSnippet = (innerElementSize: number) => {\n    switch (innerElementSize) {\n      case 1:\n        return 'return f32(W[row * uniforms.wShape[3] + col]);';\n      case 4:\n        return 'return vec4<f32>(W[(row * uniforms.wShape[3] + col) / 4]);';\n      default:\n        throw new Error(\n            `innerElementSize ${innerElementSize} is not supported.`);\n    }\n  };\n  const coordASnippet = isChannelsLast ? `\n      let coord = vec4<i32>(batch, xRow, xCol, xCh);\n      ` :\n                                         `\n      let coord = vec4<i32>(batch, xCh, xRow, xCol);\n      `;\n\n  const coordResSnippet = isChannelsLast ? `\n      let coords = vec4<i32>(\n        batch,\n        row / outWidth,\n        row % outWidth,\n        col);\n      ` :\n                                           `\n      let coords = vec4<i32>(\n        batch,\n        row,\n        col / outWidth,\n        col % outWidth);\n      `;\n\n  const xHight = isChannelsLast ? 'uniforms.xShape[1]' : 'uniforms.xShape[2]';\n  const xWidth = isChannelsLast ? 'uniforms.xShape[2]' : 'uniforms.xShape[3]';\n  const row = isChannelsLast ? 'row' : 'col';\n  const col = isChannelsLast ? 'col' : 'row';\n  const readXSnippet = `\n      let inChannels = uniforms.wShape[2];\n      let outWidth = ${\n      isChannelsLast ? 'uniforms.outShape[2]' : 'uniforms.outShape[3]'};\n      let outRow = ${row} / outWidth;\n      let outCol = ${row} % outWidth;\n\n      let WRow = ${col} / (uniforms.filterDims[1] * inChannels);\n      let WCol = ${col} / inChannels % uniforms.filterDims[1];\n      let xRow = outRow * uniforms.strides[0] + uniforms.dilations[0] * WRow - uniforms.pads[0];\n      let xCol = outCol * uniforms.strides[1] + uniforms.dilations[1] * WCol - uniforms.pads[1];\n      let xCh = ${col} % inChannels;\n      var resData = ${typeSnippet(innerElementSizeX)}(0.0);\n      // The bounds checking is always needed since we use it to pad zero for\n      // the 'same' padding type.\n      if (xRow >= 0 && xRow < ${xHight} && xCol >= 0 && xCol < ${xWidth}) {\n        ${coordASnippet}\n        let xIndex = getIndexFromCoords4D(coord, uniforms.xShape);\n        ${getXSnippet(innerElementSizeX)}\n      }\n      return resData;`;\n\n  const sampleX = isChannelsLast ? (fitAOuter && fitInner ? `\n      ${readXSnippet}` :\n                                                            `\n      if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n        ${readXSnippet}\n      }\n      return ${typeSnippet(innerElementSizeX)}(0.0);`) :\n                                   (fitInner && fitBOuter ? `\n      ${readXSnippet}` :\n                                                            `\n      if (row < uniforms.dimInner && col < uniforms.dimBOuter) {\n        ${readXSnippet}\n      }\n      return ${typeSnippet(innerElementSizeX)}(0.0);`);\n\n  const sampleW = `${getWSnippet(innerElementSizeW)}`;\n\n  const resType = typeSnippet(innerElementSize);\n  const aType = isChannelsLast ? typeSnippet(innerElementSizeX) :\n                                 typeSnippet(innerElementSizeW);\n  const bType = isChannelsLast ? typeSnippet(innerElementSizeW) :\n                                 typeSnippet(innerElementSizeX);\n  const userCode = `\n      ${\n      activationFnSnippet(\n          activation, hasPreluActivationWeights, innerElementSize === 4, 4)}\n      fn mm_readA(batch: i32, row : i32, col : i32) -> ${aType} {\n        ${isChannelsLast ? sampleX : sampleW}\n      }\n\n      fn mm_readB(batch: i32, row : i32, col : i32) -> ${bType} {\n        ${isChannelsLast ? sampleW : sampleX}\n      }\n\n      fn mm_write(batch: i32, row : i32, col : i32, valueIn : ${resType}) {\n        if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)\n        {\n        var value = valueIn;\n        let outWidth = ${\n      isChannelsLast ? 'uniforms.outShape[2]' : 'uniforms.outShape[3]'};\n        ${coordResSnippet}\n        ${biasActivationSnippet(addBias, activation)}\n        setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n        }\n      }`;\n  return userCode;\n}\n\nexport class Conv2DMMProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  variableComponents: number[];\n  uniforms =\n      `filterDims : vec2<i32>, pads : vec2<i32>, strides : vec2<i32>, dilations : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number];\n  elementsPerThread: [number, number, number];\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  isChannelsLast: boolean;\n  fitAOuter: boolean;\n  fitBOuter: boolean;\n  fitInner: boolean;\n  tileAOuter: number;\n  tileBOuter: number;\n  tileInner: number;\n  innerElementSize: number;\n  isVec4?: boolean;\n  outputComponent: number;\n  private sequentialAccessByThreads: boolean;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, dimAOuter: number, dimBOuter: number,\n      dimInner: number, addBias = false,\n      activation: backend_util.Activation = null,\n      hasPreluActivationWeights = false, sequentialAccessByThreads = false) {\n    this.outputShape = convInfo.outShape;\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    this.isVec4 =\n        (((convInfo.inChannels % 4 === 0 || convInfo.inChannels % 3 === 0) &&\n          this.isChannelsLast) ||\n         (convInfo.outWidth % 4 === 0 && !this.isChannelsLast)) &&\n        convInfo.outChannels % 4 === 0;\n    this.dispatchLayout = this.isChannelsLast ? {x: [3], y: [1, 2], z: [0]} :\n                                                {x: [2, 3], y: [1], z: [0]};\n    this.workgroupSize = computeWorkgroupSizeForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n    this.elementsPerThread = computeWorkPerThreadForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        this.elementsPerThread);\n\n    if (this.isVec4) {\n      this.outputComponent = 4;\n      if (this.isChannelsLast && convInfo.inChannels % 4 !== 0) {\n        this.innerElementSize = 3;\n        this.variableComponents = [1, 4];\n      } else {\n        this.innerElementSize = 4;\n        this.variableComponents = [4, 4];\n      }\n\n      if (addBias) {\n        this.variableNames.push('bias');\n        this.variableComponents.push(4);\n      }\n\n      if (hasPreluActivationWeights) {\n        this.variableNames.push('preluActivationWeights');\n        this.variableComponents.push(4);\n      }\n    } else {\n      this.innerElementSize = this.elementsPerThread[0];\n      if (addBias) {\n        this.variableNames.push('bias');\n      }\n\n      if (hasPreluActivationWeights) {\n        this.variableNames.push('preluActivationWeights');\n      }\n    }\n\n    this.sequentialAccessByThreads = sequentialAccessByThreads;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n\n    this.tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];\n    this.tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];\n    this.tileInner = Math.max(\n        this.workgroupSize[0] * this.innerElementSize, this.workgroupSize[1]);\n\n    this.fitAOuter = dimAOuter % this.tileAOuter === 0;\n    this.fitBOuter = dimBOuter % this.tileBOuter === 0;\n    this.fitInner = dimInner % this.tileInner === 0;\n\n    this.shaderKey = `conv2DMM_${this.elementsPerThread}_${this.activation}}_${\n        this.fitAOuter}_${this.fitBOuter}_${this.fitInner}_${this.isVec4}_${\n        this.innerElementSize}_${this.isChannelsLast}_${\n        this.sequentialAccessByThreads}`;\n  }\n\n  getUserCode(): string {\n    const matMulSource = this.isVec4 ?\n        makeMatMulPackedVec4Source(\n            this.elementsPerThread, this.workgroupSize, !this.isChannelsLast,\n            this.tileInner) :\n        makeMatMulPackedSource(\n            this.elementsPerThread, this.workgroupSize, !this.isChannelsLast,\n            this.tileInner, false, null, this.sequentialAccessByThreads);\n    const elementsSize =\n        this.isVec4 ? [this.innerElementSize, 4, 4] : [1, 1, 1];\n    const userCode = `\n    ${\n        conv2dCommonSnippet(\n            this.isChannelsLast, this.fitAOuter, this.fitBOuter, this.fitInner,\n            this.addBias, this.activation, this.hasPreluActivationWeights,\n            elementsSize[0], elementsSize[1], elementsSize[2])}\n    ${matMulSource}\n  `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport class Conv2DNaiveProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms =\n      'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>,';\n  workgroupSize: [number, number, number] = [4, 4, 8];\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  isChannelsLast: boolean;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: backend_util.Activation = null,\n      hasPreluActivationWeights = false) {\n    this.outputShape = convInfo.outShape;\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    this.dispatchLayout = this.isChannelsLast ? {x: [2], y: [1], z: [0, 3]} :\n                                                {x: [3], y: [2], z: [0, 1]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.shaderKey = `conv2dnaive_${this.activation}_${this.isChannelsLast}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n       ${\n        activationFnSnippet(\n            this.activation, this.hasPreluActivationWeights, false, 4)}\n       fn readInp(batch : i32, row : i32, col : i32, chan : i32) -> f32{\n         let coords = vec4<i32>(batch, row, col, chan);\n         if (coordsInBounds4D(coords, uniforms.xShape)) {\n           return  getX(batch, row, col, chan);\n         } else {\n          return 0.0;\n         }\n       }\n       fn readFilt(row : i32, col : i32, xChannel : i32, outChannel : i32) -> f32{\n         let coords = vec4<i32>(row, col, xChannel, outChannel);\n         if(coordsInBounds4D(coords, uniforms.wShape)) {\n           return getW(row, col, xChannel, outChannel);\n          } else {\n            return 0.0;\n          }\n       }\n       fn writeResult(batch : i32, row : i32, col : i32, chan : i32, valueIn : f32) {\n         let coords = ${\n        this.isChannelsLast ? `vec4<i32>(batch, row, col, chan);` :\n                              `vec4<i32>(batch, chan, row, col);`}\n         if (coordsInBounds4D(coords, uniforms.outShape)) {\n           var value = valueIn;\n           ${biasActivationSnippet(this.addBias, this.activation)}\n           setOutputAtCoords(coords.x, coords.y, coords.z, coords.w, value);\n         }\n       }\n       ${main('index')} {\n         let coords = getOutputCoords();\n         let batch = coords[0];\n         let outChannel = ${this.isChannelsLast ? `coords[3];` : `coords[1];`}\n         let outRow = ${this.isChannelsLast ? `coords[1];` : `coords[2];`}\n         let outCol = ${this.isChannelsLast ? `coords[2];` : `coords[3];`}\n         var acc : f32 = 0.0;\n         for (var row = 0; row < uniforms.filterDims[0]; row = row + 1) {\n           for (var col = 0; col < uniforms.filterDims[1]; col = col + 1) {\n             let xRow = outRow * uniforms.strides[0] + uniforms.dilations[0] * row - uniforms.pads[0];\n             let xCol = outCol * uniforms.strides[1] + uniforms.dilations[1] * col - uniforms.pads[1];\n             for (var xChannel = 0; xChannel < ${\n        this.isChannelsLast ? `uniforms.xShape[3];` :\n                              `uniforms.xShape[1];`} xChannel = xChannel + 1) {\n               ${\n        this.isChannelsLast ? `let v = readInp(batch, xRow, xCol, xChannel);` :\n                              `let v = readInp(batch, xChannel, xRow, xCol);`}\n               let f = readFilt(row, col, xChannel, outChannel);\n               acc = acc + v * f;\n             }\n           }\n         }\n         writeResult(batch, outRow, outCol, outChannel, acc);\n       }\n     `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Im2ColProgram implements WebGPUProgram {\n  variableNames = ['x'];\n  uniforms =\n      `pads : vec2<i32>, strides : vec2<i32>, dilations : vec2<i32>, outWidth : i32, itemsPerBlockRow : i32,\n       inChannels : i32,`;\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  isChannelsLast: boolean;\n  size = true;\n\n  constructor(outputShape: number[], isChannelsLast: boolean) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.isChannelsLast = isChannelsLast;\n    this.shaderKey = `im2col_${this.isChannelsLast}`;\n  }\n\n  getUserCode(): string {\n    const rowDim = this.isChannelsLast ? 1 : 2;\n    const colDim = this.isChannelsLast ? 2 : 3;\n\n    const row = this.isChannelsLast ? 'coords[1]' : 'coords[2]';\n    const col = this.isChannelsLast ? 'coords[2]' : 'coords[1]';\n    const getXSnippet = this.isChannelsLast ? 'getX(batch, xRow, xCol, ch)' :\n                                              'getX(batch, ch, xRow, xCol)';\n\n    const userCode = `\n    ${main('index')} {\n      let coords = getCoordsFromIndex(index);\n      if(index < uniforms.size) {\n        let batch = coords[0];\n        let row = ${row};\n        let col = ${col};\n        let offsetY = (row / uniforms.outWidth) * uniforms.strides[0] - uniforms.pads[0];\n        let xRow = offsetY + uniforms.dilations[0] * (col / uniforms.itemsPerBlockRow);\n        var value = 0.0;\n        if(xRow < uniforms.xShape[${rowDim}] && xRow >= 0) {\n          let offsetX = (row % uniforms.outWidth) * uniforms.strides[1] -\n              uniforms.pads[1];\n          let xCol = offsetX + uniforms.dilations[1] * ((col %\n              uniforms.itemsPerBlockRow) / uniforms.inChannels);\n          let ch = col % uniforms.inChannels;\n          if(xCol < uniforms.xShape[${colDim}] && xCol >= 0) {\n            value = ${getXSnippet};\n          }\n        }\n        setOutputAtIndex(index, value);\n      }\n    }\n   `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, env, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv2DMMProgram} from '../conv2d_mm_webgpu';\nimport {Conv2DNaiveProgram} from '../conv2d_naive_webgpu';\nimport {Im2ColProgram} from '../im2col_webgpu';\nimport {WebGPUProgram} from '../webgpu_program';\n\nimport {batchMatMulImpl} from './BatchMatMul_impl';\nimport {reshape} from './Reshape';\n\ntype Conv2DConfig = {\n  x: TensorInfo,\n  filter: TensorInfo,\n  convInfo: backend_util.Conv2DInfo,\n  backend: WebGPUBackend,\n  bias?: TensorInfo,\n  preluActivationWeights?: TensorInfo,\n  leakyreluAlpha?: number,\n  activation?: backend_util.Activation\n};\n\n// conv2dByMatMul fuses height and width into one dimension to compute\n// batchMatMul, so bias and activation weights are also supposed to fuse the two\n// dimensions into one.\n//\n// This function computes the target shape for fusing height and width\n// dimensions. Returning null means the shape is already compatible.\nfunction getShapeForBatchMatMul(\n    shape: number[], isChannelsLast: boolean): number[] {\n  const length = shape.length;\n  if (length >= 3) {\n    return isChannelsLast ?\n        [\n          ...shape.slice(0, -3) /* batch */,\n          shape[length - 3] * shape[length - 2] /* height * width */,\n          shape[length - 1] /* channel */\n        ] :\n        [\n          ...shape.slice(0, -3) /* batch */, shape[length - 3] /* channel */,\n          shape[length - 2] * shape[length - 1] /* height * width */\n        ];\n  } else if (!isChannelsLast && length === 1 && shape[0] > 1) {\n    return [shape[0], 1];\n  } else {\n    return null;\n  }\n}\n\n// For 1x1 kernels that iterate through every point in the input, convolution\n// can be expressed as matrix multiplication (without need for memory\n// remapping).\nfunction conv2dByMatMul({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const transposeA = isChannelsLast ? false : true;\n  const transposeB = false;\n\n  const sameSize = isChannelsLast &&\n      convInfo.filterHeight === convInfo.inHeight &&\n      convInfo.filterWidth === convInfo.inWidth &&\n      convInfo.padInfo.type === 'VALID';\n  const intermediates: TensorInfo[] = [];\n  let xReshaped;\n  let filterReshaped;\n\n  if (sameSize) {\n    const sharedDim =\n        convInfo.inHeight * convInfo.inWidth * convInfo.inChannels;\n    xReshaped = reshape({\n      inputs: {x},\n      backend,\n      attrs: {shape: [1, convInfo.batchSize, sharedDim]}\n    });\n    filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, sharedDim, convInfo.outChannels]}\n    });\n  } else {\n    xReshaped = reshape({\n      inputs: {x},\n      backend,\n      attrs: {\n        shape: isChannelsLast ?\n            [\n              convInfo.batchSize, convInfo.inHeight * convInfo.inWidth,\n              convInfo.inChannels\n            ] :\n            [\n              convInfo.batchSize, convInfo.inChannels,\n              convInfo.inHeight * convInfo.inWidth\n            ]\n      }\n    });\n    filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, convInfo.inChannels, convInfo.outChannels]}\n    });\n  }\n  intermediates.push(xReshaped);\n  intermediates.push(filterReshaped);\n\n  if (preluActivationWeights != null) {\n    const targetShape =\n        getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);\n    if (targetShape != null) {\n      preluActivationWeights = reshape({\n        inputs: {x: preluActivationWeights},\n        backend,\n        attrs: {shape: targetShape}\n      });\n      intermediates.push(preluActivationWeights);\n    }\n  }\n\n  if (bias != null) {\n    const targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);\n    if (targetShape != null) {\n      bias = reshape({inputs: {x: bias}, backend, attrs: {shape: targetShape}});\n      intermediates.push(bias);\n    }\n  }\n\n  const result = batchMatMulImpl({\n    a: isChannelsLast ? xReshaped : filterReshaped,\n    b: isChannelsLast ? filterReshaped : xReshaped,\n    transposeA,\n    transposeB,\n    backend,\n    bias,\n    activation,\n    preluActivationWeights,\n    leakyreluAlpha\n  });\n  const out = reshape(\n      {inputs: {x: result}, backend, attrs: {shape: convInfo.outShape}});\n  intermediates.push(result);\n\n  for (const i of intermediates) {\n    backend.disposeData(i.dataId);\n  }\n\n  return out;\n}\n\n// Implements the im2col algorithm as outlined in \"High Performance\n// Convolutional Neural Networks for Document Processing\" (Suvisoft, 2006)\nfunction conv2dWithIm2Col({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  // Rearranges conv2d input so each block to be convolved over forms the\n  // row of a new matrix with shape [outHeight * outWidth,\n  // filterWidth * filterHeight * inChannels]. The filter is also rearranged so\n  // each output channel forms a col of a new matrix with shape [\n  // filterWidth * filterHeight * inChannels, outChannels]. The convolution is\n  // then computed by multiplying these matrices and reshaping the result.\n  const {\n    filterWidth,\n    filterHeight,\n    inChannels,\n    strideWidth,\n    strideHeight,\n    padInfo,\n    outWidth,\n    outHeight,\n    dilationWidth,\n    dilationHeight,\n    dataFormat\n  } = convInfo;\n\n  const isChannelsLast = dataFormat === 'channelsLast';\n\n  const sharedDim = filterWidth * filterHeight * inChannels;\n  const numCols = outHeight * outWidth;\n  const x2ColShape = isChannelsLast ? [convInfo.batchSize, numCols, sharedDim] :\n                                      [convInfo.batchSize, sharedDim, numCols];\n\n  const im2ColProgram = new Im2ColProgram(x2ColShape, isChannelsLast);\n  const dimensions = [\n    {type: 'int32', data: [padInfo.top, padInfo.left]},      // Padding.\n    {type: 'int32', data: [strideHeight, strideWidth]},      // Stride.\n    {type: 'int32', data: [dilationHeight, dilationWidth]},  // Dilation.\n    {type: 'int32', data: [outWidth]},\n    {type: 'int32', data: [inChannels * filterWidth]},  // itemsPerBlockRow.\n    {type: 'int32', data: [inChannels]}\n  ];\n  const x2Col =\n      backend.runWebGPUProgram(im2ColProgram, [x], x.dtype, dimensions);\n\n  const intermediates: TensorInfo[] = [];\n  intermediates.push(x2Col);\n\n  const filterReshaped = reshape(\n      {inputs: {x: filter}, backend, attrs: {shape: [1, sharedDim, -1]}});\n  intermediates.push(filterReshaped);\n\n  if (preluActivationWeights != null) {\n    const targetShape =\n        getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);\n    if (targetShape != null) {\n      preluActivationWeights = reshape({\n        inputs: {x: preluActivationWeights},\n        backend,\n        attrs: {shape: targetShape}\n      });\n      intermediates.push(preluActivationWeights);\n    }\n  }\n\n  if (bias != null) {\n    const targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);\n    if (targetShape != null) {\n      bias = reshape({inputs: {x: bias}, backend, attrs: {shape: targetShape}});\n      intermediates.push(bias);\n    }\n  }\n\n  const transposeA = isChannelsLast ? false : true;\n  const transposeB = false;\n  const result = batchMatMulImpl({\n    a: isChannelsLast ? x2Col : filterReshaped,\n    b: isChannelsLast ? filterReshaped : x2Col,\n    transposeA,\n    transposeB,\n    backend,\n    bias,\n    activation,\n    preluActivationWeights,\n    leakyreluAlpha\n  });\n  const out = reshape(\n      {inputs: {x: result}, backend, attrs: {shape: convInfo.outShape}});\n  intermediates.push(result);\n  for (const i of intermediates) {\n    backend.disposeData(i.dataId);\n  }\n\n  return out;\n}\n\nexport function conv2DImpl({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const sameSize = isChannelsLast &&\n      convInfo.filterHeight === convInfo.inHeight &&\n      convInfo.filterWidth === convInfo.inWidth &&\n      convInfo.padInfo.type === 'VALID';\n  const useNaiveConv2d = env().getBool('WEBGPU_USE_NAIVE_CONV2D_DEBUG');\n\n  if (!useNaiveConv2d &&\n      (sameSize ||\n       (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 &&\n        convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n        convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n        (convInfo.padInfo.type === 'SAME' ||\n         convInfo.padInfo.type === 'VALID')))) {\n    return conv2dByMatMul({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  }\n\n  const thresholdFlagValue =\n      env().getNumber('WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL');\n  const thresholdToIncreaseWorkgroups = thresholdFlagValue > -1 ?\n      thresholdFlagValue :\n      backend.thresholdToIncreaseWorkgroups;\n  const workgroupsBy32x32 = convInfo.batchSize *\n      Math.ceil((convInfo.outHeight * convInfo.outWidth) / 32) *\n      Math.ceil(convInfo.outChannels / 32);\n  if (env().getBool('WEBGPU_CONV_SEPARATE_IM2COL_SHADER') ||\n      workgroupsBy32x32 <= thresholdToIncreaseWorkgroups) {\n    return conv2dWithIm2Col({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      preluActivationWeights,\n      leakyreluAlpha,\n      activation\n    });\n  }\n\n  let program: WebGPUProgram;\n  const padInfo = [convInfo.padInfo.top, convInfo.padInfo.left];\n  const dimensions = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [...padInfo]},\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]}\n  ];\n  if (useNaiveConv2d) {\n    program = new Conv2DNaiveProgram(\n        convInfo, hasBias, activation, hasPreluActivationWeights);\n  } else {\n    const dimAOuter = isChannelsLast ? convInfo.outHeight * convInfo.outWidth :\n                                       convInfo.outChannels;\n    const dimBOuter = isChannelsLast ? convInfo.outChannels :\n                                       convInfo.outHeight * convInfo.outWidth;\n    const dimInner =\n        convInfo.filterHeight * convInfo.filterWidth * convInfo.inChannels;\n    dimensions.push(\n        {type: 'int32', data: [dimAOuter]}, {type: 'int32', data: [dimBOuter]},\n        {type: 'int32', data: [dimInner]});\n\n    // Experiments show that sequential access is more friendly for Intel GPUs.\n    const sequentialAccessByThreads = backend.adapterInfo.isIntel();\n    program = new Conv2DMMProgram(\n        convInfo, dimAOuter, dimBOuter, dimInner, hasBias, activation,\n        hasPreluActivationWeights, sequentialAccessByThreads);\n  }\n\n  const intermediates: TensorInfo[] = [];\n  const inputVar: TensorInfo[] = [x, filter];\n  if (hasBias) {\n    if (!isChannelsLast && bias.shape.length === 1) {\n      bias = reshape(\n          {inputs: {x: bias}, backend, attrs: {shape: [bias.shape[0], 1, 1]}});\n      intermediates.push(bias);\n    }\n    inputVar.push(bias);\n  }\n  if (hasPreluActivationWeights) {\n    if (!isChannelsLast && preluActivationWeights.shape.length === 1) {\n      preluActivationWeights = reshape({\n        inputs: {x: preluActivationWeights},\n        backend,\n        attrs: {shape: [preluActivationWeights.shape[0], 1, 1]}\n      });\n      intermediates.push(preluActivationWeights);\n    }\n    inputVar.push(preluActivationWeights);\n  }\n  if (activation === 'leakyrelu') {\n    dimensions.push({type: 'float32', data: [leakyreluAlpha]});\n    program.uniforms += ' alpha : f32,';\n  }\n  const out = backend.runWebGPUProgram(program, inputVar, x.dtype, dimensions);\n  for (const i of intermediates) {\n    backend.disposeData(i.dataId);\n  }\n  return out;\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2D, Conv2DAttrs, Conv2DInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {conv2DImpl} from './Conv2D_impl';\n\nexport function conv2d(\n    args: {inputs: Conv2DInputs, attrs: Conv2DAttrs, backend: WebGPUBackend}) {\n  const {inputs, attrs, backend} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode} = attrs;\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n  return conv2DImpl({x, filter, convInfo, backend});\n}\n\nexport const conv2DConfig: KernelConfig = {\n  kernelName: Conv2D,\n  backendName: 'webgpu',\n  kernelFunc: conv2d as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Conv2DDerInputProgram implements WebGPUProgram {\n  variableNames = ['dy', 'W'];\n  uniforms =\n      'filterDims : vec2<i32>, pads : vec2<i32>, strides : vec2<i32>, outBackprop : vec4<i32>,';\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y?: number[], z?: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  isChannelsLast: boolean;\n  size = false;\n  isVec4 = false;\n  workPerThread = 1;\n  outputComponent: number;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    this.isVec4 = this.isChannelsLast && convInfo.outChannels % 4 === 0 &&\n        convInfo.inChannels % 4 === 0;\n    if (this.isVec4) {\n      // TODO: Expand to any value.\n      this.workPerThread = 2;\n      this.outputComponent = 4;\n      this.workgroupSize = [4, 4, 4];\n      this.dispatchLayout = {x: [3], y: [2], z: [0, 1]};\n      this.dispatch = computeDispatch(\n          this.dispatchLayout, this.outputShape, this.workgroupSize,\n          [4, this.workPerThread, 1]);\n    } else {\n      this.size = true;\n      this.workPerThread = 1;\n      this.workgroupSize = [64, 1, 1];\n      this.dispatchLayout = flatDispatchLayout(this.outputShape);\n      this.dispatch = computeDispatch(\n          this.dispatchLayout, this.outputShape, this.workgroupSize);\n    }\n    this.shaderKey = `conv2DDerInput_${this.isChannelsLast}_${this.isVec4}_${\n        this.workPerThread}`;\n  }\n\n  getUserCode(): string {\n    const rowDim = this.isChannelsLast ? 1 : 2;\n    const colDim = this.isChannelsLast ? 2 : 3;\n    const channelDim = this.isChannelsLast ? 3 : 1;\n\n    const vec4Snippet = `\n    ${main()} {\n      let batch = i32(globalId.z) / uniforms.outShape[1];\n      let r = i32(globalId.z) % uniforms.outShape[1];\n      let c = i32(globalId.y) * ${this.workPerThread};\n      let d1 = i32(globalId.x) * 4;\n\n      let dyCorner = vec2<i32>(r, c) - uniforms.pads;\n\n      // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n      // ? = to be determined. : = across all values in that axis.\n      var dotProd: array<vec4<f32>, ${this.workPerThread}>;\n      for (var i = 0; i < ${this.workPerThread}; i++) {\n        dotProd[i] = vec4<f32>(0.0);\n      }\n      for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + 1) {\n        let dyR = f32(dyCorner.x + wR) / f32(uniforms.strides.x);\n        let wRPerm = uniforms.filterDims.x - 1 - wR;\n        if (dyR < 0.0 || dyR >= f32(uniforms.outBackprop[1]) ||\n            fract(dyR) > 0.0) {\n          continue;\n        }\n        let idyR = i32(dyR);\n\n        for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + 1) {\n          let dyC = f32(dyCorner.y + wC) / f32(uniforms.strides.y);\n          let dyC2 = f32(dyCorner.y + 1 + wC) / f32(uniforms.strides.y);\n          let wCPerm = uniforms.filterDims.y - 1 - wC;\n          var bDyCVal = true;\n          var bDyCVal2 = true;\n          if (dyC < 0.0 || dyC >= f32(uniforms.outBackprop[2]) ||\n              fract(dyC) > 0.0) {\n            bDyCVal = false;\n          }\n          if (dyC2 < 0.0 || dyC2 >= f32(uniforms.outBackprop[2]) ||\n              fract(dyC2) > 0.0) {\n            bDyCVal2 = false;\n          }\n\n          let idyC = i32(dyC);\n          let idyC2 = i32(dyC2);\n          if (bDyCVal && bDyCVal2) {\n            let d2Length = uniforms.outBackprop[3];\n            for (var d2 = 0; d2 < d2Length; d2 = d2 + 4) {\n              let wValue0 = getW(wRPerm, wCPerm, d1, d2);\n              let wValue1 = getW(wRPerm, wCPerm, d1 + 1, d2);\n              let wValue2 = getW(wRPerm, wCPerm, d1 + 2, d2);\n              let wValue3 = getW(wRPerm, wCPerm, d1 + 3, d2);\n              var xValue =  getDy(batch, idyR, idyC, d2);\n              let tmpval = vec4<f32>(dot(xValue, wValue0),\n                                     dot(xValue, wValue1),\n                                     dot(xValue, wValue2),\n                                     dot(xValue, wValue3));\n              dotProd[0] = dotProd[0] + tmpval;\n              xValue = getDy(batch, idyR, idyC2, d2);\n              dotProd[1] = dotProd[1] + vec4<f32>(dot(xValue, wValue0),\n                                                  dot(xValue, wValue1),\n                                                  dot(xValue, wValue2),\n                                                  dot(xValue, wValue3));\n            }\n          } else if (bDyCVal) {\n            let d2Length = uniforms.outBackprop[3];\n            for (var d2 = 0; d2 < d2Length; d2 = d2 + 4) {\n              let wValue0 = getW(wRPerm, wCPerm, d1, d2);\n              let wValue1 = getW(wRPerm, wCPerm, d1 + 1, d2);\n              let wValue2 = getW(wRPerm, wCPerm, d1 + 2, d2);\n              let wValue3 = getW(wRPerm, wCPerm, d1 + 3, d2);\n              var xValue =  getDy(batch, idyR, idyC, d2);\n              let tmpval = vec4<f32>(dot(xValue, wValue0),\n                                     dot(xValue, wValue1),\n                                     dot(xValue, wValue2),\n                                     dot(xValue, wValue3));\n              dotProd[0] = dotProd[0] + tmpval;\n            }\n          } else if (bDyCVal2) {\n            let d2Length = uniforms.outBackprop[3];\n            for (var d2 = 0; d2 < d2Length; d2 = d2 + 4) {\n              let wValue0 = getW(wRPerm, wCPerm, d1, d2);\n              let wValue1 = getW(wRPerm, wCPerm, d1 + 1, d2);\n              let wValue2 = getW(wRPerm, wCPerm, d1 + 2, d2);\n              let wValue3 = getW(wRPerm, wCPerm, d1 + 3, d2);\n              var xValue =  getDy(batch, idyR, idyC2, d2);\n              let tmpval = vec4<f32>(dot(xValue, wValue0),\n                                     dot(xValue, wValue1),\n                                     dot(xValue, wValue2),\n                                     dot(xValue, wValue3));\n              dotProd[1] = dotProd[1] + tmpval;\n            }\n          }\n        }\n      }\n\n      for (var i = 0; i < ${this.workPerThread}; i = i + 1) {\n        let coords = vec4<i32>(batch, r, c + i, d1);\n        if (coordsInBounds4D(coords, uniforms.outShape)) {\n          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], dotProd[i]);\n        }\n      }\n    }\n    `;\n    return this.isVec4 ?\n        `\n    ${vec4Snippet}\n    ` :\n        `\n    ${main('index')} {\n      if(index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords[0];\n        let d1 = coords[${channelDim}];\n\n        let dyCorner = vec2<i32>(coords[${rowDim}], coords[${\n            colDim}]) - uniforms.pads;\n        let dyRCorner = dyCorner.x;\n        let dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + 1) {\n          let dyR = (f32(dyRCorner) + f32(wR)) / f32(uniforms.strides.x);\n          let wRPerm = uniforms.filterDims.x - 1 - wR;\n          if (dyR < 0.0 || dyR >= f32(uniforms.outBackprop[1]) || fract(dyR) > 0.0 ||\n              wRPerm < 0) {\n            continue;\n          }\n          let idyR = i32(dyR);\n\n          for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + 1) {\n            let dyC = (f32(dyCCorner) + f32(wC)) / f32(uniforms.strides.y);\n            let wCPerm = uniforms.filterDims.y - 1 - wC;\n            if (dyC < 0.0 || dyC >= f32(uniforms.outBackprop[2]) ||\n                fract(dyC) > 0.0 || wCPerm < 0) {\n              continue;\n            }\n            let idyC = i32(dyC);\n\n            for (var d2 = 0; d2 < uniforms.outBackprop[3]; d2 = d2 + 1) {\n              let xValue = ${\n            this.isChannelsLast ? 'getDy(batch, idyR, idyC, d2)' :\n                                  'getDy(batch, d2, idyR, idyC)'};\n              let wValue = getW(wRPerm, wCPerm, d1, d2);\n              dotProd = dotProd + xValue * wValue;\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n  `;\n  }\n}\n\nexport class Conv2DDerFilterProgram implements WebGPUProgram {\n  variableNames = ['x', 'dy'];\n  uniforms =\n      'pads : vec2<i32>, strides : vec2<i32>, batchSize : i32, outHeight : i32, outWidth : i32, inHeight : i32, inWidth : i32,';\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  isChannelsLast: boolean;\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.filterShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    this.shaderKey = `conv2DDerFilter_${this.isChannelsLast}`;\n  }\n\n  getUserCode(): string {\n    return `\n    ${main('index')} {\n      if(index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let wR = coords[0];\n        let wC = coords[1];\n        let d1 = coords[2];\n        let d2 = coords[3];\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        for (var b = 0; b < uniforms.batchSize; b = b + 1) {\n          for (var yR = 0; yR < uniforms.outHeight; yR = yR + 1) {\n            let xR = wR + yR * uniforms.strides[0] - uniforms.pads[0];\n            if (xR < 0 || xR >= uniforms.inHeight) {\n              continue;\n            }\n\n            for (var yC = 0; yC < uniforms.outWidth; yC = yC + 1) {\n              let xC = wC + yC * uniforms.strides[1] - uniforms.pads[1];\n\n              if (xC < 0 || xC >= uniforms.inWidth) {\n                continue;\n              }\n\n              if (${this.isChannelsLast}) {\n                let dyValue = getDy(b, yR, yC, d2);\n                let xValue = getX(b, xR, xC, d1);\n                dotProd = dotProd + xValue * dyValue;\n              } else {\n                let dyValue = getDy(b, d2, yR, yC);\n                let xValue = getX(b, d1, xR, xC);\n                dotProd = dotProd + xValue * dyValue;\n              }\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n  `;\n  }\n}\n\nexport class Conv3DDerFilterProgram implements WebGPUProgram {\n  variableNames = ['x', 'dy'];\n  uniforms =\n      `pads : vec3<i32>, strides : vec3<i32>, batchSize : i32, outDepth : i32,\n       outHeight : i32, outWidth : i32, inDepth : i32, inHeight : i32, inWidth : i32,`;\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv3DInfo) {\n    this.outputShape = convInfo.filterShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = `conv3DDerFilter`;\n  }\n\n  getUserCode(): string {\n    return `\n    ${main('index')} {\n      if(index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let wF = coords.x;\n        let wR = coords.y;\n        let wC = coords.z;\n        let d1 = coords.w;\n        let d2 = coords.u;\n\n        var dotProd = 0.0;\n        for (var b = 0; b < uniforms.batchSize; b++) {\n          for (var yF = 0; yF < uniforms.outDepth; yF++) {\n            let xF = wF + yF * uniforms.strides[0] - uniforms.pads[0];\n            if (xF < 0 || xF >= uniforms.inDepth) {\n              continue;\n            }\n\n            for (var yR = 0; yR < uniforms.outHeight; yR++) {\n              let xR = wR + yR * uniforms.strides[1] - uniforms.pads[1];\n              if (xR < 0 || xR >= uniforms.inHeight) {\n                continue;\n              }\n\n              for (var yC = 0; yC < uniforms.outWidth; yC++) {\n                let xC = wC + yC * uniforms.strides[2] - uniforms.pads[2];\n                if (xC < 0 || xC >= uniforms.inWidth) {\n                  continue;\n                }\n\n                let dyValue = getDy(b, yF, yR, yC, d2);\n                let xValue = getX(b, xF, xR, xC, d1);\n                dotProd += xValue * dyValue;\n              }\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n  `;\n  }\n}\n\nexport class Conv3DDerInputProgram implements WebGPUProgram {\n  variableNames = ['dy', 'W'];\n  uniforms = `filterDims : vec3<i32>, pads : vec3<i32>, strides : vec3<i32>,\n      outDepth : i32, outHeight : i32, outWidth : i32, outChannels : i32,`;\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv3DInfo) {\n    this.outputShape = convInfo.inShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = `conv3DDerInput`;\n  }\n\n  getUserCode(): string {\n    return `\n    ${main('index')} {\n      if(index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords.x;\n        let d1 = coords.u;\n\n        let dyCorner = vec3<i32>(coords.y, coords.z, coords.w) - uniforms.pads;\n        let dyFCorner = dyCorner.x;\n        let dyRCorner = dyCorner.y;\n        let dyCCorner = dyCorner.z;\n\n        var dotProd = 0.0;\n        for (var wF = 0; wF < uniforms.filterDims[0]; wF++) {\n          let dyF = f32(dyFCorner + wF) / f32(uniforms.strides[0]);\n          if (dyF < 0.0 || dyF >= f32(uniforms.outDepth) || fract(dyF) > 0.0) {\n            continue;\n          }\n          let idyF = i32(dyF);\n\n          let wFPerm = uniforms.filterDims[0] - 1 - wF;\n\n          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {\n            let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[1]);\n\n            if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n              continue;\n            }\n            let idyR = i32(dyR);\n\n            let wRPerm = uniforms.filterDims[1] - 1 - wR;\n\n            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {\n              let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[2]);\n\n              if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n                continue;\n              }\n              let idyC = i32(dyC);\n\n              let wCPerm = uniforms.filterDims[2] - 1 - wC;\n\n              for (var d2 = 0; d2 < uniforms.outChannels; d2++) {\n                let xValue = getDy(batch, idyF, idyR, idyC, d2);\n                let wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n  `;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropFilter, Conv2DBackpropFilterAttrs, Conv2DBackpropFilterInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv2DDerFilterProgram} from '../conv_backprop_webgpu';\n\nexport function conv2DBackpropFilter(args: {\n  inputs: Conv2DBackpropFilterInputs,\n  backend: WebGPUBackend,\n  attrs: Conv2DBackpropFilterAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, dataFormat, dimRoundingMode, filterShape} = attrs;\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad, dimRoundingMode, false /* depthwise */,\n      $dataFormat);\n\n  const program = new Conv2DDerFilterProgram(convInfo);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.batchSize]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'int32', data: [convInfo.inHeight]},\n    {type: 'int32', data: [convInfo.inWidth]}\n  ];\n  return backend.runWebGPUProgram(program, [x, dy], x.dtype, uniformData);\n}\n\nexport const conv2DBackpropFilterConfig: KernelConfig = {\n  kernelName: Conv2DBackpropFilter,\n  backendName: 'webgpu',\n  kernelFunc: conv2DBackpropFilter as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\n\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\nimport {typeSnippet, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, computeWorkgroupSizeForConv2d, computeWorkPerThreadForConv2d} from './webgpu_util';\n\nfunction conv2dTransposeCommonSnippet(innerElementSize = 4) {\n  const getWSnippet = (innerElementSize: number) => {\n    switch (innerElementSize) {\n      case 1:\n        return 'return W[getIndexFromCoords4D(coord, uniforms.wShape)];';\n      case 4:\n        return `\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = W[getIndexFromCoords4D(coord, uniforms.wShape)];\n            let v1 = W[getIndexFromCoords4D(coord1, uniforms.wShape)];\n            let v2 = W[getIndexFromCoords4D(coord2, uniforms.wShape)];\n            let v3 = W[getIndexFromCoords4D(coord3, uniforms.wShape)];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;\n      default:\n        throw new Error(\n            `innerElementSize ${innerElementSize} is not supported.`);\n    }\n  };\n\n  const readASnippet = `\n      let outRow = row / uniforms.outShape[2];\n      let outCol = row % uniforms.outShape[2];\n\n      let WRow = col / (uniforms.filterDims[1] * uniforms.outBackprop[3]);\n      let WCol = col / uniforms.outBackprop[3] % uniforms.filterDims[1];\n      let xR = f32(outRow - uniforms.pads[0] + WRow) / f32(uniforms.strides[0]);\n      let xC = f32(outCol - uniforms.pads[1] + WCol) / f32(uniforms.strides[1]);\n      if (xR < 0.0 || xR >= f32(uniforms.outBackprop[1]) || fract(xR) > 0.0) {\n        return ${typeSnippet(innerElementSize)}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(uniforms.outBackprop[2]) || fract(xC) > 0.0) {\n        return ${typeSnippet(innerElementSize)}(0.0);\n      }\n      let coord = vec4<i32>(\n          batch,\n          i32(xR),\n          i32(xC),\n          col % uniforms.outBackprop[3]);\n      return x[getIndexFromCoords4D(coord, uniforms.xShape)/${\n      innerElementSize}];`;\n\n  const sampleA = `if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n        ${readASnippet}\n      }\n      return ${typeSnippet(innerElementSize)}(0.0);`;\n\n  const userCode = `\n  fn mm_readA(batch: i32, row : i32, col : i32) -> ${\n      typeSnippet(innerElementSize)} {\n    ${sampleA}\n  }\n\n  fn mm_readB(batch: i32, row : i32, col : i32) -> ${\n      typeSnippet(innerElementSize)} {\n    let coordX = uniforms.filterDims.x - 1 -\n        row / (uniforms.filterDims[1] * uniforms.outBackprop[3]);\n    let coordY = uniforms.filterDims.y - 1 -\n        (row / uniforms.outBackprop[3]) % uniforms.filterDims[1];\n    if (row < uniforms.dimInner && col < uniforms.dimBOuter &&\n        coordX >= 0 && coordY >= 0) {\n      let rowInner = row % uniforms.outBackprop[3];\n      let coord = vec4<i32>(coordX, coordY, col, rowInner);\n      ${getWSnippet(innerElementSize)}\n    }\n    return ${typeSnippet(innerElementSize)}(0.0);\n  }\n\n  fn mm_write(batch: i32, row : i32, col : i32, valueInput : ${\n      typeSnippet(innerElementSize)}) {\n    if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n      var value = valueInput;\n      let outCoord = vec4<i32>(\n          batch,\n          row / uniforms.outShape[2],\n          row % uniforms.outShape[2],\n          col);\n      result[getIndexFromCoords4D(outCoord, uniforms.outShape)/${\n      innerElementSize}] = value;\n    }\n  }`;\n  return userCode;\n}\n\nexport class Conv2DDerInputMMProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  variableComponents: number[];\n  uniforms =\n      'filterDims : vec2<i32>, pads : vec2<i32>, strides : vec2<i32>, outBackprop : vec4<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32,';\n  workgroupSize: [number, number, number];\n  elementsPerThread: [number, number, number];\n  isVec4?: boolean;\n  outputComponent: number;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    util.assert(\n        convInfo.dataFormat === 'channelsLast',\n        () => 'TODO: NCHW is unimplemented');\n    this.isVec4 =\n        convInfo.inChannels % 4 === 0 && convInfo.outChannels % 4 === 0;\n    this.dispatchLayout = {x: [3], y: [1, 2], z: [0]};\n    this.workgroupSize = computeWorkgroupSizeForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n    this.elementsPerThread = computeWorkPerThreadForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        this.elementsPerThread);\n\n    if (this.isVec4) {\n      this.outputComponent = 4;\n      this.variableComponents = [4, 1];\n    }\n\n    this.shaderKey =\n        `conv2DDerInputMM_${this.isVec4}_${this.elementsPerThread}`;\n  }\n\n  getUserCode(): string {\n    const matMulSource = this.isVec4 ?\n        makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize) :\n        makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize);\n    const userCode = `\n    ${conv2dTransposeCommonSnippet(this.isVec4 ? 4 : 1)}\n    ${matMulSource}\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropInput, Conv2DBackpropInputAttrs, Conv2DBackpropInputInputs, env, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv2DDerInputMMProgram} from '../conv_backprop_mm_webgpu';\nimport {Conv2DDerInputProgram} from '../conv_backprop_webgpu';\n\nexport function conv2DBackpropInput(args: {\n  inputs: Conv2DBackpropInputInputs,\n  attrs: Conv2DBackpropInputAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {inputShape, strides, pad, dataFormat, dimRoundingMode} = attrs;\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      1 /* dilations */, pad, dimRoundingMode, false, $dataFormat);\n\n  const dimensions = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {\n      type: 'int32',\n      data: [\n        convInfo.filterHeight - 1 - convInfo.padInfo.top,\n        convInfo.filterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {\n      type: 'int32',\n      data: [\n        convInfo.batchSize, convInfo.outHeight, convInfo.outWidth,\n        convInfo.outChannels\n      ]\n    },\n  ];\n  let program: Conv2DDerInputProgram|Conv2DDerInputMMProgram;\n  // TODO: Experiment when to use Conv2DDerInputMMProgram algorithm.\n  if (env().getBool('WEBGPU_USE_NAIVE_CONV2D_TRANSPOSE') ||\n      convInfo.dataFormat !== 'channelsLast') {\n    program = new Conv2DDerInputProgram(convInfo);\n  } else {\n    program = new Conv2DDerInputMMProgram(convInfo);\n    const dimAOuter = convInfo.inHeight * convInfo.inWidth;\n    const dimBOuter = convInfo.inChannels;\n    const dimInner =\n        convInfo.filterHeight * convInfo.filterWidth * convInfo.outChannels;\n    dimensions.push(\n        {type: 'uint32', data: [dimAOuter]},\n        {type: 'uint32', data: [dimBOuter]},\n        {type: 'uint32', data: [dimInner]});\n  }\n  return backend.runWebGPUProgram(program, [dy, filter], 'float32', dimensions);\n}\n\nexport const conv2DBackpropInputConfig: KernelConfig = {\n  kernelName: Conv2DBackpropInput,\n  backendName: 'webgpu',\n  kernelFunc: conv2DBackpropInput as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Conv3DNaiveProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms =\n      'filterDims: vec3<i32>, pads: vec3<i32>, strides: vec3<i32>, dilations: vec3<i32>,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv3DInfo) {\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `conv3dnaive`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getOutputCoords();\n        let batch = coords.x;\n        let d2 = coords.u;\n\n        let xFRCCorner = vec3<i32>(coords.y, coords.z, coords.w) * uniforms.strides - uniforms.pads;\n        let xFCorner = xFRCCorner.x;\n        let xRCorner = xFRCCorner.y;\n        let xCCorner = xFRCCorner.z;\n\n        let inputDepthNearestVec4 = (uniforms.xShape.u / 4) * 4;\n        let inputDepthVec4Remainder = uniforms.xShape.u % 4;\n\n        var dotProd = 0.0;\n        for (var wF = 0; wF < uniforms.filterDims[0]; wF++) {\n          let xF = xFCorner + wF * uniforms.dilations[0];\n          if (xF < 0 || xF >= uniforms.xShape.y) {\n            continue;\n          }\n\n          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {\n            let xR = xRCorner + wR * uniforms.dilations[1];\n            if (xR < 0 || xR >= uniforms.xShape.z) {\n              continue;\n            }\n\n            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {\n              let xC = xCCorner + wC * uniforms.dilations[2];\n              if (xC < 0 || xC >= uniforms.xShape.w) {\n                continue;\n              }\n\n              for (var d1 = 0; d1 < inputDepthNearestVec4; d1 += 4) {\n                let xValues = vec4<f32>(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                let wValues = vec4<f32>(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (inputDepthVec4Remainder == 1) {\n                dotProd += getX(batch, xF, xR, xC, inputDepthNearestVec4) *\n                  getW(wF, wR, wC, inputDepthNearestVec4, d2);\n              } else if (inputDepthVec4Remainder == 2) {\n                let xValues = vec2<f32>(\n                  getX(batch, xF, xR, xC, inputDepthNearestVec4),\n                  getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1)\n                );\n                let wValues = vec2<f32>(\n                  getW(wF, wR, wC, inputDepthNearestVec4, d2),\n                  getW(wF, wR, wC, inputDepthNearestVec4 + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (inputDepthVec4Remainder == 3) {\n                let xValues = vec3<f32>(\n                  getX(batch, xF, xR, xC, inputDepthNearestVec4),\n                  getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1),\n                  getX(batch, xF, xR, xC, inputDepthNearestVec4 + 2)\n                );\n                let wValues = vec3<f32>(\n                  getW(wF, wR, wC, inputDepthNearestVec4, d2),\n                  getW(wF, wR, wC, inputDepthNearestVec4 + 1, d2),\n                  getW(wF, wR, wC, inputDepthNearestVec4 + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }`;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3D, Conv3DAttrs, Conv3DInputs, KernelConfig, KernelFunc, upcastType} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv3DNaiveProgram} from '../conv3d_naive_webgpu';\n\nexport function conv3D(\n    args: {inputs: Conv3DInputs, attrs: Conv3DAttrs, backend: WebGPUBackend}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number],\n      filter.shape as [number, number, number, number, number], strides,\n      dilations, pad);\n\n  const padInfo =\n      [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left];\n  const dimensions = [\n    {\n      type: 'int32',\n      data: [convInfo.filterDepth, convInfo.filterHeight, convInfo.filterWidth]\n    },\n    {type: 'int32', data: [...padInfo]}, {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.dilationDepth, convInfo.dilationHeight, convInfo.dilationWidth\n      ]\n    }\n  ];\n  const program = new Conv3DNaiveProgram(convInfo);\n  const dtype = upcastType(x.dtype, filter.dtype);\n  return backend.runWebGPUProgram(program, [x, filter], dtype, dimensions);\n}\n\nexport const conv3DConfig: KernelConfig = {\n  kernelName: Conv3D,\n  backendName: 'webgpu',\n  kernelFunc: conv3D as {} as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropFilterV2, Conv3DBackpropFilterV2Attrs, Conv3DBackpropFilterV2Inputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv3DDerFilterProgram} from '../conv_backprop_webgpu';\n\nexport function conv3DBackpropFilterV2(args: {\n  inputs: Conv3DBackpropFilterV2Inputs,\n  attrs: Conv3DBackpropFilterV2Attrs,\n  backend: WebGPUBackend,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, filterShape} = attrs;\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad);\n\n  const program = new Conv3DDerFilterProgram(convInfo);\n  const uniformData = [\n    {\n      type: 'int32',\n      data:\n          [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]\n    },\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {type: 'int32', data: [convInfo.batchSize]},\n    {type: 'int32', data: [convInfo.outDepth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'int32', data: [convInfo.inDepth]},\n    {type: 'int32', data: [convInfo.inHeight]},\n    {type: 'int32', data: [convInfo.inWidth]}\n  ];\n  return backend.runWebGPUProgram(program, [x, dy], dy.dtype, uniformData);\n}\n\nexport const conv3DBackpropFilterV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropFilterV2,\n  backendName: 'webgpu',\n  kernelFunc: conv3DBackpropFilterV2 as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropInputV2, Conv3DBackpropInputV2Attrs, Conv3DBackpropInputV2Inputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv3DDerInputProgram} from '../conv_backprop_webgpu';\n\nexport function conv3DBackpropInputV2(args: {\n  inputs: Conv3DBackpropInputV2Inputs,\n  attrs: Conv3DBackpropInputV2Attrs,\n  backend: WebGPUBackend\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {strides, pad, inputShape} = attrs;\n\n  const convInfo = backend_util.computeConv3DInfo(\n      inputShape, filter.shape as [number, number, number, number, number],\n      strides, 1 /* dilations */, pad);\n\n  const program = new Conv3DDerInputProgram(convInfo);\n  const uniformData = [\n    {\n      type: 'int32',\n      data: [convInfo.filterDepth, convInfo.filterHeight, convInfo.filterWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.filterDepth - 1 - convInfo.padInfo.front,\n        convInfo.filterHeight - 1 - convInfo.padInfo.top,\n        convInfo.filterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {type: 'int32', data: [convInfo.outDepth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'int32', data: [convInfo.outChannels]}\n  ];\n\n  return backend.runWebGPUProgram(program, [dy, filter], dy.dtype, uniformData);\n}\n\nexport const conv3DBackpropInputV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropInputV2,\n  backendName: 'webgpu',\n  kernelFunc: conv3DBackpropInputV2 as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const cos = unaryKernelFunc({opType: UnaryOpType.COS});\n\nexport const cosConfig: KernelConfig = {\n  kernelName: Cos,\n  backendName: 'webgpu',\n  kernelFunc: cos\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const cosh = unaryKernelFunc({opType: UnaryOpType.COSH});\n\nexport const coshConfig: KernelConfig = {\n  kernelName: Cosh,\n  backendName: 'webgpu',\n  kernelFunc: cosh\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class CropAndResizeProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['Image', 'Boxes', 'BoxInd'];\n  uniforms = 'extrapolationValue : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  methodId: number;\n  cropHeightBiggerThan1: boolean;\n  cropWidthBiggerThan1: boolean;\n  size = true;\n\n  constructor(\n      channnel: number, boxShape: [number, number], cropSize: [number, number],\n      method: 'bilinear'|'nearest') {\n    const [numBoxes, ] = boxShape;\n    this.outputShape = [numBoxes, cropSize[0], cropSize[1], channnel];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.methodId = method === 'bilinear' ? 1 : 0;\n    this.cropHeightBiggerThan1 = this.outputShape[1] > 1;\n    this.cropWidthBiggerThan1 = this.outputShape[2] > 1;\n    this.shaderKey = `cropAndResize_${this.methodId}_${\n        this.cropHeightBiggerThan1}_${this.cropWidthBiggerThan1}`;\n  }\n\n  getUserCode(): string {\n    const [inputHeightFloat, inputWidthFloat] =\n        [`f32(uniforms.imageShape[1] - 1)`, `f32(uniforms.imageShape[2] - 1)`];\n\n    const [heightRatio, heightScale, inY] = this.cropHeightBiggerThan1 ?\n        [\n          `(${inputHeightFloat} / f32(uniforms.outShape[1] - 1))`,\n          '(y2-y1) * height_ratio',\n          `y1*${inputHeightFloat} + f32(y)*(height_scale)`,\n        ] :\n        [\n          '0.0',\n          '0.0',\n          `0.5 * (y1+y2) * ${inputHeightFloat}`,\n        ];\n    const [widthRatio, widthScale, inX] = this.cropWidthBiggerThan1 ?\n        [\n          `(${inputWidthFloat} / f32(uniforms.outShape[2] - 1))`,\n          '(x2-x1) * width_ratio',\n          `x1*${inputWidthFloat} + f32(x)*(width_scale)`,\n        ] :\n        [\n          '0.0',\n          '0.0',\n          `0.5 * (x1+x2) * ${inputWidthFloat}`,\n        ];\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op_gpu.cu.cc\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let height_ratio = f32(${heightRatio});\n        let width_ratio = f32(${widthRatio});\n        let b = coords[0];\n        let y = coords[1];\n        let x = coords[2];\n        let d = coords[3];\n        // get box vals\n        let y1 = getBoxes(b, 0);\n        let x1 = getBoxes(b, 1);\n        let y2 = getBoxes(b, 2);\n        let x2 = getBoxes(b, 3);\n        // get image in batch index\n        let bInd = i32(round(getBoxInd(b)));\n        if(bInd < 0 || bInd >= uniforms.outShape[0]) {\n          return;\n        }\n        let height_scale = ${heightScale};\n        let width_scale = ${widthScale};\n        let in_y = ${inY};\n        if( in_y < 0.0 || in_y > ${inputHeightFloat} ) {\n          setOutputAtIndex(index, uniforms.extrapolationValue);\n          return;\n        }\n        let in_x = ${inX};\n        if( in_x < 0.0 || in_x > ${inputWidthFloat} ) {\n          setOutputAtIndex(index, uniforms.extrapolationValue);\n          return;\n        }\n        let sourceFracIndexCR = vec2<f32>(in_x,in_y);\n        if(${this.methodId} == 1) {\n          // Compute the four integer indices.\n          let sourceFloorCR = vec2<i32>(sourceFracIndexCR);\n          let sourceCeilCR = vec2<i32>(ceil(sourceFracIndexCR));\n          let topLeft = getImage(bInd, sourceFloorCR.y, sourceFloorCR.x, d);\n          let bottomLeft = getImage(bInd, sourceCeilCR.y, sourceFloorCR.x, d);\n          let topRight = getImage(bInd, sourceFloorCR.y, sourceCeilCR.x, d);\n          let bottomRight = getImage(bInd, sourceCeilCR.y, sourceCeilCR.x, d);\n          let fracCR = sourceFracIndexCR - vec2<f32>(sourceFloorCR);\n          let top = topLeft + (topRight - topLeft) * fracCR.x;\n          let bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          let newValue = top + (bottom - top) * fracCR.y;\n          setOutputAtIndex(index, newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          let sourceNearestCR = vec2<i32>(floor(\n            sourceFracIndexCR + vec2<f32>(0.5,0.5)));\n          let newValue = getImage(\n            bInd, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutputAtIndex(index, newValue);\n        }\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {CropAndResize, CropAndResizeAttrs, CropAndResizeInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CropAndResizeProgram} from '../crop_and_resize_webgpu';\n\nexport const cropAndResize = (args: {\n  inputs: CropAndResizeInputs,\n  backend: WebGPUBackend,\n  attrs: CropAndResizeAttrs\n}): TensorInfo => {\n  const {inputs, backend, attrs} = args;\n  const {image, boxes, boxInd} = inputs;\n  const {cropSize, method, extrapolationValue} = attrs;\n\n  const program = new CropAndResizeProgram(\n      image.shape[3], boxes.shape as [number, number], cropSize, method);\n  const uniformData = [{type: 'float32', data: [extrapolationValue]}];\n  return backend.runWebGPUProgram(\n      program, [image, boxes, boxInd], 'float32', uniformData);\n};\n\nexport const cropAndResizeConfig: KernelConfig = {\n  kernelName: CropAndResize,\n  backendName: 'webgpu',\n  kernelFunc: cropAndResize as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport enum CumOpType {\n  Prod = '*',\n  Sum = '+',\n}\n\nexport class CumProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workgroupSize: [number, number, number];\n  // pow(i32, i32) is not supported, use pow(f32, f32) instead.\n  uniforms = 'index : f32,';\n  size = true;\n  exclusive: boolean;\n  reverse: boolean;\n  op: CumOpType;\n\n  constructor(\n      op: CumOpType, shape: number[], exclusive: boolean, reverse: boolean) {\n    this.workgroupSize = [128, 1, 1];\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.exclusive = exclusive;\n    this.reverse = reverse;\n    this.op = op;\n    this.shaderKey = `cum_${this.op}_${this.exclusive}_${this.reverse}`;\n  }\n\n  getUserCode(): string {\n    const rank = this.outputShape.length;\n    const initVal = this.op === CumOpType.Prod ? '1.0' : '0.0';\n    const val = this.exclusive ? initVal :\n                                 `getX(${getCoords(rank, 'coords', this.op)})`;\n    const length = this.outputShape[this.outputShape.length - 1];\n    let condition = '';\n    let idxString = '';\n    // When exclusive is set, the cum op becomes roll op that copies the\n    // value from the previous index based on the direction specified by the\n    // reverse flag.\n    if (this.exclusive) {\n      condition = this.reverse ? `end != ${length - 1}` : 'end != 0';\n      idxString = this.reverse ? 'end + 1' : 'end - 1';\n    } else {\n      condition = this.reverse ? `end + pow2 < ${length}` : 'end >= pow2';\n      idxString = (this.reverse ? 'end + pow2' : 'end - pow2');\n    }\n    return `\n      ${main('index')} {\n       if (index < uniforms.size) {\n         var coords = getCoordsFromIndex(index);\n\n         let end = ${getFinalCoord(rank, 'coords', this.op)};\n         var val = ${val};\n         let pow2 = i32(pow(2.0, uniforms.index));\n         if (${condition}) {\n           let idx = ${idxString};\n           ${getFinalCoord(rank, 'coords', this.op)} = idx;\n           val ${this.op}= getX(${getCoords(rank, 'coords', this.op)});\n         }\n         setOutputAtIndex(index, val);\n       }\n      }\n    `;\n  }\n}\n\nfunction getCoords(rank: number, name: string, op: CumOpType): string {\n  if (rank === 1) {\n    return `${name}`;\n  } else if (rank === 2) {\n    return `${name}.x, ${name}.y`;\n  } else if (rank === 3) {\n    return `${name}.x, ${name}.y, ${name}.z`;\n  } else if (rank === 4) {\n    return `${name}.x, ${name}.y, ${name}.z, ${name}.w`;\n  } else {\n    throw Error(`Cumulative ${op} for rank ${rank} is not yet supported`);\n  }\n}\n\nfunction getFinalCoord(rank: number, name: string, op: CumOpType): string {\n  if (rank === 1) {\n    return `${name}`;\n  } else if (rank === 2) {\n    return `${name}.y`;\n  } else if (rank === 3) {\n    return `${name}.z`;\n  } else if (rank === 4) {\n    return `${name}.w`;\n  } else {\n    throw Error(`Cumulative ${op} for rank ${rank} is not yet supported`);\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CumOpType, CumProgram} from '../cum_webgpu';\n\nimport {identity} from './Identity';\nimport {transpose} from './Transpose';\n\nexport function cumImpl(\n    op: CumOpType, x: TensorInfo, backend: WebGPUBackend, axis: number,\n    exclusive: boolean, reverse: boolean): TensorInfo {\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(\n        `WebGPU cumprod shader expects an inner-most axis=${\n            x.shape.length - 1} ` +\n        `but got axis=${axis}`);\n  }\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({inputs: {x: permutedX}, backend});\n  // Use cum parallel algorithm, inspired by:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n  // Note: although the algorithm is called sum, it works for any associtative\n  // operator with an identity.\n\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumProgram(op, permutedX.shape, false, reverse);\n    const prevResult = result;\n    const uniformData = [{type: 'float32', data: [i]}];\n    result =\n        backend.runWebGPUProgram(program, [result], result.dtype, uniformData);\n    backend.disposeData(prevResult.dataId);\n  }\n  // For exclusive cum, shift the end result in the direction of product or sum\n  // and add 1 for product or 0 for sum to the front index.\n  if (exclusive) {\n    const program = new CumProgram(op, permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    const uniformData = [{type: 'float32', data: [0]}];\n    result =\n        backend.runWebGPUProgram(program, [result], result.dtype, uniformData);\n    backend.disposeData(prevResult.dataId);\n  }\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeData(result.dataId);\n    backend.disposeData(permutedX.dataId);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cumprod, CumprodAttrs, CumprodInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CumOpType} from '../cum_webgpu';\nimport {cumImpl} from './Cum_impl';\n\nexport function cumprod(\n    args: {inputs: CumprodInputs, backend: WebGPUBackend, attrs: CumprodAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n  return cumImpl(CumOpType.Prod, x, backend, axis, exclusive, reverse);\n}\n\nexport const cumprodConfig: KernelConfig = {\n  kernelName: Cumprod,\n  backendName: 'webgpu',\n  kernelFunc: cumprod as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cumsum, CumsumAttrs, CumsumInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CumOpType} from '../cum_webgpu';\nimport {cumImpl} from './Cum_impl';\n\nexport function cumsum(\n    args: {inputs: CumsumInputs, backend: WebGPUBackend, attrs: CumsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n  return cumImpl(CumOpType.Sum, x, backend, axis, exclusive, reverse);\n}\n\nexport const cumsumConfig: KernelConfig = {\n  kernelName: Cumsum,\n  backendName: 'webgpu',\n  kernelFunc: cumsum as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DenseBincount, DenseBincountAttrs, DenseBincountInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {BincountProgram} from '../bincount_webgpu';\n\nimport {fill} from './Fill';\n\nexport function denseBincount(args: {\n  inputs: DenseBincountInputs,\n  backend: WebGPUBackend,\n  attrs: DenseBincountAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, weights} = inputs;\n  const {size, binaryOutput} = attrs;\n\n  const xRankOne = x.shape.length === 1;\n  const weightsSize = util.sizeFromShape(weights.shape);\n  const hasWeights = weightsSize > 0;\n  const dtype = weights.dtype;\n  const xSize: [number]|[number, number] =\n      xRankOne ? [x.shape[0]] : [x.shape[0], x.shape[1]];\n  const outputSize: [number]|[number, number] =\n      xRankOne ? [size] : [x.shape[0], size];\n\n  const output = fill({backend, attrs: {shape: outputSize, value: 0, dtype}});\n  const program = new BincountProgram(xSize, hasWeights, binaryOutput);\n  const uniformData = [{type: 'int32', data: [size]}];\n  const bincountInputs: TensorInfo[] = hasWeights ? [x, weights] : [x];\n  const res = backend.runWebGPUProgram(\n      program, bincountInputs, dtype, uniformData, output);\n\n  return res;\n}\n\nexport const denseBincountConfig: KernelConfig = {\n  kernelName: DenseBincount,\n  backendName: 'webgpu',\n  kernelFunc: denseBincount as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DepthToSpaceProgram implements WebGPUProgram {\n  variableNames = ['x'];\n  outputShape: number[];\n  dataFormat: string;\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  uniforms = 'blockSize : i32,';\n\n  constructor(outputShape: number[], dataFormat: 'NHWC'|'NCHW') {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = `depthToSpace_${dataFormat}`;\n    this.dataFormat = dataFormat;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let b = coords[0];\n          let h = ${this.getHeightCoordString()};\n          let w = ${this.getWidthCoordString()};\n          let d = ${this.getDepthCoordString()};\n\n          let in_h = h / uniforms.blockSize;\n          let offset_h = h % uniforms.blockSize;\n          let in_w = w / uniforms.blockSize;\n          let offset_w = w % uniforms.blockSize;\n          let offset_d = (offset_h * uniforms.blockSize + offset_w) *\n            ${this.getOutputDepthSize()};\n          let in_d = d + offset_d;\n\n          let rlt = ${this.getInputSamplingString()};\n          setOutputAtIndex(index, rlt);\n        }\n      }`;\n    return userCode;\n  }\n\n  private getHeightCoordString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `coords[1]`;\n    } else {\n      return `coords[2]`;\n    }\n  }\n\n  private getWidthCoordString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `coords[2]`;\n    } else {\n      return `coords[3]`;\n    }\n  }\n\n  private getDepthCoordString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `coords[3]`;\n    } else {\n      return `coords[1]`;\n    }\n  }\n\n  private getOutputDepthSize(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `uniforms.outShape[3]`;\n    } else {\n      return `uniforms.outShape[1]`;\n    }\n  }\n\n  private getInputSamplingString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `getX(b, in_h, in_w, in_d)`;\n    } else {\n      return `getX(b, in_d, in_h, in_w)`;\n    }\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DepthToSpace, DepthToSpaceAttrs, DepthToSpaceInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthToSpaceProgram} from '../depth_to_space_webgpu';\n\nexport function depthToSpace(args: {\n  inputs: DepthToSpaceInputs,\n  backend: WebGPUBackend,\n  attrs: DepthToSpaceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockSize, dataFormat} = attrs;\n\n  const batchSize = x.shape[0];\n  const inputHeight = (dataFormat === 'NHWC') ? x.shape[1] : x.shape[2];\n  const inputWidth = (dataFormat === 'NHWC') ? x.shape[2] : x.shape[3];\n  const inputDepth = (dataFormat === 'NHWC') ? x.shape[3] : x.shape[1];\n\n  const outputHeight = inputHeight * blockSize;\n  const outputWidth = inputWidth * blockSize;\n  const outputDepth = inputDepth / (blockSize * blockSize);\n\n  const outputShape = (dataFormat === 'NHWC') ?\n      [batchSize, outputHeight, outputWidth, outputDepth] :\n      [batchSize, outputDepth, outputHeight, outputWidth];\n\n  const uniformData = [\n    {type: 'int32', data: [blockSize]},\n  ];\n\n  const program = new DepthToSpaceProgram(outputShape, dataFormat);\n  return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n}\n\nexport const depthToSpaceConfig: KernelConfig = {\n  kernelName: DepthToSpace,\n  backendName: 'webgpu',\n  kernelFunc: depthToSpace as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport class DepthwiseConv2DNCHWSharedProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms = `pads : vec2<i32>, inDims : vec2<i32>,`;\n  workgroupSize: [number, number, number] = [16, 16, 1];\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivation: boolean;\n  filterHeight: number;\n  filterWidth: number;\n\n  constructor(\n      outputShape: number[], filterHeight: number, filterWidth: number,\n      addBias = false, activation: backend_util.Activation = null,\n      hasPreluActivation = false) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [3], y: [2], z: [0, 1]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivation = hasPreluActivation;\n    this.filterHeight = filterHeight;\n    this.filterWidth = filterWidth;\n    this.shaderKey = `depthwiseNCHW_${this.activation}_${this.filterHeight}_${\n        this.filterWidth}`;\n  }\n\n  getUserCode(): string {\n    const filterSize = this.filterWidth * this.filterHeight;\n    const flatWorkgroupSize =\n        this.workgroupSize[0] * this.workgroupSize[1] * this.workgroupSize[2];\n    const tileAHeight = this.workgroupSize[1] + this.filterHeight - 1;\n    const tileAWidth = this.workgroupSize[0] + this.filterWidth - 1;\n\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivation, false, 4)}\n\n      var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHeight}>;\n      var<workgroup> mm_Bsub : array<array<f32, ${this.filterWidth}>, ${\n        this.filterHeight}>;\n      fn readX(batch : i32, channel : i32, row : i32, col : i32) -> f32 {\n        var value = 0.0;\n        if (row >=0 && row < uniforms.inDims[0] && col >=0 && col < uniforms.inDims[1])\n        {\n          value = getX(batch, channel, row, col);\n        }\n        return value;\n      }\n\n      ${main()} {\n        let coords = getOutputCoords();\n        let batch = coords[0];\n        let xRCCorner = vec2<i32>(coords.zw) - uniforms.pads;\n        let channelMul = uniforms.wShape[3];\n        let d1 = coords[1] / channelMul;\n        let q = coords[1] % channelMul;\n\n        let inputRowStart = xRCCorner.x;\n        let inputColStart = xRCCorner.y;\n\n        let localRow = i32(localId.y);\n        let localCol = i32(localId.x);\n\n        // Load one tile of X into local memory.\n        for (var inputRow = localRow; inputRow < ${\n        tileAHeight}; inputRow = inputRow + ${this.workgroupSize[1]}) {\n          for (var inputCol = localCol; inputCol < ${\n        tileAWidth}; inputCol = inputCol + ${this.workgroupSize[0]}) {\n            let rowOffset = inputRow - localRow;\n            let colOffset = inputCol - localCol;\n            mm_Asub[inputRow][inputCol] = readX(batch, d1, inputRowStart + rowOffset, inputColStart + colOffset);\n          }\n        }\n\n        // Load one tile of W into local memory.\n        var wIndex = i32(localIndex);\n        ${\n        filterSize < flatWorkgroupSize ?\n            `if (wIndex < ${filterSize})` :\n            `for(; wIndex < ${filterSize}; wIndex = wIndex + ${\n                flatWorkgroupSize})`}\n\n        {\n          let wRow = wIndex / ${this.filterWidth};\n          let wCol = wIndex % ${this.filterWidth};\n          mm_Bsub[wRow][wCol] = getW(wRow, wCol, d1, q);\n        }\n\n        workgroupBarrier();\n\n        var value = 0.0;\n        for (var wR = 0; wR < ${this.filterHeight}; wR = wR + 1) {\n          for (var wC = 0; wC < ${this.filterWidth}; wC = wC + 1) {\n            let xVal = mm_Asub[localRow + wR][localCol + wC];\n            let wVal = mm_Bsub[wR][wC];\n            value = fma(xVal, wVal, value);\n          }\n        }\n        ${biasActivationSnippet(this.addBias, this.activation)}\n        if (coordsInBounds4D(coords, uniforms.outShape)) {\n          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DepthwiseConv2DVec4Program implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms = 'pads : vec2<i32>, inDims : vec2<i32>, virtualWidth : i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  workPerThread = 4;\n  convInfo: backend_util.Conv2DInfo;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivation: boolean;\n  outputComponent = 4;\n  virtualWidth: number;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: backend_util.Activation = null, hasPreluActivation = false) {\n    this.outputShape = convInfo.outShape;\n    this.virtualWidth = Math.ceil(this.outputShape[2] / this.workPerThread) *\n        this.workPerThread;\n    const virtualOutputShape = [\n      this.outputShape[0], this.outputShape[1], this.virtualWidth,\n      this.outputShape[3]\n    ];\n    this.dispatchLayout = flatDispatchLayout(virtualOutputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, virtualOutputShape, this.workgroupSize,\n        [this.outputComponent * this.workPerThread, 1, 1]);\n\n    util.assert(\n        convInfo.dataFormat === 'channelsLast',\n        () => 'TODO: NCHW is unimplemented');\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.convInfo = convInfo;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivation = hasPreluActivation;\n\n    this.shaderKey =\n        `depthwiseVec4_${activation}_${this.convInfo.filterHeight}_${\n            this.convInfo.filterWidth}_${this.convInfo.strideHeight}_${\n            this.convInfo.strideWidth}_${this.workPerThread}`;\n  }\n\n  getUserCode(): string {\n    const xNumber = (this.workPerThread - 1) * this.convInfo.strideWidth +\n        this.convInfo.filterWidth;\n    const strideHeight = this.convInfo.strideHeight;\n    const strideWidth = this.convInfo.strideWidth;\n\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivation, true, 4)}\n      fn readX(batch : i32, row : i32, col : i32, channel : i32) -> vec4<f32> {\n        var value = vec4<f32>(0.0);\n        if (col >=0 && col < uniforms.inDims[1]) {\n          value = getX(batch, row, col, channel);\n        }\n        return value;\n      }\n\n      ${main('index')} {\n        let width0 = uniforms.outShape[3] / ${this.outputComponent};\n        let d1 = (index % width0) * ${this.outputComponent};\n        var index1 = index / width0;\n        let width1 = uniforms.virtualWidth / ${this.workPerThread};\n        let c = (index1 % width1) * ${this.workPerThread};\n        index1 = index1 / width1;\n        let r = index1 % uniforms.outShape[1];\n        let batch = index1 / uniforms.outShape[1];\n\n        let xRCCorner = vec2<i32>(r, c) * vec2<i32>(${strideHeight}, ${\n        strideWidth}) - uniforms.pads;\n\n        let xRCorner = xRCCorner.x;\n        let xCCorner = xRCCorner.y;\n        var xVals : array<vec4<f32>, ${xNumber}>;\n        var dotProd : array<vec4<f32>, ${this.workPerThread}>;\n        for (var i = 0; i < ${this.workPerThread}; i++) {\n          dotProd[i] = vec4<f32>(0.0);\n        }\n\n        // Use constant instead of uniform can give better performance.\n        for (var wR = 0; wR < ${this.convInfo.filterHeight}; wR = wR + 1) {\n          let xR = xRCorner + wR;\n          if (xR >=0 && xR < uniforms.inDims[0]) {\n            for (var i = 0; i < ${xNumber}; i++) {\n              xVals[i] = readX(batch, xR, xCCorner + i, d1);\n            }\n            for (var wC = 0; wC < ${this.convInfo.filterWidth}; wC = wC + 1) {\n              let wValue = getW(wR, wC, d1, 0);\n              for (var i = 0; i < ${this.workPerThread}; i++) {\n                dotProd[i] = fma(xVals[i * ${\n        strideWidth} + wC], wValue, dotProd[i]);\n              }\n            }\n          }\n        }\n\n        for (var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let coords = vec4<i32>(batch, r, c + i, d1);\n          if (coordsInBounds4D(coords, uniforms.outShape)) {\n            var value = dotProd[i];\n            ${biasActivationSnippet(this.addBias, this.activation)}\n            setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DepthwiseConv2DProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y?: number[], z?: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms = `pads : vec2<i32>, inDims : vec2<i32>, filterHeight : i32,\n      filterWidth : i32, strides : vec2<i32>, dilations : vec2<i32>,`;\n  // This is an experimental value.\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  convInfo: backend_util.Conv2DInfo;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivation: boolean;\n  isChannelsLast: boolean;\n  size = true;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: backend_util.Activation = null, hasPreluActivation = false) {\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.convInfo = convInfo;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivation = hasPreluActivation;\n    this.shaderKey = `depthwise_${this.activation}_${this.isChannelsLast}`;\n  }\n\n  getUserCode(): string {\n    const getXSnippet = this.isChannelsLast ? 'getX(batch, xR, xC, d1);' :\n                                              'getX(batch, d1, xR, xC);';\n\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivation, false, 4)}\n\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getOutputCoords();\n          let batch = coords[0];\n          let xRCCorner = vec2<i32>(coords.${\n        this.isChannelsLast ? 'yz' : 'zw'}) * uniforms.strides - uniforms.pads;\n          let d2 = coords[${this.isChannelsLast ? 3 : 1}];\n          let channelMul = uniforms.wShape[3];\n          let d1 = d2 / channelMul;\n          let q = d2 % channelMul;\n\n          let inputRowStart = xRCCorner.x;\n          let inputColStart = xRCCorner.y;\n          let inputRowEnd = inputRowStart + uniforms.filterHeight *\n              uniforms.dilations[0];\n          let inputColEnd = inputColStart + uniforms.filterWidth *\n              uniforms.dilations[1];\n\n          // Convolve x(?, ?, d1)|x(d1, ?, ?) with w(:, :, d1, q) to get\n          // y(yR, yC, d2)|y(d2, yR, yC). ? = to be determined. : = across all\n          // values in that axis. x(?, ?, d1) and y(yR, yC, d2) is for NHWC.\n          // x(d1, ?, ?) and y(d2, yR, yC) is for NCHW.\n          var value = 0.0;\n\n          // Extract if checking out of for loop for performance.\n          if (inputRowStart >= 0 && inputColStart >= 0 &&\n            inputRowEnd < uniforms.inDims[0] &&\n                inputColEnd < uniforms.inDims[1]) {\n              for (var wR = 0; wR < uniforms.filterHeight; wR = wR + 1) {\n                let xR = inputRowStart + wR * uniforms.dilations[0];\n\n                for (var wC = 0; wC < uniforms.filterWidth; wC = wC + 1) {\n                  let xC = inputColStart + wC * uniforms.dilations[1];\n\n                  let xVal = ${getXSnippet};\n                  let wVal = getW(wR, wC, d1, q);\n                  value = value + xVal * wVal;\n                }\n              }\n            } else {\n              for (var wR = 0; wR < uniforms.filterHeight; wR = wR + 1) {\n                let xR = inputRowStart + wR * uniforms.dilations[0];\n\n                if (xR < 0 || xR >= uniforms.inDims[0]) {\n                  continue;\n                }\n\n                for (var wC = 0; wC < uniforms.filterWidth; wC = wC + 1) {\n                  let xC = inputColStart + wC * uniforms.dilations[1];\n\n                  if (xC < 0 || xC >= uniforms.inDims[1]) {\n                    continue;\n                  }\n\n                  let xVal = ${getXSnippet};\n                  let wVal = getW(wR, wC, d1, q);\n                  value = value + xVal * wVal;\n                }\n              }\n            }\n            ${biasActivationSnippet(this.addBias, this.activation)}\n          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNative, DepthwiseConv2dNativeAttrs, DepthwiseConv2dNativeInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthwiseConv2DNCHWSharedProgram} from '../depthwise_conv2d_nchw_shared_webgpu';\nimport {DepthwiseConv2DVec4Program} from '../depthwise_conv2d_vec4_webgpu';\nimport {DepthwiseConv2DProgram} from '../depthwise_conv2d_webgpu';\n\nexport function depthwiseConv2dNative(args: {\n  inputs: DepthwiseConv2dNativeInputs,\n  attrs: DepthwiseConv2dNativeAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode} = attrs;\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  let $dilations = dilations;\n  if ($dilations == null) {\n    $dilations = [1, 1];\n  }\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, $dilations,\n      pad, dimRoundingMode, true /* depthwise */, $dataFormat);\n  const dimensions = [\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]},\n  ];\n\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  let program: DepthwiseConv2DProgram|DepthwiseConv2DVec4Program|\n      DepthwiseConv2DNCHWSharedProgram;\n  if (!isChannelsLast && convInfo.inHeight > 16 && convInfo.inWidth > 16 &&\n      convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n      convInfo.dilationWidth === 1 && convInfo.dilationHeight === 1 &&\n      convInfo.inChannels === convInfo.outChannels) {\n    program = new DepthwiseConv2DNCHWSharedProgram(\n        convInfo.outShape, convInfo.filterHeight, convInfo.filterWidth);\n  } else if (\n      isChannelsLast && convInfo.outHeight > 4 && convInfo.outWidth > 4 &&\n      convInfo.strideWidth <= 2 &&\n      convInfo.inChannels === convInfo.outChannels &&\n      convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n      convInfo.inChannels % 4 === 0) {\n    program = new DepthwiseConv2DVec4Program(convInfo);\n    dimensions.push({type: 'int32', data: [program.virtualWidth]});\n  } else {\n    program = new DepthwiseConv2DProgram(convInfo);\n    dimensions.push(\n        {type: 'int32', data: [convInfo.filterHeight]},\n        {type: 'int32', data: [convInfo.filterWidth]},\n        {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n          type: 'int32',\n          data: [convInfo.dilationHeight, convInfo.dilationWidth]\n        });\n  }\n\n  return backend.runWebGPUProgram(program, [x, filter], x.dtype, dimensions);\n}\n\nexport const depthwiseConv2dNativeConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNative,\n  backendName: 'webgpu',\n  kernelFunc: depthwiseConv2dNative as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DepthwiseConv2DDerFilterProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'dy'];\n  uniforms =\n      `strides : vec2<i32>, pads : vec2<i32>, filterDims : vec2<i32>, outHeight : i32,\n      outWidth : i32, inHeight : i32, inWidth : i32, batchSize : i32, channelMul : i32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.filterShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `depthwise_conv2d_backprop_filter`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let wR = coords[0];\n        let wC = coords[1];\n        let d1 = coords[2];\n        let dm = coords[3];\n        let d2 = d1 * uniforms.channelMul + dm;\n\n        var dotProd = 0.0;\n        for (var b = 0; b < uniforms.batchSize; b++) {\n          for (var yR = 0; yR < uniforms.outHeight; yR++) {\n            let xR = wR + yR * uniforms.strides[0] - uniforms.pads[0];\n\n            if (xR < 0 || xR >= uniforms.inHeight) {\n              continue;\n            }\n\n            for (var yC = 0; yC < uniforms.outWidth; yC++) {\n              let xC = wC + yC * uniforms.strides[1] - uniforms.pads[1];\n\n              if (xC < 0 || xC >= uniforms.inWidth) {\n                continue;\n              }\n\n              let dyValue = getDy(b, yR, yC, d2);\n              let xValue = getX(b, xR, xC, d1);\n              dotProd += xValue * dyValue;\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n\nexport class DepthwiseConv2DDerInputProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy', 'W'];\n  uniforms = `strides : vec2<i32>, pads : vec2<i32>, filterDims : vec2<i32>,\n       outHeight : i32, outWidth : i32, channelMul : i32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `depthwise_conv2d_backprop_input`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords[0];\n        let d1 = coords[3];\n        let dyCorner = coords.yz - uniforms.pads;\n        let dyRCorner = dyCorner.x;\n        let dyCCorner = dyCorner.y;\n\n        var dotProd = 0.0;\n        for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {\n          let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[0]);\n\n          if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n            continue;\n          }\n\n          let idyR = i32(dyR);\n          let wRPerm = uniforms.filterDims[0] - 1 - wR;\n\n          for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {\n            let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[1]);\n\n            if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n              continue;\n            }\n\n            let idyC = i32(dyC);\n            let wCPerm = uniforms.filterDims[1] - 1 - wC;\n\n            for (var dm = 0; dm < uniforms.channelMul; dm++) {\n              let d2 = d1 * uniforms.channelMul + dm;\n              let xValue = getDy(batch, idyR, idyC, d2);\n              let wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropFilterAttrs, DepthwiseConv2dNativeBackpropFilterInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthwiseConv2DDerFilterProgram} from '../conv_backprop_depthwise_webgpu';\n\nexport function depthwiseConv2dNativeBackpropFilter(args: {\n  inputs: DepthwiseConv2dNativeBackpropFilterInputs,\n  attrs: DepthwiseConv2dNativeBackpropFilterAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, filterShape} = attrs;\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const program = new DepthwiseConv2DDerFilterProgram(convInfo);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'int32', data: [convInfo.inHeight]},\n    {type: 'int32', data: [convInfo.inWidth]},\n    {type: 'int32', data: [convInfo.batchSize]},\n    {type: 'int32', data: [convInfo.outChannels / convInfo.inChannels]}\n  ];\n  return backend.runWebGPUProgram(program, [x, dy], 'float32', uniformData);\n}\n\nexport const depthwiseConv2dNativeBackpropFilterConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropFilter,\n  backendName: 'webgpu',\n  kernelFunc: depthwiseConv2dNativeBackpropFilter as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropInput, DepthwiseConv2dNativeBackpropInputAttrs, DepthwiseConv2dNativeBackpropInputInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthwiseConv2DDerInputProgram} from '../conv_backprop_depthwise_webgpu';\n\nexport function depthwiseConv2dNativeBackpropInput(args: {\n  inputs: DepthwiseConv2dNativeBackpropInputInputs,\n  attrs: DepthwiseConv2dNativeBackpropInputAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, inputShape} = attrs;\n\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const program = new DepthwiseConv2DDerInputProgram(convInfo);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n      type: 'int32',\n      data: [\n        convInfo.filterHeight - 1 - convInfo.padInfo.top,\n        convInfo.filterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'int32', data: [convInfo.outChannels / convInfo.inChannels]}\n  ];\n  return backend.runWebGPUProgram(program, [dy, filter], dy.dtype, uniformData);\n}\n\nexport const depthwiseConv2dNativeBackpropInputConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropInput,\n  backendName: 'webgpu',\n  kernelFunc: depthwiseConv2dNativeBackpropInput as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DiagProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(size: number) {\n    this.outputShape = [size, size];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'diag';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getOutputCoords();\n          let value = select(0.0, getX(coords[0]), coords[0] == coords[1]);\n          setOutputAtIndex(index, value);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Diag, DiagInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DiagProgram} from '../diag_webgpu';\nimport {reshape} from './Reshape';\n\nexport function diag(args: {inputs: DiagInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  const outShape = [...x.shape, ...x.shape];\n  const xSize = util.sizeFromShape(x.shape);\n\n  const flat = reshape({inputs: {x}, backend, attrs: {shape: [xSize]}});\n\n  const program = new DiagProgram(xSize);\n  const res = backend.runWebGPUProgram(program, [flat], flat.dtype);\n\n  const out = reshape({inputs: {x: res}, backend, attrs: {shape: outShape}});\n\n  backend.disposeData(flat.dataId);\n  backend.disposeData(res.dataId);\n\n  return out;\n}\n\nexport const diagConfig: KernelConfig = {\n  kernelName: Diag,\n  backendName: 'webgpu',\n  kernelFunc: diag as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Dilation2DProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'w'];\n  uniforms =\n      'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'dilation2d';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.size) {\n           let neg_infinity = -3.4e38;\n           let coords = getOutputCoords();\n           let batch = coords.x;\n           let d1 = coords.w;\n           let outTopLeftCorner = coords.yz * uniforms.strides - uniforms.pads;\n           let hBeg = outTopLeftCorner.x;\n           let wBeg = outTopLeftCorner.y;\n\n           var curVal = neg_infinity;\n           for (var h = 0; h < uniforms.filterDims[0]; h = h + 1) {\n             let hIn = hBeg + h * uniforms.dilations[0];\n\n             if (hIn >= 0 && hIn < uniforms.xShape[1]) {\n               for (var w = 0; w < uniforms.filterDims[1]; w = w + 1) {\n                 let wIn = wBeg + w * uniforms.dilations[1];\n\n                 if (wIn >= 0 && wIn < uniforms.xShape[2]) {\n                   let val = getX(batch, hIn, wIn, d1) + getW(h, w, d1);\n                   if (val > curVal) {\n                     curVal = val;\n                   }\n                 }\n               }\n             }\n           }\n\n           setOutputAtIndex(index, curVal);\n         }\n       }\n     `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2D, Dilation2DAttrs, Dilation2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Dilation2DProgram} from '../dilation_webgpu';\n\nexport function dilation2D(args: {\n  inputs: Dilation2DInputs,\n  attrs: Dilation2DAttrs,\n  backend: WebGPUBackend\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  const convInfo = backend_util.computeDilation2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number], strides, pad,\n      'NHWC' /* dataFormat */, dilations);\n  const padInfo = [convInfo.padInfo.top, convInfo.padInfo.left];\n  const uniformData = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [...padInfo]},\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]}\n  ];\n\n  const program = new Dilation2DProgram(convInfo);\n  const out =\n      backend.runWebGPUProgram(program, [x, filter], x.dtype, uniformData);\n\n  return out;\n}\n\nexport const dilation2DConfig: KernelConfig = {\n  kernelName: Dilation2D,\n  backendName: 'webgpu',\n  kernelFunc: dilation2D as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType} from '@tensorflow/tfjs-core';\n\nimport {atomicAddSnippet} from './shader_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Dilation2DBackpropInputProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'w', 'dy'];\n  uniforms =\n      'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>, dySize: i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  type: DataType;\n\n  constructor(convInfo: backend_util.Conv2DInfo, outputDtype: DataType) {\n    this.outputShape = convInfo.inShape;\n    this.dispatchLayout = flatDispatchLayout(convInfo.outShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, convInfo.outShape, this.workgroupSize);\n\n    if (outputDtype !== 'float32' && outputDtype !== 'int32') {\n      throw new Error(`Dilation2DBackpropInput only supports float32 and int32\n          types, does not support ${outputDtype} type.`);\n    }\n    this.type = outputDtype;\n    this.shaderKey = 'dilation2DBackpropInput';\n  }\n\n  getUserCode(): string {\n    // This implementation follows the TF c++ cuda implementation:\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dilation_ops_gpu.cu.cc\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.dySize) {\n           let coords = getDyCoordsFromIndex(index);\n           let b = coords[0];\n           let r = coords[1];\n           let c = coords[2];\n           let d = coords[3];\n\n           let dyCorner = vec2<i32>(r, c) * uniforms.strides - uniforms.pads;\n           var curVal = -3.4e38;  // neg_infinity\n           var xRMax = 0;\n           var xCMax = 0;\n\n           // In the case of multiple argmax branches, we only back-propagate\n           // along the last branch, i.e., the one with largest value of\n           // 'wR * uniforms.filterDims[1] + wC', similarly to the max-pooling\n           // backward routines.\n           for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {\n             let xR = dyCorner.x + wR * uniforms.dilations[0];\n\n             if (xR >= 0 && xR < uniforms.xShape[1]) {\n               for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {\n                 let xC = dyCorner.y + wC * uniforms.dilations[1];\n\n                 if (xC >= 0 && xC < uniforms.xShape[2]) {\n                   let val = getX(b, xR, xC, d) + getW(wR, wC, d);\n                   if (val > curVal) {\n                     curVal = val;\n                     xRMax = xR;\n                     xCMax = xC;\n                   }\n                 }\n               }\n             }\n           }\n\n           let flatIndexIn = d + uniforms.xShape[3] *\n               (xCMax + uniforms.xShape[2] * (xRMax + uniforms.xShape[1] * b));\n           let value = getDy(b, r, c, d);\n           ${\n        atomicAddSnippet(\n            '&result[flatIndexIn]', 'value', this.type as 'float32' | 'int32')}\n         }\n       }\n     `;\n    return userCode;\n  }\n}\n\nexport class Dilation2DBackpropFilterProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'w', 'dy'];\n  uniforms =\n      'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>, dySize: i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  type: DataType;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, shape: number[],\n      outputDtype: DataType) {\n    this.outputShape = convInfo.filterShape;\n    this.dispatchLayout = flatDispatchLayout(convInfo.outShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, convInfo.outShape, this.workgroupSize);\n\n    if (outputDtype !== 'float32' && outputDtype !== 'int32') {\n      throw new Error(`Dilation2DBackpropFilter only supports float32 and int32\n          types, does not support ${outputDtype} type.`);\n    }\n    this.type = outputDtype;\n    this.shaderKey = 'dilation2DBackpropFilter';\n  }\n\n  getUserCode(): string {\n    // This implementation follows the TF c++ cuda implementation:\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dilation_ops_gpu.cu.cc\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.dySize) {\n           let coords = getDyCoordsFromIndex(index);\n           let b = coords[0];\n           let r = coords[1];\n           let c = coords[2];\n           let d = coords[3];\n\n           let dyCorner = vec2<i32>(r, c) * uniforms.strides - uniforms.pads;\n           var curVal = -3.4e38;  // neg_infinity\n           var wRMax = 0;\n           var wCMax = 0;\n\n           // In the case of multiple argmax branches, we only back-propagate\n           // along the last branch, i.e., the one with largest value of\n           // 'wR * uniforms.filterDims[1] + wC', similarly to the max-pooling\n           // backward routines.\n           for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {\n             let xR = dyCorner.x + wR * uniforms.dilations[0];\n\n             if (xR >= 0 && xR < uniforms.xShape[1]) {\n               for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {\n                 let xC = dyCorner.y + wC * uniforms.dilations[1];\n\n                 if (xC >= 0 && xC < uniforms.xShape[2]) {\n                   let val = getX(b, xR, xC, d) + getW(wR, wC, d);\n                   if (val > curVal) {\n                     curVal = val;\n                     wRMax = wR;\n                     wCMax = wC;\n                   }\n                 }\n               }\n             }\n           }\n\n           let flatIndexIn = d + uniforms.wShape[2] * (wCMax + wRMax * uniforms.wShape[1]);\n           let value = getDy(b, r, c, d);\n           ${\n        atomicAddSnippet(\n            '&result[flatIndexIn]', 'value', this.type as 'float32' | 'int32')}\n         }\n       }\n     `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropFilter, Dilation2DBackpropFilterInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Dilation2DBackpropFilterProgram} from '../dilation_backprop_webgpu';\nimport {fill} from './Fill';\n\nexport function dilation2DBackpropFilter(args: {\n  inputs: Dilation2DBackpropFilterInputs,\n  attrs: Dilation2DAttrs,\n  backend: WebGPUBackend\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, dy} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  const convInfo = backend_util.computeDilation2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number], strides, pad,\n      'NHWC' /* dataFormat */, dilations);\n\n  const dtype = filter.dtype;\n  const program =\n      new Dilation2DBackpropFilterProgram(convInfo, filter.shape, dtype);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]},\n    {type: 'int32', data: [util.sizeFromShape(convInfo.outShape)]}\n  ];\n  const output = fill({backend, attrs: {shape: filter.shape, value: 0, dtype}});\n  return backend.runWebGPUProgram(\n      program, [x, filter, dy], dtype, uniformData, output);\n}\n\nexport const dilation2DBackpropFilterConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropFilter,\n  backendName: 'webgpu',\n  kernelFunc: dilation2DBackpropFilter as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropInput, Dilation2DBackpropInputInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Dilation2DBackpropInputProgram} from '../dilation_backprop_webgpu';\nimport {fill} from './Fill';\n\nexport function dilation2DBackpropInput(args: {\n  inputs: Dilation2DBackpropInputInputs,\n  attrs: Dilation2DAttrs,\n  backend: WebGPUBackend\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, dy} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  const convInfo = backend_util.computeDilation2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number], strides, pad,\n      'NHWC' /* dataFormat */, dilations);\n\n  const dtype = x.dtype;\n  const program = new Dilation2DBackpropInputProgram(convInfo, dtype);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]},\n    {type: 'int32', data: [util.sizeFromShape(convInfo.outShape)]}\n  ];\n  const output =\n      fill({backend, attrs: {shape: convInfo.inShape, value: 0, dtype}});\n  return backend.runWebGPUProgram(\n      program, [x, filter, dy], dtype, uniformData, output);\n}\n\nexport const dilation2DBackpropInputConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'webgpu',\n  kernelFunc: dilation2DBackpropInput as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType} from '@tensorflow/tfjs-core';\n\nimport {getMainHeaderString as main, PixelsOpType, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DrawProgram implements WebGPUProgram {\n  variableNames = ['Image'];\n  uniforms = 'alpha: f32,';\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  type: DataType;\n  textureFormat: GPUTextureFormat;\n  pixelsOpType = PixelsOpType.DRAW;\n  size = true;\n\n  constructor(\n      outShape: number[], type: DataType, textureFormat: GPUTextureFormat) {\n    this.outputShape = outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.type = type;\n    this.textureFormat = textureFormat;\n    this.shaderKey = `draw_${type}_${textureFormat}`;\n  }\n\n  getUserCode(): string {\n    let calculateResult;\n    const value = this.type === 'float32' ? 'value' : 'value / 255.0';\n    calculateResult = `\n      if (uniforms.numChannels == 1) {\n        rgba[0] = ${value};\n        rgba[1] = ${value};\n        rgba[2] = ${value};\n      } else {\n        rgba[d] = ${value};\n      }`;\n\n    const userCode = `\n       @group(0) @binding(0) var outImage : texture_storage_2d<${\n        this.textureFormat}, write>;\n       ${main('index')} {\n         if (index < uniforms.size) {\n           var rgba = vec4<f32>(0.0, 0.0, 0.0, uniforms.alpha);\n           for (var d = 0; d < uniforms.numChannels; d = d + 1) {\n             let value = f32(inBuf[index * uniforms.numChannels + d]);\n             ${calculateResult}\n           }\n           rgba.x = rgba.x * rgba.w;\n           rgba.y = rgba.y * rgba.w;\n           rgba.z = rgba.z * rgba.w;\n           let coords = getCoordsFromIndex(index);\n           textureStore(outImage, vec2<i32>(coords.yx), rgba);\n         }\n       }\n      `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use backend file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\nimport {Draw, DrawAttrs, DrawInputs,} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DrawProgram} from '../draw_webgpu';\n\nexport function draw(\n    args: {inputs: DrawInputs, backend: WebGPUBackend, attrs: DrawAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {image} = inputs;\n  const {canvas, options} = attrs;\n  const [height, width] = image.shape.slice(0, 2);\n  const {imageOptions} = options || {};\n  const alpha = imageOptions ?.alpha || 1;\n\n  //  'rgba8unorm' should work on macOS according to\n  //  https://bugs.chromium.org/p/chromium/issues/detail?id=1298618. But\n  //  failed on macOS/M2. So use 'bgra8unorm' first when available.\n  const format = backend.device.features.has('bgra8unorm-storage') ?\n      'bgra8unorm' :\n      'rgba8unorm';\n  const outShape = [height, width];\n  const program = new DrawProgram(outShape, image.dtype, format);\n  canvas.width = width;\n  canvas.height = height;\n  const backendName = 'webgpu';\n  let gpuContext = canvas.getContext(backendName);\n  let canvasWebGPU;\n  if (!gpuContext) {\n    canvasWebGPU = new OffscreenCanvas(width, height);\n    gpuContext = canvasWebGPU.getContext(backendName);\n  }\n  const numChannels = image.shape.length === 3 ? image.shape[2] : 1;\n  gpuContext.configure({\n    device: backend.device,\n    format,\n    usage: GPUTextureUsage.STORAGE_BINDING,\n    alphaMode: 'premultiplied'\n  });\n\n  const outputDtype = 'int32';\n  const output = backend.makeTensorInfo(outShape, outputDtype);\n  const info = backend.tensorMap.get(output.dataId);\n  info.resource = gpuContext.getCurrentTexture();\n  info.external = true;\n\n  const uniformData =\n      [{type: 'uint32', data: [numChannels]}, {type: 'float32', data: [alpha]}];\n  backend.runWebGPUProgram(program, [image], outputDtype, uniformData, output);\n\n  if (canvasWebGPU) {\n    const canvas2dContext = canvas.getContext('2d');\n    if (!canvas2dContext) {\n      throw new Error(\n          `Please make sure this canvas has only been used for 2d or webgpu context!`);\n    }\n    canvas2dContext.drawImage(canvasWebGPU, 0, 0);\n  }\n  backend.disposeData(output.dataId);\n  return image;\n}\n\nexport const drawConfig: KernelConfig = {\n  kernelName: Draw,\n  backendName: 'webgpu',\n  kernelFunc: draw as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {multiplyImplCPU as cpuMultiply} from '../kernel_utils/shared';\n\nexport const multiplyKernelFunc = binaryKernelFunc({\n  opType: BinaryOpType.MUL,\n  cpuKernelImpl: cpuMultiply,\n  supportsComplex: true\n});\n\nexport const multiplyConfig: KernelConfig = {\n  kernelName: Multiply,\n  backendName: 'webgpu',\n  kernelFunc: multiplyKernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Sum, SumAttrs, SumInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function sum(\n    args: {inputs: SumInputs, backend: WebGPUBackend, attrs: SumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  return reduce(x, axis, keepDims, 'sum', backend);\n}\n\nexport const sumConfig: KernelConfig = {\n  kernelName: Sum,\n  backendName: 'webgpu',\n  kernelFunc: sum as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Einsum, EinsumAttrs, EinsumInputs, KernelConfig, KernelFunc, Tensor, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {multiplyKernelFunc} from './Multiply';\nimport {reshape} from './Reshape';\nimport {sum} from './Sum';\nimport {transpose} from './Transpose';\n\nexport function einsum(\n    args: {inputs: EinsumInputs, backend: WebGPUBackend, attrs: EinsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {equation} = attrs;\n  const tensors = inputs as Tensor[];\n\n  const {allDims, summedDims, idDims} =\n      backend_util.decodeEinsumEquation(equation, tensors.length);\n  backend_util.checkEinsumDimSizes(allDims.length, idDims, tensors);\n  const {path, steps} = backend_util.getEinsumComputePath(summedDims, idDims);\n\n  const nSteps = steps.length;\n  let out: TensorInfo|null = null;\n  let numDimsRemaining = allDims.length;\n  const tensorsToDispose: TensorInfo[] = [];\n  for (let i = 0; i < nSteps; ++i) {\n    for (const idTerm of steps[i]) {\n      const {permutationIndices: perm, expandDims: dimsToExpand} =\n          backend_util.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);\n      let x: TensorInfo;\n      if (backend_util.isIdentityPermutation(perm)) {\n        x = tensors[idTerm];\n      } else {\n        x = transpose({inputs: {x: tensors[idTerm]}, backend, attrs: {perm}});\n        tensorsToDispose.push(x);\n      }\n      const targetShape: number[] = x.shape.slice();\n      for (let k = 0; k < dimsToExpand.length; ++k) {\n        targetShape.splice(dimsToExpand[k], 0, 1);\n      }\n\n      if (!util.arraysEqual(x.shape, targetShape)) {\n        x = reshape({inputs: {x}, backend, attrs: {shape: targetShape}});\n        tensorsToDispose.push(x);\n      }\n      if (out === null) {\n        out = x;\n      } else {\n        // tslint:disable-next-line: no-unnecessary-type-assertion\n        out =\n            multiplyKernelFunc({inputs: {a: x, b: out}, backend}) as TensorInfo;\n        tensorsToDispose.push(out);\n      }\n    }\n    if (i < nSteps - 1) {\n      if (path[i] >= 0) {\n        out = sum({\n          inputs: {x: out},\n          backend,\n          attrs: {\n            axis: path[i] - (allDims.length - numDimsRemaining),\n            keepDims: false\n          }\n        });\n        tensorsToDispose.push(out);\n      }\n      numDimsRemaining--;\n    }\n  }\n\n  // Clean up intermediate tensors.\n  for (const tensorInfo of tensorsToDispose) {\n    if (tensorInfo === out) {\n      continue;\n    }\n    backend.disposeData(tensorInfo.dataId);\n  }\n\n  return out;\n}\n\nexport const einsumConfig: KernelConfig = {\n  kernelName: Einsum,\n  backendName: 'webgpu',\n  kernelFunc: einsum as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Elu, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const elu = unaryKernelFunc({opType: UnaryOpType.ELU});\n\nexport const eluConfig: KernelConfig = {\n  kernelName: Elu,\n  backendName: 'webgpu',\n  kernelFunc: elu\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {EluGrad, EluGradInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {BinaryOpType} from '../binary_op_util';\nimport {BinaryOpProgram} from '../binary_op_webgpu';\n\nexport const eluGrad =\n    (args: {inputs: EluGradInputs, backend: WebGPUBackend}): TensorInfo => {\n      const {inputs, backend} = args;\n      const {dy, y} = inputs;\n\n      const program =\n          new BinaryOpProgram(BinaryOpType.ELU_DER, dy.shape, y.shape);\n      return backend.runWebGPUProgram(program, [dy, y], dy.dtype);\n    };\n\nexport const eluGradConfig: KernelConfig = {\n  kernelName: EluGrad,\n  backendName: 'webgpu',\n  kernelFunc: eluGrad as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Equal, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {equalImplCPU as cpuEqual} from '../kernel_utils/shared';\n\nexport const equal = binaryKernelFunc(\n    {opType: BinaryOpType.EQUAL, dtype: 'bool', cpuKernelImpl: cpuEqual});\n\nexport const equalConfig: KernelConfig = {\n  kernelName: Equal,\n  backendName: 'webgpu',\n  kernelFunc: equal\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Erf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const erf = unaryKernelFunc({opType: UnaryOpType.ERF});\n\nexport const erfConfig: KernelConfig = {\n  kernelName: Erf,\n  backendName: 'webgpu',\n  kernelFunc: erf\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {expImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const exp = unaryKernelFunc({\n  opType: UnaryOpType.EXP,\n  cpuKernelImpl: expImplCPU,\n  dtype: 'float32',\n});\n\nexport const expConfig: KernelConfig = {\n  kernelName: Exp,\n  backendName: 'webgpu',\n  kernelFunc: exp\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ExpandDims, ExpandDimsAttrs, ExpandDimsInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reshape} from './Reshape';\n\nexport function expandDims(args: {\n  inputs: ExpandDimsInputs,\n  attrs: ExpandDimsAttrs,\n  backend: WebGPUBackend\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {dim} = attrs;\n  const {input} = inputs;\n\n  const inputRank = input.shape.length;\n  const newShape = input.shape.slice();\n  let $dim = dim;\n  if (dim < 0) {\n    // Negative value is counted from the tail of rank.\n    util.assert(\n        -(inputRank + 1) <= dim,\n        () => `Axis must be in the interval [${- (inputRank + 1)}, ${\n            inputRank}]`);\n    $dim = inputRank + dim + 1;\n  }\n  newShape.splice($dim, 0, 1);\n\n  return reshape({inputs: {x: input}, backend, attrs: {shape: newShape}});\n}\n\nexport const expandDimsConfig: KernelConfig = {\n  kernelName: ExpandDims,\n  backendName: 'webgpu',\n  kernelFunc: expandDims as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {expm1ImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const expm1 =\n    unaryKernelFunc({opType: UnaryOpType.EXPM1, cpuKernelImpl: expm1ImplCPU});\n\nexport const expm1Config: KernelConfig = {\n  kernelName: Expm1,\n  backendName: 'webgpu',\n  kernelFunc: expm1\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class FFTProgram implements WebGPUProgram {\n  variableNames: string[] = ['real', 'imag'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'exponentMultiplier : f32, denominator: f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  component: string;\n\n  constructor(component: 'real'|'imag', shape: [number, number]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.component = component;\n    this.shaderKey = `fft_${component}`;\n  }\n\n  getUserCode(): string {\n    const opString = this.component === 'real' ?\n        'return real * expR - imag * expI;' :\n        'return real * expI + imag * expR;';\n    const userCode = `\n    fn unaryOpComplex(real: f32, expR: f32, imag: f32, expI: f32) -> f32 {\n      ${opString}\n    }\n\n    fn mulMatDFT(batch: i32, index: i32) -> f32 {\n      let indexRatio = f32(index) / f32(uniforms.realShape[1]);\n      let exponentMultiplierTimesIndexRatio =\n          uniforms.exponentMultiplier * indexRatio;\n\n      var result = 0.0;\n\n      for (var i = 0; i < uniforms.realShape[1]; i = i + 1) {\n        // x = (-2|2 * PI / N) * index * i;\n        let x = exponentMultiplierTimesIndexRatio * f32(i);\n        let expR = cos(x);\n        let expI = sin(x);\n        let real = getReal(batch, i);\n        let imag = getImag(batch, i);\n\n        result = result +\n            unaryOpComplex(real, expR, imag, expI) / uniforms.denominator;\n      }\n\n      return result;\n    }\n\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getOutputCoords();\n        setOutputAtIndex(index, mulMatDFT(coords[0], coords[1]));\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {FFTProgram} from '../fft_webgpu';\n\nimport {complex} from './Complex';\nimport {reshape} from './Reshape';\n\nexport function fftImpl(\n    x: TensorInfo, inverse: boolean, backend: WebGPUBackend): TensorInfo {\n  const xData = backend.tensorMap.get(x.dataId);\n\n  const inputSize = util.sizeFromShape(x.shape);\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = x.shape[x.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const toDispose = [];\n  const input2D = reshape(\n      {inputs: {x}, backend, attrs: {shape: [batch, innerDimensionSize]}});\n  toDispose.push(input2D);\n\n  const xShape = input2D.shape as [number, number];\n  const realProgram = new FFTProgram('real', xShape);\n  const imagProgram = new FFTProgram('imag', xShape);\n\n  const inputs = [\n    {\n      dataId: xData.complexTensorInfos.real.dataId,\n      dtype: xData.complexTensorInfos.real.dtype,\n      shape: xShape\n    },\n    {\n      dataId: xData.complexTensorInfos.imag.dataId,\n      dtype: xData.complexTensorInfos.imag.dtype,\n      shape: xShape\n    }\n  ];\n\n  const exponentMultiplier = inverse ? 2.0 * Math.PI : -2.0 * Math.PI;\n  const denominator = inverse ? xShape[1] : 1.0;\n  const uniformData = [\n    {type: 'float32', data: [exponentMultiplier]},\n    {type: 'float32', data: [denominator]}\n  ];\n\n  const realPart =\n      backend.runWebGPUProgram(realProgram, inputs, 'float32', uniformData);\n  toDispose.push(realPart);\n  const imagPart =\n      backend.runWebGPUProgram(imagProgram, inputs, 'float32', uniformData);\n  toDispose.push(imagPart);\n\n  const complexOutput =\n      complex({inputs: {real: realPart, imag: imagPart}, backend});\n  toDispose.push(complexOutput);\n\n  const complexOutputReshaped =\n      reshape({inputs: {x: complexOutput}, backend, attrs: {shape: x.shape}});\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n\n  return complexOutputReshaped;\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FFT, FFTInputs, KernelConfig, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {fftImpl} from './FFT_impl';\n\nexport function fft(args: {inputs: FFTInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  return fftImpl(input, false /* inverse */, backend);\n}\n\nexport const fftConfig: KernelConfig = {\n  kernelName: FFT,\n  backendName: 'webgpu',\n  kernelFunc: fft\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class FlipLeftRightProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(imageShape: [number, number, number, number]) {\n    this.outputShape = imageShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = 'flipLeftRight';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let coordX = uniforms.xShape[2] - coords[2] - 1;\n          let outputValue = getX(coords[0], coords[1], coordX, coords[3]);\n          setOutputAtIndex(index, outputValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tensor4D} from '@tensorflow/tfjs-core';\nimport {FlipLeftRight, FlipLeftRightInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {FlipLeftRightProgram} from '../flip_left_right_webgpu';\n\nexport const flipLeftRightConfig: KernelConfig = {\n    kernelName: FlipLeftRight,\n    backendName: 'webgpu',\n    kernelFunc: ({inputs, backend}) => {\n      const {image} = inputs as FlipLeftRightInputs;\n      const webgpuBackend = backend as WebGPUBackend;\n\n      const program = new FlipLeftRightProgram((image as Tensor4D).shape);\n      const output =\n          webgpuBackend.runWebGPUProgram(program, [image], image.dtype);\n      return output;\n  }\n};\n", "\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {floorImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const floor =\n    unaryKernelFunc({opType: UnaryOpType.FLOOR, cpuKernelImpl: floorImplCPU});\n\nexport const floorConfig: KernelConfig = {\n  kernelName: Floor,\n  backendName: 'webgpu',\n  kernelFunc: floor\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FloorDiv, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {floorDivImplCPU} from '../kernel_utils/shared';\n\nexport const floorDiv = binaryKernelFunc({\n  opType: BinaryOpType.FLOOR_DIV,\n  cpuKernelImpl: floorDivImplCPU,\n  dtype: 'int32'\n});\n\nexport const floorDivConfig: KernelConfig = {\n  kernelName: FloorDiv,\n  backendName: 'webgpu',\n  kernelFunc: floorDiv\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, PixelsOpType, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class FromPixelsProgram implements WebGPUProgram {\n  dispatch: [number, number, number];\n  dispatchLayout: {x: number[]};\n  pixelsOpType = PixelsOpType.FROM_PIXELS;\n  outputShape: number[] = [0];\n  shaderKey: string;\n  importVideo: boolean;\n  variableNames: string[] = [];\n  workgroupSize: [number, number, number] =\n      [256, 1, 1];  // The empirical value.\n\n  constructor(outputShape: number[], numChannels: number, importVideo = false) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [numChannels, 1, 1]);\n\n    this.importVideo = importVideo;\n    this.shaderKey = `fromPixels_${this.importVideo}`;\n  }\n\n  getUserCode(): string {\n    const textureLoad = this.importVideo ?\n        'textureLoad(src, vec2<i32>(coords.yx));' :\n        'textureLoad(src, vec2<i32>(coords.yx), 0)';\n    const textureType =\n        this.importVideo ? 'texture_external' : 'texture_2d<f32>';\n    return `\n      @binding(1) @group(0) var src: ${textureType};\n      ${main('index')} {\n        let flatIndex = index * uniforms.numChannels;\n        if (flatIndex < uniforms.size) {\n          let coords = getCoordsFromIndex(flatIndex);\n          let values = ${textureLoad};\n          for (var i = 0; i < uniforms.numChannels; i = i + 1) {\n            result[flatIndex + i] = i32(floor(255.0 * values[i]));\n          }\n        }\n      }\n  `;\n  }\n}\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use backend file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\nimport {FromPixels, FromPixelsAttrs, FromPixelsInputs, util} from '@tensorflow/tfjs-core';\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {FromPixelsProgram} from '../from_pixels_webgpu';\n\nexport const fromPixelsConfig: KernelConfig = {\n  kernelName: FromPixels,\n  backendName: 'webgpu',\n  kernelFunc: fromPixels as unknown as KernelFunc,\n};\n\nlet fromPixels2DContext: CanvasRenderingContext2D;\nlet willReadFrequently = env().getBool('CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU');\n\nexport function fromPixels(args: {\n  inputs: FromPixelsInputs,\n  backend: WebGPUBackend,\n  attrs: FromPixelsAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  let {pixels} = inputs;\n  const {numChannels} = attrs;\n\n  if (pixels == null) {\n    throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n  }\n\n  const isVideo = typeof (HTMLVideoElement) !== 'undefined' &&\n      pixels instanceof HTMLVideoElement;\n  const isImage = typeof (HTMLImageElement) !== 'undefined' &&\n      pixels instanceof HTMLImageElement;\n  const isCanvas = (typeof (HTMLCanvasElement) !== 'undefined' &&\n                    pixels instanceof HTMLCanvasElement) ||\n      (typeof (OffscreenCanvas) !== 'undefined' &&\n       pixels instanceof OffscreenCanvas);\n  const isImageBitmap =\n      typeof (ImageBitmap) !== 'undefined' && pixels instanceof ImageBitmap;\n\n  const [width, height] = isVideo ?\n      [\n        (pixels as HTMLVideoElement).videoWidth,\n        (pixels as HTMLVideoElement).videoHeight\n      ] :\n      [pixels.width, pixels.height];\n  const outputShape = [height, width, numChannels];\n\n  const importVideo =\n      env().getBool('WEBGPU_IMPORT_EXTERNAL_TEXTURE') && isVideo;\n  const isVideoOrImage = isVideo || isImage;\n  if (isImageBitmap || isCanvas || isVideoOrImage) {\n    let resource;\n    if (importVideo) {\n      resource = backend.device.importExternalTexture(\n          {source: pixels as HTMLVideoElement});\n    } else {\n      if (isVideoOrImage) {\n        const newWillReadFrequently =\n            env().getBool('CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU');\n        if (fromPixels2DContext == null ||\n            newWillReadFrequently !== willReadFrequently) {\n          willReadFrequently = newWillReadFrequently;\n          fromPixels2DContext = document.createElement('canvas').getContext(\n              '2d', {willReadFrequently});\n        }\n        fromPixels2DContext.canvas.width = width;\n        fromPixels2DContext.canvas.height = height;\n        fromPixels2DContext.drawImage(\n            pixels as HTMLVideoElement | HTMLImageElement, 0, 0, width, height);\n        pixels = fromPixels2DContext.canvas;\n      }\n\n      const usage = GPUTextureUsage.COPY_DST |\n          GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING;\n      const format = 'rgba8unorm' as GPUTextureFormat;\n      const texture = backend.textureManager.acquireTexture(\n          outputShape[1], outputShape[0], format, usage);\n      backend.queue.copyExternalImageToTexture(\n          {source: pixels as HTMLCanvasElement | ImageBitmap}, {texture},\n          [outputShape[1], outputShape[0]]);\n      resource = texture;\n    }\n\n    const size = util.sizeFromShape(outputShape);\n    const strides = util.computeStrides(outputShape);\n    const program =\n        new FromPixelsProgram(outputShape, numChannels, importVideo);\n\n    const uniformData = [\n      {type: 'uint32', data: [size]}, {type: 'uint32', data: [numChannels]},\n      {type: 'uint32', data: [...strides]}\n    ];\n    const input = backend.makeTensorInfo([height, width], 'int32');\n    const info = backend.tensorMap.get(input.dataId);\n    info.resource = resource;\n\n    const result =\n        backend.runWebGPUProgram(program, [input], 'int32', uniformData);\n    backend.disposeData(input.dataId);\n    return result;\n  }\n\n  // TODO: Encoding should happen on GPU once we no longer have to download\n  // image data to the CPU.\n  const imageData = (pixels as ImageData | backend_util.PixelData).data;\n  let pixelArray = imageData;\n  if (numChannels != null && numChannels !== 4) {\n    pixelArray = new Uint8Array(pixels.width * pixels.height * numChannels);\n\n    const dataLength = imageData.length;\n    let j = 0;\n    for (let i = 0; i < dataLength; i++) {\n      if (i % 4 < numChannels) {\n        pixelArray[j++] = imageData[i];\n      }\n    }\n  }\n\n  const output =\n      backend.makeTensorInfo(outputShape, 'int32', new Int32Array(pixelArray));\n  backend.uploadToGPU(output.dataId);\n  return output;\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class BatchNormProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y?: number[], z?: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[];\n  uniforms = 'varianceEpsilon : f32,';\n  // This is an experimental value.\n  workgroupSize: [number, number, number] = [128, 1, 1];\n  offsetShape: number[]|null;\n  scaleShape: number[]|null;\n  varianceEpsilon: number;\n  size = true;\n\n  constructor(\n      xShape: number[], meanShape: number[], varianceShape: number[],\n      offsetShape: number[]|null, scaleShape: number[]|null) {\n    this.variableNames = ['x', 'mean', 'variance'];\n    backend_util.assertAndGetBroadcastShape(xShape, meanShape);\n    backend_util.assertAndGetBroadcastShape(xShape, varianceShape);\n    this.outputShape = xShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    if (offsetShape != null) {\n      backend_util.assertAndGetBroadcastShape(xShape, offsetShape);\n      this.variableNames.push('offset');\n    }\n    if (scaleShape != null) {\n      backend_util.assertAndGetBroadcastShape(xShape, scaleShape);\n      this.variableNames.push('scale');\n    }\n    this.offsetShape = offsetShape;\n    this.scaleShape = scaleShape;\n    this.shaderKey = 'batchNorm';\n  }\n\n  getUserCode(): string {\n    let offsetSnippet = '0.0';\n    if (this.offsetShape != null) {\n      offsetSnippet = 'getOffsetByOutputIndex(index)';\n    }\n\n    let scaleSnippet = '1.0';\n    if (this.scaleShape != null) {\n      scaleSnippet = 'getScaleByOutputIndex(index)';\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size)\n        {\n          let xValue = getXByOutputIndex(index);\n          let meanValue = getMeanByOutputIndex(index);\n          let varianValue = getVarianceByOutputIndex(index);\n          let offsetValue = ${offsetSnippet};\n          let scaleValue = ${scaleSnippet};\n          let inv = scaleValue * inverseSqrt(varianValue + f32(uniforms.varianceEpsilon));\n          setOutputAtIndex(index,dot(vec3<f32>(xValue, -meanValue, offsetValue), vec3<f32>(inv, inv, 1.0)));\n        }\n      }\n  `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, Tensor} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {BatchNormProgram} from '../batchnorm_webgpu';\n\nexport const fusedBatchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'webgpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x, scale, offset, mean, variance} = inputs as FusedBatchNormInputs;\n    const {varianceEpsilon} = attrs as unknown as FusedBatchNormAttrs;\n    const webGPUBackend = backend as WebGPUBackend;\n    const batchNormInputs = [x as Tensor, mean as Tensor, variance as Tensor];\n    let offsetShape = null;\n    if (offset != null) {\n      offsetShape = offset.shape;\n      batchNormInputs.push(offset as Tensor);\n    }\n    let scaleShape = null;\n    if (scale != null) {\n      scaleShape = scale.shape;\n      batchNormInputs.push(scale as Tensor);\n    }\n    const program = new BatchNormProgram(\n        x.shape, mean.shape, variance.shape, offsetShape, scaleShape);\n    const uniformData = [{type: 'float32', data: [varianceEpsilon]}];\n    return webGPUBackend.runWebGPUProgram(\n        program, batchNormInputs, x.dtype, uniformData);\n  }\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {conv2DImpl} from './Conv2D_impl';\n\nexport function fusedConv2d(args: {\n  inputs: FusedConv2DInputs,\n  attrs: FusedConv2DAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n\n  return conv2DImpl({\n    x,\n    filter,\n    convInfo,\n    backend,\n    bias,\n    preluActivationWeights,\n    leakyreluAlpha,\n    activation\n  });\n}\n\nexport const fusedConv2DConfig: KernelConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'webgpu',\n  kernelFunc: fusedConv2d as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, FusedDepthwiseConv2D, FusedDepthwiseConv2DAttrs, FusedDepthwiseConv2DInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthwiseConv2DVec4Program} from '../depthwise_conv2d_vec4_webgpu';\nimport {DepthwiseConv2DProgram} from '../depthwise_conv2d_webgpu';\n\nexport function fusedDepthwiseConv2D(args: {\n  inputs: FusedDepthwiseConv2DInputs,\n  attrs: FusedDepthwiseConv2DAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {strides, pad, dilations, dimRoundingMode, activation, leakyreluAlpha} =\n      attrs;\n\n  let $dilations = dilations;\n  if ($dilations == null) {\n    $dilations = [1, 1];\n  }\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, $dilations),\n      () => 'Error in depthwiseConv2d: Either strides or dilations must be ' +\n          `1. Got strides ${strides} and dilations '${$dilations}'`);\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, $dilations,\n      pad, dimRoundingMode, true /* depthwise */);\n\n  const programInputs: TensorInfo[] = [x, filter];\n\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n\n  if (hasBias) {\n    programInputs.push(bias);\n  }\n  if (hasPreluActivationWeights) {\n    programInputs.push(preluActivationWeights);\n  }\n\n  const dimensions = [\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]},\n  ];\n\n  let program: DepthwiseConv2DProgram|DepthwiseConv2DVec4Program;\n  if (convInfo.outHeight > 4 && convInfo.outWidth > 4 &&\n      convInfo.strideWidth <= 2 &&\n      convInfo.inChannels === convInfo.outChannels &&\n      convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n      convInfo.inChannels % 4 === 0) {\n    program = new DepthwiseConv2DVec4Program(\n        convInfo, hasBias, activation, hasPreluActivationWeights);\n    dimensions.push({type: 'int32', data: [program.virtualWidth]});\n  } else {\n    program = new DepthwiseConv2DProgram(\n        convInfo, hasBias, activation, hasPreluActivationWeights);\n    dimensions.push(\n        {type: 'int32', data: [convInfo.filterHeight]},\n        {type: 'int32', data: [convInfo.filterWidth]},\n        {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n          type: 'int32',\n          data: [convInfo.dilationHeight, convInfo.dilationWidth]\n        });\n  }\n  if (activation === 'leakyrelu') {\n    dimensions.push({type: 'float32', data: [leakyreluAlpha]});\n    program.uniforms += ' alpha : f32,';\n  }\n  const result =\n      backend.runWebGPUProgram(program, programInputs, 'float32', dimensions);\n\n  return result;\n}\n\nexport const fusedDepthwiseConv2DConfig: KernelConfig = {\n  kernelName: FusedDepthwiseConv2D,\n  backendName: 'webgpu',\n  kernelFunc: fusedDepthwiseConv2D as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class GatherNDProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[] = ['A', 'indices'];\n  uniforms: string;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  sliceDim: number;\n  constructor(sliceDim: number, shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = `gathernd_${sliceDim}`;\n    this.sliceDim = sliceDim;\n    this.uniforms = `sliceDim : i32, strides : ${getCoordsDataType(sliceDim)},`;\n  }\n\n  getUserCode(): string {\n    let strideString;\n    if (this.sliceDim > 1) {\n      strideString = 'uniforms.strides[j]';\n    } else {\n      strideString = 'uniforms.strides';\n    }\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          var flattenIndex = 0;\n          for (var j = 0; j < uniforms.sliceDim; j = j + 1) {\n            let indexTemp = i32(round(getIndices(coords[0], j)));\n            let strideNum = ${strideString};\n            flattenIndex = flattenIndex + indexTemp * strideNum;\n          }\n\n          setOutputAtIndex(index, getA(flattenIndex, coords[1]));\n        }\n      }\n      `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, GatherNd, GatherNdInputs, KernelConfig, KernelFunc, Rank, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {GatherNDProgram} from '../gather_nd_webgpu';\nimport {gatherNdImplCPU} from '../kernel_utils/shared';\n\nimport {reshape} from './Reshape';\n\nexport function gatherNd(\n    args: {inputs: GatherNdInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs, backend} = args;\n  const {params, indices} = inputs;\n\n  const indicesShape = indices.shape;\n  const sliceRank = indicesShape[indicesShape.length - 1];\n  const paramsSize = util.sizeFromShape(params.shape);\n\n  const [resultShape, numSlices, sliceSize, strides] =\n      backend_util.prepareAndValidate(params, indices);\n\n  const flattenIndices = reshape(\n      {inputs: {x: indices}, backend, attrs: {shape: [numSlices, sliceRank]}});\n  const flattenX = reshape({\n    inputs: {x: params},\n    backend,\n    attrs: {shape: [(util.sizeFromShape(params.shape) / sliceSize), sliceSize]}\n  });\n  if (backend.shouldExecuteOnCPU([params, indices]) ||\n      params.dtype === 'string') {\n    const indicesData = backend.readSync(indices.dataId) as TypedArray;\n    const paramsBuf = backend.bufferSync<Rank, 'float32'>(params);\n    const outValue = gatherNdImplCPU(\n        indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize,\n        strides, params.shape, paramsSize);\n\n    return backend.makeTensorInfo(resultShape, params.dtype, outValue.values);\n  }\n  const program = new GatherNDProgram(sliceRank, [numSlices, sliceSize]);\n  const uniformData =\n      [{type: 'int32', data: [sliceRank]}, {type: 'int32', data: strides}];\n  const res = backend.runWebGPUProgram(\n      program, [flattenX, flattenIndices], flattenX.dtype, uniformData);\n\n  const reshaped =\n      reshape({inputs: {x: res}, backend, attrs: {shape: resultShape}});\n\n  backend.disposeData(flattenIndices.dataId);\n  backend.disposeData(flattenX.dataId);\n  backend.disposeData(res.dataId);\n\n  return reshaped;\n}\n\nexport const gatherNdConfig: KernelConfig = {\n  kernelName: GatherNd,\n  backendName: 'webgpu',\n  kernelFunc: gatherNd as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class GatherProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[] = ['A', 'indices'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  aShape: number[];\n  size = true;\n\n  constructor(aShape: number[], outputShape: number[]) {\n    this.outputShape = aShape.slice();\n    this.aShape = aShape;\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = `gather`;\n  }\n\n  getUserCode(): string {\n    const sourceCoords = getSourceCoords(this.aShape);\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let resRC = getCoordsFromIndex(index);\n          let indexZ = i32(getIndices(resRC.x, resRC.z));\n          let inBounds = select(0.0, 1.0, indexZ >= 0 && indexZ < uniforms.aShape[2]);\n          setOutputAtIndex(index, inBounds * getA(${sourceCoords}));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\n// The input and output are always flattened into rank 4 tensors.\nfunction getSourceCoords(aShape: number[]): string {\n  const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n  const sourceCoords = [];\n  for (let i = 0; i < aShape.length; i++) {\n    if (i === 2) {\n      sourceCoords.push('indexZ');\n    } else {\n      sourceCoords.push(`${currentCoords[i]}`);\n    }\n  }\n  return sourceCoords.join();\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, GatherV2, GatherV2Attrs, GatherV2Inputs, KernelConfig, KernelFunc, Rank, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {GatherProgram} from '../gather_webgpu';\nimport {gatherV2ImplCPU} from '../kernel_utils/shared';\n\nimport {reshape} from './Reshape';\n\nexport function gatherV2(\n    args:\n        {inputs: GatherV2Inputs, backend: WebGPUBackend, attrs: GatherV2Attrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, indices} = inputs;\n  const {axis, batchDims} = attrs;\n\n  // Unlike WebGL, WebGPU won't check if index is out of bound by calling\n  // backend.readSync() function in debug mode.\n  const parsedAxis = util.parseAxisParam(axis, x.shape)[0];\n\n  const shapeInfo = backend_util.segment_util.collectGatherOpShapeInfo(\n      x, indices, parsedAxis, batchDims);\n\n  const indicesSize = util.sizeFromShape(indices.shape);\n\n  const toDispose = [];\n\n  const flattenX = reshape({\n    inputs: {x},\n    backend,\n    attrs: {\n      shape: [\n        shapeInfo.batchSize, shapeInfo.outerSize, shapeInfo.dimSize,\n        shapeInfo.sliceSize\n      ]\n    }\n  });\n\n  const flattenIndex = reshape({\n    inputs: {x: indices},\n    backend,\n    attrs: {shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize]}\n  });\n\n  toDispose.push(flattenX);\n  toDispose.push(flattenIndex);\n\n  const flattenOutputShape = [\n    shapeInfo.batchSize, shapeInfo.outerSize, indicesSize / shapeInfo.batchSize,\n    shapeInfo.sliceSize\n  ];\n\n  if (backend.shouldExecuteOnCPU([x, indices])) {\n    const indicesTensorData = backend.tensorMap.get(flattenIndex.dataId);\n    const indicesValues = indicesTensorData.values as TypedArray;\n    const indicesBuffer =\n        buffer(flattenIndex.shape, flattenIndex.dtype, indicesValues) as\n        TensorBuffer<Rank>;\n    const flattenXTensorData = backend.tensorMap.get(flattenX.dataId);\n    const xValues = flattenXTensorData.values as TypedArray;\n    const xBuffer =\n        buffer(flattenX.shape, flattenX.dtype, xValues) as TensorBuffer<Rank>;\n    const outBuf = gatherV2ImplCPU(xBuffer, indicesBuffer, flattenOutputShape);\n\n    toDispose.forEach(t => backend.disposeData(t.dataId));\n\n    return backend.makeTensorInfo(\n        shapeInfo.outputShape, outBuf.dtype, outBuf.values as TypedArray);\n  }\n\n  const program = new GatherProgram(flattenX.shape, flattenOutputShape);\n  const res = backend.runWebGPUProgram(\n      program, [flattenX, flattenIndex], flattenX.dtype);\n  toDispose.push(res);\n\n  const reshaped = reshape(\n      {inputs: {x: res}, backend, attrs: {shape: shapeInfo.outputShape}});\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n  return reshaped;\n}\n\nexport const gatherV2Config: KernelConfig = {\n  kernelName: GatherV2,\n  backendName: 'webgpu',\n  kernelFunc: gatherV2 as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Greater, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {greaterImplCPU as cpuGreater} from '../kernel_utils/shared';\n\nexport const greater = binaryKernelFunc({\n  opType: BinaryOpType.GREATER,\n  cpuKernelImpl: cpuGreater,\n  dtype: 'bool',\n});\n\nexport const greaterConfig: KernelConfig = {\n  kernelName: Greater,\n  backendName: 'webgpu',\n  kernelFunc: greater\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {GreaterEqual, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {greaterEqualImplCPU as cpuGreaterEqual} from '../kernel_utils/shared';\n\nexport const greaterEqual = binaryKernelFunc({\n  opType: BinaryOpType.GREATER_EQUAL,\n  dtype: 'bool',\n  cpuKernelImpl: cpuGreaterEqual\n});\n\nexport const greaterEqualConfig: KernelConfig = {\n  kernelName: GreaterEqual,\n  backendName: 'webgpu',\n  kernelFunc: greaterEqual\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IFFT, IFFTInputs, KernelConfig, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {fftImpl} from './FFT_impl';\n\nexport function ifft(args: {inputs: IFFTInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  return fftImpl(input, true /* inverse */, backend);\n}\n\nexport const ifftConfig: KernelConfig = {\n  kernelName: IFFT,\n  backendName: 'webgpu',\n  kernelFunc: ifft\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsFinite, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const isFinite =\n    unaryKernelFunc({opType: UnaryOpType.IS_FINITE, dtype: 'bool'});\n\nexport const isFiniteConfig: KernelConfig = {\n  kernelName: IsFinite,\n  backendName: 'webgpu',\n  kernelFunc: isFinite\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsInf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const isInf =\n    unaryKernelFunc({opType: UnaryOpType.IS_INF, dtype: 'bool'});\n\nexport const isInfConfig: KernelConfig = {\n  kernelName: IsInf,\n  backendName: 'webgpu',\n  kernelFunc: isInf\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsNan, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const isNaN =\n    unaryKernelFunc({opType: UnaryOpType.IS_NAN, dtype: 'bool'});\n\nexport const isNaNConfig: KernelConfig = {\n  kernelName: IsNan,\n  backendName: 'webgpu',\n  kernelFunc: isNaN\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LeakyRelu, LeakyReluAttrs, LeakyReluInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\nexport function leakyRelu(args: {\n  inputs: LeakyReluInputs,\n  backend: WebGPUBackend,\n  attrs: LeakyReluAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {alpha} = attrs;\n  const uniformData = [{type: 'float32', data: [alpha]}];\n  const program =\n      new UnaryOpProgram(x.shape, UnaryOpType.LEAKYRELU, 'alpha : f32,');\n  return backend.runWebGPUProgram(program, [x], 'float32', uniformData);\n}\n\nexport const leakyReluConfig: KernelConfig = {\n  kernelName: LeakyRelu,\n  backendName: 'webgpu',\n  kernelFunc: leakyRelu as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Less} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {lessImplCPU as cpuLess} from '../kernel_utils/shared';\n\nexport const less = binaryKernelFunc(\n    {opType: BinaryOpType.LESS, dtype: 'bool', cpuKernelImpl: cpuLess});\n\nexport const lessConfig: KernelConfig = {\n  kernelName: Less,\n  backendName: 'webgpu',\n  kernelFunc: less\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LessEqual} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {lessEqualImplCPU as cpuLessEqual} from '../kernel_utils/shared';\n\nexport const lessEqual = binaryKernelFunc({\n  opType: BinaryOpType.LESS_EQUAL,\n  dtype: 'bool',\n  cpuKernelImpl: cpuLessEqual\n});\n\nexport const lessEqualConfig: KernelConfig = {\n  kernelName: LessEqual,\n  backendName: 'webgpu',\n  kernelFunc: lessEqual\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class LinSpaceProgram implements WebGPUProgram {\n  variableNames: string[] = [];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'start : f32, step : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shape: number) {\n    this.outputShape = [shape];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'linSpace';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          setOutputAtIndex(index, uniforms.start + f32(index) * uniforms.step);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LinSpace, LinSpaceAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {LinSpaceProgram} from '../lin_space_webgpu';\n\nexport function linSpace(args: {backend: WebGPUBackend, attrs: LinSpaceAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {start, stop, num} = attrs;\n  const step = (stop - start) / (num - 1);\n\n  const program = new LinSpaceProgram(num);\n  const uniformData =\n      [{type: 'float32', data: [start]}, {type: 'float32', data: [step]}];\n  return backend.runWebGPUProgram(program, [], 'float32', uniformData);\n}\n\nexport const linSpaceConfig: KernelConfig = {\n  kernelName: LinSpace,\n  backendName: 'webgpu',\n  kernelFunc: linSpace as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {logImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const log =\n    unaryKernelFunc({opType: UnaryOpType.LOG, cpuKernelImpl: logImplCPU});\n\nexport const logConfig: KernelConfig = {\n  kernelName: Log,\n  backendName: 'webgpu',\n  kernelFunc: log\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log1p} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const log1p = unaryKernelFunc({opType: UnaryOpType.LOG1P});\n\nexport const log1pConfig: KernelConfig = {\n  kernelName: Log1p,\n  backendName: 'webgpu',\n  kernelFunc: log1p\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalAnd} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const logicalAnd =\n    binaryKernelFunc({opType: BinaryOpType.LOGICAL_AND, dtype: 'bool'});\n\nexport const logicalAndConfig: KernelConfig = {\n  kernelName: LogicalAnd,\n  backendName: 'webgpu',\n  kernelFunc: logicalAnd\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalNot} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const logicalNot = unaryKernelFunc({opType: UnaryOpType.LOGICAL_NOT});\n\nexport const logicalNotConfig: KernelConfig = {\n  kernelName: LogicalNot,\n  backendName: 'webgpu',\n  kernelFunc: logicalNot\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalOr} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const logicalOr = binaryKernelFunc({opType: BinaryOpType.LOGICAL_OR});\n\nexport const logicalOrConfig: KernelConfig = {\n  kernelName: LogicalOr,\n  backendName: 'webgpu',\n  kernelFunc: logicalOr\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nconst powOperatorSnippet = `\n  var powValue = 0.0;\n  let basis = uniforms.bias + uniforms.alpha * sum;\n  if (uniforms.beta == 0.5) {\n    powValue = inverseSqrt(basis);\n  } else if (uniforms.beta == 1.0) {\n    powValue = 1.0 / basis;\n  } else {\n    powValue = exp(log(basis) * (-uniforms.beta));\n  }\n`;\n\nexport class LRNProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'radius : i32, bias : f32, alpha : f32, beta : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(xShape: number[]) {\n    this.outputShape = xShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = 'lrn';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getOutputCoords();\n        let b = coords[0];\n        let r = coords[1];\n        let c = coords[2];\n        let d = coords[3];\n\n        let x = getX(b, r, c, d);\n        var sum = 0.0;\n        for (var i = -uniforms.radius; i <= uniforms.radius; i = i + 1) {\n          let idx = d + i;\n          if (idx >= 0 && idx < uniforms.xShape[3]) {\n            let z = getX(b, r, c, idx);\n            sum = sum + z * z;\n          }\n        }\n        ${powOperatorSnippet}\n\n        setOutputAtIndex(index, x * powValue);\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n\nexport class LRNSharedProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'radius : i32, bias : f32, alpha : f32, beta : f32,';\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  maxAllowRadius = 16;\n  elementsPerWorkgroup: number;\n\n  constructor(xShape: number[], radius: number) {\n    util.assert(\n        radius <= this.maxAllowRadius,\n        () => `Radius must be less than or equal to ${\n            this.maxAllowRadius}, current radius is ${radius}`);\n\n    this.outputShape = xShape;\n    // The reason why not using this.workgroupSize[0] + 2 * maxAllowRadius here\n    // is to make sure that there is only one time global memory load access for\n    // each thread.\n    this.elementsPerWorkgroup = this.workgroupSize[0] - 2 * this.maxAllowRadius;\n    this.dispatchLayout = {x: [3], y: [2], z: [0, 1]};\n    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, [\n      this.elementsPerWorkgroup, this.workgroupSize[1], this.workgroupSize[2]\n    ]);\n    this.shaderKey = 'lrn_shared';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    var <workgroup>lrnSub: array<f32, ${this.workgroupSize[0]}>;\n    const elementsPerWorkgroup = ${this.elementsPerWorkgroup};\n    const maxAllowRadius = ${this.maxAllowRadius};\n\n    ${main()} {\n      let localDepth = i32(localId.x);\n      let workgroupDepth = i32(workgroupId.x) * elementsPerWorkgroup;\n      let xDepth = workgroupDepth + localDepth - maxAllowRadius;\n      let b = i32(globalId.z) / uniforms.xShape[1];\n      let r = i32(globalId.z) - b * uniforms.xShape[1];\n      let c = i32(globalId.y);\n      let d = workgroupDepth + localDepth;\n\n      var x = 0.0;\n      if (xDepth >= 0 && xDepth < uniforms.xShape[3]) {\n        x = getX(b, r, c, xDepth);\n      }\n      lrnSub[localDepth] = x;\n      workgroupBarrier();\n\n      if (localDepth < elementsPerWorkgroup && d < uniforms.outShape[3]) {\n        var sum = 0.0;\n        let index = localDepth + maxAllowRadius;\n        for (var i = -uniforms.radius; i <= uniforms.radius; i = i + 1) {\n          let z = lrnSub[index + i];\n          sum = sum + z * z;\n        }\n        ${powOperatorSnippet}\n\n        setOutputAtCoords(b, r, c, d, lrnSub[index] * powValue);\n      }\n    } `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRN, LRNAttrs, LRNInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {LRNProgram, LRNSharedProgram} from '../lrn_webgpu';\n\nexport function lrn(\n    args: {inputs: LRNInputs, backend: WebGPUBackend, attrs: LRNAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  // When the adjacent channels is less than or equal to 16, which could cover\n  // most cases, we use shared memory version to get better performance.\n  // The theoretical adjacent channels may be very large, but the shared memory\n  // size of hardware is limited, so we use the naive version when the adjacent\n  // channels is large.\n  let program: LRNProgram|LRNSharedProgram;\n  if (depthRadius > 16) {\n    program = new LRNProgram(x.shape);\n  } else {\n    program = new LRNSharedProgram(x.shape, depthRadius);\n  }\n  const uniformData = [\n    {type: 'int32', data: [depthRadius]}, {type: 'float32', data: [bias]},\n    {type: 'float32', data: [alpha]}, {type: 'float32', data: [beta]}\n  ];\n  const res = backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n\n  return res;\n}\n\nexport const lrnConfig: KernelConfig = {\n  kernelName: LRN,\n  backendName: 'webgpu',\n  kernelFunc: lrn as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class LRNGradProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['inputImage', 'outputImage', 'dy'];\n  uniforms = 'depthRadius : i32, bias : f32, alpha : f32, beta : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(inputShape: number[]) {\n    this.outputShape = inputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = 'lrn_grad';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getOutputCoords();\n        let b = coords[0];\n        let r = coords[1];\n        let c = coords[2];\n\n        let MIN_DEPTH_BEGIN = 0;\n        let MAX_DEPTH_END = uniforms.outShape[3];\n        var result = 0.0;\n        for (var d = MIN_DEPTH_BEGIN; d < MAX_DEPTH_END; d++) {\n          let depthBegin = max(MIN_DEPTH_BEGIN, d - uniforms.depthRadius);\n          let depthEnd = min(MAX_DEPTH_END, d + uniforms.depthRadius + 1);\n\n          var norm = 0.0;\n          for (var k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; k++) {\n            if (k < depthBegin) {\n              continue;\n            } else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            } else {\n              break;\n            }\n          }\n\n          norm = uniforms.alpha * norm + uniforms.bias;\n\n          for (var k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; k++) {\n            if (k < depthBegin) {\n              continue;\n            } else if (k >= depthBegin && k < depthEnd) {\n              var dyi = -2.0 * uniforms.alpha * uniforms.beta\n                * getInputImage(b, r, c, k) * getOutputImage(b, r, c, d) / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * uniforms.beta);\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            } else {\n              break;\n            }\n          }\n        }\n\n        setOutputAtIndex(index, result);\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRNGrad, LRNGradAttrs, LRNGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {LRNGradProgram} from '../lrn_grad_webgpu';\n\nexport function lrnGrad(\n    args: {inputs: LRNGradInputs, backend: WebGPUBackend, attrs: LRNGradAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, y, dy} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  const program = new LRNGradProgram(x.shape);\n  const uniformData = [\n    {type: 'int32', data: [depthRadius]}, {type: 'float32', data: [bias]},\n    {type: 'float32', data: [alpha]}, {type: 'float32', data: [beta]}\n  ];\n  const res =\n      backend.runWebGPUProgram(program, [x, y, dy], x.dtype, uniformData);\n\n  return res;\n}\n\nexport const lrnGradConfig: KernelConfig = {\n  kernelName: LRNGrad,\n  backendName: 'webgpu',\n  kernelFunc: lrnGrad as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Maximum} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {maximumImplCPU as cpuMaximum} from '../kernel_utils/shared';\n\nexport const maximum = binaryKernelFunc({\n  opType: BinaryOpType.MAX,\n  cpuKernelImpl: cpuMaximum,\n});\n\nexport const maximumConfig: KernelConfig = {\n  kernelName: Maximum,\n  backendName: 'webgpu',\n  kernelFunc: maximum\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, KernelConfig, KernelFunc, MaxPool, MaxPoolAttrs, MaxPoolInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {poolImpl} from './Pool_impl';\n\nexport function maxPool(\n    args: {inputs: MaxPoolInputs, backend: WebGPUBackend, attrs: MaxPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n\n  return poolImpl(x, convInfo, 'max', backend);\n}\n\nexport const maxPoolConfig: KernelConfig = {\n  kernelName: MaxPool,\n  backendName: 'webgpu',\n  kernelFunc: maxPool as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, KernelConfig, KernelFunc, MaxPool3D, MaxPool3DAttrs, MaxPool3DInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Pool3DProgram} from '../pool_webgpu';\n\nexport function maxPool3d(args: {\n  inputs: MaxPool3DInputs,\n  backend: WebGPUBackend,\n  attrs: MaxPool3DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dataFormat, dimRoundingMode} = attrs;\n  const dilations: [number, number, number] = [1, 1, 1];\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode, dataFormat);\n  const maxPoolProgram = new Pool3DProgram(convInfo, 'max');\n  const dimensions = [\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data:\n          [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]\n    },\n    {\n      type: 'int32',\n      data: [convInfo.inDepth, convInfo.inHeight, convInfo.inWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth, convInfo.effectiveFilterHeight,\n        convInfo.effectiveFilterWidth\n      ]\n    }\n  ];\n  return backend.runWebGPUProgram(maxPoolProgram, [x], x.dtype, dimensions);\n}\n\nexport const maxPool3DConfig: KernelConfig = {\n  kernelName: MaxPool3D,\n  backendName: 'webgpu',\n  kernelFunc: maxPool3d as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class MaxPool2DBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy', 'maxPos'];\n  uniforms =\n      `strides : vec2<i32>, pads : vec2<i32>, dilations : vec2<i32>, filterDims : vec2<i32>,\n       outHeight : i32, outWidth : i32`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'maxPool2DBackprop';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords[0];\n        let d = coords[3];\n\n        let dyRCCorner = vec2<i32>(coords.yz) - uniforms.pads;\n        let dyRCorner = dyRCCorner.x;\n        let dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        let lastIndex = uniforms.filterDims[0] * uniforms.filterDims[1] - 1;\n        for (var wR = 0; wR < uniforms.filterDims[0]; wR += uniforms.dilations[0]) {\n          let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[0]);\n\n          if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n            continue;\n          }\n          let idyR = i32(dyR);\n\n          for (var wC = 0; wC < uniforms.filterDims[1]; wC += uniforms.dilations[1]) {\n            let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[1]);\n\n            if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n              continue;\n            }\n            let idyC = i32(dyC);\n\n            let dyValue = getDy(batch, idyR, idyC, d);\n            let maxPosValue = lastIndex - i32(getMaxPos(batch, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            let curPosValue = wR * uniforms.filterDims[1] + wC;\n            let mask = select(0.0, 1.0, maxPosValue == curPosValue);\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n\nexport class MaxPool3DBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy', 'maxPos'];\n  uniforms = `strides : vec3<i32>, pads : vec3<i32>, filterDims : vec3<i32>,\n      outDepth : i32, outHeight : i32, outWidth : i32`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv3DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'maxPool3DBackprop';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords.x;\n        let ch = coords.u;\n\n        let dyCorner = vec3<i32>(coords.y, coords.z, coords.w) - uniforms.pads;\n        let dyDCorner = dyCorner.x;\n        let dyRCorner = dyCorner.y;\n        let dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        let lastIndex = uniforms.filterDims[0] * uniforms.filterDims[1] * uniforms.filterDims[2] - 1;\n\n        for (var wD = 0; wD < uniforms.filterDims[0]; wD++) {\n          let dyD = f32(dyDCorner + wD) / f32(uniforms.strides[0]);\n\n          if (dyD < 0.0 || dyD >= f32(uniforms.outDepth) || fract(dyD) > 0.0) {\n            continue;\n          }\n          let idyD = i32(dyD);\n\n          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {\n            let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[1]);\n\n            if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n              continue;\n            }\n            let idyR = i32(dyR);\n\n            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {\n              let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[2]);\n\n              if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n                continue;\n              }\n              let idyC = i32(dyC);\n\n              let dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              let maxPosValue = lastIndex - i32(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              let curPosValue = wD * uniforms.filterDims[1] * uniforms.filterDims[2] + wR * uniforms.filterDims[2] + wC;\n              let mask = select(0.0, 1.0, maxPosValue == curPosValue);\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPool3DGrad, MaxPool3DGradAttrs, MaxPool3DGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {MaxPool3DBackpropProgram} from '../max_pool_backprop_webgpu';\nimport {Pool3DProgram} from '../pool_webgpu';\n\nexport function maxPool3DGrad(args: {\n  inputs: MaxPool3DGradInputs,\n  backend: WebGPUBackend,\n  attrs: MaxPool3DGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations: [number, number, number] = [1, 1, 1];\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n\n  const maxPool3dPositionsProgram =\n      new Pool3DProgram(convInfo, 'max', true /* get positions */);\n  let uniformData = [\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data:\n          [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]\n    },\n    {\n      type: 'int32',\n      data: [convInfo.inDepth, convInfo.inHeight, convInfo.inWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth, convInfo.effectiveFilterHeight,\n        convInfo.effectiveFilterWidth\n      ]\n    }\n  ];\n  const maxPool3dPositions = backend.runWebGPUProgram(\n      maxPool3dPositionsProgram, [x], 'int32', uniformData);\n\n  const maxPool3dBackpropProgram = new MaxPool3DBackpropProgram(convInfo);\n  uniformData = [\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth - 1 - convInfo.padInfo.front,\n        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,\n        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth, convInfo.effectiveFilterHeight,\n        convInfo.effectiveFilterWidth\n      ]\n    },\n    {type: 'int32', data: [convInfo.outDepth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]}\n  ];\n  const result = backend.runWebGPUProgram(\n      maxPool3dBackpropProgram, [dy, maxPool3dPositions], x.dtype, uniformData);\n  backend.disposeData(maxPool3dPositions.dataId);\n\n  return result;\n}\n\nexport const maxPool3DGradConfig: KernelConfig = {\n  kernelName: MaxPool3DGrad,\n  backendName: 'webgpu',\n  kernelFunc: maxPool3DGrad as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPoolGrad, MaxPoolGradAttrs, MaxPoolGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {MaxPool2DBackpropProgram} from '../max_pool_backprop_webgpu';\nimport {Pool2DProgram} from '../pool_webgpu';\nimport {assertNotComplex} from '../webgpu_util';\n\nexport function maxPoolGrad(args: {\n  inputs: MaxPoolGradInputs,\n  backend: WebGPUBackend,\n  attrs: MaxPoolGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input, output} = inputs;\n  const x = input;\n  assertNotComplex([input, output], 'maxPoolGrad');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode);\n\n  const maxPoolPositionsProgram = new Pool2DProgram(convInfo, 'max', true);\n  let uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]},\n    {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]}, {\n      type: 'int32',\n      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]\n    }\n  ];\n  const maxPoolPositions = backend.runWebGPUProgram(\n      maxPoolPositionsProgram, [x], 'int32', uniformData);\n\n  const maxPoolBackpropProgram = new MaxPool2DBackpropProgram(convInfo);\n  uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,\n        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]}, {\n      type: 'int32',\n      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]\n    },\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]}\n  ];\n  const result = backend.runWebGPUProgram(\n      maxPoolBackpropProgram, [dy, maxPoolPositions], x.dtype, uniformData);\n  backend.disposeData(maxPoolPositions.dataId);\n\n  return result;\n}\n\nexport const maxPoolGradConfig: KernelConfig = {\n  kernelName: MaxPoolGrad,\n  backendName: 'webgpu',\n  kernelFunc: maxPoolGrad as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Pool2DProgram} from '../pool_webgpu';\n\nexport function maxPoolWithArgmax(args: {\n  inputs: MaxPoolWithArgmaxInputs,\n  attrs: MaxPoolWithArgmaxAttrs,\n  backend: WebGPUBackend\n}): TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {filterSize, strides, pad, includeBatchInIndex} = attrs;\n  const {x} = inputs;\n\n  util.assert(\n      x.shape.length === 4,\n      () => `Error in maxPool: input must be rank 4 but got rank ${\n          x.shape.length}.`);\n  const dilations: [number, number] = [1, 1];\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad);\n\n  const uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]},\n    {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]}, {\n      type: 'int32',\n      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]\n    }\n  ];\n  let program = new Pool2DProgram(convInfo, 'max', false);\n  const poolOutput =\n      backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n\n  program = new Pool2DProgram(convInfo, 'max', true, true, includeBatchInIndex);\n  const indexOutput =\n      backend.runWebGPUProgram(program, [x], 'int32', uniformData);\n  return [poolOutput, indexOutput];\n}\n\nexport const maxPoolWithArgmaxConfig: KernelConfig = {\n  kernelName: MaxPoolWithArgmax,\n  backendName: 'webgpu',\n  kernelFunc: maxPoolWithArgmax as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Min, MinAttrs, MinInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function min(\n    args: {inputs: MinInputs, backend: WebGPUBackend, attrs: MinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  return reduce(x, axis, keepDims, 'min', backend);\n}\n\nexport const minConfig: KernelConfig = {\n  kernelName: Min,\n  backendName: 'webgpu',\n  kernelFunc: min as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Minimum} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {minimumImplCPU as cpuMinimum} from '../kernel_utils/shared';\n\nexport const minimum = binaryKernelFunc({\n  opType: BinaryOpType.MIN,\n  cpuKernelImpl: cpuMinimum,\n});\n\nexport const minimumConfig: KernelConfig = {\n  kernelName: Minimum,\n  backendName: 'webgpu',\n  kernelFunc: minimum\n};\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class MirrorPadProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  uniforms = '';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  xShape: number[];\n  offset: number;\n  size = true;\n\n  constructor(\n      xShape: number[], paddings: Array<[number, number]>,\n      mode: 'reflect'|'symmetric') {\n    this.outputShape = paddings.map(\n        (p, i) => p[0] /* beforePad */ + xShape[i] + p[1] /* afterPad */);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.xShape = xShape;\n    paddings.map((_, i) => {\n      this.uniforms += ` pad${i} : vec2<i32>,`;\n    });\n    this.offset = mode === 'reflect' ? 0 : 1;\n    this.shaderKey = `mirrorPad_${mode}`;\n  }\n\n  getUserCode(): string {\n    const rank = this.xShape.length;\n    // The length of paddings are same with the rank of the input tensor.\n    const start = this.xShape.map((_, i) => `uniforms.pad${i}[0]`).join(',');\n    const end = this.xShape\n                    .map(\n                        (_, i) => `uniforms.pad${i}[0] + uniforms.xShape${\n                            rank > 1 ? `[${i}]` : ''}`)\n                    .join(',');\n\n    const shaderStart = rank === 1 ? 'start' : 'start[i]';\n    const shaderEnd = rank === 1 ? 'end' : 'end[i]';\n    const shaderOutC = rank === 1 ? 'outC' : 'outC[i]';\n    const dtype = getCoordsDataType(rank);\n    const unpackedCoords = rank > 1 ?\n        ['coords[0]', 'coords[1]', 'coords[2]', 'coords[3]'].slice(0, rank) :\n        'coords';\n\n    return `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let start = ${dtype}(${start});\n          let end = ${dtype}(${end});\n          var outC = getCoordsFromIndex(index);\n          for (var i = 0; i < ${rank}; i = i + 1) {\n            if (${shaderOutC} < ${shaderStart}) {\n              ${shaderOutC} = ${shaderStart} * 2 - ${shaderOutC} - ${\n        this.offset};\n            } else if(${shaderOutC} >= ${shaderEnd}) {\n              ${shaderOutC} = (${shaderEnd} - 1) * 2 - ${shaderOutC} + ${\n        this.offset};\n            }\n          }\n          let coords = outC - start;\n          setOutputAtIndex(index, getX(${unpackedCoords}));\n        }\n      }\n    `;\n  }\n}\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, MirrorPad, MirrorPadAttrs, MirrorPadInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {MirrorPadProgram} from '../mirror_pad_webgpu';\n\nexport const mirrorPadConfig: KernelConfig = {\n  kernelName: MirrorPad,\n  backendName: 'webgpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MirrorPadInputs;\n    const {paddings, mode} = attrs as unknown as MirrorPadAttrs;\n    const webGPUBackend = backend as WebGPUBackend;\n\n    const uniformData = paddings.map(p => {\n      return {type: 'int32', data: [p[0], p[1]]};\n    });\n    const program = new MirrorPadProgram(x.shape, paddings, mode);\n    const output =\n        webGPUBackend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n\n    return output;\n  }\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Mod} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const mod = binaryKernelFunc({opType: BinaryOpType.MOD});\n\nexport const modConfig: KernelConfig = {\n  kernelName: Mod,\n  backendName: 'webgpu',\n  kernelFunc: mod\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class MultinomialProgram implements WebGPUProgram {\n  variableNames: string[] = ['probs'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'seed : f32, numOutcomes: i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(batchSize: number, numSamples: number) {\n    this.outputShape = [batchSize, numSamples];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'multinomial';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    fn random (seed : f32, resultUV : vec2<f32>) -> f32 {\n      let HASHSCALE1 = 443.8975;\n      let p = resultUV * seed;\n      var p3  = fract(vec3<f32>(p.xyx) * HASHSCALE1);\n      p3 = p3 + dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getOutputCoords();\n        let batch = coords[0];\n\n        let resUV = vec2<f32>(f32(coords[1]) / f32(uniforms.outShape[1]),\n            f32(coords[0]) / f32(uniforms.outShape[0]));\n        let r = random(uniforms.seed, resUV);\n        var cdf = 0.0;\n        for (var i = 0; i < uniforms.numOutcomes - 1; i = i + 1) {\n          cdf = cdf + getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutputAtIndexI32(index, i);\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutputAtIndexI32(index, uniforms.numOutcomes - 1);\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {flatDispatchLayout} from './webgpu_util';\n\nexport class SoftmaxProgram implements WebGPUProgram {\n  variableNames = ['logits'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number];\n\n  constructor(outputShape: number[]) {\n    this.outputShape = outputShape;  // [rows, cols]\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = [this.outputShape[0], 1, 1];\n    if (this.outputShape[1] >= 4096) {\n      this.workgroupSize = [256, 1, 1];\n    } else {\n      this.workgroupSize = [64, 1, 1];\n    }\n    this.shaderKey = 'softmax';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    var<workgroup> buf : array<f32, ${this.workgroupSize[0]}>;\n    var<workgroup> rowMaxShared : f32;\n    var<workgroup> rowSumShared : f32;\n    const blockSize = ${this.workgroupSize[0]};\n    ${main('index')} {\n      let row = index / blockSize;\n      let tid = i32(localId.x);\n      let cols = uniforms.outShape[1];\n\n      var threadMax = -3.402823e+38f;\n      for (var col = tid; col < cols; col += blockSize) {\n        let value = getLogits(row, col);\n        threadMax = max(threadMax, value);\n      }\n      if (tid < cols) {\n        buf[tid] = threadMax;\n      }\n      workgroupBarrier();\n\n      var reduceSize = min(cols, blockSize);\n      for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n        reduceSize = currSize + (reduceSize & 1);\n        if (tid < currSize) {\n          buf[tid] = max(buf[tid], buf[tid + reduceSize]);\n        }\n        workgroupBarrier();\n      }\n\n      if (tid == 0) {\n        rowMaxShared = buf[0];\n      }\n      workgroupBarrier();\n\n      var threadSum = 0.0;\n      for (var col = tid; col < cols; col += blockSize) {\n        let subExp = exp(getLogits(row, col) - rowMaxShared);\n        threadSum += subExp;\n      }\n      buf[tid] = threadSum;\n      workgroupBarrier();\n\n      for (var currSize = blockSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n        if (tid < currSize) {\n          buf[tid] = buf[tid] + buf[tid + currSize];\n        }\n        workgroupBarrier();\n      }\n\n      if (tid == 0) {\n        rowSumShared = buf[0];\n      }\n      workgroupBarrier();\n\n      for (var col = tid; col < cols; col += blockSize) {\n        let value = exp(getLogits(row, col) - rowMaxShared) / rowSumShared;\n        setOutputAtCoords(row, col, value);\n      }\n  }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Softmax, SoftmaxAttrs, SoftmaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {SoftmaxProgram} from '../softmax_webgpu';\n\nimport {reshape} from './Reshape';\n\nexport function softmax(\n    args: {inputs: SoftmaxInputs, backend: WebGPUBackend, attrs: SoftmaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {dim} = attrs;\n\n  const logitsReshaped = reshape({\n    inputs: {x: logits},\n    backend,\n    attrs: {\n      shape: [\n        util.sizeFromShape(logits.shape) / logits.shape[dim], logits.shape[dim]\n      ]\n    }\n  });\n  const program = new SoftmaxProgram(logitsReshaped.shape);\n  const res = backend.runWebGPUProgram(program, [logitsReshaped], logits.dtype);\n  const resReshaped =\n      reshape({inputs: {x: res}, backend, attrs: {shape: logits.shape}});\n  backend.disposeData(logitsReshaped.dataId);\n  backend.disposeData(res.dataId);\n  return resReshaped;\n}\n\nexport const softmaxConfig: KernelConfig = {\n  kernelName: Softmax,\n  backendName: 'webgpu',\n  kernelFunc: softmax as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Multinomial, MultinomialAttrs, MultinomialInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {MultinomialProgram} from '../multinomial_webgpu';\n\nimport {softmax} from './Softmax';\n\nexport function multinomial(args: {\n  inputs: MultinomialInputs,\n  backend: WebGPUBackend,\n  attrs: MultinomialAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {numSamples, seed, normalized} = attrs;\n\n  const probs = normalized ?\n      logits :\n      softmax(\n          {inputs: {logits}, backend, attrs: {dim: logits.shape.length - 1}});\n  const batchSize = probs.shape[0];\n  const numOutcomes = probs.shape[1];\n  const program = new MultinomialProgram(batchSize, numSamples);\n  const uniformData =\n      [{type: 'float32', data: [seed]}, {type: 'int32', data: [numOutcomes]}];\n  const res = backend.runWebGPUProgram(program, [probs], 'int32', uniformData);\n  if (!normalized) {\n    backend.disposeData(probs.dataId);\n  }\n  return res;\n}\n\nexport const multinomialConfig: KernelConfig = {\n  kernelName: Multinomial,\n  backendName: 'webgpu',\n  kernelFunc: multinomial as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Neg, NegInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {negImplCPU} from '../kernel_utils/shared';\n\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\n// This doesn't use unaryKernelFunc because negImplCPU is not of type\n// SimpleUnaryKernelImplCPU.\nexport function neg(args: {inputs: NegInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (backend.shouldExecuteOnCPU([x])) {\n    const xData = backend.tensorMap.get(x.dataId);\n    const [outValues, newShape] =\n        negImplCPU(xData.values as TypedArray, x.shape, x.dtype);\n    return backend.makeTensorInfo(newShape, x.dtype, outValues);\n  }\n\n  const program = new UnaryOpProgram(x.shape, UnaryOpType.NEG);\n\n  return backend.runWebGPUProgram(program, [x], x.dtype);\n}\n\nexport const negConfig: KernelConfig = {\n  kernelName: Neg,\n  backendName: 'webgpu',\n  kernelFunc: neg as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV3, NonMaxSuppressionV3Attrs, NonMaxSuppressionV3Inputs, TypedArray} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nexport function nonMaxSuppressionV3(args: {\n  inputs: NonMaxSuppressionV3Inputs,\n  backend: WebGPUBackend,\n  attrs: NonMaxSuppressionV3Attrs\n}) {\n  console.warn(\n      'tf.nonMaxSuppression() in webgpu locks the UI thread. ' +\n      'Call tf.nonMaxSuppressionAsync() instead');\n\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold} = attrs;\n\n  const boxesVals = backend.readSync(boxes.dataId) as TypedArray;\n  const scoresVals = backend.readSync(scores.dataId) as TypedArray;\n\n  const {selectedIndices} = kernel_impls.nonMaxSuppressionV3Impl(\n      boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n\n  return backend.makeTensorInfo(\n      [selectedIndices.length], 'int32', new Int32Array(selectedIndices));\n}\n\nexport const nonMaxSuppressionV3Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV3,\n  backendName: 'webgpu',\n  kernelFunc: nonMaxSuppressionV3 as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nexport type TypedArray = Float32Array|Int32Array|Uint8Array;\n\nexport function nonMaxSuppressionV5(args: {\n  inputs: NonMaxSuppressionV5Inputs,\n  backend: WebGPUBackend,\n  attrs: NonMaxSuppressionV5Attrs\n}): [TensorInfo, TensorInfo] {\n  console.warn(\n      'tf.nonMaxSuppression() in webgpu locks the UI thread. ' +\n      'Call tf.nonMaxSuppressionAsync() instead');\n\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma} = attrs;\n\n  const boxesVals = backend.readSync(boxes.dataId) as TypedArray;\n  const scoresVals = backend.readSync(scores.dataId) as TypedArray;\n\n  const maxOutputSizeVal = maxOutputSize;\n  const iouThresholdVal = iouThreshold;\n  const scoreThresholdVal = scoreThreshold;\n  const softNmsSigmaVal = softNmsSigma;\n\n  const {selectedIndices, selectedScores} =\n      kernel_impls.nonMaxSuppressionV5Impl(\n          boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal,\n          scoreThresholdVal, softNmsSigmaVal);\n\n  return [\n    backend.makeTensorInfo(\n        [selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n    backend.makeTensorInfo(\n        [selectedScores.length], 'float32', new Float32Array(selectedScores))\n  ];\n}\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'webgpu',\n  kernelFunc: nonMaxSuppressionV5 as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class OneHotProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'onValue : f32, offValue : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(numIndices: number, depth: number) {\n    this.outputShape = [numIndices, depth];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = 'onehot';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          setOutputAtIndex(index, mix(uniforms.offValue, uniforms.onValue,\n                                      f32(i32(round(getX(coords.x))) == coords.y)));\n        }\n      }\n    `;\n\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OneHot, OneHotAttrs, OneHotInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {OneHotProgram} from '../onehot_webgpu';\nimport {reshape} from './Reshape';\n\nexport function oneHot(\n    args: {inputs: OneHotInputs, backend: WebGPUBackend, attrs: OneHotAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {indices} = inputs;\n  const {dtype, depth, onValue, offValue} = attrs;\n\n  const indicesSize = util.sizeFromShape(indices.shape);\n  const program = new OneHotProgram(indicesSize, depth);\n  const reshaped =\n      reshape({inputs: {x: indices}, backend, attrs: {shape: [indicesSize]}});\n\n  const uniformData =\n      [{type: 'float32', data: [onValue]}, {type: 'float32', data: [offValue]}];\n  const result =\n      backend.runWebGPUProgram(program, [reshaped], dtype, uniformData);\n  backend.disposeData(reshaped.dataId);\n\n  const outShape = [...indices.shape, depth];\n  const out = reshape({inputs: {x: result}, backend, attrs: {shape: outShape}});\n  backend.disposeData(result.dataId);\n\n  return out;\n}\n\nexport const oneHotConfig: KernelConfig = {\n  kernelName: OneHot,\n  backendName: 'webgpu',\n  kernelFunc: oneHot as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, ZerosLike, ZerosLikeInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\n\nexport function zerosLike(\n    args: {inputs: ZerosLikeInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = zerosLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeData(realPart.dataId);\n    backend.disposeData(r.dataId);\n    backend.disposeData(imagPart.dataId);\n    backend.disposeData(i.dataId);\n\n    return result;\n  } else {\n    return fill({\n      attrs: {\n        shape: x.shape,\n        dtype: x.dtype,\n        value: x.dtype === 'string' ? '' : 0\n      },\n      backend\n    });\n  }\n}\n\nexport const zerosLikeConfig: KernelConfig = {\n  kernelName: ZerosLike,\n  backendName: 'webgpu',\n  kernelFunc: zerosLike as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OnesLike, OnesLikeInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {zerosLike} from './ZerosLike';\n\nexport function onesLike(\n    args: {inputs: OnesLikeInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (x.dtype === 'string') {\n    throw new Error('onesLike is not supported under string dtype');\n  } else if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = onesLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeData(realPart.dataId);\n    backend.disposeData(r.dataId);\n    backend.disposeData(imagPart.dataId);\n    backend.disposeData(i.dataId);\n\n    return result;\n  } else {\n    return fill({attrs: {shape: x.shape, dtype: x.dtype, value: 1}, backend});\n  }\n}\n\nexport const onesLikeConfig: KernelConfig = {\n  kernelName: OnesLike,\n  backendName: 'webgpu',\n  kernelFunc: onesLike as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Pack, PackAttrs, PackInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {concat} from './Concat';\nimport {expandDims} from './ExpandDims';\n\nexport function pack(\n    args: {inputs: PackInputs, backend: WebGPUBackend, attrs: PackAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  if (inputs.length === 1) {\n    return expandDims(\n        {inputs: {input: inputs[0]}, backend, attrs: {dim: axis}});\n  }\n\n  const shape = inputs[0].shape;\n  const dtype = inputs[0].dtype;\n\n  inputs.forEach(t => {\n    util.assertShapesMatch(\n        shape, t.shape,\n        'All tensors passed to stack must have matching shapes');\n    util.assert(\n        dtype === t.dtype,\n        () => 'All tensors passed to stack must have matching dtypes');\n  });\n\n  const intermediateTensorInfos: TensorInfo[] = [];\n  const expandedTensors = inputs.map(t => {\n    const expandedT =\n        expandDims({inputs: {input: t}, backend, attrs: {dim: axis}});\n    intermediateTensorInfos.push(expandedT);\n    return expandedT;\n  });\n\n  const result = concat({inputs: expandedTensors, backend, attrs: {axis}});\n\n  intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));\n\n  return result;\n}\n\nexport const packConfig: KernelConfig = {\n  kernelName: Pack,\n  backendName: 'webgpu',\n  kernelFunc: pack as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport function padCommon(shape: number[], fillZero = false): string {\n  const rank = shape.length;\n  const type = getCoordsDataType(rank);\n  const start = shape.map((_, i) => `uniforms.pad${i}[0]`).join(',');\n  const end = shape\n                  .map(\n                      (_, i) => `uniforms.pad${i}[0] + uniforms.xShape${\n                          rank > 1 ? `[${i}]` : ''}`)\n                  .join(',');\n  const startValue = rank > 1 ? `${type}(${start})` : `${start}`;\n  const endValue = rank > 1 ? `${type}(${end})` : `${end}`;\n\n  const leftPadCondition =\n      rank > 1 ? `any(paddedCoords < start)` : `paddedCoords < start`;\n  const rightPadCondition =\n      rank > 1 ? `any(paddedCoords >= end)` : `paddedCoords >= end`;\n\n  const unpackedCoords = rank > 1 ?\n      ['coords[0]', 'coords[1]', 'coords[2]', 'coords[3]'].slice(0, rank) :\n      'coords';\n  return `\n        let start = ${startValue};\n        let end = ${endValue};\n        if (${leftPadCondition} || ${rightPadCondition}) {\n          setOutputAtIndex(index, ${fillZero ? 0.0 : 'uniforms.constantValue'});\n        } else {\n          let coords = paddedCoords - start;\n          setOutputAtIndex(index, getX(${unpackedCoords}));\n        }\n  `;\n}\n\nexport class PadProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'constantValue : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  xShape: number[];\n  size = true;\n\n  constructor(xShape: number[], paddings: Array<[number, number]>) {\n    this.outputShape = paddings.map(\n        (p, i) => p[0] /* beforePad */ + xShape[i] + p[1] /* afterPad */);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    paddings.map((_, i) => {\n      this.uniforms += ` pad${i} : vec2<i32>,`;\n    });\n    this.xShape = xShape;\n    this.shaderKey = 'pad';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let paddedCoords = getCoordsFromIndex(index);\n          ${padCommon(this.xShape)}\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, PadV2, PadV2Attrs, PadV2Inputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\nimport {PadProgram} from '../pad_webgpu';\nimport {fill} from './Fill';\n\nexport const padV2 =\n    (args: {inputs: PadV2Inputs,\n            backend: WebGPUBackend,\n            attrs: PadV2Attrs}): TensorInfo => {\n      const {inputs, backend, attrs} = args;\n      const {x} = inputs;\n      const {paddings, constantValue} = attrs;\n      if (paddings.every(p => util.arraysEqual(p, [0, 0]))) {\n        return identity({inputs: {x}, backend});\n      }\n      if (util.sizeFromShape(x.shape) === 0) {\n        // Short-circuit the computation, since x doesn't have value, only\n        // the shape is used to compute output shape to pad.\n        const outputShape = paddings.map(\n            (p, i) =>\n                p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n        return fill({\n          backend,\n          attrs: {shape: outputShape, value: constantValue, dtype: x.dtype}\n        });\n      }\n      const uniformData = [{type: 'float32', data: [constantValue]}];\n      paddings.map(p => uniformData.push({type: 'int32', data: [p[0], p[1]]}));\n      const program = new PadProgram(x.shape, paddings);\n      return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n    };\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'webgpu',\n  kernelFunc: padV2 as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Pow} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const pow = binaryKernelFunc({\n  opType: BinaryOpType.POW,\n});\n\nexport const powConfig: KernelConfig = {\n  kernelName: Pow,\n  backendName: 'webgpu',\n  kernelFunc: pow\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Prelu, PreluInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {BinaryOpProgram} from '../binary_op_webgpu';\n\nexport function prelu(args: {inputs: PreluInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x, alpha} = inputs;\n\n  const program = new BinaryOpProgram(BinaryOpType.PRELU, x.shape, alpha.shape);\n  return backend.runWebGPUProgram(program, [x, alpha], 'float32');\n}\n\nexport const preluConfig: KernelConfig = {\n  kernelName: Prelu,\n  backendName: 'webgpu',\n  kernelFunc: prelu as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Prod, ProdAttrs, ProdInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function prod(\n    args: {inputs: ProdInputs, backend: WebGPUBackend, attrs: ProdAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  return reduce(x, axis, keepDims, 'prod', backend);\n}\n\nexport const prodConfig: KernelConfig = {\n  kernelName: Prod,\n  backendName: 'webgpu',\n  kernelFunc: prod as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Range, RangeAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {rangeImplCPU} from '../kernel_utils/shared';\n\nexport const range =\n    (args: {backend: WebGPUBackend, attrs: RangeAttrs}): TensorInfo => {\n      const {backend, attrs} = args;\n      const {start, stop, step, dtype} = attrs;\n      const values = rangeImplCPU(start, stop, step, dtype);\n      return backend.makeTensorInfo([values.length], dtype, values);\n    };\n\nexport const rangeConfig: KernelConfig = {\n  kernelName: Range,\n  backendName: 'webgpu',\n  kernelFunc: range as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, RealDiv} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const realDiv = binaryKernelFunc({opType: BinaryOpType.DIV});\n\nexport const realDivConfig: KernelConfig = {\n  kernelName: RealDiv,\n  backendName: 'webgpu',\n  kernelFunc: realDiv as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Reciprocal} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const reciprocal = unaryKernelFunc({opType: UnaryOpType.RECIPROCAL});\n\nexport const reciprocalConfig: KernelConfig = {\n  kernelName: Reciprocal,\n  backendName: 'webgpu',\n  kernelFunc: reciprocal\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const relu = unaryKernelFunc({opType: UnaryOpType.RELU});\n\nexport const reluConfig: KernelConfig = {\n  kernelName: Relu,\n  backendName: 'webgpu',\n  kernelFunc: relu\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu6} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const relu6 = unaryKernelFunc({opType: UnaryOpType.RELU6});\n\nexport const relu6Config: KernelConfig = {\n  kernelName: Relu6,\n  backendName: 'webgpu',\n  kernelFunc: relu6\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ResizeBilinearProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'adjustHeightWidth : vec2<f32>, halfPixelCenters : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(\n      inputShape: [number, number, number, number], newHeight: number,\n      newWidth: number) {\n    this.outputShape = [inputShape[0], newHeight, newWidth, inputShape[3]];\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `resizeBilinear`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n          let b = coords[0];\n          let d = coords[3];\n          let rc = coords.yz;\n\n          let effectiveInSize = vec2<f32>(\n            f32(uniforms.xShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.xShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveOutSize = vec2<f32>(\n            f32(uniforms.outShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.outShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveInputOverOutputRatioRC =\n              effectiveInSize / effectiveOutSize;\n\n          // Fractional source index\n          let sourceFracIndexRC =\n            (vec2<f32>(rc) + vec2<f32>(uniforms.halfPixelCenters)) *\n            effectiveInputOverOutputRatioRC - vec2<f32>(uniforms.halfPixelCenters);\n\n          // Compute the four integer indices.\n          let sourceFloorRC = vec2<i32>(sourceFracIndexRC);\n          let sourceCeilRC = vec2<i32>(\n            min(vec2<f32>(uniforms.xShape.yz) - vec2<f32>(1.0), ceil(sourceFracIndexRC)));\n\n          let topLeft = getX(b, sourceFloorRC.x, sourceFloorRC.y, d);\n          let bottomLeft = getX(b, sourceCeilRC.x, sourceFloorRC.y, d);\n          let topRight = getX(b, sourceFloorRC.x, sourceCeilRC.y, d);\n          let bottomRight = getX(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n          let fracRC = sourceFracIndexRC - vec2<f32>(sourceFloorRC);\n\n          let top = topLeft + (topRight - topLeft) * fracRC.y;\n          let bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n          let newValue = top + (bottom - top) * fracRC.x;\n\n          setOutputAtIndex(index, newValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinear, ResizeBilinearAttrs, ResizeBilinearInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ResizeBilinearProgram} from '../resize_bilinear_webgpu';\n\nexport function resizeBilinear(args: {\n  inputs: ResizeBilinearInputs,\n  backend: WebGPUBackend,\n  attrs: ResizeBilinearAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, size, halfPixelCenters} = attrs;\n\n  const [newHeight, newWidth] = size;\n  const adjustHeight = alignCorners && newHeight > 1 ? 1.0 : 0.0;\n  const adjustWidth = alignCorners && newWidth > 1 ? 1.0 : 0.0;\n  const halfPixelCentersValue = halfPixelCenters ? 0.5 : 0.0;\n  const uniformData = [\n    {type: 'float32', data: [adjustHeight, adjustWidth]},\n    {type: 'float32', data: [halfPixelCentersValue]}\n  ];\n\n  const program = new ResizeBilinearProgram(\n      images.shape as [number, number, number, number], newHeight, newWidth);\n\n  return backend.runWebGPUProgram(program, [images], 'float32', uniformData);\n}\n\nexport const resizeBilinearConfig: KernelConfig = {\n  kernelName: ResizeBilinear,\n  backendName: 'webgpu',\n  kernelFunc: resizeBilinear as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ResizeBilinearBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy'];\n  uniforms =\n      `effectiveXSize : vec2<i32>, effectiveYSize : vec2<i32>, heightScale : f32, widthScale : f32,\n       invHeightScale : f32, invWidthScale : f32, winHeight : i32, winWidth : i32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  alignCorners: boolean;\n  size = true;\n\n  constructor(\n      inputShape: [number, number, number, number], alignCorners: boolean) {\n    this.outputShape = inputShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.alignCorners = alignCorners;\n    this.shaderKey = `resizeBilinearBackprop_${alignCorners}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getOutputCoords();\n          let b = coords[0];\n          let d = coords[3];\n          let r = coords[1];\n          let c = coords[2];\n\n          var accumulator = 0.0;\n\n          // Compute bounds for where in dy we will look\n          let startRLerp = floor(f32(r) * uniforms.invHeightScale);\n          let startDyR = i32(startRLerp - f32(uniforms.winHeight / 2));\n\n          let startCLerp = floor(f32(c) * uniforms.invWidthScale);\n          let startDyC = i32(startCLerp - f32(uniforms.winWidth / 2));\n\n          // Loop over dy\n          for (var dyROffset = 0; dyROffset < uniforms.winHeight; dyROffset++) {\n            let dyR = startDyR + dyROffset;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyR < 0 || dyR >= uniforms.dyShape[1]) {\n              continue;\n            }\n\n            for (var dyCOffset = 0; dyCOffset < uniforms.winWidth; dyCOffset++) {\n              let dyC = startDyC + dyCOffset;\n\n              // Guard against the window exceeding the bounds of dy\n              if (dyC < 0 || dyC >= uniforms.dyShape[2]) {\n                continue;\n              }\n\n              let dxR = f32(dyR) * uniforms.heightScale;\n              let topDxRIndex = i32(floor(dxR));\n              let bottomDxRIndex = i32(min(ceil(dxR), f32(uniforms.outShape[1] - 1)));\n              let dxRLerp = dxR - f32(topDxRIndex);\n              let inverseDxRLerp = 1.0 - dxRLerp;\n\n              let dxC = f32(dyC) * uniforms.widthScale;\n              let leftDxCIndex = i32(floor(dxC));\n              let rightDxCIndex = i32(min(ceil(dxC), f32(uniforms.outShape[2] - 1)));\n              let dxCLerp = dxC - f32(leftDxCIndex);\n              let inverseDxCLerp = 1.0 - dxCLerp;\n\n              if (r == topDxRIndex && c == leftDxCIndex) {\n                // topLeft\n                accumulator +=\n                  getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n              }\n\n              if (r == topDxRIndex && c == rightDxCIndex) {\n                // topRight\n                accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n              }\n\n              if (r == bottomDxRIndex && c == leftDxCIndex) {\n                // bottomLeft\n                accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n              }\n\n              if (r == bottomDxRIndex && c == rightDxCIndex) {\n                // bottomRight\n                accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n              }\n            }\n          }\n          // End loop over dy\n\n          setOutputAtIndex(index, accumulator);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinearGrad, ResizeBilinearGradAttrs, ResizeBilinearGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ResizeBilinearBackpropProgram} from '../resize_bilinear_backprop_webgpu';\n\nexport function resizeBilinearGrad(args: {\n  inputs: ResizeBilinearGradInputs,\n  backend: WebGPUBackend,\n  attrs: ResizeBilinearGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  const [, xHeight, xWidth, ] =\n      images.shape as [number, number, number, number];\n  const [, yHeight, yWidth] = dy.shape as [number, number, number, number];\n\n  const effectiveXSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n    (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n  ];\n\n  const effectiveYSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n    (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n  ];\n\n  const heightScale = effectiveXSize[0] / effectiveYSize[0];\n  const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n  const invHeightScale = 1 / heightScale;\n  const invWidthScale = 1 / widthScale;\n\n  // This defines the size of the window of values around a particular\n  // index in dy that we want to search for contributions to dx.\n  const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n  const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n  const program = new ResizeBilinearBackpropProgram(\n      images.shape as [number, number, number, number], alignCorners);\n  const uniformData = [\n    {type: 'int32', data: effectiveXSize},\n    {type: 'int32', data: effectiveYSize},\n    {type: 'float32', data: [heightScale]},\n    {type: 'float32', data: [widthScale]},\n    {type: 'float32', data: [invHeightScale]},\n    {type: 'float32', data: [invWidthScale]},\n    {type: 'int32', data: [winHeight]}, {type: 'int32', data: [winWidth]}\n  ];\n  return backend.runWebGPUProgram(program, [dy], dy.dtype, uniformData);\n}\n\nexport const resizeBilinearGradConfig: KernelConfig = {\n  kernelName: ResizeBilinearGrad,\n  backendName: 'webgpu',\n  kernelFunc: resizeBilinearGrad as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ResizeNearestNeighborProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'adjustHeightWidth : vec2<f32>, roundBase : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  halfPixelCenters: boolean;\n  size = true;\n\n  constructor(\n      inputShape: [number, number, number, number], newHeight: number,\n      newWidth: number, halfPixelCenters: boolean) {\n    this.outputShape = [inputShape[0], newHeight, newWidth, inputShape[3]];\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.halfPixelCenters = halfPixelCenters;\n    this.shaderKey = `resizeNearest_${halfPixelCenters}`;\n  }\n\n  getUserCode(): string {\n    let sourceFracIndexRC: string;\n    if (this.halfPixelCenters) {\n      sourceFracIndexRC =\n          `max((vec2<f32>(rc) + vec2<f32>(0.5)) * effectiveInputOverOutputRatioRC` +\n          `, vec2<f32>(0.0))`;\n    } else {\n      sourceFracIndexRC = `vec2<f32>(rc) * effectiveInputOverOutputRatioRC`;\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let b = coords[0];\n          let d = coords[3];\n          let rc = coords.yz;\n\n          let effectiveInSize = vec2<f32>(\n            f32(uniforms.xShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.xShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveOutSize = vec2<f32>(\n            f32(uniforms.outShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.outShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveInputOverOutputRatioRC =\n              effectiveInSize / effectiveOutSize;\n\n          // Fractional source index\n          let sourceFracIndexRC = ${sourceFracIndexRC};\n\n          // Compute the coordinators of nearest neighbor point.\n          let inputShapeRC = vec2<f32>(f32(uniforms.xShape.y), f32(uniforms.xShape.z));\n          let sourceNearestRC = vec2<i32>(\n            min(inputShapeRC - 1.0, floor(sourceFracIndexRC + uniforms.roundBase)));\n          let newValue = getX(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n          setOutputAtIndex(index, newValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighbor, ResizeNearestNeighborAttrs, ResizeNearestNeighborInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ResizeNearestNeighborProgram} from '../resize_nearest_neighbor_webgpu';\n\nexport function resizeNearestNeighbor(args: {\n  inputs: ResizeNearestNeighborInputs,\n  backend: WebGPUBackend,\n  attrs: ResizeNearestNeighborAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, halfPixelCenters, size} = attrs;\n\n  const [newHeight, newWidth] = size;\n  const adjustHeight = alignCorners && newHeight > 1 ? 1.0 : 0.0;\n  const adjustWidth = alignCorners && newWidth > 1 ? 1.0 : 0.0;\n  // When align corners is false, we rounds the value with floor.\n  const roundBase = alignCorners ? 0.5 : 0.0;\n  const uniformData = [\n    {type: 'float32', data: [adjustHeight, adjustWidth]},\n    {type: 'float32', data: [roundBase]}\n  ];\n\n  const program = new ResizeNearestNeighborProgram(\n      images.shape as [number, number, number, number], newHeight, newWidth,\n      halfPixelCenters);\n  return backend.runWebGPUProgram(program, [images], images.dtype, uniformData);\n}\n\nexport const resizeNearestNeighborConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighbor,\n  backendName: 'webgpu',\n  kernelFunc: resizeNearestNeighbor as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ResizeNearestNeigborBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy'];\n  uniforms =\n      `effectiveXSize : vec2<i32>, effectiveYSize : vec2<i32>, invHeightScale : f32, invWidthScale : f32,\n       winHeight : i32, winWidth : i32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  alignCorners: boolean;\n  size = true;\n\n  constructor(\n      inputShape: [number, number, number, number], alignCorners: boolean) {\n    this.outputShape = inputShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.alignCorners = alignCorners;\n    this.shaderKey = `resizeNearestNeigborBackprop_${alignCorners}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getOutputCoords();\n          let b = coords[0];\n          let d = coords[3];\n          let r = coords[1];\n          let c = coords[2];\n\n          var accumulator = 0.0;\n\n          // Compute bounds for where in dy we will look\n          let startRLerp = floor(f32(r) * uniforms.invHeightScale);\n          let startDyR = i32(floor(startRLerp - f32(uniforms.winHeight / 2)));\n\n          let startCLerp = floor(f32(c) * uniforms.invWidthScale);\n          let startDyC = i32(floor(startCLerp - f32(uniforms.winWidth / 2)));\n\n          // Loop over dy\n          for (var dyROffset = 0; dyROffset < uniforms.winHeight; dyROffset++) {\n            let dyR = startDyR + dyROffset;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyR < 0 || dyR >= uniforms.dyShape[1]) {\n              continue;\n            }\n\n            for (var dyCOffset = 0; dyCOffset < uniforms.winWidth; dyCOffset++) {\n              let dyC = startDyC + dyCOffset;\n\n              // Guard against the window exceeding the bounds of dy\n              if (dyC < 0 || dyC >= uniforms.dyShape[2]) {\n                continue;\n              }\n\n              let sourceFracRow = f32(uniforms.effectiveXSize[0]) *\n                  (f32(dyR) / f32(uniforms.effectiveYSize[0]));\n\n              let sourceFracCol = f32(uniforms.effectiveXSize[1]) *\n                  (f32(dyC) / f32(uniforms.effectiveYSize[1]));\n\n              let sourceNearestRow =\n                  i32(min(f32(uniforms.outShape[1] - 1),\n                  ${\n        this.alignCorners ? 'floor(sourceFracRow + 0.5)' :\n                            'floor(sourceFracRow)'}));\n\n              let sourceNearestCol =\n                  i32(min(f32(uniforms.outShape[2] - 1),\n                  ${\n        this.alignCorners ? 'floor(sourceFracCol + 0.5)' :\n                            'floor(sourceFracCol)'}));\n\n              if (r == sourceNearestRow && c == sourceNearestCol) {\n                accumulator += getDy(b, dyR, dyC, d);\n              }\n            }\n          }\n          // End loop over dy\n\n          setOutputAtIndex(index, accumulator);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighborGrad, ResizeNearestNeighborGradAttrs, ResizeNearestNeighborGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ResizeNearestNeigborBackpropProgram} from '../resize_nearest_neighbor_backprop_webgpu';\n\nexport function resizeNearestNeighborGrad(args: {\n  inputs: ResizeNearestNeighborGradInputs,\n  backend: WebGPUBackend,\n  attrs: ResizeNearestNeighborGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  const [, xHeight, xWidth] = images.shape as [number, number, number, number];\n  const [, yHeight, yWidth] = dy.shape as [number, number, number, number];\n\n  const effectiveXSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n    (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n  ];\n\n  const effectiveYSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n    (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n  ];\n\n  const heightScale = effectiveXSize[0] / effectiveYSize[0];\n  const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n  const invHeightScale = 1 / heightScale;\n  const invWidthScale = 1 / widthScale;\n\n  // This defines the size of the window of values around a particular\n  // index in dy that we want to search for contributions to dx.\n  const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n  const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n  const program = new ResizeNearestNeigborBackpropProgram(\n      images.shape as [number, number, number, number], alignCorners);\n  const uniformData = [\n    {type: 'int32', data: effectiveXSize},\n    {type: 'int32', data: effectiveYSize},\n    {type: 'float32', data: [invHeightScale]},\n    {type: 'float32', data: [invWidthScale]},\n    {type: 'int32', data: [winHeight]}, {type: 'int32', data: [winWidth]}\n  ];\n  return backend.runWebGPUProgram(program, [dy], dy.dtype, uniformData);\n}\n\nexport const resizeNearestNeighborGradConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighborGrad,\n  backendName: 'webgpu',\n  kernelFunc: resizeNearestNeighborGrad as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ReverseProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms: string;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(xShape: [number, number, number, number]) {\n    this.outputShape = xShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.uniforms = ` axis : vec4<i32>,`;\n    this.shaderKey = 'reverse';\n  }\n\n  getUserCode(): string {\n    const reverseCoordsSnippet = `\n      // Using uniform variables as judging conditions, so the function has\n      // coherent execution within all threads.\n      fn getReverseCoords(coords : vec4<i32>) -> vec4<i32> {\n        var reverseCoords = coords;\n        if (uniforms.axis[0] == 1) {\n          reverseCoords[0] = uniforms.xShape[0] - coords[0] - 1;\n        }\n        if (uniforms.axis[1] == 1) {\n          reverseCoords[1] = uniforms.xShape[1] - coords[1] - 1;\n        }\n        if (uniforms.axis[2] == 1) {\n          reverseCoords[2] = uniforms.xShape[2] - coords[2] - 1;\n        }\n        if (uniforms.axis[3] == 1) {\n          reverseCoords[3] = uniforms.xShape[3] - coords[3] - 1;\n        }\n\n        return reverseCoords;\n      }\n    `;\n    const userCode = `\n      ${reverseCoordsSnippet}\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let reverseCoords = getReverseCoords(coords);\n          setOutputAtIndex(index, getX(reverseCoords[0],\n              reverseCoords[1], reverseCoords[2], reverseCoords[3]));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reverse, ReverseAttrs, ReverseInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ReverseProgram} from '../reverse_webgpu';\n\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\n\nexport function reverse(\n    args: {inputs: ReverseInputs, backend: WebGPUBackend, attrs: ReverseAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dims} = attrs;\n\n  const xRank = x.shape.length;\n  if (xRank === 0) {\n    return identity({inputs: {x}, backend});\n  }\n\n  const xShape = x.shape;\n  const xShape4D: [number, number, number, number] = [1, 1, 1, 1];\n  xShape.forEach((d, i) => {\n    const index = i + 4 - xRank;\n    xShape4D[index] = d;\n  });\n\n  const axes = util.parseAxisParam(dims, x.shape);\n  const dims4D: [number, number, number, number] = [0, 0, 0, 0];\n  axes.forEach(ax => {\n    const index = ax + 4 - xRank;\n    dims4D[index] = 1;\n  });\n  const uniformData = [{type: 'int32', data: dims4D}];\n\n  const xReshaped = reshape({inputs: {x}, backend, attrs: {shape: xShape4D}});\n\n  const program = new ReverseProgram(xShape4D);\n  const values = backend.runWebGPUProgram(\n      program, [xReshaped], xReshaped.dtype, uniformData);\n  backend.disposeData(xReshaped.dataId);\n\n  const result =\n      reshape({inputs: {x: values}, backend, attrs: {shape: xShape}});\n  backend.disposeData(values.dataId);\n\n  return result;\n}\n\nexport const reverseConfig: KernelConfig = {\n  kernelName: Reverse,\n  backendName: 'webgpu',\n  kernelFunc: reverse as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class RotateProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms: string;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  fillSnippet: string;\n  size = true;\n\n  constructor(\n      imageShape: [number, number, number, number],\n      fillValue: number|[number, number, number]) {\n    this.outputShape = imageShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.uniforms = `centerX : f32, centerY : f32, sinRadians : f32,\n          cosRadians : f32,`;\n    this.shaderKey = 'rotate';\n    this.outputShape = imageShape;\n\n    if (typeof fillValue === 'number') {\n      this.uniforms += ` fillValue : f32,`;\n      this.fillSnippet = `var outputValue = uniforms.fillValue;`;\n      this.shaderKey += '_float';\n    } else {\n      this.uniforms += ` fillValue : vec3<f32>,`;\n      this.fillSnippet = `var outputValue = uniforms.fillValue[coords[3]];`;\n      this.shaderKey += '_vec3';\n    }\n  }\n\n  getUserCode(): string {\n    const userCode = `\n        ${main('index')} {\n          if (index < uniforms.size) {\n            let coords = getCoordsFromIndex(index);\n            let coordXFloat = (f32(coords[2]) - uniforms.centerX) *\n                uniforms.cosRadians - (f32(coords[1]) - uniforms.centerY) *\n                uniforms.sinRadians;\n            let coordYFloat = (f32(coords[2]) - uniforms.centerX) *\n                uniforms.sinRadians + (f32(coords[1]) - uniforms.centerY) *\n                uniforms.cosRadians;\n            let coordX = i32(round(coordXFloat + uniforms.centerX));\n            let coordY = i32(round(coordYFloat + uniforms.centerY));\n            ${this.fillSnippet}\n            if(coordX >= 0 && coordX < uniforms.xShape[2] && coordY >= 0 &&\n                coordY < uniforms.xShape[1]) {\n              outputValue = getX(coords[0], coordY, coordX, coords[3]);\n            }\n            setOutputAtIndex(index, outputValue);\n          }\n        }\n      `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, Tensor4D} from '@tensorflow/tfjs-core';\nimport {RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {RotateProgram} from '../rotate_webgpu';\n\nexport const rotateWithOffsetConfig: KernelConfig = {\n    kernelName: RotateWithOffset,\n    backendName: 'webgpu',\n    kernelFunc: ({inputs, attrs, backend}) => {\n      const {image} = inputs as RotateWithOffsetInputs;\n      const {radians, fillValue, center} =\n          attrs as unknown as RotateWithOffsetAttrs;\n      const webgpuBackend = backend as WebGPUBackend;\n\n      const program = new RotateProgram((image as Tensor4D).shape, fillValue);\n      const [centerX, centerY] =\n          backend_util.getImageCenter(center, image.shape[1], image.shape[2]);\n      const uniformData = [\n            {type: 'float32', data: [centerX]},\n            {type: 'float32', data: [centerY]},\n            {type: 'float32', data: [Math.sin(radians)]},\n            {type: 'float32', data: [Math.cos(radians)]}\n          ];\n\n      if (typeof fillValue === 'number') {\n        uniformData.push(\n            {type: 'float32', data: [Number.parseFloat(fillValue.toFixed(2))]});\n      } else {\n        uniformData.push({type: 'float32', data: fillValue});\n      }\n\n      const output = webgpuBackend.runWebGPUProgram(\n          program, [image], image.dtype, uniformData);\n      return output;\n   }\n };\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Round} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const round = unaryKernelFunc({opType: UnaryOpType.ROUND});\n\nexport const roundConfig: KernelConfig = {\n  kernelName: Round,\n  backendName: 'webgpu',\n  kernelFunc: round\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {rsqrtImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const rsqrt =\n    unaryKernelFunc({opType: UnaryOpType.RSQRT, cpuKernelImpl: rsqrtImplCPU});\n\nexport const rsqrtConfig: KernelConfig = {\n  kernelName: Rsqrt,\n  backendName: 'webgpu',\n  kernelFunc: rsqrt\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType} from '@tensorflow/tfjs-core';\n\nimport {atomicAddSnippet} from './shader_util';\nimport {dataTypeToGPUType, getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ScatterProgram implements WebGPUProgram {\n  variableNames = ['updates', 'indices'];\n  uniforms: string;\n  outputShape: number[];\n  sumDupeIndices: boolean;\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  updatesRank: number;\n  indicesRank: number;\n  sliceDimGreaterThanOne: boolean;\n  atomic = true;\n  type: DataType;\n\n  constructor(\n      flattenXShape: number[], sliceDim: number, indicesRank: number,\n      updatesRank: number, strides: number[], shape: number[],\n      outputDtype: DataType, sumDupeIndices = true) {\n    this.outputShape = shape;\n    this.type = outputDtype;\n    this.sumDupeIndices = sumDupeIndices;\n    this.dispatchLayout = flatDispatchLayout(flattenXShape);\n    // Dispatching based on |updates| shape instead of output shape.\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, flattenXShape, this.workgroupSize);\n    this.sliceDimGreaterThanOne = sliceDim > 1;\n    this.shaderKey =\n        `scatter_${indicesRank}_${updatesRank}_${this.sliceDimGreaterThanOne}_${\n            outputDtype}_${sumDupeIndices}_${strides.length}`;\n    const stridesType = getCoordsDataType(strides.length);\n    this.uniforms =\n        `sliceDim : i32, strides: ${stridesType}, updatesSize: i32,`;\n    this.updatesRank = updatesRank;\n    this.indicesRank = indicesRank;\n  }\n\n  getUserCode(): string {\n    let indicesString = '';\n    if (this.indicesRank === 1) {\n      indicesString = 'coords[0]';\n    } else if (this.indicesRank === 2) {\n      indicesString = 'coords[0], j';\n    }\n    const indicesSnippet = `getIndices(${indicesString})`;\n\n    const strideString = this.sliceDimGreaterThanOne ? 'uniforms.strides[j]' :\n                                                       'uniforms.strides';\n\n    let outCoordsString = '';\n    let getUpdatesCoordsFromFlatIndex = '';\n    if (this.dispatchLayout.x.length === 1) {\n      outCoordsString = 'flattenedIndex';\n      getUpdatesCoordsFromFlatIndex = `\n      fn getUpdatesCoordsFromFlatIndex(index : i32) -> i32 {\n        return index;\n      }\n      `;\n    } else if (this.dispatchLayout.x.length === 2) {\n      outCoordsString = 'vec2<i32>(flattenedIndex, coords[1])';\n      getUpdatesCoordsFromFlatIndex = `\n      fn getUpdatesCoordsFromFlatIndex(index : i32) -> vec2<i32> {\n        // N.B. |updates| could be a scalar tensor, conceptually representing a\n        // 2D tensor with all values equal to that. By design, its size must be\n        // the same as |outShape[1]| in one dimension, and |indicesShape[0]|\n        // gives the other.\n        let sliceSize = uniforms.outShape[1];\n        let d0 = index / sliceSize;\n        let d1 = index - d0 * sliceSize;\n        return vec2<i32>(d0, d1);\n      }\n      `;\n    }\n    const updatesString =\n        Array.from({length: this.updatesRank}, (_, idx) => `coords[${idx}]`);\n    const updatesSnippet = `getUpdates(${updatesString.join(', ')})`;\n\n    const userCode = `\n    ${getUpdatesCoordsFromFlatIndex}\n      ${main('index')} {\n        if (index < uniforms.updatesSize) {\n          let coords = getUpdatesCoordsFromFlatIndex(index);\n          var flattenedIndex = 0;\n          for (var j = 0; j < uniforms.sliceDim; j = j + 1) {\n            let indexInside = i32(round(${indicesSnippet}));\n            flattenedIndex = flattenedIndex + indexInside * ${strideString};\n          }\n          let updateValue =\n              ${dataTypeToGPUType(this.type)}(${updatesSnippet});\n          let flatIndex = getOutputIndexFromCoords(${outCoordsString});\n\n          ${\n        this.sumDupeIndices ?\n            atomicAddSnippet(\n                '&result[flatIndex]', 'updateValue',\n                this.type as 'float32' | 'int32') :\n            `atomicStore(&result[flatIndex], bitcast<i32>(updateValue));`}\n        }\n      }`;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ScatterNd, ScatterNdAttrs, ScatterNdInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ScatterProgram} from '../scatter_webgpu';\n\nimport {fill} from './Fill';\nimport {reshape} from './Reshape';\n\nexport function scatterNd(args: {\n  inputs: ScatterNdInputs,\n  backend: WebGPUBackend,\n  attrs: ScatterNdAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {indices, updates} = inputs;\n  const {shape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(updates, indices, shape);\n\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  if (outputSize === 0) {\n    return backend.makeTensorInfo(shape, indices.dtype);\n  }\n\n  const flattenIndices = reshape(\n      {inputs: {x: indices}, backend, attrs: {shape: [numUpdates, sliceRank]}});\n  const flattenX = reshape(\n      {inputs: {x: updates}, backend, attrs: {shape: [numUpdates, sliceSize]}});\n\n  const type = flattenX.dtype;\n  const output =\n      fill({backend, attrs: {shape: flattenShape, value: 0, dtype: type}});\n  const size = util.sizeFromShape(flattenX.shape);\n  const uniformData = [\n    {type: 'int32', data: [sliceRank]}, {type: 'int32', data: strides},\n    {type: 'int32', data: [size]}\n  ];\n  const program = new ScatterProgram(\n      flattenX.shape, sliceRank, flattenIndices.shape.length,\n      flattenX.shape.length, strides, flattenShape, type);\n  const res = backend.runWebGPUProgram(\n      program, [flattenX, flattenIndices], type, uniformData, output);\n\n  const reshaped = reshape({inputs: {x: res}, backend, attrs: {shape}});\n\n  backend.disposeData(flattenIndices.dataId);\n  backend.disposeData(flattenX.dataId);\n  backend.disposeData(res.dataId);\n\n  return reshaped;\n}\n\nexport const scatterNdConfig: KernelConfig = {\n  kernelName: ScatterNd,\n  backendName: 'webgpu',\n  kernelFunc: scatterNd as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SearchSortedProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['sortedSequence', 'values'];\n  uniforms = 'numInputs : i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  side: string;\n\n  constructor(outputShape: [number, number], side: 'left'|'right') {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.side = side;\n    this.shaderKey = `search_sorted_${side}`;\n  }\n\n  getUserCode(): string {\n    const boundComparator = this.side === 'left' ? '<' : '<=';\n    const userCode = `\n      fn findBound(batch: i32, value: f32) -> i32 {\n        var left = i32(0);\n        var right = uniforms.numInputs;\n        while (left < right) {\n          var mid = (left + right) / 2;\n          if (getSortedSequence(batch, mid) ${boundComparator} value) {\n            left = mid + 1;\n          } else {\n            right = mid;\n          }\n        }\n        return right;\n      }\n\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let value = getValuesByOutputIndex(index);\n          setOutputAtIndexI32(index, findBound(coords[0], value));\n        }\n      }\n    `;\n\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SearchSorted, SearchSortedAttrs, SearchSortedInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {SearchSortedProgram} from '../search_sorted_webgpu';\n\nexport function searchSorted(args: {\n  inputs: SearchSortedInputs,\n  backend: WebGPUBackend,\n  attrs: SearchSortedAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {sortedSequence, values} = inputs;\n  const {side} = attrs;\n\n  const program =\n      new SearchSortedProgram([values.shape[0], values.shape[1]], side);\n  const uniformData = [{type: 'int32', data: [sortedSequence.shape[1]]}];\n  return backend.runWebGPUProgram(\n      program, [sortedSequence, values], 'int32', uniformData);\n}\n\nexport const searchSortedConfig: KernelConfig = {\n  kernelName: SearchSorted,\n  backendName: 'webgpu',\n  kernelFunc: searchSorted as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SelectProgram implements WebGPUProgram {\n  variableNames = ['c', 'a', 'b'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  cRank: number;\n  rank: number;\n  size = true;\n\n  constructor(cRank: number, shape: number[], rank: number) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.cRank = cRank;\n    this.rank = rank;\n    this.shaderKey = 'select';\n  }\n\n  getUserCode(): string {\n    // TODO(WGSL): below code can be merged with getUserCode.\n    let cCoords;\n    let abCoords;\n    if (this.rank > 4) {\n      throw Error(`Where for rank ${this.rank} is not yet supported`);\n    }\n\n    if (this.rank === 1) {\n      abCoords = `resRC`;\n      cCoords = `resRC`;\n    } else {\n      const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n      const cCoordVars = [];\n      const abCoordVars = [];\n      for (let i = 0; i < this.outputShape.length; i++) {\n        abCoordVars.push(`${currentCoords[i]}`);\n        if (i < this.cRank) {\n          cCoordVars.push(`${currentCoords[i]}`);\n        }\n      }\n      cCoords = cCoordVars.join();\n      abCoords = abCoordVars.join();\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let resRC = getCoordsFromIndex(index);\n          let cVal = getC(${cCoords});\n          if (cVal >= 1.0) {\n            setOutputAtIndex(index, getA(${abCoords}));\n          } else {\n            setOutputAtIndex(index, getB(${abCoords}));\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Select, SelectInputs, TensorInfo, upcastType} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {SelectProgram} from '../select_webgpu';\n\nexport function select(args: {inputs: SelectInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {condition, t, e} = inputs;\n\n  const program =\n      new SelectProgram(condition.shape.length, t.shape, t.shape.length);\n  return backend.runWebGPUProgram(\n      program, [condition, t, e], upcastType(t.dtype, e.dtype));\n}\n\nexport const selectConfig: KernelConfig = {\n  kernelName: Select,\n  backendName: 'webgpu',\n  kernelFunc: select as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Selu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const selu = unaryKernelFunc({opType: UnaryOpType.SELU});\n\nexport const seluConfig: KernelConfig = {\n  kernelName: Selu,\n  backendName: 'webgpu',\n  kernelFunc: selu\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sigmoid} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sigmoid = unaryKernelFunc({opType: UnaryOpType.SIGMOID});\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: Sigmoid,\n  backendName: 'webgpu',\n  kernelFunc: sigmoid,\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sign} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sign = unaryKernelFunc({opType: UnaryOpType.SIGN});\n\nexport const signConfig: KernelConfig = {\n  kernelName: Sign,\n  backendName: 'webgpu',\n  kernelFunc: sign\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sin} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sin = unaryKernelFunc({opType: UnaryOpType.SIN});\n\nexport const sinConfig: KernelConfig = {\n  kernelName: Sin,\n  backendName: 'webgpu',\n  kernelFunc: sin\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sinh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sinh = unaryKernelFunc({opType: UnaryOpType.SINH});\n\nexport const sinhConfig: KernelConfig = {\n  kernelName: Sinh,\n  backendName: 'webgpu',\n  kernelFunc: sinh\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Softplus} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const softplus = unaryKernelFunc({opType: UnaryOpType.SOFTPLUS});\n\nexport const softplusConfig: KernelConfig = {\n  kernelName: Softplus,\n  backendName: 'webgpu',\n  kernelFunc: softplus\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {padCommon} from './pad_webgpu';\nimport {getSwitchedCoords} from './transpose_webgpu';\nimport {getCoordsDataType, getCoordsFromIndexSnippet, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SpaceToBatchNDProgram implements WebGPUProgram {\n  variableNames = ['x'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = '';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  newDim: number[];\n  xShape: number[];\n  paddedXShape: number[];\n  size = true;\n\n  constructor(\n      xShape: number[], paddedXShape: number[],\n      paddings: Array<[number, number]>, reshapedPaddedXShape: number[],\n      newDim: number[], paddedXShapeStridesShapeLength: number) {\n    const outputShape: number[] = new Array(reshapedPaddedXShape.length);\n    for (let i = 0; i < outputShape.length; i++) {\n      outputShape[i] = reshapedPaddedXShape[newDim[i]];\n    }\n    this.outputShape = outputShape;\n    this.newDim = newDim;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.xShape = xShape;\n    this.paddedXShape = paddedXShape;\n    this.uniforms += `reshapedPaddedXShape : ${\n        getCoordsDataType(\n            reshapedPaddedXShape.length)}, paddedXShapeStrides : ${\n        getCoordsDataType(paddedXShapeStridesShapeLength)}, `;\n    paddings.map((_, i) => {\n      this.uniforms += ` pad${i} : vec2<i32>,`;\n    });\n    this.shaderKey = `spaceToBatchND_${newDim}`;\n  }\n\n  getUserCode(): string {\n    const dtype = getCoordsDataType(this.outputShape.length);\n    const switched = getSwitchedCoords(this.newDim);\n\n    const userCode = `\n      ${getCoordsFromIndexSnippet(this.paddedXShape, 'PaddedX')}\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let switchedIndex = getIndexFromCoords${this.outputShape.length}D(${\n        dtype}(${switched}), uniforms.reshapedPaddedXShape);\n          let paddedCoords = getPaddedXCoordsFromIndex(switchedIndex);\n          ${padCommon(this.xShape, true)}\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {SpaceToBatchNDProgram} from '../space_to_batchND_webgpu';\n\nimport {reshape} from './Reshape';\n\nexport const spaceToBatchND = (args: {\n  inputs: SpaceToBatchNDInputs,\n  backend: WebGPUBackend,\n  attrs: SpaceToBatchNDAttrs\n}): TensorInfo => {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, paddings} = attrs;\n\n  util.assert(\n      x.shape.length <= 4,\n      () => 'spaceToBatchND for rank > 4 with a WebGPU backend not ' +\n          'implemented yet');\n\n  const prod = blockShape.reduce((a, b) => a * b);\n\n  const completePaddings: Array<[number, number]> = [[0, 0]];\n  completePaddings.push(...paddings as Array<[number, number]>);\n  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n    completePaddings.push([0, 0]);\n  }\n\n  const paddedXShape = completePaddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n  const reshapedPaddedShape =\n      backend_util.getReshaped(paddedXShape, blockShape, prod, false);\n\n  const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n      reshapedPaddedShape.length, blockShape.length, false);\n\n  const flattenShape =\n      backend_util.getReshapedPermuted(paddedXShape, blockShape, prod, false);\n\n  const paddedXShapeStrides = util.computeStrides(paddedXShape);\n  const program = new SpaceToBatchNDProgram(\n      x.shape, paddedXShape, completePaddings, reshapedPaddedShape,\n      permutedReshapedPaddedPermutation, paddedXShapeStrides.length);\n  const uniformData = [\n    {type: 'int32', data: reshapedPaddedShape},\n    {type: 'int32', data: paddedXShapeStrides}\n  ];\n  completePaddings.map(\n      p => uniformData.push({type: 'int32', data: [p[0], p[1]]}));\n  const paddedXT = backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n  const result =\n      reshape({inputs: {x: paddedXT}, backend, attrs: {shape: flattenShape}});\n  backend.disposeData(paddedXT.dataId);\n  return result;\n};\n\nexport const spaceToBatchNDConfig: KernelConfig = {\n  kernelName: SpaceToBatchND,\n  backendName: 'webgpu',\n  kernelFunc: spaceToBatchND as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType} from '@tensorflow/tfjs-core';\n\nimport {atomicAddSnippet} from './shader_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SparseSegmentSumProgram implements WebGPUProgram {\n  variableNames = ['input', 'indices', 'segmentIds'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'segmentSize : i32, sparseSize : i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  type: DataType;\n\n  constructor(outShape: number[], sparseSize: number, outputDtype: DataType) {\n    this.outputShape = outShape;\n    this.type = outputDtype;\n    this.dispatchLayout = flatDispatchLayout([sparseSize]);\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, [sparseSize], this.workgroupSize);\n\n    this.shaderKey = 'sparseSegmentSum';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.sparseSize) {\n        let indexInSegmentIds = index / uniforms.segmentSize;\n        let indexInSegment = index % uniforms.segmentSize;\n        let indexInInput = indices[indexInSegmentIds];\n        let segmentId = segmentIds[indexInSegmentIds];\n\n        let value = input[indexInInput * uniforms.segmentSize + indexInSegment];\n        let outIndex = segmentId * uniforms.segmentSize + indexInSegment;\n        ${\n        atomicAddSnippet(\n            '&result[outIndex]', 'value', this.type as 'float32' | 'int32')}\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n\nexport class SparseSegmentIdCountProgram implements WebGPUProgram {\n  variableNames = ['segmentIds'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n\n  constructor(outShape: number, segmentIdsShape: number[]) {\n    this.outputShape = [outShape];\n    this.dispatchLayout = flatDispatchLayout(segmentIdsShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, segmentIdsShape, this.workgroupSize);\n\n    this.shaderKey = 'sparseSegmentIdCountProgram';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.segmentIdsShape) {\n        let segmentId = segmentIds[index];\n        ${atomicAddSnippet('&result[segmentId]', '1', 'int32')}\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n\nexport class SparseSegmentMeanProgram implements WebGPUProgram {\n  variableNames = ['segmentSum', 'sameSegmentIdCount'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'segmentSize : i32';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  type: DataType;\n\n  constructor(outShape: number[], outputDtype: DataType) {\n    this.outputShape = outShape;\n    this.type = outputDtype;\n    this.dispatchLayout = flatDispatchLayout(outShape);\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, outShape, this.workgroupSize);\n\n    this.shaderKey = 'sparseSegmentMean';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let segmentId = index / uniforms.segmentSize;\n        let count = sameSegmentIdCount[segmentId];\n        if (count != 0) {\n          ${\n        this.type === 'float32' ?\n            'setOutputAtIndex(index, segmentSum[index] / f32(count));' :\n            'setOutputAtIndexI32(index, segmentSum[index] / count);'}\n        }\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {fill} from '../kernels/Fill';\nimport {SparseSegmentIdCountProgram, SparseSegmentMeanProgram, SparseSegmentSumProgram} from '../sparse_segment_reduce_webgpu';\nimport {WebGPUProgram} from '../webgpu_program';\n\nexport function sparseSegmentReduce(\n    input: TensorInfo, indices: TensorInfo, segmentIds: TensorInfo,\n    isSum = false, backend: WebGPUBackend): TensorInfo {\n  const inputSize = util.sizeFromShape(input.shape);\n  const segmentSize = inputSize / input.shape[0];\n  const dtype = input.dtype;\n\n  // Note that the current implementation assumes that segmentIds values are\n  // sorted.\n  const numIndices = util.sizeFromShape(indices.shape);\n  const $segmentIds = backend.readSync(segmentIds.dataId) as TypedArray;\n  const lastSegmentIdPlusOne =\n      numIndices > 0 ? $segmentIds[numIndices - 1] + 1 : 0;\n  const outputRows = lastSegmentIdPlusOne;\n\n  let program: WebGPUProgram;\n  const outputShape = input.shape.slice();\n  outputShape[0] = outputRows;\n\n  const sparseSize = numIndices * segmentSize;\n  const sparseSegmentSum =\n      fill({backend, attrs: {shape: outputShape, value: 0, dtype}});\n  program = new SparseSegmentSumProgram(outputShape, sparseSize, dtype);\n  let uniformData = [\n    {type: 'int32', data: [segmentSize]}, {type: 'int32', data: [sparseSize]}\n  ];\n  const $sparseSegmentSum = backend.runWebGPUProgram(\n      program, [input, indices, segmentIds], dtype, uniformData,\n      sparseSegmentSum);\n\n  if (isSum) {\n    return $sparseSegmentSum;\n  }\n\n  const sparseSegmentIdCount =\n      fill({backend, attrs: {shape: [outputRows], value: 0, dtype: 'int32'}});\n  program = new SparseSegmentIdCountProgram(outputRows, segmentIds.shape);\n  const $sparseSegmentIdCount = backend.runWebGPUProgram(\n      program, [segmentIds], 'int32', null, sparseSegmentIdCount);\n\n  const sparseSegmentMean =\n      fill({backend, attrs: {shape: outputShape, value: 0, dtype}});\n  program = new SparseSegmentMeanProgram(outputShape, dtype);\n  uniformData = [{type: 'int32', data: [segmentSize]}];\n  const $sparseSegmentMean = backend.runWebGPUProgram(\n      program, [$sparseSegmentSum, $sparseSegmentIdCount], dtype, uniformData,\n      sparseSegmentMean);\n\n  backend.disposeData($sparseSegmentSum.dataId);\n  backend.disposeData($sparseSegmentIdCount.dataId);\n  return $sparseSegmentMean;\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SparseSegmentMean, SparseSegmentMeanInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {sparseSegmentReduce} from '../kernel_utils/sparse_segment_reduce';\n\nexport function sparseSegmentMean(\n    args: {inputs: SparseSegmentMeanInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {data, indices, segmentIds} = inputs;\n\n  return sparseSegmentReduce(data, indices, segmentIds, false, backend);\n}\n\nexport const sparseSegmentMeanConfig: KernelConfig = {\n  kernelName: SparseSegmentMean,\n  backendName: 'webgpu',\n  kernelFunc: sparseSegmentMean as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SparseSegmentSum, SparseSegmentSumInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {sparseSegmentReduce} from '../kernel_utils/sparse_segment_reduce';\n\nexport function sparseSegmentSum(\n    args: {inputs: SparseSegmentSumInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {data, indices, segmentIds} = inputs;\n\n  return sparseSegmentReduce(data, indices, segmentIds, true, backend);\n}\n\nexport const sparseSegmentSumConfig: KernelConfig = {\n  kernelName: SparseSegmentSum,\n  backendName: 'webgpu',\n  kernelFunc: sparseSegmentSum as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class TileProgram implements WebGPUProgram {\n  variableNames = ['A'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  rank: number;\n\n  constructor(aShape: number[], reps: number[]) {\n    const outputShape: number[] = new Array(aShape.length);\n    for (let i = 0; i < outputShape.length; i++) {\n      outputShape[i] = aShape[i] * reps[i];\n    }\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.rank = this.outputShape.length;\n    this.shaderKey = 'tile';\n  }\n\n  getUserCode(): string {\n    const sourceCoords = getSourceCoords(this.rank, 'uniforms.');\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let resRC = getCoordsFromIndex(index);\n          setOutputAtIndex(index, getA(${sourceCoords}));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\nfunction getSourceCoords(rank: number, uniformPrefix = ''): string {\n  if (rank >= 5) {\n    throw Error(`Tile for rank ${rank} is not yet supported`);\n  }\n  if (rank === 1) {\n    return `(resRC % ${uniformPrefix}aShape)`;\n  }\n\n  const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n  const sourceCoords = [];\n  for (let i = 0; i < rank; i++) {\n    sourceCoords.push(`(${currentCoords[i]} % ${uniformPrefix}aShape[${i}])`);\n  }\n  return sourceCoords.join();\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, KernelConfig, KernelFunc, TensorInfo, Tile, TileAttrs, TileInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {tileImplCPU} from '../kernel_utils/shared';\nimport {TileProgram} from '../tile_webgpu';\n\nexport function tile(\n    params: {inputs: TileInputs, backend: WebGPUBackend, attrs: TileAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = params;\n  const {x} = inputs;\n  const {reps} = attrs;\n\n  // tile gpu program cannot handle rank >= 5 case.\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string' ||\n      x.shape.length >= 5) {\n    // Even thought string tensor is always on CPU, just to be consistent on how\n    // to access tensor data.\n    const data = backend.readSync(x.dataId);\n    const value = x.dtype === 'string' ?\n        (data as Uint8Array[]).map(d => util.decodeString(d)) :\n        data as TypedArray;\n    const buf = buffer(x.shape, x.dtype, value);\n    const outBuf = tileImplCPU(buf, reps);\n    return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n  }\n\n  const program = new TileProgram(x.shape, reps);\n  const output = backend.runWebGPUProgram(program, [x], x.dtype);\n\n  return output;\n}\n\nexport const tileConfig: KernelConfig = {\n  kernelName: Tile,\n  backendName: 'webgpu',\n  kernelFunc: tile as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Rank, SparseToDense, SparseToDenseAttrs, SparseToDenseInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {scatterImplCPU} from '../kernel_utils/shared';\nimport {ScatterProgram} from '../scatter_webgpu';\n\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\nimport {tile} from './Tile';\n\nexport function sparseToDense(args: {\n  inputs: SparseToDenseInputs,\n  backend: WebGPUBackend,\n  attrs: SparseToDenseAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {sparseIndices, sparseValues, defaultValue} = inputs;\n  const {outputShape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n\n  const sumDupeIndices = false;\n  if (sparseValues.dtype === 'string') {\n    const indicesBuf = backend.bufferSync<Rank, 'int32'>(sparseIndices);\n    const updatesBuf = backend.bufferSync<Rank, 'string'>(sparseValues);\n    const $defaultValue = util.decodeString(\n        backend.readSync(defaultValue.dataId)[0] as Uint8Array);\n    const outBuf = scatterImplCPU(\n        indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates,\n        sliceRank, strides, $defaultValue, sumDupeIndices);\n    return backend.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);\n  }\n\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  const $sparseIndices = reshape({\n    inputs: {x: sparseIndices},\n    backend,\n    attrs: {shape: [numUpdates, sliceRank]}\n  });\n  const $sparseValues = sparseValues.shape.length ?\n      reshape({\n        inputs: {x: sparseValues},\n        backend,\n        attrs: {shape: [numUpdates, sliceSize]}\n      }) :\n      identity({inputs: {x: sparseValues}, backend});\n\n  const type = $sparseValues.dtype;\n  const zero =\n      backend.makeTensorInfo([], type, util.makeZerosTypedArray(1, type));\n\n  // Fill output tensor with the default value.\n  const $defaultValue = reshape({\n    inputs: {x: defaultValue},\n    backend,\n    attrs: {shape: Array(flattenShape.length).fill(1)}\n  });\n  const $denseValues =\n      tile({inputs: {x: $defaultValue}, backend, attrs: {reps: flattenShape}});\n\n  const size = util.sizeFromShape([numUpdates, sliceSize]);\n  const uniformData = [\n    {type: 'int32', data: [sliceRank]},\n    {type: 'int32', data: strides},\n    {type: 'int32', data: [size]},\n  ];\n\n  switch (numUpdates) {\n    case 0:\n      break;\n    case 1:\n      if (true) {\n        const program = new ScatterProgram(\n            [numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length,\n            $sparseValues.shape.length, strides, flattenShape, type,\n            sumDupeIndices);\n        backend.runWebGPUProgram(\n            program, [$sparseValues, $sparseIndices], type, uniformData,\n            $denseValues);\n      }\n      break;\n    default:\n      if (true) {\n        // First replace the default value with 0 at indices.\n        const program = new ScatterProgram(\n            [numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length,\n            zero.shape.length, strides, flattenShape, type, sumDupeIndices);\n        backend.runWebGPUProgram(\n            program, [zero, $sparseIndices], type, uniformData, $denseValues);\n      }\n      {\n        // Then replace 0 with the (sum of) sparse value(s) at indices.\n        const program = new ScatterProgram(\n            [numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length,\n            $sparseValues.shape.length, strides, flattenShape, type);\n        backend.runWebGPUProgram(\n            program, [$sparseValues, $sparseIndices], type, uniformData,\n            $denseValues);\n      }\n  }\n\n  const denseValues = reshape(\n      {inputs: {x: $denseValues}, backend, attrs: {shape: outputShape}});\n\n  backend.disposeData($sparseIndices.dataId);\n  backend.disposeData($sparseValues.dataId);\n  backend.disposeData($defaultValue.dataId);\n  backend.disposeData(zero.dataId);\n  backend.disposeData($denseValues.dataId);\n  return denseValues;\n}\n\nexport const sparseToDenseConfig: KernelConfig = {\n  kernelName: SparseToDense,\n  backendName: 'webgpu',\n  kernelFunc: sparseToDense as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, SplitV, SplitVAttrs, SplitVInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {slice} from './Slice';\n\nexport function splitV(\n    args: {inputs: SplitVInputs, backend: WebGPUBackend, attrs: SplitVAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {numOrSizeSplits, axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, x.shape)[0];\n  const splitSizes = backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);\n\n  const xRank = x.shape.length;\n  const begin = new Array(xRank).fill(0);\n  const size = x.shape.slice();\n\n  return splitSizes.map(s => {\n    const sliceSize = [...size];\n    sliceSize[$axis] = s;\n    const sliceT =\n        slice({inputs: {x}, backend, attrs: {begin, size: sliceSize}});\n    begin[$axis] += s;\n    return sliceT;\n  });\n}\n\nexport const splitVConfig: KernelConfig = {\n  kernelName: SplitV,\n  backendName: 'webgpu',\n  kernelFunc: splitV as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sqrt = unaryKernelFunc({opType: UnaryOpType.SQRT});\n\nexport const sqrtConfig: KernelConfig = {\n  kernelName: Sqrt,\n  backendName: 'webgpu',\n  kernelFunc: sqrt\n};\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Square, SquareInputs} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const squareConfig: KernelConfig = {\n  kernelName: Square,\n  backendName: 'webgpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as SquareInputs;\n    const webGPUBackend = backend as WebGPUBackend;\n    const program = new UnaryOpProgram(x.shape, UnaryOpType.SQUARE);\n    return webGPUBackend.runWebGPUProgram(program, [x], x.dtype);\n  }\n};\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const squaredDifference = binaryKernelFunc({\n  opType: BinaryOpType.SQUARED_DIFFERENCE,\n});\n\nexport const squaredDifferenceConfig: KernelConfig = {\n  kernelName: SquaredDifference,\n  backendName: 'webgpu',\n  kernelFunc: squaredDifference\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Step, StepAttrs, TensorInfo, UnaryInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\nexport function step(\n    {inputs, attrs, backend}:\n        {inputs: UnaryInputs, attrs: StepAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {x} = inputs;\n  const program =\n      new UnaryOpProgram(x.shape, UnaryOpType.STEP, 'stepAlpha : f32,');\n  const uniformData = [{type: 'float32', data: [attrs.alpha]}];\n  return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n}\n\nexport const stepConfig: KernelConfig = {\n  kernelName: Step,\n  backendName: 'webgpu',\n  kernelFunc: step as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class StridedSliceProgram implements WebGPUProgram {\n  variableNames = ['x'];\n  uniforms: string;\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  // TODO(xing.xu): Increase the workPerThread.\n  workPerThread = 1;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(destSize: number[]) {\n    this.outputShape = destSize;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n\n    const dtype = getCoordsDataType(this.outputShape.length);\n    this.uniforms = `begin : ${dtype},  strides : ${dtype}, `;\n    this.shaderKey = 'stridedSlice';\n  }\n\n  getUserCode(): string {\n    const rank = this.outputShape.length;\n    let newCoords = '';\n    if (rank === 1) {\n      newCoords = 'coords * uniforms.strides + uniforms.begin';\n    } else {\n      let outputAxis = 0;\n      newCoords =\n          this.outputShape\n              .map((_, i) => {\n                outputAxis++;\n                return this.outputShape.length === 1 ?\n                    `coords * uniforms.strides[${i}] + uniforms.begin[${i}]` :\n                    `coords[${outputAxis - 1}] * uniforms.strides[${\n                        i}] + uniforms.begin[${i}]`;\n              })\n              .join(',');\n    }\n\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.size) {\n           let coords = getCoordsFromIndex(index);\n           setOutputAtIndex(index, getX(${newCoords}));\n         }\n       }\n     `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, KernelConfig, KernelFunc, Rank, slice_util, StridedSlice, StridedSliceAttrs, StridedSliceInputs, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {stridedSliceImplCPU} from '../kernel_utils/shared';\n\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {StridedSliceProgram} from '../strided_slice_webgpu';\n\nexport function stridedSlice(args: {\n  inputs: StridedSliceInputs,\n  backend: WebGPUBackend,\n  attrs: StridedSliceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {\n    begin,\n    end,\n    strides,\n    beginMask,\n    endMask,\n    ellipsisMask,\n    newAxisMask,\n    shrinkAxisMask\n  } = attrs;\n\n  const {\n    finalShapeSparse,\n    finalShape,\n    isIdentity,\n    sliceDim0,\n    isSimpleSlice,\n    begin: $begin,\n    end: $end,\n    strides: $strides\n  } =\n      slice_util.sliceInfo(\n          x.shape, begin, end, strides, beginMask, endMask, ellipsisMask,\n          newAxisMask, shrinkAxisMask);\n\n  let result;\n\n  if (isIdentity) {\n    // Optimization #1, slice is a no-op plus reshape\n    result = reshape({inputs: {x}, backend, attrs: {shape: finalShape}});\n  } else if (sliceDim0 || isSimpleSlice) {\n    // Optimization #2, slice is memory contiguous (only occurs in dim 0)\n    util.assert(\n        x.shape.length >= 1,\n        () => `Input must have rank at least 1, got: ${x.shape.length}`);\n\n    const size = slice_util.computeOutShape($begin, $end, $strides);\n    // To tolerate begin[0] > end[0] (a 0-output slice), we min(begin, end).\n    const sliced = slice({inputs: {x}, backend, attrs: {begin: $begin, size}});\n    result =\n        reshape({inputs: {x: sliced}, backend, attrs: {shape: finalShape}});\n    backend.disposeData(sliced.dataId);\n  } else {\n    const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n    if (shouldExecuteOnCPU) {\n      const values = backend.readSync(x.dataId) as TypedArray;\n      const xBuf = buffer(x.shape, x.dtype, values) as TensorBuffer<Rank>;\n      const resultValues =\n          stridedSliceImplCPU(finalShapeSparse, xBuf, $strides, $begin);\n      result = backend.makeTensorInfo(finalShape, x.dtype, resultValues.values);\n    } else {\n      const program = new StridedSliceProgram(finalShapeSparse);\n      const uniformData =\n          [{type: 'int32', data: $begin}, {type: 'int32', data: $strides}];\n      const resultValues =\n          backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n      result = reshape(\n          {inputs: {x: resultValues}, backend, attrs: {shape: finalShape}});\n      backend.disposeData(resultValues.dataId);\n    }\n  }\n\n  return result;\n}\n\nexport const stridedSliceConfig: KernelConfig = {\n  kernelName: StridedSlice,\n  backendName: 'webgpu',\n  kernelFunc: stridedSlice as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringNGrams, StringNGramsAttrs, StringNGramsInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {stringNGramsImplCPU} from '../kernel_utils/shared';\n\nexport function stringNGrams(args: {\n  inputs: StringNGramsInputs,\n  backend: WebGPUBackend,\n  attrs: StringNGramsAttrs\n}): [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {\n    separator,\n    nGramWidths,\n    leftPad,\n    rightPad,\n    padWidth,\n    preserveShortSequences\n  } = attrs;\n  const {data, dataSplits} = inputs;\n  const $data = backend.readSync(data.dataId) as Uint8Array[];\n  const $dataSplits = backend.readSync(dataSplits.dataId) as Int32Array;\n\n  const [nGrams, nGramsSplits] = stringNGramsImplCPU(\n      $data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth,\n      preserveShortSequences);\n  return [\n    backend.makeTensorInfo([nGrams.length], 'string', nGrams),\n    backend.makeTensorInfo(dataSplits.shape, 'int32', nGramsSplits),\n  ];\n}\n\nexport const stringNGramsConfig: KernelConfig = {\n  kernelName: StringNGrams,\n  backendName: 'webgpu',\n  kernelFunc: stringNGrams as unknown as KernelFunc,\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {subImplCPU as cpuSub} from '../kernel_utils/shared';\n\nexport const sub = binaryKernelFunc(\n    {opType: BinaryOpType.SUB, cpuKernelImpl: cpuSub, supportsComplex: true});\n\nexport const subConfig: KernelConfig = {\n  kernelName: Sub,\n  backendName: 'webgpu',\n  kernelFunc: sub\n};\n", "/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tan} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const tan = unaryKernelFunc({opType: UnaryOpType.TAN});\n\nexport const tanConfig: KernelConfig = {\n  kernelName: Tan,\n  backendName: 'webgpu',\n  kernelFunc: tan\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tanh} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const tanh = unaryKernelFunc({opType: UnaryOpType.TANH});\n\nexport const tanhConfig: KernelConfig = {\n  kernelName: Tanh,\n  backendName: 'webgpu',\n  kernelFunc: tanh\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, TensorInfo, TensorScatterUpdate, TensorScatterUpdateAttrs, TensorScatterUpdateInputs, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ScatterProgram} from '../scatter_webgpu';\n\nimport {reshape} from './Reshape';\nimport {tile} from './Tile';\n\nexport function tensorScatterUpdate(args: {\n  inputs: TensorScatterUpdateInputs,\n  backend: WebGPUBackend,\n  attrs: TensorScatterUpdateAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {tensor, indices, updates} = inputs;\n  const {} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(updates, indices, tensor.shape);\n\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  if (outputSize === 0) {\n    return backend.makeTensorInfo(tensor.shape, indices.dtype);\n  }\n\n  const toDispose = [];\n\n  const flattenIndices = reshape(\n      {inputs: {x: indices}, backend, attrs: {shape: [numUpdates, sliceRank]}});\n  toDispose.push(flattenIndices);\n  const flattenX = reshape(\n      {inputs: {x: updates}, backend, attrs: {shape: [numUpdates, sliceSize]}});\n  toDispose.push(flattenX);\n  const flattenTensor =\n      reshape({inputs: {x: tensor}, backend, attrs: {shape: flattenShape}});\n  toDispose.push(flattenTensor);\n  const output = tile({\n    inputs: {x: flattenTensor},\n    backend,\n    attrs: {reps: Array(flattenShape.length).fill(1)}\n  });\n  const program = new ScatterProgram(\n      [numUpdates, sliceSize], sliceRank, flattenIndices.shape.length,\n      flattenX.shape.length, strides, flattenShape, tensor.dtype, false);\n  const size = util.sizeFromShape([numUpdates, sliceSize]);\n  const uniformData = [\n    {type: 'int32', data: [sliceRank]},\n    {type: 'int32', data: strides},\n    {type: 'int32', data: [size]},\n  ];\n  const res = backend.runWebGPUProgram(\n      program, [flattenX, flattenIndices], flattenTensor.dtype, uniformData,\n      output);\n  toDispose.push(res);\n\n  const reshaped =\n      reshape({inputs: {x: res}, backend, attrs: {shape: tensor.shape}});\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n\n  return reshaped;\n}\n\nexport const tensorScatterUpdateConfig: KernelConfig = {\n  kernelName: TensorScatterUpdate,\n  backendName: 'webgpu',\n  kernelFunc: tensorScatterUpdate as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\n// Based on Algorithm 2 of Bitonic Top K, ref:\n// https://anilshanbhag.in/static/papers/gputopk_sigmod18.pdf\n// The original algorithm is based on computing the top K only, however\n// since for TFJS we require the indices of the top K values as well then the\n// algorithm found here is a bit modified. Rather than producing the values\n// at each step, the indices containing the top K are generated instead.\n// The output values are not generated to reduce the number of outputs in the\n// GPU, the values can easily be retrieved from the indices using a gather\n// op.\n\nexport class SwapProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'indices'];\n  uniforms: string;\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  size = true;\n\n  constructor(shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.uniforms = `inputSize : i32, firstPass : i32, negativeInf : f32,\n        dir : i32, inc : i32,`;\n    this.shaderKey = 'swap';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n        ${main('index')} {\n          if (index < uniforms.size) {\n            let outC = getCoordsFromIndex(index);\n            let batch = outC[0];\n            let elemIdx = outC[1];\n            // We compare elements pair-wise within a group of size 2 * inc.\n            // The comparing rule for each group alternates between ascending\n            // and descending. Within each group, we compare each pair at\n            // positions i and i+inc. To decide whether an element at position i\n            // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\n            // inc, it is in the first half of the group, we denote it as x0,\n            // otherwise we denote it as x1.\n            // For example, as shown in the Bitonic top K paper referenced\n            // above, Figure5(a) shows that element[1] is in the second half of\n            // the group when group size is 2, but it is in the first half of\n            // the group when group size is 4.\n            let isFirstInPair = elemIdx % (2 * uniforms.inc) < uniforms.inc;\n            var i = 0;\n            if (isFirstInPair) {\n              i = elemIdx;\n            } else {\n              i = elemIdx - uniforms.inc;\n            }\n\n            var i0 = 0;\n            if (uniforms.firstPass == 1) {\n              i0 = i;\n            } else {\n              i0 = i32(getIndices(batch, i));\n            }\n\n            var i1 = 0;\n            if (uniforms.firstPass == 1) {\n              i1 = i + uniforms.inc;\n            } else {\n              i1 = i32(getIndices(batch, i + uniforms.inc));\n            }\n\n            var x0 = f32(0.0);\n            var x1 = f32(0.0);\n            if (i0 < uniforms.inputSize) {\n              x0 = getX(batch, i0);\n            } else {\n              x0 = uniforms.negativeInf;\n            }\n            if (i1 < uniforms.inputSize) {\n              x1 = getX(batch, i1);\n            } else {\n              x1 = uniforms.negativeInf;\n            }\n\n            let reverse = elemIdx % (2 * uniforms.dir) >= uniforms.dir;\n            let isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\n            if (reverse == isGreater) {\n              // Elements in opposite order of direction\n              let iTemp = i0;\n              i0 = i1;\n              i1 = iTemp;\n            }\n            if (isFirstInPair) {\n              setOutputAtIndex(index, f32(i0));\n            } else {\n              setOutputAtIndex(index, f32(i1));\n            }\n          }\n        }\n      `;\n    return userCode;\n  }\n}\n\nexport class MergeProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'indices'];\n  uniforms: string;\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  size = true;\n\n  constructor(shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    // |n| Size of the original input of TopK\n    // |firstPass| indicates if this is the first time swap is being used which\n    // means no indices input containing the top K is present yet.\n    // |k| Top k elements desired\n    this.uniforms = `inputSize : i32, firstPass : i32, k : i32,`;\n    this.shaderKey = 'merge';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n        ${main('index')} {\n          if (index < uniforms.size) {\n            let outC = getCoordsFromIndex(index);\n            let batch = outC[0];\n            let elemIdx = outC[1];\n            // The output size is half of the previous size.\n            // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _\n            // (k=4), we only need to output the indices at positions |, the\n            // indices at positions _ can be thrown away, see Figure5(b) After\n            // Phase 2 (Merge phase) in the Bitonic Top K paper referenced\n            // above.\n            // For example, the paper shows we only need to output the orange\n            // bars. The output sequence should look like this | | | | | | | |.\n            // Because the sequence is halved, to map the output index back to\n            // the previous sequence to find the corresponding value, we need\n            // to double the index. When we double the index, we basically\n            // interpolate a position, so 2i looks like\n            // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k\n            // position of each 2k positions by - elemIdx % k. E.g. for output\n            // at index 4,5,6,7, we want to get the corresponding element at\n            // original index 8,9,10,11, for output at index 8,9,10,11,\n            // we want to get the corresponding element at original index\n            // 16,17,18,19, so on and so forth.\n\n            var i = 0;\n            if (elemIdx < uniforms.k) {\n              i = elemIdx;\n            } else {\n              i = elemIdx * 2 - elemIdx % uniforms.k;\n            }\n            var i0 = 0;\n            if (uniforms.firstPass == 1) {\n              i0 = i;\n            } else {\n              i0 = i32(getIndices(batch, i));\n            }\n            var i1 = 0;\n            if (uniforms.firstPass == 1) {\n              i1 = i + uniforms.k;\n            } else {\n              i1 = i32(getIndices(batch, i + uniforms.k));\n            }\n\n            let x0 = getX(batch, i0);\n            var x1 = f32(0.0);\n            if (i1 < uniforms.inputSize) {\n              x1 = getX(batch, i1);\n            } else {\n              x1 = x0;\n            }\n\n            if (x0 >= x1) {\n              setOutputAtIndex(index, f32(i0));\n            } else {\n              setOutputAtIndex(index, f32(i1));\n            }\n          }\n        }\n      `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, TensorInfo, TopK, TopKAttrs, TopKInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {topKImplCPU} from '../kernel_utils/shared';\nimport {MergeProgram, SwapProgram} from '../top_k_webgpu';\nimport {fill} from './Fill';\nimport {gatherV2} from './GatherV2';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\n\nfunction disposeIntermediateTensorInfoOrNull(\n    backend: WebGPUBackend, tensorInfo: TensorInfo) {\n  if (tensorInfo !== null) {\n    backend.disposeData(tensorInfo.dataId);\n  }\n}\n\nfunction roundUpToPow2(num: number) {\n  let pow2 = 1;\n  while (pow2 < num) {\n    pow2 *= 2;\n  }\n  return pow2;\n}\n\n// Based on Algorithm 2 of Bitonic Top K, ref:\n// https://anilshanbhag.in/static/papers/gputopk_sigmod18.pdf\nexport function topK(\n    args: {inputs: TopKInputs, backend: WebGPUBackend, attrs: TopKAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {k, sorted}= attrs;\n\n  const xShape = x.shape;\n  const lastDim = xShape[xShape.length - 1];\n\n  if (backend.shouldExecuteOnCPU([x])) {\n    const xVals = backend.readSync(x.dataId) as TypedArray;\n    const [allTopKVals, allTopKIndices] =\n        topKImplCPU(xVals, xShape, x.dtype as NumericDataType, k, sorted);\n\n    return [\n      backend.makeTensorInfo(\n          allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),\n      backend.makeTensorInfo(\n          allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)\n    ];\n  }\n\n  if (k === 0) {\n    xShape[xShape.length - 1] = 0;\n    return [\n      backend.makeTensorInfo(xShape, x.dtype, []),\n      backend.makeTensorInfo(xShape, 'int32', [])\n    ];\n  }\n\n  if (lastDim === 1 /* firstPass */) {\n    return [\n      x, fill({attrs: {shape: xShape, dtype: 'int32', value: 0}, backend})\n    ];\n  }\n\n  // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n  const xSize = util.sizeFromShape(xShape);\n  const batch = xSize / lastDim;\n  const x2D = reshape({inputs: {x}, attrs: {shape: [batch, lastDim]}, backend});\n\n  const kPow2 = roundUpToPow2(k);\n  const lastDimPow2 = roundUpToPow2(lastDim);\n\n  // Only the indices containing the top K are kept at every step to reduce\n  // number of outputs in the GPU algorithms, so once the final set of indices\n  // is computed then gather is used to grab the corresponding values\n  // from the original input.\n  let indices: TensorInfo = null;\n\n  // GPU algorithm always takes in an indices input but this input is not used\n  // on the first run of a GPU algorithm, therefore if indices is null we simply\n  // pass in x2D instead of it but the value will not actually be used\n  const getInputs = () => indices === null ? [x2D, x2D] : [x2D, indices];\n\n  const runSwap = (dir: number, inc: number, shape: number[]) => {\n    const inputs = getInputs();\n    const program = new SwapProgram(shape);\n    const firstPass = indices === null ? 1 : 0;\n    const uniformDataSwap = [\n        {type: 'int32', data: [lastDim]},\n        {type: 'int32', data: [firstPass]},\n        {type: 'float32', data: [Number.NEGATIVE_INFINITY]},\n        {type: 'int32', data: [dir]},\n        {type: 'int32', data: [inc]}\n    ];\n    const prevIndices = indices;\n    indices = backend.runWebGPUProgram(\n        program, inputs, 'int32', uniformDataSwap);\n    disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n  };\n\n  // Step 1: local sort\n  for (let len = 1; len < kPow2; len *= 2) {\n    const dir = len * 2;\n    for (let inc = len; inc >= 1; inc /= 2) {\n      runSwap(dir, inc, [batch, lastDimPow2]);\n    }\n  }\n\n  // Step 2: merge\n  for (let indicesSize = lastDimPow2; indicesSize > kPow2; indicesSize /= 2) {\n    const inputs = getInputs();\n    const mergeProgram = new MergeProgram([batch, indicesSize / 2]);\n    const firstPass = indices === null ? 1 : 0;\n    const uniformDataMerge = [\n        {type: 'int32', data: [lastDim]},\n        {type: 'int32', data: [firstPass]},\n        {type: 'int32', data: [kPow2]}\n    ];\n    const prevIndices = indices;\n    indices = backend.runWebGPUProgram(\n        mergeProgram, inputs, 'int32', uniformDataMerge);\n    disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n\n    // Step 3: rebuild\n    const len = kPow2 / 2;\n    const dir = len * 2;\n    for (let inc = len; inc >= 1; inc /= 2) {\n      runSwap(dir, inc, indices.shape);\n    }\n  }\n\n  // Keep only the requested top K results instead of kPow2\n  let prevIndices = indices;\n  indices = slice(\n      {inputs: {x: indices}, backend, attrs: {begin: 0, size: [batch, k]}});\n  disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n\n  // Gather values on last dimension\n  let values = gatherV2(\n      {inputs: {x: x2D, indices}, backend, attrs: {axis: 1, batchDims: 1}});\n  disposeIntermediateTensorInfoOrNull(backend, x2D);\n\n  // Reshape back to the original input shape, except that the last\n  // dimension is k.\n  const newShape = xShape.slice(0, -1);\n  newShape.push(k);\n\n  prevIndices = indices;\n  indices = reshape({inputs: {x: indices}, attrs: {shape: newShape}, backend});\n  disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n\n  const prevValues = values;\n  values = reshape({inputs: {x: values}, attrs: {shape: newShape}, backend});\n  disposeIntermediateTensorInfoOrNull(backend, prevValues);\n\n  return [values, indices];\n}\n\nexport const topKConfig: KernelConfig = {\n  kernelName: TopK,\n  backendName: 'webgpu',\n  kernelFunc: topK as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class TransformProgram implements WebGPUProgram {\n  variableNames = ['Image', 'Transforms'];\n  outputShape: number[];\n  uniforms = 'interpolationModeId : i32, fillModeId : i32, fillValue : f32,';\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(outShape: [number, number, number, number]) {\n    this.outputShape = outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = 'transform';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n          fn mapCoord(outCoord : f32, len : f32) -> f32{\n            var inCoord = outCoord;\n            if(uniforms.fillModeId == 2) {\n              if (inCoord < 0.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz2 = 2.0 * len;\n                  if (inCoord < sz2) {\n                    inCoord = sz2 * f32(i32(f32(-inCoord / sz2))) +\n                    inCoord;\n                  }\n                  if (inCoord < -len) {\n                    inCoord = inCoord + sz2;\n                  } else {\n                    inCoord = -inCoord - 1.0;\n                  }\n                }\n              } else if (inCoord > len - 1.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz2 = 2.0 * len;\n                  inCoord = inCoord - sz2 * f32(i32(f32(inCoord / sz2)));\n                  if (inCoord >= len) {\n                    inCoord = sz2 - inCoord - 1.0;\n                  }\n                }\n              }\n              return clamp(inCoord, 0.0, len - 1.0);\n            } else if (uniforms.fillModeId == 3) {\n              if (inCoord < 0.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz = len - 1.0;\n                  inCoord = inCoord + len * (f32(i32(f32(-inCoord / sz))) + 1.0);\n                }\n              } else if (inCoord > len - 1.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz = len - 1.0;\n                  inCoord = inCoord - len * f32(i32(f32(inCoord / sz)));\n                }\n              }\n              return clamp(inCoord, 0.0, len - 1.0);\n            } else if (uniforms.fillModeId == 4) {\n              return clamp(outCoord, 0.0, len - 1.0);\n            }\n            return outCoord;\n          }\n          fn readWithFillValue(batch : i32, coordY : i32, coordX : i32,\n            channel : i32) -> f32 {\n            var outputValue : f32;\n            if (0 <= coordY && coordY < uniforms.imageShape[1] && 0 <= coordX && coordX < uniforms.imageShape[2]) {\n                outputValue = getImage(batch, coordY, coordX, channel);\n            } else {\n              outputValue = uniforms.fillValue;\n            }\n            return outputValue;\n          }\n\n          ${main('index')} {\n            if (index < uniforms.size) {\n              let coords = getCoordsFromIndex(index);\n              var outputValue : f32;\n              let batch = coords[0];\n              let x = coords[2];\n              let y = coords[1];\n              let channel = coords[3];\n              let xf = f32(x);\n              let yf = f32(y);\n              let a1 = getTransforms(batch, 0);\n              let a2 = getTransforms(batch, 1);\n              let a3 = getTransforms(batch, 2);\n              let b1 = getTransforms(batch, 3);\n              let b2 = getTransforms(batch, 4);\n              let b3 = getTransforms(batch, 5);\n              let c1 = getTransforms(batch, 6);\n              let c2 = getTransforms(batch, 7);\n              let projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = uniforms.fillValue;\n              } else {\n                let inX = (a1 * xf + a2 * yf + a3) / projection;\n                let inY = (b1 * xf + b2 * yf + b3) / projection;\n                let mapX = mapCoord(inX, f32(uniforms.imageShape[2]));\n                let mapY = mapCoord(inY, f32(uniforms.imageShape[1]));\n\n                if (uniforms.interpolationModeId == 1) {\n                  let coordY = i32(round(mapY));\n                  let coordX = i32(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  let yFloor = floor(mapY);\n                  let xFloor = floor(mapX);\n                  let yCeil = yFloor + 1.0;\n                  let xCeil = xFloor + 1.0;\n                  let valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, i32(yFloor), i32(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, i32(yFloor), i32(xCeil), channel);\n                  let valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, i32(yCeil), i32(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, i32(yCeil), i32(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutputAtIndex(index, outputValue);\n            }\n          }\n        `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transform, TransformAttrs, TransformInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {TransformProgram} from '../transform_webgpu';\n\nexport function transform(args: {\n  inputs: TransformInputs,\n  backend: WebGPUBackend,\n  attrs: TransformAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {image, transforms} = inputs;\n  const {interpolation, fillMode, fillValue, outputShape} = attrs;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n  const [outHeight, outWidth] =\n      outputShape != null ? outputShape : [imageHeight, imageWidth];\n  const outShape =\n      [batch, outHeight, outWidth,\n       numChannels] as [number, number, number, number];\n\n  const program = new TransformProgram(outShape);\n  const interpolationModeId = interpolation === 'nearest' ? 1 : 2;\n  let fillModeId: number;\n  switch (fillMode) {\n    case 'constant':\n      fillModeId = 1;\n      break;\n    case 'reflect':\n      fillModeId = 2;\n      break;\n    case 'wrap':\n      fillModeId = 3;\n      break;\n    case 'nearest':\n      fillModeId = 4;\n      break;\n    default:\n      fillModeId = 1;\n      break;\n  }\n  const uniformData = [\n    {type: 'int32', data: [interpolationModeId]},\n    {type: 'int32', data: [fillModeId]}, {type: 'float32', data: [fillValue]}\n  ];\n  return backend.runWebGPUProgram(\n      program, [image, transforms], 'float32', uniformData);\n}\n\nexport const transformConfig: KernelConfig = {\n  kernelName: Transform,\n  backendName: 'webgpu',\n  kernelFunc: transform as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unpack, UnpackAttrs, UnpackInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\n\nexport function unpack(\n    args:\n        {inputs: UnpackInputs, backend: WebGPUBackend, attrs: UnpackAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {value} = inputs;\n  let {axis} = attrs;\n\n  if (axis < 0) {\n    axis += value.shape.length;\n  }\n\n  const x = value;\n  const xRank = x.shape.length;\n\n  const num = value.shape[axis];\n  const outShape: number[] = new Array(xRank - 1);\n  let outIndex = 0;\n  for (let i = 0; i < xRank; i++) {\n    if (i !== axis) {\n      outShape[outIndex++] = x.shape[i];\n    }\n  }\n\n  const toDispose = [];\n\n  const begin = new Array(xRank).fill(0);\n  const size = x.shape.slice();\n  size[axis] = 1;\n  const res: TensorInfo[] = new Array(num);\n  for (let i = 0; i < res.length; i++) {\n    begin[axis] = i;\n    const sliced = slice({inputs: {x}, backend, attrs: {begin, size}});\n    const reshaped =\n        reshape({inputs: {x: sliced}, backend, attrs: {shape: outShape}});\n    res[i] = reshaped;\n\n    toDispose.push(sliced);\n  }\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n  return res;\n}\n\nexport const unpackConfig: KernelConfig = {\n  kernelName: Unpack,\n  backendName: 'webgpu',\n  kernelFunc: unpack as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType} from '@tensorflow/tfjs-core';\n\nimport {atomicAddSnippet} from './shader_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class UnsortedSegmentSumProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'segmentIds'];\n  uniforms = 'numSegments : i32, xSize: i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  type: DataType;\n\n  constructor(inShape: number[], outShape: number[], outputDtype: DataType) {\n    this.outputShape = outShape;\n    this.dispatchLayout = flatDispatchLayout(inShape);\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, inShape, this.workgroupSize);\n    if (outputDtype !== 'float32' && outputDtype !== 'int32') {\n      throw new Error(`UnsortedSegmentSum only supports float32 and int32\n              types, does not support ${outputDtype} type.`);\n    }\n    this.type = outputDtype;\n    this.shaderKey = 'unsortedSegmentSum';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.xSize) {\n        let coords = getXCoordsFromIndex(index);\n        let b = coords[0];\n        let inCol = coords[1];\n\n        let segmentId = i32(getSegmentIds(inCol));\n        if (segmentId >= 0) {\n          let flatIndex = b * uniforms.numSegments + segmentId % uniforms.numSegments;\n          let value = getX(b, inCol);\n\n          ${\n        atomicAddSnippet(\n            '&result[flatIndex]', 'value', this.type as 'float32' | 'int32')}\n        }\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n", "/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, TensorInfo, UnsortedSegmentSum, UnsortedSegmentSumAttrs, UnsortedSegmentSumInputs, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnsortedSegmentSumProgram} from '../unsorted_segment_sum_webgpu';\n\nimport {fill} from './Fill';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function unsortedSegmentSum(args: {\n  inputs: UnsortedSegmentSumInputs,\n  backend: WebGPUBackend,\n  attrs: UnsortedSegmentSumAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, segmentIds} = inputs;\n  const {numSegments} = attrs;\n\n  const xRank = x.shape.length;\n\n  const toDispose = [];\n\n  let axis = 0;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n    toDispose.push(permutedX);\n    axis = backend_util.getInnerMostAxes(1, xRank)[0];\n  }\n\n  const outShape = backend_util.segment_util.computeOutShape(\n      permutedX.shape, axis, numSegments);\n  const inSize = util.sizeFromShape([permutedX.shape[axis]]);\n  const a2D =\n      reshape({inputs: {x: permutedX}, backend, attrs: {shape: [-1, inSize]}});\n  toDispose.push(a2D);\n\n  const dtype = x.dtype;\n  const shape = [a2D.shape[0], numSegments];\n  const output = fill({backend, attrs: {shape, value: 0, dtype}});\n  const program = new UnsortedSegmentSumProgram(a2D.shape, shape, dtype);\n  const uniformData = [\n    {type: 'int32', data: [numSegments]},\n    {type: 'int32', data: [util.sizeFromShape(a2D.shape)]}\n  ];\n  const segResult = backend.runWebGPUProgram(\n      program, [a2D, segmentIds], dtype, uniformData, output);\n\n  const reshaped =\n      reshape({inputs: {x: segResult}, backend, attrs: {shape: outShape}});\n  toDispose.push(segResult);\n  let result = reshaped;\n  if (permutation != null) {\n    toDispose.push(reshaped);\n    const perm = backend_util.getUndoAxesPermutation(permutation);\n    result = transpose({inputs: {x: result}, backend, attrs: {perm}});\n  }\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n  return result;\n}\n\nexport const unsortedSegmentSumConfig: KernelConfig = {\n  kernelName: UnsortedSegmentSum,\n  backendName: 'webgpu',\n  kernelFunc: unsortedSegmentSum as unknown as KernelFunc\n};\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {_fusedMatMulConfig} from './kernels/_FusedMatMul';\nimport {absConfig} from './kernels/Abs';\nimport {acosConfig} from './kernels/Acos';\nimport {acoshConfig} from './kernels/Acosh';\nimport {addConfig} from './kernels/Add';\nimport {addNConfig} from './kernels/AddN';\nimport {allConfig} from './kernels/All';\nimport {anyConfig} from './kernels/Any';\nimport {argMaxConfig} from './kernels/ArgMax';\nimport {argMinConfig} from './kernels/ArgMin';\nimport {asinConfig} from './kernels/Asin';\nimport {asinhConfig} from './kernels/Asinh';\nimport {atanConfig} from './kernels/Atan';\nimport {atan2Config} from './kernels/Atan2';\nimport {atanhConfig} from './kernels/Atanh';\nimport {avgPoolConfig} from './kernels/AvgPool';\nimport {avgPool3DConfig} from './kernels/AvgPool3D';\nimport {avgPool3DGradConfig} from './kernels/AvgPool3DGrad';\nimport {avgPoolGradConfig} from './kernels/AvgPoolGrad';\nimport {batchMatMulConfig} from './kernels/BatchMatMul';\nimport {batchToSpaceNDConfig} from './kernels/BatchToSpaceND';\nimport {bincountConfig} from './kernels/Bincount';\nimport {broadcastArgsConfig} from './kernels/BroadcastArgs';\nimport {castConfig} from './kernels/Cast';\nimport {ceilConfig} from './kernels/Ceil';\nimport {clipByValueConfig} from './kernels/ClipByValue';\nimport {complexConfig} from './kernels/Complex';\nimport {complexAbsConfig} from './kernels/ComplexAbs';\nimport {concatConfig} from './kernels/Concat';\nimport {conv2DConfig} from './kernels/Conv2D';\nimport {conv2DBackpropFilterConfig} from './kernels/Conv2DBackpropFilter';\nimport {conv2DBackpropInputConfig} from './kernels/Conv2DBackpropInput';\nimport {conv3DConfig} from './kernels/Conv3D';\nimport {conv3DBackpropFilterV2Config} from './kernels/Conv3DBackpropFilterV2';\nimport {conv3DBackpropInputV2Config} from './kernels/Conv3DBackpropInputV2';\nimport {cosConfig} from './kernels/Cos';\nimport {coshConfig} from './kernels/Cosh';\nimport {cropAndResizeConfig} from './kernels/CropAndResize';\nimport {cumprodConfig} from './kernels/Cumprod';\nimport {cumsumConfig} from './kernels/Cumsum';\nimport {denseBincountConfig} from './kernels/DenseBincount';\nimport {depthToSpaceConfig} from './kernels/DepthToSpace';\nimport {depthwiseConv2dNativeConfig} from './kernels/DepthwiseConv2dNative';\nimport {depthwiseConv2dNativeBackpropFilterConfig} from './kernels/DepthwiseConv2dNativeBackpropFilter';\nimport {depthwiseConv2dNativeBackpropInputConfig} from './kernels/DepthwiseConv2dNativeBackpropInput';\nimport {diagConfig} from './kernels/Diag';\nimport {dilation2DConfig} from './kernels/Dilation2D';\nimport {dilation2DBackpropFilterConfig} from './kernels/Dilation2DBackpropFilter';\nimport {dilation2DBackpropInputConfig} from './kernels/Dilation2DBackpropInput';\nimport {drawConfig} from './kernels/Draw';\nimport {einsumConfig} from './kernels/Einsum';\nimport {eluConfig} from './kernels/Elu';\nimport {eluGradConfig} from './kernels/EluGrad';\nimport {equalConfig} from './kernels/Equal';\nimport {erfConfig} from './kernels/Erf';\nimport {expConfig} from './kernels/Exp';\nimport {expandDimsConfig} from './kernels/ExpandDims';\nimport {expm1Config} from './kernels/Expm1';\nimport {fftConfig} from './kernels/FFT';\nimport {fillConfig} from './kernels/Fill';\nimport {flipLeftRightConfig} from './kernels/FlipLeftRight';\nimport {floorConfig} from './kernels/Floor';\nimport {floorDivConfig} from './kernels/FloorDiv';\nimport {fromPixelsConfig} from './kernels/FromPixels';\nimport {fusedBatchNormConfig} from './kernels/FusedBatchNorm';\nimport {fusedConv2DConfig} from './kernels/FusedConv2D';\nimport {fusedDepthwiseConv2DConfig} from './kernels/FusedDepthwiseConv2D';\nimport {gatherNdConfig} from './kernels/GatherNd';\nimport {gatherV2Config} from './kernels/GatherV2';\nimport {greaterConfig} from './kernels/Greater';\nimport {greaterEqualConfig} from './kernels/GreaterEqual';\nimport {identityConfig} from './kernels/Identity';\nimport {ifftConfig} from './kernels/IFFT';\nimport {imagConfig} from './kernels/Imag';\nimport {isFiniteConfig} from './kernels/IsFinite';\nimport {isInfConfig} from './kernels/IsInf';\nimport {isNaNConfig} from './kernels/IsNaN';\nimport {leakyReluConfig} from './kernels/LeakyRelu';\nimport {lessConfig} from './kernels/Less';\nimport {lessEqualConfig} from './kernels/LessEqual';\nimport {linSpaceConfig} from './kernels/LinSpace';\nimport {logConfig} from './kernels/Log';\nimport {log1pConfig} from './kernels/Log1p';\nimport {logicalAndConfig} from './kernels/LogicalAnd';\nimport {logicalNotConfig} from './kernels/LogicalNot';\nimport {logicalOrConfig} from './kernels/LogicalOr';\nimport {lrnConfig} from './kernels/LRN';\nimport {lrnGradConfig} from './kernels/LRNGrad';\nimport {maxConfig} from './kernels/Max';\nimport {maximumConfig} from './kernels/Maximum';\nimport {maxPoolConfig} from './kernels/MaxPool';\nimport {maxPool3DConfig} from './kernels/MaxPool3D';\nimport {maxPool3DGradConfig} from './kernels/MaxPool3DGrad';\nimport {maxPoolGradConfig} from './kernels/MaxPoolGrad';\nimport {maxPoolWithArgmaxConfig} from './kernels/MaxPoolWithArgmax';\nimport {meanConfig} from './kernels/Mean';\nimport {minConfig} from './kernels/Min';\nimport {minimumConfig} from './kernels/Minimum';\nimport {mirrorPadConfig} from './kernels/MirrorPad';\nimport {modConfig} from './kernels/Mod';\nimport {multinomialConfig} from './kernels/Multinomial';\nimport {multiplyConfig} from './kernels/Multiply';\nimport {negConfig} from './kernels/Neg';\nimport {nonMaxSuppressionV3Config} from './kernels/NonMaxSuppressionV3';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {notEqualConfig} from './kernels/NotEqual';\nimport {oneHotConfig} from './kernels/OneHot';\nimport {onesLikeConfig} from './kernels/OnesLike';\nimport {packConfig} from './kernels/Pack';\nimport {padV2Config} from './kernels/PadV2';\nimport {powConfig} from './kernels/Pow';\nimport {preluConfig} from './kernels/Prelu';\nimport {prodConfig} from './kernels/Prod';\nimport {rangeConfig} from './kernels/Range';\nimport {realConfig} from './kernels/Real';\nimport {realDivConfig} from './kernels/RealDiv';\nimport {reciprocalConfig} from './kernels/Reciprocal';\nimport {reluConfig} from './kernels/Relu';\nimport {relu6Config} from './kernels/Relu6';\nimport {reshapeConfig} from './kernels/Reshape';\nimport {resizeBilinearConfig} from './kernels/ResizeBilinear';\nimport {resizeBilinearGradConfig} from './kernels/ResizeBilinearGrad';\nimport {resizeNearestNeighborConfig} from './kernels/ResizeNearestNeighbor';\nimport {resizeNearestNeighborGradConfig} from './kernels/ResizeNearestNeighborGrad';\nimport {reverseConfig} from './kernels/Reverse';\nimport {rotateWithOffsetConfig} from './kernels/RotateWithOffset';\nimport {roundConfig} from './kernels/Round';\nimport {rsqrtConfig} from './kernels/Rsqrt';\nimport {scatterNdConfig} from './kernels/ScatterNd';\nimport {searchSortedConfig} from './kernels/SearchSorted';\nimport {selectConfig} from './kernels/Select';\nimport {seluConfig} from './kernels/Selu';\nimport {sigmoidConfig} from './kernels/Sigmoid';\nimport {signConfig} from './kernels/Sign';\nimport {sinConfig} from './kernels/Sin';\nimport {sinhConfig} from './kernels/Sinh';\nimport {sliceConfig} from './kernels/Slice';\nimport {softmaxConfig} from './kernels/Softmax';\nimport {softplusConfig} from './kernels/Softplus';\nimport {spaceToBatchNDConfig} from './kernels/SpaceToBatchND';\nimport {sparseSegmentMeanConfig} from './kernels/SparseSegmentMean';\nimport {sparseSegmentSumConfig} from './kernels/SparseSegmentSum';\nimport {sparseToDenseConfig} from './kernels/SparseToDense';\nimport {splitVConfig} from './kernels/SplitV';\nimport {sqrtConfig} from './kernels/Sqrt';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {stepConfig} from './kernels/Step';\nimport {stridedSliceConfig} from './kernels/StridedSlice';\nimport {stringNGramsConfig} from './kernels/StringNGrams';\nimport {subConfig} from './kernels/Sub';\nimport {sumConfig} from './kernels/Sum';\nimport {tanConfig} from './kernels/Tan';\nimport {tanhConfig} from './kernels/Tanh';\nimport {tensorScatterUpdateConfig} from './kernels/TensorScatterUpdate';\nimport {tileConfig} from './kernels/Tile';\nimport {topKConfig} from './kernels/TopK';\nimport {transformConfig} from './kernels/Transform';\nimport {transposeConfig} from './kernels/Transpose';\nimport {unpackConfig} from './kernels/Unpack';\nimport {unsortedSegmentSumConfig} from './kernels/UnsortedSegmentSum';\nimport {zerosLikeConfig} from './kernels/ZerosLike';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  _fusedMatMulConfig,\n  absConfig,\n  acosConfig,\n  acoshConfig,\n  addConfig,\n  addNConfig,\n  allConfig,\n  anyConfig,\n  argMaxConfig,\n  argMinConfig,\n  asinConfig,\n  asinhConfig,\n  atanConfig,\n  atan2Config,\n  atanhConfig,\n  avgPoolConfig,\n  avgPool3DConfig,\n  avgPool3DGradConfig,\n  avgPoolGradConfig,\n  batchMatMulConfig,\n  batchToSpaceNDConfig,\n  bincountConfig,\n  broadcastArgsConfig,\n  castConfig,\n  ceilConfig,\n  clipByValueConfig,\n  complexConfig,\n  complexAbsConfig,\n  concatConfig,\n  conv2DConfig,\n  conv2DBackpropFilterConfig,\n  conv2DBackpropInputConfig,\n  conv3DConfig,\n  conv3DBackpropFilterV2Config,\n  conv3DBackpropInputV2Config,\n  cosConfig,\n  coshConfig,\n  cropAndResizeConfig,\n  cumprodConfig,\n  cumsumConfig,\n  denseBincountConfig,\n  depthToSpaceConfig,\n  depthwiseConv2dNativeBackpropFilterConfig,\n  depthwiseConv2dNativeBackpropInputConfig,\n  depthwiseConv2dNativeConfig,\n  diagConfig,\n  dilation2DConfig,\n  dilation2DBackpropFilterConfig,\n  dilation2DBackpropInputConfig,\n  drawConfig,\n  einsumConfig,\n  eluConfig,\n  eluGradConfig,\n  equalConfig,\n  erfConfig,\n  expConfig,\n  expandDimsConfig,\n  expm1Config,\n  fftConfig,\n  fillConfig,\n  flipLeftRightConfig,\n  fromPixelsConfig,\n  floorConfig,\n  floorDivConfig,\n  fusedBatchNormConfig,\n  fusedConv2DConfig,\n  fusedDepthwiseConv2DConfig,\n  gatherNdConfig,\n  gatherV2Config,\n  greaterConfig,\n  greaterEqualConfig,\n  identityConfig,\n  ifftConfig,\n  imagConfig,\n  isFiniteConfig,\n  isInfConfig,\n  isNaNConfig,\n  leakyReluConfig,\n  lessConfig,\n  lessEqualConfig,\n  linSpaceConfig,\n  log1pConfig,\n  logConfig,\n  logicalAndConfig,\n  logicalNotConfig,\n  logicalOrConfig,\n  lrnConfig,\n  lrnGradConfig,\n  maxConfig,\n  maximumConfig,\n  maxPoolConfig,\n  maxPoolGradConfig,\n  maxPool3DConfig,\n  maxPool3DGradConfig,\n  maxPoolWithArgmaxConfig,\n  meanConfig,\n  minConfig,\n  minimumConfig,\n  mirrorPadConfig,\n  modConfig,\n  multinomialConfig,\n  multiplyConfig,\n  negConfig,\n  nonMaxSuppressionV3Config,\n  nonMaxSuppressionV5Config,\n  notEqualConfig,\n  oneHotConfig,\n  onesLikeConfig,\n  packConfig,\n  padV2Config,\n  powConfig,\n  preluConfig,\n  prodConfig,\n  rangeConfig,\n  realConfig,\n  realDivConfig,\n  reciprocalConfig,\n  reluConfig,\n  relu6Config,\n  reshapeConfig,\n  resizeBilinearConfig,\n  resizeBilinearGradConfig,\n  resizeNearestNeighborConfig,\n  resizeNearestNeighborGradConfig,\n  reverseConfig,\n  rotateWithOffsetConfig,\n  roundConfig,\n  rsqrtConfig,\n  scatterNdConfig,\n  searchSortedConfig,\n  selectConfig,\n  seluConfig,\n  sigmoidConfig,\n  signConfig,\n  sinConfig,\n  sinhConfig,\n  sliceConfig,\n  stepConfig,\n  stridedSliceConfig,\n  stringNGramsConfig,\n  softmaxConfig,\n  softplusConfig,\n  spaceToBatchNDConfig,\n  sparseSegmentMeanConfig,\n  sparseSegmentSumConfig,\n  sparseToDenseConfig,\n  splitVConfig,\n  sqrtConfig,\n  squareConfig,\n  squaredDifferenceConfig,\n  subConfig,\n  sumConfig,\n  tanConfig,\n  tanhConfig,\n  tensorScatterUpdateConfig,\n  tileConfig,\n  topKConfig,\n  transformConfig,\n  transposeConfig,\n  unpackConfig,\n  unsortedSegmentSumConfig,\n  zerosLikeConfig\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmBA,IAAM,MAAM,IAAG;AAGf,IAAI,aAAa,qCAAqC,MAAM,EAAE;AAM9D,IAAI,aAAa,sBAAsB,MAAM,IAAI;AAOjD,IAAI,aAAa,8BAA8B,MAAM,EAAE;AAMvD,IAAI,aAAa,qCAAqC,MAAM,IAAI;AAMhE,IAAI,aAAa,4BAA4B,MAAM,KAAK;AAQxD,IAAI,aAAa,qCAAqC,MAAM,GAAI;AAMhE,IAAI,aAAa,2BAA2B,MAAM,KAAK;AAKvD,IAAI,aAAa,kCAAkC,MAAM,IAAI;AAK7D,IAAI,aAAa,iCAAiC,MAAM,KAAK;AAO7D,IAAI,aACA,sDAAsD,MAAM,EAAE;AAKlE,IAAI,aAAa,sCAAsC,MAAM,KAAK;AAOlE,IAAI,aAAa,uBAAuB,MAAM,EAAE;AAGhD,IAAI,aAAa,8BAA8B,MAAM,KAAK;;;AC7EpD,IAAO,cAAP,MAAkB;EAKtB,YAAY,aAA2B;AACrC,QAAI,aAAa;AACf,WAAK,SAAS,YAAY;AAC1B,WAAK,eAAe,YAAY;AAChC,WAAK,qBAAqB,KAAK,sBAAqB;;EAExD;EAEQ,wBAAqB;AAC3B,QAAI,KAAK,QAAO,GAAI;AAClB,UAAI,KAAK,aAAa,WAAW,KAAK,GAAG;AACvC,eAAO,OAAO,KAAK,aAAa,MAAM,KAAK,CAAC;iBACnC,KAAK,aAAa,WAAW,IAAI,GAAG;AAC7C,eAAO;;;AAGX,WAAO;EACT;EAEA,UAAO;AACL,WAAO,KAAK,WAAW;EACzB;;;;AC1BI,IAAO,gBAAP,MAAoB;EASxB,YAAoB,QAAiB;AAAjB,SAAA,SAAA;AARZ,SAAA,iBAAiB;AACjB,SAAA,iBAAiB;AACjB,SAAA,cAAwC,oBAAI,IAAG;AAC/C,SAAA,cAAwC,oBAAI,IAAG;AAEhD,SAAA,eAAe;AACf,SAAA,oBAAoB;EAEa;EAExC,cACI,MAAc,OAA4B,mBAAmB,OAC7D,QAAQ,MAAI;AACd,QAAIA;AACJ,UAAM,MAAM,aAAa,MAAM,KAAK;AAEpC,QAAI,OAAO;AACT,UAAI,CAAC,KAAK,YAAY,IAAI,GAAG,GAAG;AAC9B,aAAK,YAAY,IAAI,KAAK,CAAA,CAAE;;AAG9B,UAAI,KAAK,YAAY,IAAI,GAAG,EAAE,SAAS,GAAG;AACxC,QAAAA,UAAS,KAAK,YAAY,IAAI,GAAG,EAAE,IAAG;AACtC,aAAK;aACA;AACL,QAAAA,UAAS,KAAK,OAAO,aAAa,EAAC,MAAM,OAAO,iBAAgB,CAAC;AACjE,aAAK,qBAAqB;;WAEvB;AACL,MAAAA,UAAS,KAAK,OAAO,aAAa,EAAC,MAAM,OAAO,iBAAgB,CAAC;AACjE,WAAK,qBAAqB;;AAG5B,QAAI,CAAC,KAAK,YAAY,IAAI,GAAG,GAAG;AAC9B,WAAK,YAAY,IAAI,KAAK,CAAA,CAAE;;AAE9B,SAAK,YAAY,IAAI,GAAG,EAAE,KAAKA,OAAM;AACrC,SAAK;AACL,SAAK,gBAAgB;AAErB,WAAOA;EACT;EAEA,cAAcA,SAAmB,QAAQ,MAAI;AAC3C,QAAI,KAAK,YAAY,SAAS,GAAG;AAC/B;;AAGF,UAAM,OAAOA,QAAO;AACpB,UAAM,QAAQA,QAAO;AAErB,UAAM,MAAM,aAAa,MAAM,KAAK;AACpC,UAAM,cAAc,KAAK,YAAY,IAAI,GAAG;AAC5C,UAAM,QAAQ,YAAY,QAAQA,OAAM;AACxC,QAAI,QAAQ,GAAG;AACb,YAAM,IAAI,MAAM,0CAA0C;;AAE5D,gBAAY,KAAK,IAAI,YAAY,YAAY,SAAS,CAAC;AACvD,gBAAY,IAAG;AACf,SAAK;AACL,SAAK,gBAAgB;AAErB,QAAI,OAAO;AACT,WAAK,YAAY,IAAI,GAAG,EAAE,KAAKA,OAAM;AACrC,WAAK;WACA;AACL,MAAAA,QAAO,QAAO;AACd,WAAK,qBAAqB;;EAE9B;EAEA,oBAAiB;AACf,WAAO,KAAK;EACd;EAEA,oBAAiB;AACf,WAAO,KAAK;EACd;EAEA,UAAO;AACL,SAAK,YAAY,QAAQ,CAAC,SAAS,QAAO;AACxC,cAAQ,QAAQ,CAAAA,YAAS;AACvB,QAAAA,QAAO,QAAO;MAChB,CAAC;IACH,CAAC;AAED,SAAK,YAAY,QAAQ,CAAC,SAAS,QAAO;AACxC,cAAQ,QAAQ,CAAAA,YAAS;AACvB,QAAAA,QAAO,QAAO;MAChB,CAAC;IACH,CAAC;AAED,SAAK,cAAc,oBAAI,IAAG;AAC1B,SAAK,cAAc,oBAAI,IAAG;AAC1B,SAAK,iBAAiB;AACtB,SAAK,iBAAiB;AACtB,SAAK,eAAe;AACpB,SAAK,oBAAoB;EAC3B;;AAGF,SAAS,aAAa,MAAc,OAA0B;AAC5D,SAAO,GAAG,IAAI,IAAI,KAAK;AACzB;;;ACxGM,IAAO,iBAAP,MAAqB;EASzB,YAAoB,QAAiB;AAAjB,SAAA,SAAA;AARZ,SAAA,kBAAkB;AAClB,SAAA,kBAAkB;AAClB,SAAA,eAA0C,oBAAI,IAAG;AACjD,SAAA,eAA0C,oBAAI,IAAG;AAElD,SAAA,eAAe;AACf,SAAA,oBAAoB;EAEa;EAExC,eACI,OAAe,QAAgB,QAC/B,OAA2B;AAC7B,UAAM,kBAAkB,mBAAmB,MAAM;AACjD,UAAM,WAAW,QAAQ,SAAS;AAClC,UAAM,MAAM,cAAc,OAAO,QAAQ,QAAQ,KAAK;AACtD,QAAI,CAAC,KAAK,aAAa,IAAI,GAAG,GAAG;AAC/B,WAAK,aAAa,IAAI,KAAK,CAAA,CAAE;;AAG/B,QAAI,CAAC,KAAK,aAAa,IAAI,GAAG,GAAG;AAC/B,WAAK,aAAa,IAAI,KAAK,CAAA,CAAE;;AAG/B,SAAK,gBAAgB;AACrB,SAAK;AAEL,QAAI,KAAK,aAAa,IAAI,GAAG,EAAE,SAAS,GAAG;AACzC,WAAK;AAEL,YAAMC,cAAa,KAAK,aAAa,IAAI,GAAG,EAAE,MAAK;AACnD,WAAK,aAAa,IAAI,GAAG,EAAE,KAAKA,WAAU;AAC1C,aAAOA;;AAGT,SAAK,qBAAqB;AAE1B,UAAM,aAAa,KAAK,OAAO,cAAc;MAC3C,MAAM,CAAC,OAAO,MAAM;MACpB;MACA;KACD;AACD,SAAK,aAAa,IAAI,GAAG,EAAE,KAAK,UAAU;AAE1C,WAAO;EACT;EAEA,eAAe,SAAmB;AAChC,QAAI,KAAK,aAAa,SAAS,GAAG;AAChC;;AAGF,UAAM,QAAQ,QAAQ;AACtB,UAAM,SAAS,QAAQ;AACvB,UAAM,SAAS,QAAQ;AACvB,UAAM,QAAQ,QAAQ;AAEtB,UAAM,MAAM,cAAc,OAAO,QAAQ,QAAQ,KAAK;AACtD,QAAI,CAAC,KAAK,aAAa,IAAI,GAAG,GAAG;AAC/B,WAAK,aAAa,IAAI,KAAK,CAAA,CAAE;;AAG/B,SAAK,aAAa,IAAI,GAAG,EAAE,KAAK,OAAO;AACvC,SAAK;AACL,SAAK;AAEL,UAAM,cAAc,KAAK,aAAa,IAAI,GAAG;AAC7C,UAAM,eAAe,YAAY,QAAQ,OAAO;AAChD,QAAI,eAAe,GAAG;AACpB,YAAM,IAAI,MACN,0EACiB;;AAEvB,gBAAY,OAAO,cAAc,CAAC;AAClC,UAAM,kBAAkB,mBAAmB,MAAM;AACjD,UAAM,WAAW,QAAQ,SAAS;AAClC,SAAK,gBAAgB;EACvB;EAEA,qBAAkB;AAChB,WAAO,KAAK;EACd;EAEA,qBAAkB;AAChB,WAAO,KAAK;EACd;EAEA,UAAO;AACL,SAAK,aAAa,QAAQ,CAAC,UAAU,QAAO;AAC1C,eAAS,QAAQ,aAAU;AACzB,gBAAQ,QAAO;MACjB,CAAC;IACH,CAAC;AAED,SAAK,aAAa,QAAQ,CAAC,UAAU,QAAO;AAC1C,eAAS,QAAQ,aAAU;AACzB,gBAAQ,QAAO;MACjB,CAAC;IACH,CAAC;AAED,SAAK,eAAe,oBAAI,IAAG;AAC3B,SAAK,eAAe,oBAAI,IAAG;AAC3B,SAAK,kBAAkB;AACvB,SAAK,kBAAkB;AACvB,SAAK,eAAe;AACpB,SAAK,oBAAoB;EAC3B;;AAGF,SAAS,cACL,OAAe,QAAgB,QAC/B,OAA2B;AAC7B,SAAO,GAAG,KAAK,IAAI,MAAM,IAAI,MAAM,IAAI,KAAK;AAC9C;AAEA,SAAS,mBAAmB,QAAwB;AAClD,MAAI,WAAW,cAAc;AAC3B,WAAO;SACF;AACL,UAAM,IAAI,MAAM,GAAG,MAAM,oBAAoB;;AAEjD;;;ACzHM,SAAU,2BACZ,YAAsB,cAAoB;AAC5C,MAAI,KAAK,IAAI,GAAG,UAAU,IAAI,GAAG;AAC/B,UAAM,IAAI,MAAM,0DAA0D;;AAG5E,QAAM,YAAY,WAAW;AAC7B,QAAM,aAAa;AACnB,QAAM,QAAQ,WAAW,IAAI,OAAK,GAAG,YAAY,IAAI,WAAW,CAAC,CAAC,EAAE;AACpE,QAAM,UAAU,IAAI,MAAM,YAAY,CAAC;AACvC,UAAQ,YAAY,CAAC,IAAI,MAAM,YAAY,CAAC;AAC5C,WAAS,IAAI,YAAY,GAAG,KAAK,GAAG,EAAE,GAAG;AACvC,YAAQ,CAAC,IAAI,IAAI,QAAQ,IAAI,CAAC,CAAC,MAAM,MAAM,IAAI,CAAC,CAAC;;AAGnD,SAAO;AACT;AAEO,IAAM,mBACT,CAAC,KAAa,GAAW,SAA2B;AAClD,MAAI,SAAS,SAAS;AACpB,WAAO,aAAa,GAAG,kBAAkB,CAAC;SACrC;AAGL,WAAO;;;;4DAI6C,CAAC;;oDAET,GAAG;;;;;;;;AAQnD;;;ACpCJ,IAAY;CAAZ,SAAYC,eAAY;AACtB,EAAAA,cAAAA,cAAA,aAAA,IAAA,CAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,MAAA,IAAA,CAAA,IAAA;AACF,GAHY,iBAAA,eAAY,CAAA,EAAA;AAuCjB,IAAM,iBACT,CAAC,QAAmB,SAAwB,YAC3C,QAAoB,wBACS;AAC5B,QAAM,aAAa,EAAC,OAAO,OAAO,OAAO,OAAO,OAAO,MAAK;AAC5D,QAAM,SAAS,WAAW,YAAY,YAAY,OAAO;AACzD,QAAM,SAAS,OAAO,mBAClB,EAAC,MAAM,QAAQ,OAAO,QAAQ,YAAY,KAAI,CAAC;AAEnD,MAAI,oBAAoB,IAAG,EAAG,IAAI,qBAAqB;AACvD,MAAI,sBAAsB,IAAI;AAC5B,wBAAoB,kBAAkB,YAAW;AACjD,UAAM,mBAAmB,kBAAkB,MAAM,GAAG;AACpD,QAAI,sBAAsB,SACtB,iBAAiB,KACb,UAAQ,QAAQ,UAAU,YAAW,EAAG,SAAS,IAAI,CAAC,GAAG;AAC/D,cAAQ,MAAM,QAAQ,SAAS;AAC/B,cAAQ,MAAM,MAAM;AACpB,cAAQ,SAAQ;;;AAIpB,MAAI,qBAAqB;AACvB,WAAO,OAAO,2BAA2B;MACvC,SAAS,EAAC,QAAQ,YAAY,SAAQ;MACtC,OAAO,QAAQ,YAAY;MAC3B,QAAQ;KACT;SACI;AACL,WAAO,OAAO,sBAAsB;MAClC,SAAS,EAAC,QAAQ,YAAY,SAAQ;MACtC,OAAO,QAAQ,YAAY;MAC3B,QAAQ;KACT;;AAEL;AAEG,IAAM,cAAc,CAAC,WAAmB,OAAO,UAAS;AAC7D,UAAQ,WAAW;IACjB,KAAK;AACH,aAAO,GAAG,IAAI;IAChB,KAAK;AACH,aAAO,QAAQ,IAAI;IACrB,KAAK;AACH,aAAO,QAAQ,IAAI;IACrB,KAAK;AACH,aAAO,QAAQ,IAAI;IACrB;AACE,YAAM,IAAI,MAAM,GAAG,SAAS,cAAc,IAAI,oBAAoB;;AAExE;AAEM,SAAU,kBAAkB,MAAY;AAC5C,MAAI,QAAQ,GAAG;AACb,WAAO;aACE,SAAS,GAAG;AACrB,WAAO;aACE,SAAS,GAAG;AACrB,WAAO;aACE,SAAS,GAAG;AACrB,WAAO;aACE,SAAS,GAAG;AACrB,WAAO;aACE,SAAS,GAAG;AACrB,WAAO;SACF;AACL,UAAM,MAAM,gBAAgB,IAAI,uBAAuB;;AAE3D;AAEM,SAAU,aAAa,OAAa;AACxC,MAAI,UAAU,GAAG;AACf,WAAO;aACE,UAAU,GAAG;AACtB,WAAO;aACE,UAAU,GAAG;AACtB,WAAO;aACE,UAAU,GAAG;AACtB,WAAO;aACE,UAAU,GAAG;AACtB,WAAO;aACE,UAAU,GAAG;AACtB,WAAO;SACF;AACL,UAAM,MAAM,SAAS,KAAK,uBAAuB;;AAErD;AAIM,SAAU,uBAAuB,QAAgB;AACrD,MAAI;AACJ,UAAQ,OAAO,QAAQ;IACrB,KAAK;AACH,gBAAU;;;AAGV;IACF,KAAK;AACH,gBAAU;kBACE,OAAO,CAAC,CAAC;;AAErB;IACF;AACE,YAAM,MAAM,aAAa;;AAE7B,SAAO;AACT;AAEM,SAAU,qBACZ,gBAAyB,SAAsB;AACjD,MAAI;AACJ,YAAU;OACL,uBAAuB,OAAO,CAAC;;;;;;;;;;;UAW5B,iBAAiB,4BAA4B,SAAS;;;AAG9D,SAAO;AACT;AAEM,SAAU,uBAAuB,SAAsB;AAC3D,SAAO;6BACoB,QAAQ,cAAc,CAAC,CAAC,KAC/C,QAAQ,cAAc,CAAC,CAAC,KAAK,QAAQ,cAAc,CAAC,CAAC;;AAE3D;AAEA,SAAS,WACL,WAAwB,YACxB,SAAsB;AACxB,QAAM,iBAA2B,CAAA;AACjC,QAAM,oBAAoB,QAAQ,cAAc,CAAC,IAC7C,QAAQ,cAAc,CAAC,IAAI,QAAQ,cAAc,CAAC;AACtD,UAAQ,kBACJ,QAAQ,kBAAkB,QAAQ,kBAAkB;AACxD,iBAAe,KAAK;;;;;;;;;;UAWhB,eAAe,OAAO,IAClB,8BACA;qEAEI,iBAAiB;;SAEtB;;KAEJ;AAEH,MAAI,QAAQ,gBAAgB,MAAM;AAChC,UAAM,eAAe,QAAQ,iBAAiB,aAAa,cACvD,gEACI,kBAAkB,WAAW,OAAO,QAAQ,eAAe,CAAC,OAChE,0DACI,kBAAkB,UAAU,CAAC,EAAE,OAAO,QAAQ,eAAe,CAAC;AACtE,UAAM,sBACF,WAAW,MAAM,WAAW,IAAI,cAAc;AAClD,mBAAe,KAAK;;8BAEM,mBAAmB;;;;;;UAMvC,YAAY;;OAEf;AACH,UAAMC,kBAAiB,qBAAqB,OAAO;AACnD,WAAO;MACL;MACA,eAAe,KAAK,IAAI;MACxB,0BAA0B,WAAW,KAAK;MAC1C,QAAQ,YAAW;MACnB,qBAAqBA,iBAAgB,OAAO;MAC5C,KAAK,IAAI;;AAGb,MAAI;AACJ,MAAI;AACJ,MAAI,qBAAqB;AACzB,UAAQ,cAAc,QAAQ,CAAC,GAAG,MAAK;AACrC,UAAM,cAAc,kBAAkB,UAAU,CAAC,EAAE,MAAM,MAAM;AAC/D,0BACI,GAAG,EAAE,OAAO,CAAC,EAAE,YAAW,IAAK,EAAE,MAAM,CAAC,CAAC,WAAW,WAAW;AACnE,oBAAgB,UAAU,CAAC,EAAE,MAAM,SAAS;AAC5C,sBAAkB,kBAAkB,aAAa;AACjD,0BACI,GAAG,EAAE,OAAO,CAAC,EAAE,YAAW,IAAK,EAAE,MAAM,CAAC,CAAC,iBACrC,eAAe;EACzB,CAAC;AACD,QAAM,iBAAiB,kBAAkB,WAAW,MAAM,MAAM;AAChE,wBAAsB,cAAc,cAAc;AAClD,kBAAgB,WAAW,MAAM,SAAS;AAC1C,oBAAkB,kBAAkB,aAAa;AACjD,wBAAsB;4BACI,eAAe;AAEzC,MAAI,QAAQ,MAAM;AAChB,0BAAsB;;AAGxB,MAAI,QAAQ,UAAU;AACpB,0BAAsB,QAAQ;;AAEhC,wBAAsB;AACtB,uBAAqB,gBAAgB,kBAAkB;AAEvD,iBAAe,KAAK,kBAAkB;AAGtC,MAAI,QAAQ,QAAQ;AAClB,mBAAe,KAAK;;KAEnB;SACI;AACL,mBAAe,KAAK;qEAEhB,kBAAkB,WAAW,OAAO,QAAQ,eAAe,CAAC;KAC/D;;AAEH,UAAQ,cAAc,QAAQ,CAAC,GAAG,MAAK;AACrC,mBAAe,KAAK;2BACG,IAAI,CAAC,wBAAwB,CAAC,WACjD,QAAQ,qBACJ,kBACI,UAAU,CAAC,EAAE,OAAO,QAAQ,mBAAmB,CAAC,CAAC,IACrD,kBAAkB,UAAU,CAAC,EAAE,OAAO,QAAQ,eAAe,CAAC;SACjE;EACP,CAAC;AAED,MAAI,uBAAuB,IAAI;AAC7B,mBAAe,KAAK;2BAEhB,IAAI,QAAQ,cAAc,MAAM;OACjC;;AAGL,QAAM,gBACF,uBAAuB,WAAW,OAAO,QAAQ,cAAc;AAEnE,QAAM,UAAU;IACd;IAAe,eAAe,KAAK,IAAI,IAAI;IAC3C,0BAA0B,WAAW,KAAK;IAAG;IAC7C,gCAAgC,WAAW,MAAM,MAAM;;AAEzD,MAAI,CAAC,QAAQ,QAAQ;AACnB,YAAQ,KAAK,iBACT,WAAW,OAAO,WAAW,OAAO,QAAQ,eAAe,CAAC;;AAGlE,UAAQ,cAAc,QAAQ,CAAC,GAAG,MAAK;AACrC,YAAQ,KAAK,GAAG,0BAA0B,UAAU,CAAC,EAAE,OAAO,CAAC,CAAC,EAAE;EACpE,CAAC;AAED,QAAM,eACF,UACK,IACG,CAAC,GAAG,MAAM,gBACN,GAAG,WAAW,OACd,QAAQ,qBAAqB,QAAQ,mBAAmB,CAAC,IAC5B,QAAQ,iBACrC,QAAQ,eAAe,EAAE,WAAW,WAAW,MAAM,MAAM,CAAC,EACnE,KAAK,IAAI;AAClB,UAAQ,KAAK,YAAY;AACzB,UAAQ,KAAK,QAAQ,YAAW,CAAE;AAClC,QAAM,iBAAiB,qBAAqB,OAAO;AACnD,UAAQ,KAAK,qBAAqB,gBAAgB,OAAO,CAAC;AAC1D,QAAM,SAAS,QAAQ,KAAK,IAAI;AAChC,SAAO;AACT;AAEM,SAAU,cACZ,SAAwB,YACxB,QAAkB;AACpB,MAAI,MAAM,QAAQ;AAClB,MAAI,QAAQ,gBAAgB,MAAM;AAChC,WAAO;;AAGT,QAAM,SAAqB,CAAA;AAC3B,QAAM,QAAkC,CAAA;AACxC,aAAW,QAAQ,aAAU;AAC3B,WAAO,KAAK,QAAQ,KAAK;AACzB,UAAM,KAAK,QAAQ,KAAK;EAC1B,CAAC;AACD,SAAO,KAAK,OAAO,KAAK;AACxB,QAAM,KAAK,OAAO,KAAK;AAEvB,QAAM,gBACF,WAAW,IAAI,OAAK,qBAAa,iBAAiB,EAAE,OAAO,OAAO,KAAK,CAAC;AAC5E,QAAM,4BACF,WAAW,IAAI,OAAK,aAAK,YAAY,EAAE,OAAO,OAAO,KAAK,CAAC,EAAE,KAAK,GAAG;AACzE,QAAM,mBAAmB,cAAc,IAAI,OAAK,EAAE,KAAK,GAAG,CAAC,EAAE,KAAK,GAAG;AAErE,QAAM,qBAAqB,eAAe,OAAO,IAAI,iBAAiB;AAEtE,SAAO,OAAO,QAAQ,gBAAgB,QAAQ,cAAc,KAAK,GAAG,IAAI,MACpE,OAAO,IAAI,WAAS,MAAM,MAAM,EAAE,KAAK,GAAG,IAAI,MAAM,KAAK,GAAG,IAC5D,QAAQ,cAAc,KAAK,GAAG,IAAI,mBAClC,4BAA4B;AAEhC,SAAO;AACT;AAEA,IAAM,gBAAgB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAoDtB,IAAM,eAAe;;;;;AAef,SAAU,0BAA0B,OAAiB,OAAO,IAAE;AAClE,QAAM,OAAO,MAAM;AACnB,QAAM,WAAW,SAAS,KACtB,MAAM,KAAK,OAAO,CAAC,EAAE,YAAW,IAAK,KAAK,MAAM,CAAC,CAAC,oBAClD;AACJ,QAAM,cAAc,SAAS,KACzB,GAAG,KAAK,OAAO,CAAC,EAAE,YAAW,IAAK,KAAK,MAAM,CAAC,CAAC,iBAC/C;AAEJ,MAAI,QAAQ,GAAG;AACb,WAAO,MAAM,QAAQ;;AAGvB,QAAM,UAAU,aAAK,eAAe,KAAK;AACzC,QAAM,QAAQ,kBAAkB,IAAI;AAEpC,QAAMC,UAAmB,CAAA;AACzB,WAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,IAAAA,QAAO,KAAK,IAAI,CAAC,EAAE;;AAGrB,MAAI,QAAQ,WAAW,GAAG;AACxB,WAAO,UAAU,QAAQ;kCAErB,WAAW,oCAAoC,WAAW;;;;AAIhE,MAAI;AACJ,YAAU,wBACN,QACK,IAAI,CAAC,GAAG,MAAK;AACZ,UAAM,QAAQ,OAAOA,QAAO,CAAC,CAAC,wBAC1B,WAAW,IAAI,aAAa,CAAC,CAAC;AAClC,UAAM,QAAQ,MAAM,QAAQ,SAAS,IACjC,OAAOA,QAAO,IAAI,CAAC,CAAC,eAAeA,QAAO,CAAC,CAAC,eACxC,WAAW,IAAI,aAAa,CAAC,CAAC,KAClC,qBAAqBA,QAAO,CAAC,CAAC,eAAe,WAAW,IACpD,aAAa,CAAC,CAAC;AACvB,WAAO,GAAG,KAAK,KAAK,KAAK;EAC3B,CAAC,EACA,KAAK,EAAE;AAEhB,SAAO;SACA,QAAQ,oBAAoB,KAAK;QAClC,OAAO;eACA,KAAK,IAAIA,QAAO,KAAK,GAAG,CAAC;;;AAGxC;AAEA,SAAS,wBACL,WAAsB,WAAiB;AACzC,QAAM,UAAU,UAAU;AAC1B,QAAM,OAAO,UAAU,MAAM;AAC7B,QAAM,OAAO,kBAAkB,IAAI;AACnC,QAAM,WAAW,QAAQ,QAAQ,OAAO,CAAC,EAAE,YAAW,IAAK,QAAQ,MAAM,CAAC;AAC1E,QAAM,OAAO,CAAC,MAAM,MAAM,MAAM,MAAM,MAAM,IAAI,EAAE,MAAM,GAAG,IAAI;AAC/D,QAAM,SAAS,KAAK,IAAI,OAAK,GAAG,CAAC,QAAQ,EAAE,KAAK,IAAI;AAEpD,MAAI,OAAO,GAAG;AACZ,WAAO;WACA,QAAQ,SAAS,YAAY,SAAS,CAAC;iBACjC,YAAY,SAAS,CAAC,IAAI,OAAO;;;;AAKhD,QAAM,WACF,YAAY,QAAQ,OAAO,CAAC,EAAE,YAAW,IAAK,QAAQ,MAAM,CAAC,CAAC;AAClE,MAAI,UAAU,GAAG,IAAI;AACrB,MAAI,SAAS,GAAG;AACd,cAAU;;AAGZ,SAAO;SACA,QAAQ,IAAI,MAAM,QAAQ,YAAY,SAAS,CAAC;eAC1C,YAAY,SAAS,CAAC,IAAI,OAAO,sBAC1C,OAAO,IAAI,IAAI,IAAI,KAAK,KAAK,GAAG,CAAC;UAC7B,QAAQ,IAAI,cAAc,IAAI,KAAK,MAAM,SAAS,EAAE;;;AAG9D;AAEA,SAAS,wBACL,WAAsB,UAAoB,WAC1CC,uBAA6B;AAC/B,QAAM,UAAU,UAAU;AAC1B,QAAM,iBAAiB,QAAQ,OAAO,CAAC,EAAE,YAAW,IAAK,QAAQ,MAAM,CAAC;AAExE,QAAM,WAAW,QAAQ,iBAAiB;AAE1C,QAAM,SAAS,UAAU,MAAM;AAC/B,QAAM,UAAU,SAAS;AACzB,QAAM,OAAO,kBAAkB,OAAO;AAKtC,MAAI,aAAK,YAAY,UAAU,OAAO,QAAQ,KAAKA,uBAAsB;AACvE,WAAO;SACF,QAAQ,+BAA+B,YAAY,SAAS,CAAC;eACvD,YAAY,SAAS,CAAC,IAAI,OAAO;;;SAGvC,QAAQ,mBAAmB,IAAI,QAAQ,YAAY,SAAS,CAAC;eACvD,YAAY,SAAS,CAAC,IAAI,OAAO,IACxC,UAAU,IAAI,qCACA,QAAQ,GAAG,cAAc,IAAI,KAAK,MAAM,SAAS,EAAE;;;;AAKvE,QAAM,gBACF,qBAAa,iBAAiB,UAAU,OAAO,QAAQ;AAC3D,QAAM,WAAW,UAAU;AAE3B,MAAI,gBAAgB;AAEpB,MAAI,WAAW,GAAG;AAChB,WAAO;SACF,QAAQ,+BAA+B,YAAY,SAAS,CAAC;kBACpD,cAAc;;;SAGvB,QAAQ,mBAAmB,IAAI,QAAQ,YAAY,SAAS,CAAC;kBACpD,cAAc;;;SAGvB;AACL,QAAI,UAAU,KAAK,cAAc,UAAU,GAAG;AAC5C,sBAAgB;WACX;AACL,sBACI,cAAc,IAAI,OAAK,UAAU,aAAa,IAAI,QAAQ,CAAC,OAAO,EAC7D,KAAK,IAAI;;;AAItB,MAAI,wBAAwB;AAC5B,MAAI,UAAU,KAAK,SAAS,GAAG;AAC7B,4BAAwB;SACnB;AACL,QAAI,UAAU,GAAG;AACf,YAAM,aAAa,kBAAkB,MAAM;AAC3C,YAAM,eACF,UAAU,MAAM,IAAI,CAAC,GAAG,MAAM,UAAU,aAAa,IAAI,QAAQ,CAAC,EAAE,EAC/D,KAAK,IAAI;AAClB,8BAAwB,GAAG,UAAU,IAAI,YAAY;WAChD;AACL,8BAAwB;;;AAI5B,QAAM,WACF,YAAY,QAAQ,OAAO,CAAC,EAAE,YAAW,IAAK,QAAQ,MAAM,CAAC,CAAC;AAClE,QAAM,UAAU,GAAG,MAAM;AAEzB,SAAO;OACF,QAAQ,+BAA+B,YAAY,SAAS,CAAC;;MAE9D,aAAa;aACN,YAAY,SAAS,CAAC,IAAI,OAAO,sBAAsB,OAAO,IACrE,qBAAqB,KAAK,QAAQ,IAClC,cAAc,IAAI,KAAK,MAAM,SAAS,EAAE;;;OAGvC,QAAQ,qBAAqB,IAAI,QAAQ,YAAY,SAAS,CAAC;;MAEhE,aAAa;aACN,YAAY,SAAS,CAAC,IAAI,OAAO,sBAAsB,OAAO,IACrE,qBAAqB,KAAK,QAAQ,IAClC,cAAc,IAAI,KAAK,MAAM,SAAS,EAAE;;;AAG9C;AAEA,SAAS,gBACL,WAAsB,UAAoB,WAC1CA,uBAA6B;AAC/B,MAAI,MAAM,wBAAwB,WAAW,SAAS;AAEtD,QAAM,UAAU,UAAU;AAC1B,MAAI,QAAQ,UAAU,SAAS,QAAQ;AACrC,WAAO,wBACH,WAAW,UAAU,WAAWA,qBAAoB;;AAG1D,SAAO;AACT;AAMA,SAAS,uBACL,UACA,gBAAyD;AAC3D,QAAM,EAAC,GAAG,IAAI,CAAA,GAAI,IAAI,CAAA,EAAE,IAAI;AAE5B,QAAM,UAAU,SAAS;AACzB,QAAM,OAAO,EAAE,SAAS,EAAE,SAAS,EAAE;AAGrC,MAAI,SAAS,SAAS;AACpB,WAAO;;AAGT,MAAI,EAAE,WAAW,SAAS;AACxB,UAAMC,SAAQ,kBAAkB,OAAO;AACvC,UAAMC,WAAU,2BAA2BD,MAAK;;;;;AAKhD,WAAOC;;AAGT,MAAI,sBAAsB;AAC1B,QAAM,OAAO,CAAC,GAAG,GAAG,CAAC;AAErB,WAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,UAAM,MAAM,KAAK,CAAC;AAElB,QAAI,IAAI,WAAW,GAAG;AACpB;;AAGF,QAAI,IAAI,WAAW,GAAG;AACpB,6BAAuB,QAAQ,IAAI,CAAC,CAAC,mBAAmB,CAAC;WACpD;AACL,YAAM,UAAU,2BAA2B,KAAK,mBAAmB;AACnE,6BAAuB,YAAY,CAAC,mBAAmB,CAAC;AACxD,eAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,+BAAuB,QAAQ,IAAI,CAAC,CAAC,WAAW,CAAC,MAAM,QAAQ,CAAC,CAAC;AAEjE,YAAI,MAAM,QAAQ,SAAS,GAAG;AAC5B,iCAAuB,QAAQ,IAAI,IAAI,CAAC,CAAC,WAC7B,CAAC,OAAO,IAAI,CAAC,CAAC,MAAM,QAAQ,CAAC,CAAC;eACrC;AACL,iCACI,QAAQ,CAAC,WAAW,CAAC,OAAO,IAAI,CAAC,CAAC,MAAM,QAAQ,CAAC,CAAC;;;;;AAM9D,QAAM,aAAa,CAAA;AACnB,WAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,eAAW,KAAK,IAAI,CAAC,EAAE;;AAGzB,QAAM,QAAQ,kBAAkB,IAAI;AACpC,MAAI,UAAU,2BAA2B,KAAK;IAC5C,mBAAmB;;AAErB,MAAI,WAAW,WAAW,GAAG;AAC3B,eAAW,UAAU,KAAK;SACrB;AACL,eAAW,UAAU,KAAK,IAAI,WAAW,KAAK,GAAG,CAAC;;AAGpD,SAAO;AACT;AAEA,SAAS,gCAAgC,SAAe;AACtD,MAAI,UAAU;AACd,UAAQ,SAAS;IACf,KAAK;IACL,KAAK;AACH,iBAAW;;;;;AAKX;IACF,KAAK;AACH,iBAAW;;;;;AAKX;IACF,KAAK;AACH,iBAAW;;;;;AAKX;IACF,KAAK;AACH,iBAAW;;;;;;AAMX;IACF,KAAK;AACH,iBAAW;;;;;;;;;AASX;IACF,KAAK;AACH,iBAAW;;;;;;;;;;AAUX;IACF;AACE,mBAAK,OAAO,OAAO,MAAM,eAAe,OAAO,SAAS;AACxD;;AAEJ,SAAO;AACT;AAEA,SAAS,eAAe,SAAsB;AAC5C,SAAO,QAAQ,SAAS,CAAC,MAAM,KAAK,QAAQ,SAAS,CAAC,MAAM;AAC9D;AAEM,SAAU,kBAAkB,MAAgB,YAAY,GAAC;AAC7D,MAAI,SAAS,WAAW;AACtB,WAAO,YAAY,WAAW,KAAK;aAC1B,SAAS,WAAW,SAAS,QAAQ;AAC9C,WAAO,YAAY,WAAW,KAAK;;AAErC,QAAM,IAAI,MAAM,QAAQ,IAAI,oBAAoB;AAClD;AAEA,SAAS,iBACL,UAAoB,eAAyB,WAAiB;AAChE,QAAM,UAAU,SAAS;AACzB,QAAM,UAAU,kBAAkB,eAAe,SAAS;AAC1D,MAAI,UACA,gDAAgD,YAAY,SAAS,CAAC;4BAChD,OAAO;;;sDAIzB,YAAY,WAAW,KAAK,CAAC;4BACX,OAAO;;;AAGjC,MAAI,WAAW,GAAG;AAChB,UAAM,OAAO,CAAC,MAAM,MAAM,MAAM,MAAM,MAAM,IAAI,EAAE,MAAM,GAAG,OAAO;AAClE,UAAM,OAAO,kBAAkB,OAAO;AAEtC,eAAW;6BACc,KAAK,IAAI,OAAK,GAAG,CAAC,QAAQ,EAAE,KAAK,IAAI,CAAC,aAC3D,YAAY,SAAS,CAAC;mDACqB,IAAI,IAAI,KAAK,KAAK,IAAI,CAAC;oCAElE,cAAc,IAAI,KAAK,MAAM,SAAS,EAAE;;gCAGxC,KAAK,IAAI,OAAK,GAAG,CAAC,QAAQ,EAAE,KAAK,IAAI,CAAC,aACtC,YAAY,WAAW,KAAK,CAAC;mDACc,IAAI,IAAI,KAAK,KAAK,IAAI,CAAC;uCAElE,cAAc,IAAI,KAAK,MAAM,SAAS,EAAE;;;;AAK9C,SAAO;AACT;AAEA,SAAS,gBAAgB,eAAqB;AAE5C,QAAM,cAAc;AACpB,kBAAgB,cAAc,QAAQ,aAAa,CAAC,UAAS;AAC3D,WAAO,gBAAgB;EACzB,CAAC;AAGD,QAAM,cAAc;AACpB,kBAAgB,cAAc,QAAQ,aAAa,CAAC,GAAG,IAAI,OAAM;AAC/D,WAAO,MAAM,EAAE,gBAAgB,EAAE;EACnC,CAAC;AACD,SAAO;AACT;AACA,SAAS,qBAAqB,SAAsB;AAClD,MAAI,QAAQ,eAAe,eAAe,GAAG,KACzC,QAAQ,eAAe,EAAE,WAAW,GAAG;AACzC,WAAO;;AAET,MAAI,QAAQ,eAAe,eAAe,GAAG,KACzC,QAAQ,eAAe,EAAE,WAAW,GAAG;AACzC,WAAO;;AAET,SAAO;AACT;;;ACp1BA;;;;;;;;;;;;;AAkBA,IAAM,eAAe,CAAC,QAAiB;AACrC,MAAI,UAAU;AACd,WAAS,IAAI,GAAG,IAAI,IAAI,QAAQ,KAAK;AACnC,eAAW,IAAI,CAAC;;AAElB,SAAO;AACT;AAEM,SAAU,wBACZ,UAAoB,OAAe;AACrC,MAAI,SAAS,WAAW,MAAM,QAAQ;AACpC,UAAM,IAAI,MACN,+BAA+B,SAAS,MAAM,+BACf,MAAM,MAAM,4BACrB;;AAE5B,SAAO,MAAM,MACT,CAAC,KAAa,WAAmB,MAAM,SAAS,MAAM,MAAM,CAAC;AACnE;AAIM,SAAU,gBACZ,QAAmD,aACnD,gBAA0C,CAAC,GAAG,GAAG,CAAC,GAClD,oBACI,CAAC,GAAG,GAAG,CAAC,GAAC;AACf,QAAM,CAAC,WAAW,WAAW,SAAS,IAAI;IACxC,KAAK,KACD,aAAa,OAAO,EAAE,IAAI,OAAK,YAAY,CAAC,CAAC,CAAC,KAC7C,cAAc,CAAC,IAAI,kBAAkB,CAAC,EAAE;IAC7C,OAAO,IAAI,KAAK,KACD,aAAa,OAAO,EAAE,IAAI,OAAK,YAAY,CAAC,CAAC,CAAC,KAC7C,cAAc,CAAC,IAAI,kBAAkB,CAAC,EAAE,IAC7C;IACX,OAAO,IAAI,KAAK,KACD,aAAa,OAAO,EAAE,IAAI,OAAK,YAAY,CAAC,CAAC,CAAC,KAC7C,cAAc,CAAC,IAAI,kBAAkB,CAAC,EAAE,IAC7C;;AAEb,SAAO,CAAC,WAAW,WAAW,SAAS;AACzC;AAOM,SAAU,8BACZ,WAAmB,UAAkB,WACrC,aAAa,OAAK;AAQpB,QAAM,gBAA0C,CAAC,GAAG,GAAG,CAAC;AACxD,QAAM,oBAA8C,CAAC,GAAG,GAAG,CAAC;AAE5D,MAAI,CAAC,YAAY;AACf,QAAI,aAAa,GAAG;AAClB,wBAAkB,CAAC,IAAI;;AAGzB,QAAI,YAAY,MAAM,aAAa,IAAI;AACrC,oBAAc,CAAC,IAAI;;;AAIvB,SAAO,EAAC,eAAe,kBAAiB;AAC1C;AAEM,SAAU,8BACZ,QAAmD,aACnD,SAAS,OAAK;AAChB,MAAI,QAAQ;AACV,WAAO,CAAC,GAAG,GAAG,CAAC;;AAGjB,QAAM,OAAO,aAAa,OAAO,EAAE,IAAI,OAAK,YAAY,CAAC,CAAC,CAAC;AAC3D,QAAM,OAAO,aAAa,OAAO,EAAE,IAAI,OAAK,YAAY,CAAC,CAAC,CAAC;AAS3D,MAAI,QAAQ,GAAG;AACb,WAAO,CAAC,GAAG,IAAI,CAAC;;AAElB,MAAI,QAAQ,GAAG;AACb,WAAO,CAAC,IAAI,GAAG,CAAC;;AAGlB,SAAO,CAAC,IAAI,IAAI,CAAC;AACnB;AAEM,SAAU,8BACZ,QAAmD,aACnD,SAAS,OAAK;AAChB,MAAI,QAAQ;AACV,WAAO,CAAC,GAAG,GAAG,CAAC;;AAGjB,QAAM,OAAO,aAAa,OAAO,EAAE,IAAI,OAAK,YAAY,CAAC,CAAC,CAAC;AAC3D,QAAM,OAAO,aAAa,OAAO,EAAE,IAAI,OAAK,YAAY,CAAC,CAAC,CAAC;AAI3D,MAAI,QAAQ,GAAG;AACb,WAAO,CAAC,GAAG,GAAG,CAAC;;AAEjB,MAAI,QAAQ,GAAG;AACb,WAAO,CAAC,GAAG,GAAG,CAAC;;AAGjB,SAAO,CAAC,GAAG,GAAG,CAAC;AACjB;AAEM,SAAU,mBAAmB,OAAe;AAChD,SAAO,EAAC,GAAG,MAAM,IAAI,CAAC,GAAG,MAAM,CAAC,EAAC;AACnC;AAEM,SAAU,mBAAmB,OAAe;AAChD,MAAI,UAAU,aAAa,UAAU,WAAW,UAAU,UACtD,UAAU,UAAU;AACtB,WAAO;aACE,UAAU,aAAa;AAChC,WAAO;SACF;AACL,UAAM,IAAI,MAAM,iBAAiB,KAAK,EAAE;;AAE5C;AAEM,SAAU,oBAAiB;AAC/B,SAAO,CAAC,EAAE,OAAO,eAAe,eAAgB,WAAW,aACrD,WAAW,UAAU;AAC7B;AAEM,SAAU,iBACZ,QAAiC,QAAc;AACjD,MAAI,CAAC,MAAM,QAAQ,MAAM,GAAG;AAC1B,aAAS,CAAC,MAAM;;AAElB,SAAO,QAAQ,OAAI;AACjB,QAAI,KAAK,MAAM;AACb,mBAAK,OACD,EAAE,UAAU,aACZ,MAAM,GAAG,MAAM,4DACa;;EAEpC,CAAC;AACH;AAEA,IAAY;CAAZ,SAAYC,oBAAiB;AAC3B,EAAAA,mBAAAA,mBAAA,qBAAA,IAAA,CAAA,IAAA;AACA,EAAAA,mBAAAA,mBAAA,qBAAA,IAAA,CAAA,IAAA;AACA,EAAAA,mBAAAA,mBAAA,8BAAA,IAAA,CAAA,IAAA;AACA,EAAAA,mBAAAA,mBAAA,qBAAA,IAAA,CAAA,IAAA;AACA,EAAAA,mBAAAA,mBAAA,WAAA,IAAA,CAAA,IAAA;AACF,GANY,sBAAA,oBAAiB,CAAA,EAAA;;;AC9G7B,IAAM,6BACF,IAAG,EAAG,UAAU,mCAAmC;AAGvD,IAAM,kBACF,CAAC,QACA,YAAmE;AAClE,QAAM,0CACF,OAAO,OAAO;AAClB,QAAM,SAAS,QAAQ,gBAAgB;AACvC,QAAM,WAAW,QAAQ,UAAU;AACnC,MAAI,SAAS,MAAM,CAAC,MAAM,KAAK,uCAAuC,GAAG;AACvE,WAAO;;AAGT,eAAK,OACD,SAAS,CAAC,IAAI,2CACV,OAAO,MAAM,UAAa,OAAO,MAAM,QAC3C,MAAM,0DAA0D;AAEpE,MAAI,kBAAkB,KAAK,KAAK,KAAK,KAAK,SAAS,CAAC,CAAC,CAAC;AACtD,MAAI,kBAAkB,yCAAyC;AAC7D,sBAAkB,KAAK,KAAK,KAAK,KAAK,SAAS,CAAC,CAAC,CAAC;AAClD,iBAAK,OACD,mBAAmB,yCACnB,MAAM,6CAA6C;AACvD,WAAO,CAAC,iBAAiB,iBAAiB,eAAe;SACpD;AACL,WAAO,CAAC,iBAAiB,iBAAiB,CAAC;;AAE/C;AAEJ,IAAa,gBAAb,MAAa,uBAAsB,cAAa;EAiCtC,aAAU;AAChB,WAAO,eAAc;EACvB;EAEA,YAAY,QAAmB,aAA4B;AACzD,UAAK;AA1BC,SAAA,uBAAuB,oBAAI,QAAO;AAClC,SAAA,sBAAsB;AACtB,SAAA,WAAW;AACX,SAAA,iBAAiB;AAGjB,SAAA,4BAAsC,CAAA;AAKtC,SAAA,qBAAgC;AAChC,SAAA,WAAwB;AACxB,SAAA,gBAAgB;AAChB,SAAA,yBAAsC,CAAA;AAEtC,SAAA,yBAAsC,CAAA;AACtC,SAAA,eAAe;AACf,SAAA,oBAAoB;AACpB,SAAA,0BAA0B;AAQhC,QAAI,CAAa,kBAAiB,GAAI;AACpC,YAAM,IAAI,MAAM,wCAAwC;;AAE1D,SAAK,gBAAgB,CAAA;AACrB,SAAK,SAAS;AACd,SAAK,QAAQ,OAAO;AACpB,SAAK,iBAAiB;AACtB,SAAK,qBAAqB;AAC1B,SAAK,cAAc,IAAI,YAAY,WAAW;AAC9C,SAAK,wBAAwB,KAAK,OAAO,SAAS,IAAI,iBAAiB;AACvE,SAAK,gCACD,KAAK,YAAY,sBAAsB,KAAK,KAAK;AAErD,SAAK,gBAAgB,IAAI,cAAc,KAAK,MAAM;AAClD,SAAK,iBAAiB,IAAI,eAAe,KAAK,MAAM;AACpD,SAAK,YAAY,IAAI,YAAY,MAAM,OAAM,CAAE;AAI/C,QAAI,IAAG,EAAG,QAAQ,yBAAyB,GAAG;AAC5C,WAAK,cAAc,SAAS,cAAc,QAAQ;AAClD,WAAK,YAAY,QAAQ;AACzB,WAAK,YAAY,SAAS;AAE1B,WAAK,eAAe,KAAK,YAAY,WAAW,QAAQ;AACxD,WAAK,aAAa,UAAU;QAC1B;QACA,QAAQ;OACT;AAED,eAAS,KAAK,YAAY,KAAK,WAAW;;EAE9C;EAES,iBAAc;AACrB,WAAO;EACT;;;;;;;;EASS,YAAY,QAAgB,QAAQ,OAAK;AAEhD,QAAI,CAAC,KAAK,UAAU,IAAI,MAAM,GAAG;AAC/B,aAAO;;AAGT,UAAM,aAAa,KAAK,UAAU,IAAI,MAAM;AAC5C,QAAI,OAAO;AACT,iBAAW,WAAW;WACjB;AACL,iBAAW;;AAGb,QAAI,WAAW,WAAW,GAAG;AAC3B,aAAO;;AAGT,QAAI,WAAW,sBAAsB,MAAM;AACzC,WAAK,YAAY,WAAW,mBAAmB,KAAK,MAAM;AAC1D,WAAK,YAAY,WAAW,mBAAmB,KAAK,MAAM;;AAG5D,QAAI,KAAK,qBAAqB,IAAI,MAAM,GAAG;AACzC,WAAK,0BAA0B,KAAK,MAAM;AAC1C,aAAO;;AAGT,SAAK,gBAAgB,MAAM;AAC3B,SAAK,UAAU,OAAO,MAAM;AAE5B,WAAO;EACT;EAES,SAAM;AACb,WAAO;MACL,eAAe,KAAK,cAAc;MAClC,wBAAwB,KAAK,cAAc;MAC3C,YAAY;;EAEhB;EAEQ,gBAAgB,QAAc;AACpC,UAAM,aAAa,KAAK,UAAU,IAAI,MAAM;AAC5C,QAAI,CAAC,cAAc,CAAC,WAAW,UAAU;AACvC;;AAIF,QAAI,WAAW,UAAU;AACvB,iBAAW,WAAW;AACtB;;AAEF,QAAI,WAAW,oBAAoB,WAAW;AAC5C,WAAK,cAAc,cAAc,WAAW,QAAQ;eAC3C,WAAW,oBAAoB,YAAY;AACpD,WAAK,eAAe,eAAe,WAAW,QAAQ;;AAExD,eAAW,WAAW;EACxB;;EAGS,SAAS,QAAc;AAC9B,QAAI,KAAK,UAAU,IAAI,MAAM,GAAG;AAC9B,YAAM,aAAa,KAAK,UAAU,IAAI,MAAM;AAC5C,aAAO,WAAW;;AAEpB,WAAO;EACT;;EAGS,OAAO,QAAc;AAC5B,UAAM,aAAa,KAAK,UAAU,IAAI,MAAM;AAC5C,eAAW;EACb;;EAGA,OAAO,QAAc;AACnB,QAAI,KAAK,UAAU,IAAI,MAAM,GAAG;AAC9B,YAAM,aAAa,KAAK,UAAU,IAAI,MAAM;AAC5C,iBAAW;;EAEf;EAES,MAAM,QAAuB,OAAiB,OAAe;AAEpE,QAAI,UAAU,eAAe,UAAU,MAAM;AAC3C,YAAM,IAAI,MACN,uEACoC;;AAE1C,UAAM,SAAS,EAAC,IAAI,KAAK,WAAU,EAAE;AACrC,SAAK,UAAU,IAAI,QAAQ,EAAC,OAAO,OAAO,QAAQ,UAAU,EAAC,CAAC;AAC9D,WAAO;EACT;EAES,KACL,QAAgB,QAAuB,OAAiB,OACxD,UAAgB;AAClB,QAAI,UAAU,aAAa;AACzB,YAAM,IAAI,MACN,uEACoC;;AAE1C,SAAK,UAAU,IAAI,QAAQ,EAAC,OAAO,OAAO,QAAQ,SAAQ,CAAC;EAC7D;EAEA,cAAW;AACT,SAAK,MAAM,OAAO,CAAC,KAAK,eAAe,OAAM,CAAE,CAAC;AAChD,SAAK,iBAAiB;AACtB,SAAK,sBAAsB;AAE3B,SAAK,uBAAuB,oBAAI,QAAO;AAEvC,SAAK,0BAA0B,QAAQ,OAAI;AACzC,WAAK,gBAAgB,CAAC;AACtB,WAAK,UAAU,OAAO,CAAC;IACzB,CAAC;AAED,SAAK,uBAAuB,QACxB,OAAK,KAAK,cAAc,cAAc,CAAC,CAAC;AAC5C,SAAK,uBAAuB,QACxB,OAAK,KAAK,cAAc,cAAc,GAAG,KAAK,CAAC;AAEnD,SAAK,4BAA4B,CAAA;AACjC,SAAK,yBAAyB,CAAA;AAC9B,SAAK,yBAAyB,CAAA;EAChC;EAEA,4BAAyB;AACvB,QAAI,CAAC,KAAK,gBAAgB;AACxB,WAAK,iBAAiB,KAAK,OAAO,qBAAoB;;EAE1D;EAEA,wBAAqB;AACnB,QAAI,KAAK,oBAAoB;AAC3B,WAAK,mBAAmB,IAAG;AAC3B,WAAK,qBAAqB;;EAE9B;;EAGA,MAAM,8BAA2B;AAC/B,QAAI;AACJ,QAAI;AACF,kBAAY,MAAM,QAAQ,IAAI,OAAO,OAAO,KAAK,aAAa,CAAC;aACxD,GAAG;AAEV,YAAM,IAAI,MAAM,EAAE,OAAO;;AAE3B,WAAO,KAAK,KAAK,aAAa,EAAE,IAAI,CAAC,KAAK,MAAK;AAC7C,WAAK,cAAc,GAAG,IAAI,UAAU,CAAC;IACvC,CAAC;EACH;EAEO,MAAM,cAAcC,SAAiB;AAC1C,QAAI,IAAG,EAAG,QAAQ,4BAA4B,GAAG;AAC/C,cAAQ,KACJ,oIAAoI;AACxI,aAAO;;AAET,UAAM,OAAOA,QAAO;AACpB,UAAM,gBAAgB,KAAK,cAAc,cACrC,MAAM,eAAe,WAAW,eAAe,QAAQ;AAC3D,SAAK,0BAAyB;AAC9B,SAAK,sBAAqB;AAC1B,SAAK,eAAe,mBAAmBA,SAAQ,GAAG,eAAe,GAAG,IAAI;AACxE,SAAK,YAAW;AAEhB,UAAM,cAAc,SAAS,WAAW,IAAI;AAC5C,UAAM,SAAS,cAAc,eAAc,EAAG,MAAM,CAAC;AAErD,kBAAc,MAAK;AACnB,QAAI,iBAAiB,MAAM;AACzB,WAAK,cAAc,cAAc,aAAa;;AAKhD,QAAI,IAAG,EAAG,QAAQ,yBAAyB,GAAG;AAC5C,mBAAK,OACD,KAAK,iBAAiB,QACtB,MAAM,wCAAwC;AAClD,WAAK,aAAa,kBAAiB;;AAGrC,WAAO;EACT;EAEQ,qBAAqB,QAAgB,MAAmB;AAE9D,UAAM,aAAa,KAAK,UAAU,IAAI,MAAM;AAC5C,eAAW,SAAS;AACpB,WAAO,WAAW;EACpB;EAES,SAAS,QAAc;AAC9B,UAAM,aAAa,KAAK,UAAU,IAAI,MAAM;AAC5C,UAAM,EAAC,QAAQ,mBAAkB,IAAI;AAErC,QAAI,UAAU,QAAQ,WAAW,UAAU,UAAU;AACnD,aAAO;;AAGT,QAAI,WAAW,UAAU,aAAa;AACpC,YAAM,aACF,KAAK,SAAS,mBAAmB,KAAK,MAAM;AAChD,YAAM,aACF,KAAK,SAAS,mBAAmB,KAAK,MAAM;AAChD,YAAM,cAAc,aAAK,mCACrB,qBAAa,uBAAuB,YAAY,UAAU,EAAE,QAC5D,SAAS;AACb,WAAK,qBAAqB,QAAQ,WAAW;AAC7C,aAAO;;AAGT,QAAI,CAAC,KAAK,mBAAmB;AAC3B,WAAK,oBAAoB;AACzB,cAAQ,KACJ,oIACmE;;AAGzE,UAAM,aAAmC,CAAC,UAAU,eAAe;AAEnE,UAAMA,UAAS,WAAW;AAC1B,UAAM,aAAaA,QAAO;AAC1B,iBAAK,OACD,aAAa,MAAM,GACnB,MAAM,4EAC6C;AACvD,UAAM,aAAa,aAAa;AAChC,UAAM,UAAU,IAAI,YAAY,UAAU;AAE1C,UAAM,cAAc,KAAK,eAAe;AACxC,UAAM,uBACF,WAAW,IAAI,OAAK,IAAI,gBAAgB,aAAa,YAAY,CAAC;AACtE,UAAM,qBAAqB,IAAI,gBAAgB,aAAa,YAAY;AAExE,SAAK,sBAAqB;AAC1B,yBACK,IAAI,CAAC,SAAS,UAAS;AACtB,YAAM,UAAU,QAAQ,WAAW,QAAQ;AAG3C,cAAQ,UAAU;QAChB,QAAQ,KAAK;QACb,QAAQ;QACR,OAAO,gBAAgB;QACvB,WAAW,WAAW,KAAK;OAC5B;AACD,aAAO,QAAQ,kBAAiB;IAClC,CAAC,EACA,IAAI,CAAC,SAAS,UAAS;AACtB,YAAM,cAAc,cAAc;AAClC,YAAM,mBACF,CAACC,QAAeC,SAAgBC,YAAkB;AAChD,aAAK,0BAAyB;AAC9B,aAAK,eAAe,oBAChB;UACE,QAAAH;UACA;UACA,QAAAG;WAEF;UACE;WAEF;UACE,OAAAF;UACA,QAAAC;SACD;AACL,aAAK,YAAW;AAEhB,cAAM,UAAU,mBAAmB,WAAW,MAAM;UAClD,oBAAoB;SACrB;AACD,gBAAQ,UAAU,GAAG,GAAGD,QAAOC,OAAM;AACrC,gBAAQ,UAAU,qBAAqB,KAAK,GAAG,GAAG,CAAC;AACnD,cAAM,gBACF,QAAQ,aAAa,GAAG,GAAGD,QAAOC,OAAM,EAAE;AAC9C,cAAM,YAAY,WAAW,KAAK;AAClC,cAAM,OACF,IAAI,kBAAkB,SAASC,SAAQF,SAAQC,UAAS,CAAC;AAC7D,iBAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK,GAAG;AACvC,cAAI,cAAc,iBAAiB;AACjC,iBAAK,IAAI,CAAC,IAAI,cAAc,IAAI,CAAC;iBAC5B;AACL,kBAAM,QAAQ,cAAc,CAAC;AAC7B,iBAAK,CAAC,IAAI,cAAc,IAAI,CAAC;AAC7B,iBAAK,IAAI,CAAC,IAAI,cAAc,IAAI,CAAC;AACjC,iBAAK,IAAI,CAAC,IAAI;;;MAGpB;AAEJ,YAAM,iBACF,KAAK,MAAM,cAAc,cAAc,aAAa;AACxD,UAAI,QAAQ,aAAa,SAAS,cAAc,SAAS;AACzD,eAAS,IAAI,GAAG,IAAI,gBAAgB,KAAK;AAEvC,yBAAiB,OAAO,QAAQ,MAAM;AACtC,kBAAU,cAAc,eAAe;;AAGzC,YAAM,aAAa,cAAc,cAAc;AAC/C,eAAS,KAAK,MAAM,aAAa,WAAW;AAC5C,UAAI,SAAS,GAAG;AAEd,yBAAiB,OAAO,QAAQ,MAAM;AACtC,kBAAU,UAAU,cAAc;;AAGpC,cAAQ,aAAa;AACrB,UAAI,QAAQ,GAAG;AAEb,yBAAiB,OAAO,GAAG,MAAM;;IAErC,CAAC;AAEL,UAAM,OACF,aAAK,mCAAmC,SAAS,WAAW,KAAK;AACrE,SAAK,qBAAqB,QAAQ,IAAI;AACtC,WAAO;EACT;EAES,MAAM,KAAK,QAAc;AAChC,QAAI,CAAC,KAAK,UAAU,IAAI,MAAM,GAAG;AAC/B,YAAM,IAAI,MAAM,UAAU,MAAM,sBAAsB;;AAExD,UAAM,aAAa,KAAK,UAAU,IAAI,MAAM;AAE5C,UAAM,EAAC,OAAM,IAAI;AAEjB,QAAI,UAAU,MAAM;AAClB,aAAO;;AAIT,QAAI;AACJ,QAAI,WAAW,UAAU,aAAa;AACpC,YAAM,KAAK,MAAM,QAAQ,IAAI;QAC3B,KAAK,KAAK,WAAW,mBAAmB,KAAK,MAAM;QACnD,KAAK,KAAK,WAAW,mBAAmB,KAAK,MAAM;OACpD;AAED,YAAM,aAAa,GAAG,CAAC;AACvB,YAAM,aAAa,GAAG,CAAC;AACvB,aAAO,qBAAa,uBAChB,YAA4B,UAA0B;WACrD;AACL,YAAM,OAAO,MAAM,KAAK,cAAc,WAAW,QAAqB;AACtE,aAAO,aAAK,mCAAmC,MAAM,WAAW,KAAK;;AAEvE,SAAK,qBAAqB,QAAQ,IAAI;AACtC,WAAO;EACT;;;EAIQ,WAAW,WAAoB;AACrC,UAAM,OAAO,UAAU;AACvB,UAAM,QAAQ,UAAU;AACxB,UAAM,YAAY,KAAK,cAAc,cAAc,MAAM,KAAK;AAC9D,SAAK,0BAAyB;AAC9B,SAAK,sBAAqB;AAC1B,SAAK,eAAe,mBAAmB,WAAW,GAAG,WAAW,GAAG,IAAI;AACvE,SAAK,YAAW;AAChB,WAAO;EACT;;;;EAKS,wBACL,YAAwB,OAAiB,OAAe;AAC1D,QAAIF,UAAS,WAAW;AACxB,QAAI,UAAU,aAAa;AACzB,YAAM,IAAI,MAAM,qCAAqC;;AAEvD,UAAM,SAAS,EAAC,IAAI,KAAK,WAAU,EAAE;AACrC,SAAK,UAAU,IAAI,QAAQ;MACzB;MACA;MACA,QAAQ;MACR,UAAU;MACV,UAAU,WAAW;KACtB;AACD,UAAM,aAAa,KAAK,UAAU,IAAI,MAAM;AAC5C,UAAM,OAAmB,mBAAmB,WAAW,KAAK,IACxD,aAAK,cAAc,WAAW,KAAK;AACvC,QAAI,WAAW,OAAO,OAAO,MAAM;AACjC,YAAM,IAAI,MAAM,kBACZ,WAAW,OAAO,IAAI,iCAAiC,IAAI,IAAI;gBAEhE,WAAW,OAAO,SACjB,eAAe,UAAU,eAAe,gBACzC,eAAe,UAAU,eAAe,WAAW;AACtD,YAAM,IAAI,MACN,kFAAkF;;AAIxF,QAAI,WAAW,aAAa,MAAM;AAChC,MAAAA,UAAS,KAAK,WAAWA,OAAM;;AAEjC,eAAW,WAAWA;AACtB,WAAO,OAAM,EAAG,qBAAqB,QAAQ,OAAO,OAAO,IAAI;EACjE;;;;;EAMS,UAAU,QAAc;AAC/B,UAAM,gBAAgB,KAAK,UAAU,IAAI,MAAM;AAC/C,UAAM,EAAC,QAAQ,OAAO,OAAO,SAAQ,IAAI;AAEzC,QAAI,UAAU,aAAa;AACzB,YAAM,IAAI,MAAM,sDAAsD;;AAGxE,QAAI,YAAY,MAAM;AACpB,UAAI,UAAU,MAAM;AAClB,cAAM,IAAI,MAAM,gCAAgC;aAC3C;AACL,cAAM,IAAI,MAAM,iCAAiC;;;AAIrD,UAAM,YAAY;AAClB,UAAM,OAAO,UAAU;AACvB,UAAM,QAAQ,UAAU;AACxB,UAAMA,UAAS,KAAK,cAAc,cAAc,MAAM,KAAK;AAC3D,SAAK,0BAAyB;AAC9B,SAAK,sBAAqB;AAC1B,SAAK,eAAe,mBAChB,UAAuB,GAAGA,SAAQ,GAAG,IAAI;AAC7C,SAAK,YAAW;AAEhB,UAAM,aAAa,KAAK,eAAe,OAAO,KAAK;AAEnD,UAAM,YAAY,OAAM,EAAG,yBAAyB,UAAU;AAE9D,UAAM,aAAa,KAAK,UAAU,IAAI,WAAW,MAAM;AACvD,eAAW,WAAWA;AAEtB,WAAO,EAAC,WAAW,QAAAA,QAAM;EAC3B;EAEA,WAA+C,GAAa;AAE1D,UAAM,OAAO,KAAK,SAAS,EAAE,MAAM;AACnC,QAAI,EAAE,UAAU,UAAU;AACxB,UAAI;AAEF,cAAM,UAAW,KAAsB,IAAI,OAAK,aAAK,aAAa,CAAC,CAAC;AACpE,eAAO,OAAO,EAAE,OAAsB,EAAE,OAAO,OAAO;eAEtD,IAAM;AACN,cAAM,IAAI,MAAM,kDAAkD;;;AAGtE,WAAO,OAAO,EAAE,OAAsB,EAAE,OAAO,IAAkB;EAEnE;EAES,MAAM,KAAK,GAAa;AAC/B,QAAI,CAAC,KAAK,yBAAyB,CAAC,KAAK,yBAAyB;AAChE,cAAQ,KACJ,mOAIkB;AACtB,WAAK,0BAA0B;;AAGjC,UAAM,kBAAkB,KAAK;AAC7B,UAAM,kBAA+B,CAAA;AAErC,QAAI,gBAAgB;AACpB,QAAI,KAAK,sBAAsB,MAAM;AACnC,WAAK,qBAAqB;AAC1B,sBAAgB;WACX;AACL,WAAK,aAAa,KAAK,eAAe;;AAExC,SAAK,eAAe;AAEpB,MAAC;AAED,UAAM,8BACF,aAAK,QAAQ,KAAK,aAAa,IAAI,CAAC,MAAwB,EAAE,KAAK,CAAC,EAC/D,OAAO,OAAK,KAAK,IAAI;AAC9B,UAAM,4BACF,aAAK,QAAQ,KAAK,aAAa,IAAI,CAAC,MAAwB,EAAE,IAAI,CAAC,EAC9D,OAAO,OAAK,KAAK,IAAI;AAE9B,SAAK,eAAe;AAEpB,QAAI,eAAe;AACjB,WAAK,qBAAqB;;AAE5B,UAAM,MAAwB;MAC5B,cAAc,KAAK;MACnB,gBAAgB,KAAK;MACrB,UAAU;MACV,QAAQ;;AAGV,UAAM,WAAW,MAAM,QAAQ,IAAI,2BAA2B;AAC9D,QAAI,UAAU,IAAI,aAAK,IAAI,QAAQ;AACnC,QAAI,qBAAqB,IAAI,MACzB,SAAS,IAAI,CAAC,GAAG,OAAO,EAAC,MAAM,0BAA0B,CAAC,GAAG,IAAI,EAAC,EAAE,EAC/D,IAAI,OAAK,GAAG,EAAE,IAAI,KAAK,EAAE,EAAE,EAAE,EAC7B,KAAK,IAAI;AAClB,SAAK,eAAe;AACpB,SAAK,iBAAiB;AACtB,WAAO;EACT;EAEA,eACI,OAAiB,OACjB,QAA+B;AACjC,QAAI,UAAU,YAAY,UAAU,QAAQ,OAAO,SAAS,KACxD,aAAK,SAAS,OAAO,CAAC,CAAC,GAAG;AAC5B,eAAU,OAA+B,IAAI,OAAK,aAAK,aAAa,CAAC,CAAC;;AAExE,UAAM,SAAS,KAAK,MAAM,QAAyB,OAAO,KAAK;AAC/D,WAAO,EAAC,QAAQ,OAAO,MAAK;EAC9B;EAEQ,gBAAgB,QAAmB;AACzC,QAAI,CAAC,QAAQ;AACX,aAAO;;AAGT,UAAM,aAAa,KAAK,UAAU,IAAI,OAAO,MAAM;AACnD,UAAM,WAAW,WAAW;AAE5B,QAAI,oBAAoB,WAAW;AACjC,aAAO,EAAC,QAAQ,SAAQ;;AAE1B,QAAI,oBAAoB,YAAY;AAClC,aAAO,SAAS,WAAU;;AAG5B,WAAO;EACT;EAEA,YAAY,QAAc;AACxB,UAAM,aAAa,KAAK,UAAU,IAAI,MAAM;AAE5C,QAAI,WAAW,YAAY,MAAM;AAC/B;;AAGF,UAAM,OAAmB,mBAAmB,WAAW,KAAK,IACxD,aAAK,cAAc,WAAW,KAAK;AACvC,QAAIA;AACJ,UAAM,QAAQ,eAAe,UAAU,eAAe,WAClD,eAAe;AACnB,QAAI,WAAW,QAAQ;AACrB,MAAAA,UAAS,KAAK,cAAc,cAAc,MAAM,OAAO,IAAI;AAC3D,UAAIA,QAAO,aAAa,YAAY;AAClC,cAAM,gBAAgB,KAAK,cAAc,cACrC,MAAM,eAAe,YAAY,eAAe,UAAU,MAC1D,KAAK;AACT,cAAM,cAAc,cAAc,eAAc;AAChD,YAAI,WAAW,UAAU,WAAW,WAAW,UAAU,QAAQ;AAC/D,cAAI,WAAW,WAAW,EAAE,IAAI,WAAW,MAAoB;eAC1D;AACL,cAAI,aAAa,WAAW,EAAE,IAAI,WAAW,MAAsB;;AAErE,sBAAc,MAAK;AACnB,aAAK,0BAAyB;AAC9B,aAAK,sBAAqB;AAC1B,aAAK,eAAe,mBAChB,eAAe,GAAGA,SAAQ,GAAG,IAAI;AAErC,aAAK,uBAAuB,KAAK,aAAa;aACzC;AACL,cAAM,cAAcA,QAAO,eAAc;AACzC,YAAI,WAAW,UAAU,WAAW,WAAW,UAAU,QAAQ;AAC/D,cAAI,WAAW,WAAW,EAAE,IAAI,WAAW,MAAoB;eAC1D;AACL,cAAI,aAAa,WAAW,EAAE,IAAI,WAAW,MAAsB;;AAErE,QAAAA,QAAO,MAAK;;AAId,iBAAW,SAAS;WACf;AACL,MAAAA,UAAS,KAAK,cAAc,cAAc,MAAM,KAAK;;AAEvD,eAAW,WAAWA;EACxB;EAEQ,aAAa,gBAA8B;AACjD,QAAI,gBAAgB;AACpB,QAAI,YAAY;AAChB,UAAM,UAAoB,CAAA;AAC1B,QAAI,sBAAsB;AAC1B,mBAAe,QAAQ,CAAC,MAAK;AAC3B,UAAI,EAAE,KAAK,WAAW,GAAG;AACvB,UAAE,OAAO,CAAC,CAAC;;AAGb,UAAI;AACJ,cAAQ,EAAE,KAAK,QAAQ;QACrB,KAAK;AACH,0BAAgB;AAChB;QACF,KAAK;AACH,0BAAgB;AAChB;QACF,KAAK;AACH,0BAAgB;AAChB;QACF,KAAK;AACH,0BAAgB;AAChB;QACF,KAAK;AACH,0BAAgB;AAChB;QACF,KAAK;AACH,0BAAgB;AAChB;QACF;AACE,uBAAK,OAAO,OAAO,MAAM,eAAe,EAAE,KAAK,MAAM,SAAS;;AAGlE,UAAI,cAAc,KAAK,cAAc,GAAG;AACtC,wBAAgB;;AAElB,UAAI,gBAAgB,qBAAqB;AACvC,8BAAsB;;AAExB,sBAAgB,KAAK,KAAK,gBAAgB,aAAa,IAAI;AAC3D,kBAAY,EAAE,KAAK;AACnB,cAAQ,KAAK,aAAa;AAC1B,uBAAiB,EAAE,KAAK,SAAS;IACnC,CAAC;AAED,oBACI,KAAK,KAAK,gBAAgB,mBAAmB,IAAI;AACrD,UAAM,cAAc,IAAI,YAAY,aAAa;AACjD,mBAAe,QAAQ,CAAC,GAAG,MAAK;AAC9B,YAAM,SAAS,QAAQ,CAAC;AACxB,UAAI,EAAE,SAAS,SAAS;AACtB,YAAI,WAAW,aAAa,QAAQ,EAAE,KAAK,MAAM,EAAE,IAAI,EAAE,IAAI;iBACpD,EAAE,SAAS,UAAU;AAC9B,YAAI,YAAY,aAAa,QAAQ,EAAE,KAAK,MAAM,EAAE,IAAI,EAAE,IAAI;aACzD;AACL,YAAI,aAAa,aAAa,QAAQ,EAAE,KAAK,MAAM,EAAE,IAAI,EAAE,IAAI;;IAEnE,CAAC;AAED,UAAM,gBAAgB,KAAK,cAAc,cACrC,eAAe,eAAe,WAAW,eAAe,OAAO;AACnE,SAAK,MAAM,YAAY,eAAe,GAAG,aAAa,GAAG,aAAa;AACtE,SAAK,uBAAuB,KAAK,aAAa;AAE9C,WAAO,EAAC,QAAQ,GAAG,MAAM,eAAe,QAAQ,cAAa;EAC/D;EAEO,iBACH,SAAuC,QACvC,aAAuB,uBACvB,QAAmB;AACrB,QAAI,CAAC,QAAQ;AACX,eAAS,KAAK,eAAe,QAAQ,aAAa,WAAW;;AAE/D,QAAI,aAAK,cAAc,OAAO,KAAK,MAAM,GAAG;AAG1C,WAAK,UAAU,IAAI,OAAO,MAAM,EAAE,SAC9B,aAAK,uBAAuB,OAAO,OAAoB,CAAC;AAC5D,aAAO;;AAET,SAAK,YAAY,OAAO,MAAM;AAC9B,YAAQ,WAAW,gBAAgB,KAAK,QAAQ,OAAO;AAEvD,UAAM,aAAa,OAAO,IAAI,CAAC,OAAmB,MAAa;AAC7D,UAAI,MAAM,UAAU,aAAa;AAC/B,cAAM,IAAI,MACN,iIAEQ;;AAEd,WAAK,YAAY,MAAM,MAAM;AAE7B,aAAO;;;QAGL,OAAO,KAAK,UAAU,IAAI,MAAM,MAAM,EAAE;QACxC,OAAO,MAAM;QACb,MAAM,QAAQ,cAAc,CAAC;;IAEjC,CAAC;AAED,YAAQ,YACW,cAAc,SAAS,YAAY,MAAM;AAE5D,UAAM,sBAAsB,IAAG,EAAG,QAAQ,4BAA4B;AACtE,QAAI,EAAE,QAAQ,aAAa,KAAK,gBAAgB;AAC9C,WAAK,cAAc,QAAQ,SAAS,IAAmB,eACnD,KAAK,QAAQ,SAAS,YAAY,QAAQ,mBAAmB;;AAEnE,YAAQ,WAAW,KAAK,cAAc,QAAQ,SAAS;AAEvD,QAAI,CAAC,qBAAqB;AACxB,WAAK,gBAAgB,SAAS,QAAQ,QAAQ,qBAAqB;;AAErE,WAAO;EACT;EAEQ,gBACJ,SAAuC,QACvC,QAAsB,uBAAsC;AAC9D,QAAI,QAAQ,oBAAoB,SAAS;AACvC,YAAM,IAAI,MACN,iFAAiF;;AAIvF,QAAI,iBAAiC,CAAA;AACrC,QAAI,eAA2B,CAAA;AAC/B,UAAM,eAAe;AACrB,QAAI,QAAQ,gBAAgB,MAAM;AAChC,qBAAe,KACX,EAAC,MAAM,WAAW,MAAM,CAAC,GAAG,EAAC,GAAG,EAAC,MAAM,WAAW,MAAM,CAAC,QAAQ,EAAC,CAAC;AACvE,qBAAe,OAAO,OAAO,MAAM,EAAE,IAAI,OAAK,EAAE,KAAK;AACrD,YAAMI,gBAAe;AACrB,mBAAa,IAAI,OAAI;AACnB,uBAAe,KAAK,EAAC,MAAMA,eAAc,MAAM,EAAC,CAAC;AACjD,cAAM,UAAU,aAAK,eAAe,CAAC;AACrC,uBAAe,KAAK,EAAC,MAAMA,eAAc,MAAM,QAAO,CAAC;MACzD,CAAC;WACI;AACL,YAAM,UAAU,aAAK,eAAe,OAAO,KAAK;AAChD,qBAAe,KAAK,EAAC,MAAM,cAAc,MAAM,QAAO,CAAC;;AAEzD,QAAI,QAAQ,MAAM;AAChB,YAAM,OAAO,aAAK,cAAc,QAAQ,WAAW;AACnD,qBAAe,KAAK;QAClB,MAAM;QACN,MAAM,CAAC,QAAQ,kBAAkB,OAAO,QAAQ,kBAAkB,IAAI;OACvE;;AAGH,QAAI,uBAAuB;AACzB,uBAAiB,CAAC,GAAG,gBAAgB,GAAG,qBAAqB;;AAE/D,UAAM,WAAW;MACf,KAAK,gBAAgB,MAAM;MAAG,GAAG,OAAO,IAAI,OAAK,KAAK,gBAAgB,CAAC,CAAC;MACxE,KAAK,aAAa,cAAc;;AAGlC,WAAO,QAAQ,WAAQ;AACrB,WAAK,qBAAqB,IAAI,MAAM,MAAM;IAC5C,CAAC;AACD,SAAK,qBAAqB,IAAI,OAAO,MAAM;AAE3C,UAAM,YAAY,KAAK,OAAO,gBAAgB;MAC5C,QAAQ,QAAQ,SAAS,mBAAmB,CAAC;MAC7C,SAAS,SAAS,IAAI,CAAC,GAAG,OAAO,EAAC,SAAS,GAAG,UAAU,EAAC,EAAE;KAC5D;AAED,UAAM,oBAAoB,KAAK,gBAAgB;AAC/C,SAAK,0BAAyB;AAE9B,UAAM,wBAAkD,CAAA;AACxD,QAAI,qBAAqB,KAAK,uBAAuB;AACnD,WAAK,sBAAqB;AAC1B,UAAI,KAAK,YAAY,MAAM;AACzB,aAAK,WAAW,KAAK,OAAO,eAAe;UACzC,MAAM;UACN,OAAO,KAAK;SACb;;AAEH,4BAAsB,kBAAkB;QACtC,UAAU,KAAK;QACf,2BAA2B;QAC3B,qBAAqB;;AAEvB,WAAK,qBACD,KAAK,eAAe,iBAAiB,qBAAqB;eACrD,CAAC,KAAK,oBAAoB;AACnC,WAAK,qBACD,KAAK,eAAe,iBAAiB,qBAAqB;;AAGhE,SAAK,mBAAmB,YAAY,QAAQ,QAAQ;AACpD,SAAK,mBAAmB,aAAa,GAAG,SAAS;AACjD,SAAK,mBAAmB,mBACpB,QAAQ,SAAS,CAAC,GAAG,QAAQ,SAAS,CAAC,GAAG,QAAQ,SAAS,CAAC,CAAC;AACjE,SAAK;AAEL,QAAI,qBACA,IAAG,EAAG,IAAI,mCAAmC,KAC/B,KAAK,uBACnB,QAAQ,iBAAgC,aAAa,MAAM;AAC7D,WAAK,sBAAqB;AAC1B,UAAI,mBAAmB;AACrB,aAAK,aAAa,KACd,EAAC,MAAM,QAAQ,YAAY,MAAM,OAAO,KAAK,aAAY,EAAE,CAAC;aAC3D;AACL,aAAK,YAAW;;;EAGtB;EAEA,MAAM,eAAY;AAChB,QAAI,CAAC,KAAK,uBAAuB;AAC/B,aAAO;;AAGT,QAAI,KAAK,sBAAsB,MAAM;AACnC,WAAK,qBAAqB,KAAK,cAAc,cACzC,KAAK,gBAAgB,GACrB,eAAe,WAAW,eAAe,WACrC,eAAe,aAAa;;AAEtC,SAAK,eAAe,gBAChB,KAAK,UAAU,GAAG,KAAK,eAAe,KAAK,oBAAoB,CAAC;AAEpE,UAAM,qBAAqB,KAAK,cAAc,cAC1C,KAAK,gBAAgB,GACrB,eAAe,WAAW,eAAe,QAAQ;AAErD,SAAK,eAAe,mBAChB,KAAK,oBAAoB,GAAG,oBAAoB,GAChD,KAAK,gBAAgB,CAAC;AAE1B,SAAK,YAAW;AAEhB,UAAM,mBAAmB,SAAS,WAAW,IAAI;AACjD,UAAM,cAAc,IAAI,eAAe,mBAAmB,eAAc,CAAE;AAC1E,UAAM,OAAO,OAAO,YAAY,CAAC,IAAI,YAAY,CAAC,CAAC,IAAI;AACvD,uBAAmB,MAAK;AACxB,SAAK,cAAc,cAAc,kBAAkB;AACnD,WAAO;EACT;EAEA,mBACI,QACA,gBAAgB,4BAA0B;AAC5C,WAAO,IAAG,EAAG,QAAQ,oBAAoB,KACrC,OAAO,MACH,WAAS,KAAK,UAAU,IAAI,MAAM,MAAM,EAAE,YAAY,QAClD,aAAK,cAAc,MAAM,KAAK,IAAI,aAAa;EAC7D;EAES,aAAU;AACjB,WAAO,KAAK,UAAU,WAAU,IAAK,KAAK,0BAA0B;EACtE;EAES,UAAO;AACd,QAAI,KAAK,UAAU;AACjB;;AAEF,QAAI,KAAK,YAAY,MAAM;AACzB,WAAK,SAAS,QAAO;;AAEvB,SAAK,cAAc,QAAO;AAC1B,SAAK,eAAe,QAAO;AAC3B,SAAK,WAAW;EAClB;;AAt6Be,cAAA,aAAa;;;AC7F9B,IAAI,kBAAiB,GAAI;AACvB;IAAgB;IAAU,YAAW;AACnC,YAAM,gBAA0C;QAC9C,iBAAiB,IAAG,EAAG,IAAI,0BAA0B,IACjD,cACA;;AAGN,YAAM,UAAU,MAAM,UAAU,IAAI,eAAe,aAAa;AAChE,YAAM,mBAAwC,CAAA;AAE9C,YAAM,mBAAmB,CAAA;AACzB,UAAI,QAAQ,SAAS,IAAI,iBAAiB,GAAG;AAC3C,yBAAiB,KAAK,iBAAiB;;AAEzC,UAAI,QAAQ,SAAS,IAAI,oBAAoB,GAAG;AAC9C,yBAAiB,KAAK,CAAC,oBAAoB,CAAC;;AAE9C,uBAAiB,mBACb;AAEJ,YAAM,gBAAgB,QAAQ;AAC9B,uBAAiB,iBAAiB;QAChC,kCACI,cAAc;QAClB,oCACI,cAAc;QAClB,+BAA+B,cAAc;QAC7C,iBAAiB,cAAc;QAC/B,4BAA4B,cAAc;QAC1C,qCACI,cAAc;;AAGpB,YAAM,SAAoB,MAAM,QAAQ,cAAc,gBAAgB;AACtE,YAAM,cACJ,UAAU,UACN,QAAQ,OACR,wBAAwB,UAEtB,MAAO,QAAgB,mBAAkB,IACzC;AACR,aAAO,IAAI,cAAc,QAAQ,WAAW;IAC9C;IAAG;;EAAc;;;;AClDnB,IAAY;CAAZ,SAAYC,eAAY;AACtB,EAAAA,cAAAA,cAAA,KAAA,IAAA,CAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,OAAA,IAAA,CAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,uBAAA,IAAA,CAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,uBAAA,IAAA,CAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,KAAA,IAAA,CAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,SAAA,IAAA,CAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,OAAA,IAAA,CAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,WAAA,IAAA,CAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,SAAA,IAAA,CAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,eAAA,IAAA,CAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,MAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,YAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,aAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,YAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,WAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,OAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,oBAAA,IAAA,EAAA,IAAA;AACA,EAAAA,cAAAA,cAAA,KAAA,IAAA,EAAA,IAAA;AACF,GAxBY,iBAAA,eAAY,CAAA,EAAA;AA0BxB,IAAM,MAAM;AACZ,IAAM,QAAQ;AAKd,IAAM,wBAAwB;AAC9B,IAAM,wBAAwB;AAC9B,IAAM,MAAM;AACZ,IAAM,UAAU;AAChB,IAAM,QAAQ;;;;;AAKd,IAAM,YAAY;;;;;;;AAOlB,IAAM,UAAU;;;;;AAKhB,IAAM,gBAAgB;;;;;AAKtB,IAAM,OAAO;;;;;AAKb,IAAM,aAAa;;;;;AAKnB,IAAM,cAAc;AACpB,IAAM,mBAAmB;;AAEzB,IAAM,aAAa;AACnB,IAAM,kBAAkB;;AAExB,IAAM,MAAM;AACZ,IAAM,MAAM;AACZ,IAAM,MAAM;;;;;;AAMZ,IAAM,WAAW;;;;;;;;;;;;;;;;AAgBjB,IAAM,MAAM;AACZ,IAAM,YAAY;;;;AAIlB,IAAM,iBAAiB;;;;AAKvB,IAAM,MAAM;;;;;;;;AAQZ,IAAM,WAAW;;;;;;;;;;;;;;;;;;;;;;AAuBjB,IAAM,QAAQ;AACd,IAAM,aAAa;;;;AAInB,IAAM,qBAAqB;AAC3B,IAAM,MAAM;AAEN,SAAU,kBACZ,MAAoB,SAAiB;AACvC,MAAI;AAGJ,KAAG;AACD,YAAQ,MAAM;MACZ,KAAK,aAAa;AAChB,sBAAc;AACd;MACF,KAAK,aAAa;AAChB,sBAAc;AACd;MACF,KAAK,aAAa;AAChB,sBAAc;AACd;MACF,KAAK,aAAa;AAChB,sBAAc,UAAU,WAAW;AACnC;MACF,KAAK,aAAa;AAChB,sBAAc,UAAU,iBAAiB;AACzC;MACF,KAAK,aAAa;AAChB,sBAAc,UAAU,WAAW;AACnC;MACF;AACE;;AAGJ,QAAIC;AACJ,QAAI;AACJ,QAAI;AACJ,QAAI,SAAS;AACX,MAAAA,SAAQ;AACR,eAAS;AACT,cAAQ;WACH;AACL,MAAAA,SAAQ;AACR,eAAS;AACT,cAAQ;;AAGV,WAAO;qBACUA,MAAK;0CACgB,MAAM;qBAC3BA,MAAK;0CACgB,MAAM;;;;;;UAMtC,WAAW;;0BAEK,MAAM;cAClB,KAAK;;;WAGR;AAGT,UAAQ,MAAM;IACZ,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,aAAO,UAAU,mBAAmB;IACtC,KAAK,aAAa;AAChB,aAAO,UAAU,kBAAkB;IACrC,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,aAAO,UAAU,aAAa;IAChC,KAAK,aAAa;AAChB,oBAAc;AACd;IACF,KAAK,aAAa;AAChB,oBAAc;AACd;IACF;;AAGF,SAAO;MACH,WAAW;;;AAGjB;;;ACtQA,IAAY;CAAZ,SAAYC,cAAW;AACrB,EAAAA,aAAAA,aAAA,KAAA,IAAA,CAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,CAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,OAAA,IAAA,CAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,CAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,OAAA,IAAA,CAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,CAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,OAAA,IAAA,CAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,CAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,KAAA,IAAA,CAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,CAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,OAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,OAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,WAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,QAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,QAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,QAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,OAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,aAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,OAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,WAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,YAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,OAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,OAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,SAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,UAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,QAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,KAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,MAAA,IAAA,EAAA,IAAA;AACA,EAAAA,aAAAA,aAAA,QAAA,IAAA,EAAA,IAAA;AACF,GA1CY,gBAAA,cAAW,CAAA,EAAA;AA4CvB,IAAM,MAAM;AACZ,IAAM,OAAO;;;;;;AAMb,IAAM,QAAQ;;;;;;AAMd,IAAM,OAAO;;;;;;AAMb,IAAM,QAAQ;AACd,IAAM,OAAO;;;;;;AAMb,IAAM,QAAQ;;;;;;;;;;;;AAYd,IAAM,OAAO;AACb,IAAM,MAAM;AACZ,IAAM,OAAO;;;;AAIb,IAAM,QAAQ;AACd,IAAM,MAAM;AACZ,IAAM,WAAW;;;;;;;;;;;;;;;;AAgBjB,IAAM,MAAM;;;;YAIA,qBAAa,KAAK;aACjB,qBAAa,MAAM;aACnB,qBAAa,MAAM;aACnB,qBAAa,MAAM;aACnB,qBAAa,MAAM;aACnB,qBAAa,MAAM;;;;;;;AAOhC,IAAM,MAAM;AACZ,IAAM,QAAQ;AACd,IAAM,YAAY;AAClB,IAAM,SAAS;AACf,IAAM,SAAS;AACf,IAAM,SAAS;AACf,IAAM,MAAM;;AAEZ,IAAM,QAAQ;;;;AAId,IAAM,cAAc;AACpB,IAAM,MAAM;AACZ,IAAM,YAAY;AAClB,IAAM,iBAAiB;;;;AAIvB,IAAM,aAAa;AACnB,IAAM,OAAO;AACb,IAAM,QAAQ;AACd,IAAM,aACF;AACJ,IAAM,YAAY;;;AAGlB,IAAM,QAAQ;AACd,IAAM,QAAQ;AAGd,IAAM,OAAO;;aAEA,qBAAa,UAAU;;aAEvB,qBAAa,eAAe;;;AAGzC,IAAM,UAAU;AAChB,IAAM,OAAO;AACb,IAAM,MAAM;AACZ,IAAM,OAAO;;;;AAIb,IAAM,WAAW;;;;;;;;;;;;;;;;AAgBjB,IAAM,OAAO;AACb,IAAM,SAAS;AACf,IAAM,OAAO;;;;;;;AAOb,IAAM,MAAM;AACZ,IAAM,OAAO;;;;AAIb,IAAM,SAAS;AAET,SAAU,iBAAiB,MAAmB,SAAiB;AACnE,UAAQ,MAAM;IACZ,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO,UAAU,WAAW;IAC9B,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO,UAAU,iBAAiB;IACpC,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO,UAAU,YAAY;IAC/B,KAAK,YAAY;AACf,aAAO,UAAU,aAAa;IAChC,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IACT,KAAK,YAAY;AACf,aAAO;IAET;AACE,YAAM,IAAI,MAAM,cAAc,IAAI,sBAAsB;;AAE9D;;;AC3RM,SAAU,oBACZ,YAAqC,4BAA4B,OACjE,SAAS,OAAO,eAAe,GAAC;AAClC,MAAI,eAAe,MAAM;AACvB,WAAO;;AAGT,MAAI,sBAAsB;AAC1B,MAAI,eAAe,UAAU;AAC3B,0BAAsB,iBAAiB,YAAY,MAAM;aAChD,eAAe,QAAQ;AAChC,0BAAsB,iBAAiB,YAAY,MAAM,MAAM;aACtD,eAAe,OAAO;AAC/B,0BAAsB,iBAAiB,YAAY,KAAK,MAAM;aACrD,eAAe,SAAS;AACjC,0BAAsB,iBAAiB,YAAY,OAAO,MAAM;aACvD,eAAe,SAAS;AACjC,0BAAsB,kBAAkB,aAAa,OAAO,MAAM;aACzD,eAAe,WAAW;AACnC,0BAAsB,iBAAiB,YAAY,SAAS,MAAM;aACzD,eAAe,aAAa;AACrC,0BAAsB,iBAAiB,YAAY,WAAW,MAAM;SAC/D;AACL,UAAM,IAAI,MAAM,cACZ,UAAU,mDAAmD;;AAEnE,QAAM,cAAc,SAAS,IAAI;AACjC,QAAM,WAAW,YAAY,WAAW;AACxC,MAAIC,uBAAsB;AAC1B,MAAI,2BAA2B;AAC7B,IAAAA,uBAAsB;0BACA,QAAQ,iBAAiB,YAAY,aACvD,QAAQ;;UAEN,mBAAmB;;SAEpB;AACL,IAAAA,uBAAsB;0BACA,QAAQ,iBAAiB,YAAY,aACvD,QAAQ;UACN,mBAAmB;;;AAG3B,SAAOA;AACT;AAEM,SAAU,sBACZ,SAAkB,YAAmC;AACvD,SAAO;QACD,UAAU,mDAAmD,EAAE;QAC/D,aAAa,uCAAuC,EAAE;;AAE9D;;;ACpDM,SAAU,mBACZ,YAAqB,YAAqB,YAAY,OACtD,YAAY,OAAO,WAAW,OAAO,YAAY,GAAC;AACpD,eAAK,OACD,cAAc,cAAc,KAAK,CAAC,YAClC,MAAM,cAAc,UAAU,0CAC1B,SAAS,EAAE;AACnB,QAAM,UAAU;QAEZ,aAAa,mCACA,gCAAgC;;;AAGjD,QAAM,UAAU,aAAa,mCACA;AAE7B,SAAO;mDAC0C,YAAY,SAAS,CAAC;kBACvD,YAAY,SAAS,CAAC;MAElC,aAAa,WACT,UACA;MAEI,aACI,4DACA,0DAA0D;;QAEpE,OAAO;;KAEV;;;;mDAI8C,YAAY,SAAS,CAAC;kBACvD,YAAY,SAAS,CAAC;MAClC,OAAO;;;;AAIb;AAEM,SAAU,wBACZ,SAAkB,YAAqC,YACvD,YAAqB,YAAY,OAAO,YAAY,OAAO,WAAW,OACtE,YAAY,GAAC;AACf,SAAO;IAEH,mBACI,YAAY,YAAY,WAAW,WAAW,UAAU,SAAS,CAAC;yDAEtE,YAAY,SAAS,CAAC;MAEtB,aAAa,YACT,KACA,2DAA2D;;;;QAI7D,sBAAsB,SAAS,UAAU,CAAC;;;;;AAKlD;AAEA,IAAM,6BACF,CAACC,YAAoB,qBAA4B;AAC/C,MAAIA,YAAW;AACb,WAAO;;;wCAGyB,gBAAgB;;SAG3C;AACL,WAAO;;;gCAGiB,gBAAgB;;;AAG5C;AAEJ,IAAM,yBACF,CAAC,YAAqB,kBAA0B,cAC/C,cAAqB;AACpB,MAAI,YAAY;AACd,WAAO;4BACa,SAAS;;;8BAGP,YAAY;;;;SAI7B;AACL,QAAI,aAAa;AACjB,QAAI,SAAS;AACb,aAAS,IAAI,GAAG,IAAI,kBAAkB,KAAK;AACzC,oBAAc,cAAc,CAAC,kBAAkB,gBAAgB,MAC3D,CAAC;AACL,gBACI,uBAAuB,CAAC,uBAAuB,CAAC;;AAEtD,WAAO;4BACa,YAAY,gBAAgB;UAC9C,UAAU;8BACU,YAAY;;YAE9B,MAAM;;;;AAId;AAEE,SAAU,2BACZ,eAAyB,eACzB,aAAa,OAAO,YAAY,IAAI,SAAS,OAAO,kBAAkB,IACtE,iBAAiB,OAAK;AACxB,QAAM,aAAa,cAAc,CAAC,IAAI,cAAc,CAAC;AACrD,QAAM,aAAa,cAAc,CAAC,IAAI,cAAc,CAAC;AACrD,QAAM,aAAa,aAAa,aAAa;AAC7C,QAAM,aAAa,aAAa,YAAY;AAC5C,QAAM,mBAAmB,aAAa,cAAc,CAAC;AACrD,QAAM,gBAAgB,YAAY,cAAc,CAAC;AACjD,QAAM,eAAe,cAAc,CAAC;AACpC,QAAM,eAAe,cAAc,CAAC;AACpC,eAAK,QACC,cAAc,qBAAqB,KAAK,cAAc,CAAC,MAAM,KAC7D,CAAC,eAAe,qBAAqB,KAAK,qBAAqB,OAC7D,aAAa,cAAc,CAAC,MAAM,KAClC,YAAY,cAAc,CAAC,MAAM,KAAK,cAAc,CAAC,MAAM,GAC/D,MAAM,iBAAiB,UAAU,8BAC7B,gBAAgB,yBAAyB,cAAc,CAAC,CAAC;wCAC3B,gBAAgB;mBACrC,UAAU,yCACnB,cAAc,CAAC,CAAC,eAChB,SAAS,0CACT,cAAc,CAAC,CAAC,kBAAkB,cAAc,CAAC,CAAC,aAAa;AACvE,SAAO;4CACmC,gBAAgB,UACtD,aAAa,gBAAgB,MAAM,UAAU;oDAE7C,aAAa,cAAc,CAAC,CAAC,MAAM,SAAS;;IAE9C,oBAAI,CAAE;;+BAEqB,YAAY;;;wCAGH,YAAY;wCACZ,YAAY;kBAClC,SAAS,MAAM,iBAAiB;mBAE5C,UAAU,CAAC,iBAAiB,UAAU,4BAA4B;mBAElE,UAAU,CAAC,iBAAiB,UAAU,4BAA4B;gDACxB,UAAU;;qBAGpD,SAAS,GAAG,KAAK,KAAK,kBAAkB,SAAS,CAAC,KACzC,6BAA6B,SAAS,MAAM;mBACxC,SAAS,qBAAqB,eAAe,KAAK,GAAG;;gCAExC,YAAY;;;gCAGZ,aAAa;;;4CAGD,YAAY;;;cAG1C,2BAA2B,YAAY,gBAAgB,CAAC;;;;4CAI1B,aAAa;;;;;4BAK7B,SAAS;;;;UAK/B,uBACI,YAAY,kBAAkB,cAAc,SAAS,CAAC;;;;wCAIxB,YAAY;;;;AAIpD;AAEA,IAAM,yBAAyB,CAACA,eAAsB;AACpD,MAAIA,YAAW;AACb,WAAO;;;;;SAMF;AACL,WAAO;;;;;;AAMX;AAEA,IAAM,0BAA0B,CAAC,eAAuB;AACtD,SAAO,aAAa,kDAEA;AACtB;AAIM,SAAU,uBACZ,eAAyB,eACzB,aAAa,OAAO,YAAY,IAAI,SAAS,OAAO,kBAAkB,IACtE,4BAA4B,OAAO,iBAAiB,OAAK;AAC3D,QAAM,aAAa,cAAc,CAAC,IAAI,cAAc,CAAC;AACrD,QAAM,aAAa,cAAc,CAAC,IAAI,cAAc,CAAC;AACrD,QAAM,aAAa,aAAa,aAAa;AAC7C,QAAM,aAAa,aAAa,YAAY;AAC5C,eAAK,OACD,aAAa,cAAc,CAAC,MAAM,KAC9B,aAAa,cAAc,CAAC,MAAM,KAClC,YAAY,cAAc,CAAC,MAAM,GACrC,MAAM,cAAc,UAAU,yCAC1B,cAAc,CAAC,CAAC,gBAChB,UAAU,yCACV,cAAc,CAAC,CAAC,eAChB,SAAS,yCAAyC,cAAc,CAAC,CAAC,EAAE;AAC5E,QAAM,gBAAgB,aAAa,cAAc,CAAC;AAClD,QAAM,gBAAgB,aAAa,cAAc,CAAC;AAClD,QAAM,gBAAgB,YAAY,cAAc,CAAC;AACjD,QAAM,eAAe,cAAc,CAAC;AACpC,QAAM,eAAe,cAAc,CAAC;AACpC,QAAM,gBAAgB,4BAClB;;;kDAG4C,UAAU;kDACV,UAAU;;;;;mDAMlD,UAAU,2BAA2B,cAAc,CAAC,CAAC;qDAErD,UAAU,2BAA2B,cAAc,CAAC,CAAC;cACjD,uBAAuB,UAAU,CAAC;;;;mDAKtC,SAAS,2BAA2B,cAAc,CAAC,CAAC;yDAEpD,UAAU,2BAA2B,cAAc,CAAC,CAAC;;;;;;4BAMnC,SAAS;;;;mCAIF,YAAY;8BACjB,SAAS;wCACC,YAAY;6DACS,cAAc,CAAC,CAAC;;8CAE/B,YAAY;4BAEhD,aACI,oCAAoC,cAAc,CAAC,CAAC,OACpD,iCAAiC,cAAc,CAAC,CAAC,OAAO;gDACtB,YAAY;;;;;;;;0CAQlB,YAAY;4DACM,cAAc,CAAC,CAAC;4CAChC,YAAY;8DACM,cAAc,CAAC,CAAC;;;;UAKxE;mCAC6B,YAAY;mCACZ,YAAY;;sCAET,YAAY;sCACZ,YAAY;8CACJ,UAAU;;oCAEpB,aAAa;oCACb,aAAa;oCACb,aAAa;;;;wCAIT,aAAa;0CACX,aAAa;;;UAG7C,uBAAuB,UAAU,CAAC;;;;;wCAKJ,aAAa;0CACX,YAAY;;;;;;;;wBAQ9B,SAAS;;;;+BAIF,YAAY;0BACjB,SAAS;oCACC,YAAY;;;;0CAIN,YAAY;UAC5C,wBAAwB,UAAU,CAAC;4CACD,YAAY;;;;;;;;;;sCAUlB,YAAY;wCACV,YAAY;;;;;;AAOlD,SAAO;gDACuC,UAAU,MAAM,UAAU;gDAC1B,UAAU,MAAM,SAAS;;MAEnE,oBAAI,CAAE;oBACQ,SAAS,MAAM,iBAAiB;qBAE9C,UAAU,CAAC,iBAAiB,UAAU,4BAA4B;qBAElE,UAAU,CAAC,iBAAiB,UAAU,4BAA4B;uBAElE,SAAS,GAAG,KAAK,KAAK,kBAAkB,SAAS,CAAC,KACzC,6BAA6B,SAAS,MAAM;qBACtC,SAAS,qBAAqB,eAAe,KAAK,GAAG;;mCAEvC,YAAY,MAAM,YAAY;;;0CAGvB,YAAY;4CACV,YAAY;;;;QAIhD,aAAa;;;AAGrB;AAEA,IAAM,qBAAqB,CAACA,eAAsB;AAChD,SAAOA,aAAY;;;;;MAMA;;;;;;AAMrB;AAEM,SAAU,8BACZ,eAAyC,aAAa,OAAK;AAC7D,eAAK,OACD,cAAc,CAAC,MAAM,KAAK,cAAc,CAAC,MAAM,GAC/C,MAAM,iDAAiD,aAAa,GAAG;AAC3E,QAAM,WAAW,cAAc,CAAC,IAAI;AACpC,SAAO;gDACuC,cAAc,CAAC,CAAC;;MAE1D,oBAAI,CAAE;;;;;iDAKqC,QAAQ;;;;;;;;;;yBAUhC,QAAQ;uCACM,mBAAmB,UAAU,CAAC;;;;8BAIvC,WAAW,CAAC;2BACf,QAAQ;;;;;;;;;;;;;;;;AAgBnC;AAEM,IAAO,sBAAP,MAA0B;EAuB9B,YACI,QAAkC,aAClC,aAAa,OAAO,aAAa,OAAO,OAAmB,MAC3D,aAAsC,MACtC,yBAAqC,MACrC,4BAA4B,OAAK;AAvBrC,SAAA,gBAAgB,CAAC,KAAK,GAAG;AACzB,SAAA,WAAW;AAuBT,SAAK,cAAc;AACnB,SAAK,iBAAiB,EAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,EAAC;AAC7C,UAAM,WAAW,aAAa,OAAO,CAAC,IAAI,OAAO,CAAC;AAClD,SAAK,UAAW,WAAW,MAAM,KAAK,CAAC,cACvB,YAAY,CAAC,IAAI,MAAM,KAAK,eACxC,YAAY,CAAC,IAAI,MAAM,KAAK,CAAC;AACjC,SAAK,kBAAkB,KAAK,SAAS,IAAI;AACzC,SAAK,YAAY,YAAY,CAAC,MAAM,KAAK,CAAC;AAE1C,QAAI,CAAC,KAAK,UAAU,KAAK,WAAW;AAElC,WAAK,oBAAoB,CAAC,GAAG,GAAG,CAAC;AACjC,WAAK,gBAAgB,CAAC,IAAI,GAAG,CAAC;WACzB;AACL,YAAM,gBAAgB,8BAClB,YAAY,CAAC,GAAG,UAAU,YAAY,CAAC,GAAG,UAAU;AACxD,WAAK,gBAAgB,cAAc;AACnC,WAAK,oBAAoB,cAAc;;AAGzC,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,KAAK,iBAAiB;AAE1B,UAAM,UAAU,QAAQ;AACxB,UAAM,4BAA4B,0BAA0B;AAC5D,QAAI,SAAS;AACX,WAAK,cAAc,KAAK,MAAM;;AAGhC,QAAI,2BAA2B;AAC7B,WAAK,cAAc,KAAK,wBAAwB;;AAGlD,SAAK,4BAA4B;AACjC,SAAK,aAAa;AAClB,SAAK,aAAa;AAClB,SAAK,UAAU;AACf,SAAK,aAAa;AAClB,SAAK,4BAA4B;AACjC,KAAC,KAAK,WAAW,KAAK,WAAW,KAAK,QAAQ,IAC1C,KAAK,YAAY,YAAY,CAAC,GAAG,YAAY,CAAC,GAAG,QAAQ;AAC7D,SAAK,YAAY,gBAAgB,KAAK,iBAAiB,IAAI,UAAU,IACjE,UAAU,IAAI,KAAK,UAAU,IAAI,KAAK,SAAS,IAAI,KAAK,SAAS,IACjE,KAAK,QAAQ,IAAI,KAAK,MAAM,IAAI,KAAK,SAAS,IAC9C,KAAK,yBAAyB;EACpC;EAEA,YAAY,WAAmB,WAAmB,UAAgB;AAEhE,UAAM,aAAa,KAAK,cAAc,CAAC,IAAI,KAAK,kBAAkB,CAAC;AACnE,UAAM,aAAa,KAAK,cAAc,CAAC,IAAI,KAAK,kBAAkB,CAAC;AAEnE,QAAI,CAAC,KAAK,UAAU,KAAK,WAAW;AAElC,WAAK,YAAY,KAAK,cAAc,CAAC,IAAI;WACpC;AACL,WAAK,YAAY;;AAGnB,UAAM,YAAY,YAAY,eAAe;AAC7C,UAAM,YAAY,YAAY,eAAe;AAC7C,UAAM,WAAW,WAAW,KAAK,cAAc;AAC/C,WAAO,CAAC,WAAW,WAAW,QAAQ;EACxC;EAEA,cAAW;AACT,UAAM,WAAW;QAEb,oBACI,KAAK,YAAY,KAAK,2BAA2B,KAAK,MAAM,CAAC;QAEjE,wBACI,KAAK,SAAS,KAAK,YACnB,OACA,KAAK,YAAY,KAAK,WAAW,KAAK,WAAW,KAAK,UACtD,KAAK,SAAS,IAAI,CAAC,CAAC;QAExB,KAAK,SACD,2BACI,KAAK,mBAAmB,KAAK,eAAe,KAAK,YACjD,KAAK,WAAW,OAAO,MAAM,IAAI,IACpC,KAAK,YAAY,8BACI,KAAK,eAAe,KAAK,UAAU,IACvC,uBACI,KAAK,mBAAmB,KAAK,eAC7B,KAAK,YAAY,KAAK,WAAW,OAAO,MACxC,KAAK,2BAA2B,IAAI,CAAE;;AAEpE,WAAO;EACT;;;;AC9jBI,SAAU,uBAAuB,gBAAsB;AAC3D,SAAO;4CACmC,cAAc;MACpD,oBAAI,CAAE;;;;;;;;;yDAS6C,cAAc;;;;;;;;8BAQzC,iBAAiB,CAAC;;;;;;;;;;;;;;;AAehD;AAEM,IAAO,sBAAP,MAA0B;EAc9B,YACI,aAAuC,aAAa,OACpD,aAAa,OAAO,OAAmB,MACvC,aAAsC,MACtC,yBAAqC,MAAI;AAb7C,SAAA,gBAAgB,CAAC,KAAK,GAAG;AACzB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,KAAK,GAAG,CAAC;AAYlD,SAAK,cAAc;AACnB,SAAK,iBAAiB,EAAC,GAAG,CAAA,GAAI,GAAG,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC,EAAC;AAC/C,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,UAAM,UAAU,QAAQ;AACxB,UAAM,4BAA4B,0BAA0B;AAC5D,QAAI,SAAS;AACX,WAAK,cAAc,KAAK,MAAM;;AAGhC,QAAI,2BAA2B;AAC7B,WAAK,cAAc,KAAK,wBAAwB;;AAGlD,SAAK,aAAa;AAClB,SAAK,aAAa;AAClB,SAAK,UAAU;AACf,SAAK,aAAa;AAClB,SAAK,4BAA4B;AACjC,SAAK,YACD,gBAAgB,KAAK,UAAU,IAAI,UAAU,IAAI,UAAU;EACjE;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAoB,KAAK,YAAY,KAAK,yBAAyB,CAAC;QAEpE,wBACI,KAAK,SAAS,KAAK,YAAY,KAAK,YAAY,KAAK,UAAU,CAAC;QACpE,uBAAuB,KAAK,cAAc,CAAC,CAAC,CAAC;;AAEjD,WAAO;EACT;;;;AC3FI,SAAU,gCACZ,eAAuC;AACzC,QAAM,aAAa,cAAc,CAAC;AAClC,QAAM,aAAa,cAAc,CAAC;AAClC,QAAM,YAAY,aAAa,aAAa,aAAa;AACzD,SAAO;8CACqC,SAAS,MAAM,UAAU;8CACzB,UAAU,MAAM,SAAS;;;;;;;;IAQnE,oBAAI,CAAE;;;;;;;;;;+CAUqC,SAAS;;;;;;;;gCAQxB,SAAS;gCACT,SAAS;;;;;;;;;;;;kCAYP,SAAS;kCACT,SAAS;;4BAEf,SAAS;;;;;;;;;AASrC;AAEM,IAAO,+BAAP,MAAmC;EAcvC,YACI,QAAkC,QAClC,aAAuC,aAAa,OACpD,aAAa,OAAO,OAAmB,MACvC,aAAsC,MACtC,yBAAqC,MAAI;AAd7C,SAAA,gBAAgB,CAAC,KAAK,GAAG;AACzB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAajD,SAAK,cAAc;AAEnB,SAAK,iBAAiB,EAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,EAAC;AAC7C,SAAK,WAAW;MACd,KAAK,KAAK,YAAY,CAAC,IAAI,KAAK,cAAc,CAAC,CAAC;MAChD,KAAK,KAAK,YAAY,CAAC,IAAI,KAAK,cAAc,CAAC,CAAC;MAAG,YAAY,CAAC;;AAGlE,UAAM,UAAU,QAAQ;AACxB,QAAI,SAAS;AACX,WAAK,cAAc,KAAK,MAAM;;AAGhC,UAAM,4BAA4B,0BAA0B;AAC5D,QAAI,2BAA2B;AAC7B,WAAK,cAAc,KAAK,wBAAwB;;AAGlD,SAAK,aAAa;AAClB,SAAK,aAAa;AAClB,SAAK,UAAU;AACf,SAAK,aAAa;AAClB,SAAK,4BAA4B;AACjC,SAAK,YACD,yBAAyB,KAAK,UAAU,IAAI,UAAU,IAAI,UAAU;EAC1E;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAoB,KAAK,YAAY,KAAK,yBAAyB,CAAC;QAEpE,wBACI,KAAK,SAAS,KAAK,YAAY,KAAK,YAAY,KAAK,UAAU,CAAC;QACpE,gCAAgC,KAAK,aAAa,CAAC;;AAEvD,WAAO;EACT;;;;ACjHI,IAAO,sBAAP,MAA0B;EAe9B,YACI,aAAuC,UACvC,aAAa,OAAO,aAAa,OAAK;AAZ1C,SAAA,gBAAgB,CAAC,KAAK,GAAG;AACzB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,GAAG,GAAG,CAAC;AAIlD,SAAA,SAAS;AAET,SAAA,kBAAkB;AAKhB,iBAAK,OACD,YAAY,CAAC,MAAM,GACnB,MAAM,8CAA8C;AACxD,SAAK,cAAc;AACnB,SAAK,iBAAiB,EAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,EAAC;AAChD,UAAM,UAAU,cAAc,KAAK,YAAY,CAAC,IAAI,MAAM,KAC1C,CAAC,cAAc,WAAW,MAAM,MAC5C,KAAK,YAAY,CAAC,IAAI,MAAM;AAChC,SAAK,oBAAoB,CAAC,GAAG,GAAG,KAAK,eAAe;AACpD,SAAK,kBAAkB,SAAS,IAAI;AACpC,QAAI,CAAC,QAAQ;AACX,UAAI,KAAK,YAAY,CAAC,IAAI,IAAI;AAC5B,aAAK,kBAAkB,CAAC,IAAI;;AAE9B,UAAI,KAAK,YAAY,CAAC,IAAI,IAAI;AAC5B,aAAK,kBAAkB,CAAC,IAAI;;;AAIhC,SAAK,WAAW,gBACZ,KAAK,gBACL;MACE,KAAK,YAAY,CAAC;MAAG,KAAK,YAAY,CAAC;MAAG,KAAK,YAAY,CAAC;MAC5D;OAEF,KAAK,eAAe,KAAK,iBAAiB;AAE9C,SAAK,aAAa;AAClB,SAAK,aAAa;AAClB,SAAK,YAAY,gBAAgB,UAAU,IAAI,UAAU,IACrD,KAAK,iBAAiB,IAAI,KAAK,eAAe;EACpD;EAEA,cAAW;AACT,UAAM,YAAY,KAAK;AACvB,UAAM,WAAW;QAEb,mBACI,OAAO,KAAK,YAAY,OAAO,OAAO,OAAO,SAAS,CAAC;8DAE3D,YAAY,SAAS,CAAC;;;;;;gCAME,SAAS;cAEjC,iBACI,0BAA0B,GAAG,YAAY,IAAI,aAAa,OAAO,IACjE,SAAS,CAAC;;;;QAKd,cAAc,IAAI,2BACI,KAAK,mBAAmB,KAAK,eAC7B,KAAK,YAAY,IAAI,MAAM,KAAK,eAAe,IACnD,uBACI,KAAK,mBAAmB,KAAK,eAC7B,KAAK,YAAY,IAAI,MAAM,KAAK,eAAe,CAAC;;AAE1E,WAAO;EACT;;AAGI,IAAO,wBAAP,MAA4B;EAahC,YACI,aAAuB,OAAmB,MAC1C,aAAsC,MACtC,yBAAqC,MAAI;AAb7C,SAAA,WAAW;AAGX,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AASL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,UAAU,QAAQ;AACvB,SAAK,4BAA4B,0BAA0B;AAC3D,SAAK,aAAa;AAClB,QAAI,KAAK,SAAS;AAChB,WAAK,cAAc,KAAK,MAAM;;AAGhC,QAAI,KAAK,2BAA2B;AAClC,WAAK,cAAc,KAAK,wBAAwB;;AAGlD,SAAK,YAAY,kBAAkB,UAAU;EAC/C;EAEA,cAAW;AACT,WAAO;MACL,oBAAoB,KAAK,YAAY,KAAK,yBAAyB,CAAC;MACpE,oBAAK,OAAO,CAAC;;;;UAIT,sBAAsB,KAAK,SAAS,KAAK,UAAU,CAAC;;;;;EAK5D;;;;ACxII,IAAO,cAAP,MAAkB;EAUtB,YAAY,OAAe;AAT3B,SAAA,gBAA0B,CAAA;AAC1B,SAAA,cAAwB,CAAA;AAIxB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;MACf,oBAAK,OAAO,CAAC;;;;;;AAMf,WAAO;EACT;;;;AC1BI,SAAU,KAAK,MAAgD;AAEnE,QAAM,EAAC,SAAS,MAAK,IAAI;AACzB,QAAM,EAAC,OAAO,MAAK,IAAI;AACvB,MAAI,EAAC,MAAK,IAAI;AAEd,UAAQ,SAAS,aAAK,WAAW,KAAK;AAEtC,MAAI,UAAU,UAAU;AAEtB,UAAM,SAAS,aAAK,kBAAkB,OAAO,aAAK,cAAc,KAAK,CAAC;AACtE,WAAO,KAAK,KAAe;AAC3B,WAAO,QAAQ,eAAe,OAAO,OAAO,MAAM;SAC7C;AACL,UAAM,UAAU,IAAI,YAAY,KAAK;AACrC,UAAM,cAAc,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,KAAe,EAAC,CAAC;AAC/D,WAAO,QAAQ,iBAAiB,SAAS,CAAA,GAAI,OAAO,WAAW;;AAEnE;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACxBR,SAAU,QACZ,MAA0E;AAE5E,QAAM,EAAC,QAAQ,MAAK,IAAI;AACxB,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,MAAK,IAAI;AAEhB,QAAM,QAAQ,aAAK,cAAc,EAAE,KAAK;AACxC,QAAM,SAAS,aAAK,uBAAuB,OAAO,KAAK;AACvD,QAAM,SAAS,aAAK,cAAc,MAAM;AAExC,eAAK,OACD,UAAU,QACV,MAAM,kBAAkB,MAAM,SAAS,MAAM,gCAC/B,EAAE,KAAK,SAAS,KAAK,+EACe;AAGtD,OAAK,QAAQ,OAAO,EAAE,MAAM;AAC5B,SAAO,EAAC,QAAQ,EAAE,QAAQ,OAAO,QAAQ,OAAO,EAAE,MAAK;AACzD;AAEO,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACJR,SAAU,gBAAgB,EAC9B,GACA,GACA,YACA,YACA,SACA,OAAO,MACP,yBAAyB,MACzB,iBAAiB,GACjB,aAAa,KAAI,GACC;AAClB,QAAM,QAAQ,EAAE,MAAM;AACtB,QAAM,QAAQ,EAAE,MAAM;AAEtB,QAAM,cAAc,aAAa,EAAE,MAAM,QAAQ,CAAC,IAAI,EAAE,MAAM,QAAQ,CAAC;AACvE,QAAM,cAAc,aAAa,EAAE,MAAM,QAAQ,CAAC,IAAI,EAAE,MAAM,QAAQ,CAAC;AAEvE,QAAM,cAAc,aAAa,EAAE,MAAM,QAAQ,CAAC,IAAI,EAAE,MAAM,QAAQ,CAAC;AACvE,QAAM,cAAc,aAAa,EAAE,MAAM,QAAQ,CAAC,IAAI,EAAE,MAAM,QAAQ,CAAC;AAEvE,QAAM,aAAa,EAAE,MAAM,MAAM,GAAG,EAAE;AACtC,QAAM,aAAa,EAAE,MAAM,MAAM,GAAG,EAAE;AAEtC,QAAM,YAAY,aAAK,cAAc,UAAU;AAC/C,QAAM,YAAY,aAAK,cAAc,UAAU;AAE/C,QAAM,oBAAoB,uBAAe,2BACrC,EAAE,MAAM,MAAM,GAAG,EAAE,GAAG,EAAE,MAAM,MAAM,GAAG,EAAE,CAAC;AAC9C,QAAM,WAAW,kBAAkB,OAAO,CAAC,aAAa,WAAW,CAAC;AAEpE,eAAK,OACD,gBAAgB,aAChB,MAAM,kCAAkC,WAAW,UAC5C,WAAW,4BAA4B,EAAE,KAAK,QAC9C,EAAE,KAAK,mBAAmB,UAAU,mBACpB,UAAU,cAAc;AAEnD,QAAM,WAAqC,aACvC,CAAC,WAAW,aAAa,WAAW,IACpC,CAAC,WAAW,aAAa,WAAW;AACxC,QAAM,WAAqC,aACvC,CAAC,WAAW,aAAa,WAAW,IACpC,CAAC,WAAW,aAAa,WAAW;AAGxC,QAAM,MAAM,QAAQ,EAAC,QAAQ,EAAC,GAAG,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AACvE,QAAM,MAAM,QAAQ,EAAC,QAAQ,EAAC,GAAG,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AACvE,QAAM,gBAA8B,CAAC,KAAK,GAAG;AAE7C,QAAM,WAAW,KAAK,IAAI,WAAW,SAAS;AAE9C,QAAM,SAAuB,CAAC,KAAK,GAAG;AACtC,QAAM,aAAa;IACjB,EAAC,MAAM,SAAS,MAAM,CAAC,WAAW,EAAC;IAAG,EAAC,MAAM,SAAS,MAAM,CAAC,WAAW,EAAC;IACzE,EAAC,MAAM,SAAS,MAAM,CAAC,WAAW,EAAC;;AAGrC,MAAI;AACJ,MAAI;AACJ,QAAM,cACF,CAAC,UAAU,aAAa,WAAW;AACvC,MAAI,oBAAoB,IAAG,EAAG,IAAI,4BAA4B;AAC9D,MAAI,oBAAoB,GAAG;AAWzB,UAAM,qBACF,IAAG,EAAG,UAAU,oDAAoD;AACxE,UAAM,gCAAgC,qBAAqB,IACvD,qBACA,QAAQ;AACZ,UAAM,oBACF,WAAW,KAAK,KAAK,cAAc,EAAE,IAAI,KAAK,KAAK,cAAc,EAAE;AACvE,UAAM,mBACF,qBAAqB,iCACpB,eAAe,KACf,qBAAqB,gCAAgC;AAC1D,QAAI,kBAAkB;AACpB,UAAI,WAAW,cAAc,eAAe,KAAK;AAC/C,4BAAoB,kBAAkB;iBAC7B,aAAa,KAAK,eAAe,KAAM;AAChD,4BAAoB,kBAAkB;aACjC;AACL,4BAAoB,kBAAkB;;WAEnC;AACL,0BAAoB,kBAAkB;;;AAI1C,UAAQ,mBAAmB;IACzB,KAAK,kBAAkB;AACrB,gBAAU,IAAI,oBACV,aAAa,YAAY,YAAY,MAAM,YAC3C,sBAAsB;AAC1B;IACF,KAAK,kBAAkB,qBAAqB;AAG1C,YAAM,KACF,EAAC,SAAS,OAAO,EAAC,OAAO,aAAa,OAAO,GAAG,OAAO,EAAE,MAAK,EAAC,CAAC;AACpE,gBAAU,IAAI,oBACV,aAAa,aAAa,YAAY,UAAU;AACpD,UAAI,QAAQ,YAAY;AACtB,cACI,QAAQ,iBAAiB,SAAS,QAAQ,EAAE,OAAO,YAAY,GAAG;AACtE,cAAM,wBAAwB,IAAI,sBAC9B,IAAI,OAAO,MAAM,YAAY,sBAAsB;AACvD,YAAI,cAAc;AAClB,cAAM,mBAAiC,CAAC,GAAG;AAC3C,YAAI,MAAM;AACR,2BAAiB,KAAK,IAAI;;AAE5B,YAAI,wBAAwB;AAC1B,2BAAiB,KAAK,sBAAsB;;AAE9C,YAAI,eAAe,aAAa;AAC9B,wBAAc,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,cAAc,EAAC,CAAC;AACxD,gCAAsB,YAAY;;AAEpC,cAAM,eAAe,QAAQ,iBACzB,uBAAuB,kBAAkB,IAAI,OAAO,WAAW;AACnE,sBAAc,KAAK,GAAG;AACtB,cAAMC,eAAc,QAChB,EAAC,QAAQ,EAAC,GAAG,aAAY,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AAClE,sBAAc,KAAK,YAAY;AAC/B,mBAAW,KAAK,eAAe;AAC7B,kBAAQ,YAAY,EAAE,MAAM;;AAE9B,eAAOA;;AAET;;IAEF,KAAK,kBAAkB;AACrB,gBAAU,IAAI,6BACV,UAAU,UAAU,aAAa,YAAY,YAAY,MACzD,YAAY,sBAAsB;AACtC;IACF,KAAK,kBAAkB;AAGrB,YAAM,4BAA4B,QAAQ,YAAY,QAAO;AAC7D,gBAAU,IAAI,oBACV,UAAU,aAAa,YAAY,YAAY,MAAM,YACrD,wBAAwB,yBAAyB;AACrD;IACF;AACE,YAAM,IAAI,MAAM,iCAAiC,iBAAiB,GAAG;;AAGzE,MAAI,MAAM;AACR,WAAO,KAAK,IAAI;;AAElB,MAAI,wBAAwB;AAC1B,WAAO,KAAK,sBAAsB;;AAEpC,MAAI,eAAe,aAAa;AAC9B,eAAW,KAAK,EAAC,MAAM,WAAW,MAAM,CAAC,cAAc,EAAC,CAAC;AACzD,YAAQ,YAAY;;AAEtB,QAAM,QAAQ,iBAAiB,SAAS,QAAQ,EAAE,OAAO,YAAY,GAAG;AACxE,QAAM,cACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,IAAG,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AACjE,gBAAc,KAAK,GAAG;AACtB,aAAW,KAAK,eAAe;AAC7B,YAAQ,YAAY,EAAE,MAAM;;AAE9B,SAAO;AACT;;;ACnMM,SAAU,aAAa,MAI5B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,GAAG,MAAM,uBAAsB,IAAI;AAC7C,QAAM,EAAC,YAAY,YAAY,YAAY,eAAc,IAAI;AAE7D,SAAO,gBAAgB;IACrB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;GACD;AACH;AAEO,IAAM,qBAAmC;EAC9C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACzBR,IAAO,yBAAP,MAA6B;EAUjC,YAAY,IAAkB,QAAkB,QAAgB;AAThE,SAAA,gBAAgB,CAAC,SAAS,SAAS,SAAS,OAAO;AAKnD,SAAA,gBAA0C,CAAC,KAAK,GAAG,CAAC;AAEpD,SAAA,OAAO;AAGL,SAAK,cAAc,qBAAa,2BAA2B,QAAQ,MAAM;AACzE,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY,mBAAmB,EAAE;AACtC,SAAK,KAAK;EACZ;EAEA,cAAW;AACT,UAAM,QAAQ,kBAAkB,KAAK,IAAI,KAAK;AAC9C,UAAM,WAAW;;;UAGX,KAAK;;;QAGP,oBAAK,OAAO,CAAC;;;;;;;;;;AAUjB,WAAO;EACT;;;;ACtCI,IAAO,kBAAP,MAAsB;EAiB1B,YAAY,IAAkB,QAAkB,QAAgB;AAVhE,SAAA,OAAO;AACP,SAAA,gBAAgB,CAAC,KAAK,GAAG;AAUvB,SAAK,cAAc,qBAAa,2BAA2B,QAAQ,MAAM;AACzE,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,KAAK;AAEV,SAAK,uBACD,OAAO,UAAU,KAAK,OAAO,SAAS,KAAK,OAAO,CAAC,IAAI;AAC3D,SAAK,uBACD,OAAO,UAAU,KAAK,OAAO,SAAS,KAAK,OAAO,CAAC,IAAI;AAE3D,QAAI,KAAK,wBAAwB,KAAK,sBAAsB;AAC1D,WAAK,kBAAkB;AACvB,WAAK,qBAAqB,CAAC,GAAG,CAAC;AAG/B,WAAK,oBACD,KAAK,uBAAuB,OAAO,CAAC,IAAI,OAAO,CAAC;AACpD,WAAK,YAAY,UAAU,EAAE,IAAI,KAAK,iBAAiB;AACvD,WAAK,OAAO;AAGZ,WAAK,gBAAgB,CAAC,KAAK,GAAG,CAAC;WAC1B;AACL,YAAM,gBACF,OAAO,SAAS,KAAK,OAAO,OAAO,SAAS,CAAC,IAAI,MAAM;AAC3D,YAAM,gBACF,OAAO,SAAS,KAAK,OAAO,OAAO,SAAS,CAAC,IAAI,MAAM;AAC3D,UAAI,iBAAiB,eAAe;AAClC,aAAK,kBAAkB;AACvB,aAAK,qBAAqB,CAAC,GAAG,CAAC;iBAE5B,kBACC,aAAK,cAAc,MAAM,KAAK,OAAO,OAAO,SAAS,CAAC,MAAM,MAC7D,kBACC,aAAK,cAAc,MAAM,KAAK,OAAO,OAAO,SAAS,CAAC,MAAM,IAAK;AACrE,aAAK,kBAAkB;AACvB,aAAK,qBAAqB,gBAAgB,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC;aACnD;AACL,aAAK,kBAAkB;AACvB,aAAK,qBAAqB,CAAC,GAAG,CAAC;;AAEjC,WAAK,OAAO;AACZ,WAAK,YAAY,UAAU,EAAE,IAAI,KAAK,kBAAkB;AAGxD,WAAK,gBAAgB,CAAC,KAAK,GAAG,CAAC;;AAEjC,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,CAAC,KAAK,iBAAiB,GAAG,CAAC,CAAC;EAClC;EAEA,cAAW;AACT,QAAI;AACJ,UAAM,QAAQ,KAAK,oBAAoB,IAAI,cAAc;AACzD,UAAM,UAAU;6BACS,KAAK,SAAS,KAAK,QAAQ,KAAK;QACrD,kBAAkB,KAAK,IAAI,KAAK,oBAAoB,CAAC,CAAC;;;AAI1D,QAAI,KAAK,SAAS,UAAU;AAC1B,YAAM,qBAAqB,KAAK,oBAAoB,IAChD,UAAU,KAAK,YAAY,SAAS,CAAC,MACrC;AACJ,YAAM,oBAAoB,KAAK,uBAC3B;8BACoB,kBAAkB,OACtC,qBAAqB,kBAAkB;;AAE3C,iBAAW;UACP,OAAO;gDAC+B,KAAK,iBAAiB;UAC5D,oBAAK,OAAO,CAAC;;;4BAGK,KAAK,iBAAiB;0CAExC,KAAK,uBAAuB,MAAM,GAAG;;;;;;cAMjC,iBAAiB;;;;;WAKpB;AACL,iBAAW;SACR,OAAO;SACP,oBAAK,OAAO,CAAC;;qDAE+B,KAAK,eAAe;qBACpD,KAAK;qBACL,KAAK;;;;;;AAOtB,WAAO;EACT;;;;AC5HI,SAAU,SACZ,MAAsD;AACxD,QAAM,EAAC,OAAM,IAAI;AACjB,QAAM,EAAC,EAAC,IAAI;AAEZ,OAAK,QAAQ,OAAO,EAAE,MAAM;AAC5B,SAAO,EAAC,QAAQ,EAAE,QAAQ,OAAO,EAAE,OAAO,OAAO,EAAE,MAAK;AAC1D;AAEO,IAAM,iBAA+B;EAC1C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACFR,SAAU,QAAQ,MAAqD;AAE3E,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,MAAAC,OAAM,MAAAC,MAAI,IAAI;AAErB,QAAM,cAAc,QAAQ,eAAeD,MAAK,OAAO,WAAW;AAClE,QAAME,WAAU,QAAQ,UAAU,IAAI,YAAY,MAAM;AAExD,QAAM,iBAAiB,SAAS,EAAC,QAAQ,EAAC,GAAGF,MAAI,GAAG,QAAO,CAAC;AAE5D,QAAM,iBAAiB,SAAS,EAAC,QAAQ,EAAC,GAAGC,MAAI,GAAG,QAAO,CAAC;AAE5D,EAAAC,SAAQ,qBAAqB,EAAC,MAAM,gBAAgB,MAAM,eAAc;AAExE,SAAO;AACT;AAEO,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC7BR,IAAO,iBAAP,MAAqB;EAWzB,YAAY,aAAuB,IAAiB,WAAW,IAAE;AANjE,SAAA,gBAAgB,CAAC,GAAG;AAIpB,SAAA,OAAO;AAIL,UAAM,iBAAiB;AACvB,SAAK,gBAAgB,CAAC,gBAAgB,GAAG,CAAC;AAC1C,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,KAAK;AACV,QAAI,aAAa,IAAI;AACnB,WAAK,WAAW;;AAElB,SAAK,YAAY,SAAS,EAAE;EAC9B;EAEA,cAAW;AACT,WAAO;;UAED,iBAAiB,KAAK,IAAI,KAAK,CAAC;;QAElC,oBAAK,OAAO,CAAC;;;;;;;EAOnB;;;;ACfI,SAAU,gBACZ,EAAC,QAAQ,eAAe,MAAK,GAAwB;AACvD,SAAO,CAAC,EAAC,QAAQ,QAAO,MAAK;AAC3B,UAAM,EAAC,EAAC,IAAI;AACZ,UAAM,gBAAgB;AAEtB,UAAM,SAAS,SAAS,EAAE;AAC1B,QAAI,cAAc,mBAAmB,CAAC,CAAC,CAAC,KAAK,iBAAiB,MAAM;AAClE,YAAM,QAAQ,cAAc,UAAU,IAAI,EAAE,MAAM;AAClD,YAAM,YAAY,cAAc,MAAM,QAAsB,MAAM;AAClE,aAAO,cAAc,eAAe,EAAE,OAAO,QAAQ,SAAS;;AAGhE,UAAM,UAA0B,IAAI,eAAe,EAAE,OAAO,MAAM;AAClE,WAAO,cAAc,iBAAiB,SAAS,CAAC,CAAC,GAAG,MAAM;EAC5D;AACF;AAkBM,SAAU,iBACZ,EAAC,QAAQ,eAAe,kBAAkB,OAAO,MAAK,GAC5B;AAC5B,SAAO,CAAC,EAAC,QAAQ,QAAO,MAAK;AAC3B,UAAM,EAAC,GAAG,EAAC,IAAI;AACf,UAAM,gBAAgB;AAEtB,QAAI,mBAAmB,EAAE,UAAU,aAAa;AAC9C,YAAM,QAAQ,cAAc,UAAU,IAAI,EAAE,MAAM;AAClD,YAAM,QAAQ,cAAc,UAAU,IAAI,EAAE,MAAM;AAClD,UAAIC,OAAkBC;AACtB,UAAI,WAAW,aAAa,KAAK;AAC/B,SAACD,OAAMC,KAAI,IAAI;UACb,CAAC,MAAM,mBAAmB,MAAM,MAAM,mBAAmB,IAAI;UAC7D,CAAC,MAAM,mBAAmB,MAAM,MAAM,mBAAmB,IAAI;UAC7D,IAAI,kBAAe;AACnB,gBAAM,CAAC,OAAO,KAAK,IAAI;AAEvB,gBAAM,UAAU;YACd,QAAQ,MAAM;YACd,OAAO,MAAM;YACb,OAAO,EAAE;;AAEX,gBAAM,UAAU;YACd,QAAQ,MAAM;YACd,OAAO,MAAM;YACb,OAAO,EAAE;;AAGX,gBAAMC,WAAU,IAAI,gBAAgB,QAAQ,EAAE,OAAO,EAAE,KAAK;AAC5D,iBAAO,cAAc,iBACjBA,UAAS,CAAC,SAAS,OAAO,GAC1B,WAAW,MAAM,OAAO,MAAM,KAAK,CAAC;QAC1C,CAAC;aACI;AACL,cAAM,cAAc,IAAI,uBACpB,aAAa,uBAAuB,EAAE,OAAO,EAAE,KAAK;AACxD,cAAM,cAAc,IAAI,uBACpB,aAAa,uBAAuB,EAAE,OAAO,EAAE,KAAK;AAExD,cAAMC,UAAS;UACb;YACE,QAAQ,MAAM,mBAAmB,KAAK;YACtC,OAAO,MAAM,mBAAmB,KAAK;YACrC,OAAO,EAAE;;UAEX;YACE,QAAQ,MAAM,mBAAmB,KAAK;YACtC,OAAO,MAAM,mBAAmB,KAAK;YACrC,OAAO,EAAE;;UAEX;YACE,QAAQ,MAAM,mBAAmB,KAAK;YACtC,OAAO,MAAM,mBAAmB,KAAK;YACrC,OAAO,EAAE;;UAEX;YACE,QAAQ,MAAM,mBAAmB,KAAK;YACtC,OAAO,MAAM,mBAAmB,KAAK;YACrC,OAAO,EAAE;;;AAIb,QAAAH,QAAO,cAAc,iBAAiB,aAAaG,SAAQ,SAAS;AACpE,QAAAF,QAAO,cAAc,iBAAiB,aAAaE,SAAQ,SAAS;;AAGtE,YAAM,gBACF,QAAQ,EAAC,QAAQ,EAAC,MAAAH,OAAM,MAAAC,MAAI,GAAG,SAAS,cAAa,CAAC;AAE1D,oBAAc,YAAYD,MAAK,MAAM;AACrC,oBAAc,YAAYC,MAAK,MAAM;AAIrC,aAAO;;AAGT,UAAM,SAAS,SAAS,WAAW,EAAE,OAAO,EAAE,KAAK;AACnD,SAAK,EAAE,UAAU,YAAY,EAAE,UAAU,YACpC,cAAc,mBAAmB,CAAC,GAAG,CAAC,CAAC,MACxC,iBAAiB,MAAM;AACzB,YAAM,QAAQ,cAAc,UAAU,IAAI,EAAE,MAAM,EAAE;AACpD,YAAM,QAAQ,cAAc,UAAU,IAAI,EAAE,MAAM,EAAE;AACpD,YAAM,eAAe,EAAE,UAAU;;QAE7B,qBAAa,uBAAuB,KAA4B;UAChE;AACJ,YAAM,eAAe,EAAE,UAAU;;QAE7B,qBAAa,uBAAuB,KAA4B;UAChE;AACJ,YAAM,CAAC,WAAW,QAAQ,IACtB,cAAc,EAAE,OAAO,EAAE,OAAO,cAAc,cAAc,MAAM;AAEtE,aAAO,cAAc,eAAe,UAAU,QAAQ,SAAS;;AAEjE,UAAM,UAAU,IAAI,gBAAgB,QAAQ,EAAE,OAAO,EAAE,KAAK;AAC5D,WAAO,cAAc,iBAAiB,SAAS,CAAC,GAAG,CAAC,GAAG,MAAM;EAC/D;AACF;;;ACtJA,IAAM,EACJ,SAAS,YACT,UAAU,aACV,UAAU,aACV,YAAY,eACZ,WAAW,cACX,SAAS,YACT,WAAW,cACX,WAAW,cACX,cAAc,iBACd,cAAc,iBACd,cAAc,iBACd,kBAAkB,qBAClB,aAAa,gBACb,eAAe,kBACf,UAAU,aACV,SAAS,YACT,SAAS,YACT,aAAa,gBACb,aAAa,gBACb,cAAc,iBACd,SAAS,YACT,cAAc,iBACd,UAAU,aACV,WAAW,cACX,WAAW,cACX,aAAa,gBACb,eAAe,kBACf,WAAW,cACX,kBAAkB,qBAClB,kBAAkB,qBAClB,SAAS,YACT,UAAU,aACV,UAAU,aACV,eAAe,kBACf,YAAY,cAAa,IACvB;;;AC1CG,IAAM,MACT,gBAAgB,EAAC,QAAQ,YAAY,KAAK,eAAe,iBAAgB,CAAC;AAEvE,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,OAAO,gBAAgB,EAAC,QAAQ,YAAY,KAAI,CAAC;AAEvD,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,QAAQ,gBAAgB,EAAC,QAAQ,YAAY,MAAK,CAAC;AAEzD,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,gBAAgB,iBACzB,EAAC,QAAQ,aAAa,KAAK,eAAe,YAAQ,iBAAiB,KAAI,CAAC;AAErE,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACTR,IAAO,oBAAP,MAAwB;EAU5B,YAAY,QAAkB;AAJ9B,SAAA,gBAAgB;AAChB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,OAAO,CAAC;AAC3B,SAAK,gBAAgB,OAAO,IAAI,CAAC,GAAG,MAAM,IAAI,CAAC,EAAE;AACjD,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,CAAC,KAAK,eAAe,GAAG,CAAC,CAAC;AAC9B,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAqB,CAAA;AAE3B,SAAK,cAAc,QAAQ,cAAW;AACpC,eAAS,KAAK,QAAQ,QAAQ,SAAS,QAAQ,yBAAyB;IAC1E,CAAC;AAED,UAAM,YAAY,KAAK,cACA,IAAI,cAAW;AACd,aAAO,IAAI,QAAQ;IACrB,CAAC,EACA,KAAK,KAAK;AAEjC,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;8BACS,KAAK,aAAa;oCACZ,KAAK,aAAa;;;cAGxC,SAAS,KAAK,YAAY,CAAC;0CACC,SAAS;;;;;AAK/C,WAAO;EACT;;;;AC1CI,SAAU,KAAK,MAAkD;AAErE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAE1B,QAAM,UAAU;AAChB,MAAI,QAAQ,WAAW,GAAG;AACxB,WAAO,SAAS,EAAC,QAAQ,EAAC,GAAG,QAAQ,CAAC,EAAC,GAAG,QAAO,CAAC;;AAGpD,QAAM,QACF,QAAQ,IAAI,OAAK,EAAE,KAAK,EAAE,OAAO,CAAC,IAAI,OAAO,WAAW,IAAI,EAAE,CAAC;AACnE,QAAM,SAAS,QAAQ,IAAI,OAAK,EAAE,KAAK;AACvC,QAAM,UAAU,IAAI,kBAAkB,MAAM;AAC5C,SAAO,QAAQ,iBAAiB,SAAS,SAAS,KAAK;AACzD;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACtBR,IAAO,yBAAP,MAA6B;EASjC,YAAY,QAAkB,QAAgB;AAR9C,SAAA,gBAAgB,CAAC,GAAG;AAMpB,SAAA,gBAA0C,CAAC,IAAI,IAAI,CAAC;AAGlD,UAAM,cAAwB,IAAI,MAAM,OAAO,MAAM;AACrD,aAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK;AAC3C,kBAAY,CAAC,IAAI,OAAO,OAAO,CAAC,CAAC;;AAEnC,SAAK,cAAc;AACnB,SAAK,iBAAiB,EAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,EAAC;AACrC,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAAe,CAAC,GAAG,GAAG,CAAC,CAAC;AAExE,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,iBAAK,OACD,KAAK,cAAc,CAAC,MAAM,KAAK,cAAc,CAAC,GAC9C,MAAM,gDACF,KAAK,cAAc,CAAC,CAAC,MAAM,KAAK,cAAc,CAAC,CAAC,EAAE;AAC1D,UAAM,WAAW,KAAK,cAAc,CAAC;AACrC,UAAM,WAAW;+CAC0B,KAAK,cAAc,CAAC,IAAI,CAAC,MAChE,KAAK,cAAc,CAAC,CAAC;QACrB,oBAAI,CAAE;uCACyB,QAAQ;uCACR,QAAQ;;;;;;;;mCAQZ,QAAQ;mCACR,QAAQ;;;;;;;AAOvC,WAAO;EACT;;;;ACnDI,IAAO,mBAAP,MAAuB;EAW3B,YAAY,QAAkB,QAAgB;AAV9C,SAAA,gBAAgB,CAAC,GAAG;AAKpB,SAAA,gBAAgB;AAChB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAEnD,SAAA,OAAO;AAGL,UAAM,cAAwB,IAAI,MAAM,OAAO,MAAM;AACrD,aAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK;AAC3C,kBAAY,CAAC,IAAI,OAAO,OAAO,CAAC,CAAC;;AAEnC,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,CAAC,KAAK,eAAe,GAAG,CAAC,CAAC;AAE9B,SAAK,SAAS;AACd,SAAK,YAAY,aAAa,MAAM;EACtC;EAEA,cAAW;AACT,UAAM,QAAQ,kBAAkB,KAAK,YAAY,MAAM;AACvD,UAAM,WAAW,kBAAkB,KAAK,MAAM;AAE9C,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;6BACQ,KAAK,aAAa;oCACX,KAAK,aAAa;;;8DAI9C,KAAK,YAAY,MAAM;gBACf,KAAK,IAAI,QAAQ;;;;;AAK7B,WAAO;EACT;;AAGI,SAAU,kBAAkB,QAAgB;AAChD,QAAM,OAAO,OAAO;AACpB,MAAI,OAAO,GAAG;AACZ,UAAM,MAAM,sBAAsB,IAAI,uBAAuB;;AAE/D,QAAM,iBAAiB,IAAI,MAAM,IAAI;AACrC,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,mBAAe,OAAO,CAAC,CAAC,IAAI,UAAU,aAAa,CAAC,CAAC;;AAGvD,SAAO,eAAe,KAAI;AAC5B;;;ACrDM,SAAU,UAAU,MAIzB;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,KAAI,IAAI;AACf,QAAM,gBAAgB;AAEtB,QAAM,QAAQ,EAAE,MAAM;AACtB,QAAM,WAAqB,IAAI,MAAM,KAAK;AAC1C,WAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,KAAK;AACxC,aAAS,CAAC,IAAI,EAAE,MAAM,KAAK,CAAC,CAAC;;AAE/B,MAAI,QAAQ,mBAAmB,CAAC,CAAC,CAAC,GAAG;AACnC,UAAM,QAAQ,cAAc,UAAU,IAAI,EAAE,MAAM;AAClD,UAAM,SAAS,MAAM;AACrB,UAAM,YAAY,iBAAa,QAAQ,EAAE,OAAO,EAAE,OAAO,MAAM,QAAQ;AACvE,WAAO,QAAQ,eAAe,UAAU,EAAE,OAAO,SAAS;;AAE5D,MAAI,EAAE,MAAM,WAAW,KAAK,aAAK,YAAY,MAAM,CAAC,GAAG,CAAC,CAAC,GAAG;AAC1D,UAAMG,WAAU,IAAI,uBAAuB,EAAE,OAAO,IAAI;AACxD,WAAO,cAAc,iBAAiBA,UAAS,CAAC,CAAC,GAAG,EAAE,KAAK;;AAE7D,QAAM,UAAU,IAAI,iBAAiB,EAAE,OAAO,IAAI;AAClD,SAAO,cAAc,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,KAAK;AAC7D;AAEO,IAAM,kBAAgC;EAC3C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACpCR,IAAO,gBAAP,MAAoB;EAYxB,YACI,YACA,YACA,0BAAgC;AATpC,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AAGX,SAAA,OAAO;AAML,SAAK,aAAa,CAAC,WAAW,WAAW,WAAW,MAAM;AAC1D,UAAM,CAAC,WAAW,IACd,qBAAa,0BAA0B,KAAK,YAAY,CAAC,CAAC,CAAC;AAC/D,SAAK,cAAc,YAAY,WAAW,IAAI,CAAC,CAAC,IAAI;AAKpD,QAAI,WAAW,UAAU,SAAS,4BAA4B,KAAK;AACjE,WAAK,gBAAgB,CAAC,KAAK,GAAG,CAAC;eACtB,WAAW,UAAU,MAAM;AACpC,WAAK,gBAAgB,CAAC,KAAK,GAAG,CAAC;WAC1B;AACL,WAAK,gBAAgB,CAAC,IAAI,GAAG,CAAC;;AAEhC,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AAGzD,SAAK,WACD,gBAAgB,KAAK,gBAAgB,KAAK,aAAa,CAAC,GAAG,GAAG,CAAC,CAAC;AAEpE,SAAK,aAAa;AAClB,SAAK,YAAY,UAAU,UAAU;EACvC;EAEA,cAAW;AACT,QAAI,WAAW;AACf,QAAI,YAAY;AAChB,UAAM,iBAAiB,KAAK,cAAc,CAAC;AAC3C,QAAI,KAAK,eAAe,SAAS,KAAK,eAAe,OAAO;AAC1D,iBAAW;;;qDAIP,KAAK,eAAe,QAAQ,MAAM,GAAG;;AAEzC,kBAAY;eACH,KAAK,eAAe,SAAS,KAAK,eAAe,QAAQ;AAClE,iBAAW;eACF,KAAK,eAAe,QAAQ;AACrC,iBAAW;AACX,kBAAY;eACH,KAAK,eAAe,OAAO;AACpC,iBAAW;AACX,kBAAY;eACH,KAAK,eAAe,OAAO;AACpC,iBAAW;AACX,kBAAY;;AAGd,UAAM,gBAAgB,KAAK,eAAe;;MAEtC;QACA;AAEJ,UAAM,sBAAsB;mDACmB,cAAc;;AAG7D,UAAM,WAAW;;;;;SAKZ,mBAAmB;;;wBAIpB,KAAK,YAAY,WAAW,IACxB,iBACA,iBAAiB;;;SAGpB,oBAAK,OAAO,CAAC;qCACe,cAAc;;2BAExB,SAAS;;qDAEiB,cAAc;;uBAE5C,cAAc;;aAExB,QAAQ;;;;;6CAKwB,cAAc;;;;;;cAM7C,QAAQ;;;;;;;;YAQV,aAAa;;;;AAIrB,WAAO;EACT;;;;ACnHF,IAAM,eAAkD;EACtD,QAAQ;EACR,OAAO;EACP,OAAO;;AAGH,SAAU,OACZ,GAAe,MAAuB,UACtC,YAAyB,SAAsB;AACjD,QAAM,QAAQ,EAAE,MAAM;AACtB,QAAM,YAAY,CAAA;AAElB,QAAM,WAAW,aAAK,eAAe,MAAM,EAAE,KAAK;AAClD,MAAI,OAAO;AACX,QAAM,eAAe,qBAAa,mBAAmB,MAAM,KAAK;AAEhE,MAAI,QAAQ;AACZ,MAAI,gBAAgB,MAAM;AACxB,YAAQ,UAAU,EAAC,QAAQ,EAAC,EAAC,GAAG,OAAO,EAAC,MAAM,aAAY,GAAG,QAAO,CAAC;AACrE,WAAO,qBAAa,iBAAiB,KAAK,QAAQ,KAAK;AACvD,cAAU,KAAK,KAAK;;AAGtB,uBAAa,2BAA2B,YAAY,MAAM,KAAK;AAE/D,QAAM,CAAC,gBAAgB,WAAW,IAC9B,qBAAa,0BAA0B,MAAM,OAAO,IAAI;AAC5D,MAAI,cAAc;AAClB,MAAI,UAAU;AAEZ,kBAAc,qBAAa,qBAAqB,gBAAgB,QAAQ;;AAG1E,MAAI;AACJ,OAAK,eAAe,SAAS,eAAe,WACxC,QAAQ,mBAAmB,CAAC,KAAK,CAAC,GAAG;AACvC,UAAM,QAAQ,QAAQ,UAAU,IAAI,MAAM,MAAM,EAAE;AAClD,YAAQ,YAAY;MAClB,KAAK;AACH,cAAM,YAAY,WACd,OAAO,aAAK,cAAc,WAAW,GAAG,aAAa,EAAE,KAAK;AAChE,cAAM,QAAQ,eAAe,aAAa,EAAE,OAAO,SAAS;AAC5D;MACF,KAAK;AACH,cAAM,EAAC,SAAS,UAAU,SAAQ,IAC9B,YAAY,MAAM,OAAO,MAAM,OAAO,OAAO,IAAI;AACrD,cAAM,QAAQ,eAAe,UAAU,UAAU,OAAO;AACxD;MACF;AACE,cAAM,IAAI,MACN,GAAG,UAAU,2CAA2C;;SAE3D;AACL,UAAM,SAAS,aAAK,cAAc,WAAW;AAC7C,UAAM,QAAQ,aAAK,cAAc,MAAM,KAAK;AAC5C,UAAM,YAAY,QAAQ;AAE1B,UAAM,aAAa,EAAC,YAAY,QAAQ,QAAQ,WAAW,SAAS,EAAC;AACrE,UAAM,QAAQ,aAAa,UAAU,KAAK,WAAW,EAAE,KAAK;AAC5D,UAAM,cAAc;MAClB,EAAC,MAAM,SAAS,MAAM,CAAC,MAAM,EAAC;;AAEhC,UAAM,UAAU,IAAI,cAChB,YAAY,YAAY,QAAQ,OAAO,OAAO,wBAAwB;AAC1E,UAAM,UACF,QAAQ,iBAAiB,SAAS,CAAC,KAAK,GAAG,OAAO,WAAW;AACjE,cAAU,KAAK,OAAO;AAEtB,UAAM,QAAQ,EAAC,QAAQ,EAAC,GAAG,QAAO,GAAG,OAAO,EAAC,OAAO,YAAW,GAAG,QAAO,CAAC;;AAG5E,YAAU,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAEpD,SAAO;AACT;;;AChFM,SAAU,IACZ,MAAkE;AAEpE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,UAAU,KAAI,IAAI;AAEzB,SAAO,OAAO,GAAG,MAAM,UAAU,OAAO,OAAO;AACjD;AAEO,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACbR,SAAU,IACZ,MAAkE;AAEpE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,UAAU,KAAI,IAAI;AAEzB,SAAO,OAAO,GAAG,MAAM,UAAU,OAAO,OAAO;AACjD;AAEO,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACdR,IAAO,mBAAP,MAAuB;EAc3B,YAAY,YAAsB,MAAc,YAAuB;AATvE,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AAIX,SAAA,OAAO;AAIL,UAAM,OAAO,CAAC,IAAI;AAElB,SAAK,KAAK,eAAe,QAAQ,MAAM;AAGvC,UAAM,CAAC,aAAa,WAAW,IAC3B,qBAAa,0BAA0B,YAAY,IAAI;AAE3D,SAAK,cAAc,YAAY,WAAW,IAAI,CAAC,CAAC,IAAI;AACpD,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AAMzD,QAAI,aAAK,cAAc,WAAW,IAAI,IAAI;AACxC,WAAK,OAAO;AACZ,WAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;WACxD;AACL,WAAK,OAAO;AAGZ,WAAK,WACD,gBAAgB,KAAK,gBAAgB,KAAK,aAAa,CAAC,GAAG,GAAG,CAAC,CAAC;;AAGtE,SAAK,aAAa;AAClB,SAAK,YAAY,aAAa,KAAK,EAAE,IAAI,KAAK,IAAI;EACpD;EAEA,cAAW;AACT,UAAM,iBAAiB,KAAK,cAAc,CAAC;AAC3C,UAAM,uBAAuB,MAAK;AAChC,UAAI,KAAK,WAAW,WAAW,GAAG;AAChC,eAAO;aACF;AACL,eAAO,mBAAmB,aAAa,KAAK,WAAW,SAAS,CAAC,CAAC;;IAEtE;AAEA,UAAM,oBAAoB,MAAK;AAC7B,UAAI,UAAU;AACd,UAAI,KAAK,YAAY,WAAW,GAAG;AACjC,YAAI,KAAK,WAAW,WAAW,GAAG;AAChC,qBAAW;;aAER;AACL,iBAAS,IAAI,GAAG,IAAI,KAAK,YAAY,QAAQ,KAAK;AAChD,qBAAW,gBAAgB,aAAa,CAAC,CAAC;;;AAG9C,aAAO;IACT;AAEA,QAAI,KAAK,SAAS,UAAU;AAC1B,YAAM,sBAAsB;iDACe,cAAc;gDACf,cAAc;;AAExD,YAAM,WAAW;;;;;QAKf,mBAAmB;;QAEnB,oBAAK,OAAO,CAAC;oCACe,cAAc;6BACrB,qBAAoB,CAAE;;;;;;sBAM7B,cAAc;iCACH,kBAAiB,CAAE;+CACL,KAAK,EAAE;;;;;;;;;kDASJ,cAAc;;;;;;4BAMpC,KAAK,EAAE;;;;;;;;;;;;;;;AAe7B,aAAO;WACF;AACL,YAAM,WAAW;QACf,oBAAK,OAAO,CAAC;;;;iCAIY,kBAAiB,CAAE;+BACrB,qBAAoB,CAAE;;mCAElB,kBAAiB,CAAE;4BAC1B,KAAK,EAAE;;;;;;;;;AAS7B,aAAO;;EAEX;;;;AC7II,SAAU,OACZ,MAAwE;AAE1E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,KAAI,IAAI;AAEf,MAAI,OAAO,aAAK,eAAe,MAAM,EAAE,KAAK;AAC5C,QAAM,eAAe,qBAAa,mBAAmB,MAAM,EAAE,MAAM,MAAM;AACzE,MAAI,KAAK;AACT,QAAM,0BAA0B,CAAA;AAChC,MAAI,gBAAgB,MAAM;AACxB,SAAK,UAAU,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,MAAM,aAAY,EAAC,CAAC;AAClE,4BAAwB,KAAK,EAAE;AAC/B,WAAO,qBAAa,iBAAiB,KAAK,QAAQ,GAAG,MAAM,MAAM;;AAGnE,uBAAa,2BAA2B,UAAU,CAAC,KAAK,CAAC,CAAC,GAAG,GAAG,MAAM,MAAM;AAC5E,QAAM,UAAU,IAAI,iBAAiB,GAAG,OAAO,KAAK,CAAC,GAAG,KAAK;AAC7D,QAAM,cAAc,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,OAAO,iBAAiB,EAAC,CAAC;AACxE,QAAM,MAAM,QAAQ,iBAAiB,SAAS,CAAC,EAAE,GAAG,SAAS,WAAW;AACxE,0BAAwB,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAClE,SAAO;AACT;AAEO,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC5BR,SAAU,OACZ,MAAwE;AAE1E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,KAAI,IAAI;AAEf,MAAI,OAAO,aAAK,eAAe,MAAM,EAAE,KAAK;AAC5C,QAAM,eAAe,qBAAa,mBAAmB,MAAM,EAAE,MAAM,MAAM;AACzE,MAAI,KAAK;AACT,QAAM,0BAA0B,CAAA;AAChC,MAAI,gBAAgB,MAAM;AACxB,SAAK,UAAU,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,MAAM,aAAY,EAAC,CAAC;AAClE,4BAAwB,KAAK,EAAE;AAC/B,WAAO,qBAAa,iBAAiB,KAAK,QAAQ,GAAG,MAAM,MAAM;;AAGnE,uBAAa,2BAA2B,UAAU,CAAC,KAAK,CAAC,CAAC,GAAG,GAAG,MAAM,MAAM;AAC5E,QAAM,UAAU,IAAI,iBAAiB,GAAG,OAAO,KAAK,CAAC,GAAG,KAAK;AAC7D,QAAM,cAAc,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,OAAO,iBAAiB,EAAC,CAAC;AACxE,QAAM,MAAM,QAAQ,iBAAiB,SAAS,CAAC,EAAE,GAAG,SAAS,WAAW;AACxE,0BAAwB,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAClE,SAAO;AACT;AAEO,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC7BP,IAAM,OAAO,gBAAgB,EAAC,QAAQ,YAAY,KAAI,CAAC;AAEvD,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,QAAQ,gBAAgB,EAAC,QAAQ,YAAY,MAAK,CAAC;AAEzD,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,OAAO,gBAAgB,EAAC,QAAQ,YAAY,KAAI,CAAC;AAEvD,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACPP,IAAM,QAAQ,iBAAiB,EAAC,QAAQ,aAAa,MAAK,CAAC;AAE3D,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACHP,IAAM,QAAQ,gBAAgB,EAAC,QAAQ,YAAY,MAAK,CAAC;AAEzD,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACPR,IAAO,qCAAP,MAAyC;EAU7C,YAAY,UAAiC;AAL7C,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,KAAK,GAAG,CAAC;AACpD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AAEzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;AAejB,WAAO;EACT;;;;ACtCI,IAAO,gBAAP,MAAoB;EAiBxB,YACI,UAAmC,UACnC,mBAAmB,OAAO,mBAAmB,OAC7C,oBAAoB,OAAK;AAf7B,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WACI;AAGJ,SAAA,gBAA0C,CAAC,KAAK,GAAG,CAAC;AAEpD,SAAA,OAAO;AASL,QAAI,aAAa,SAAS,kBAAkB;AAC1C,YAAM,IAAI,MAAM,4CAA4C;;AAG9D,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,WAAW;AAChB,SAAK,mBAAmB;AACxB,SAAK,mBAAmB;AACxB,SAAK,oBAAoB;AACzB,SAAK,YAAY,UAAU,QAAQ,IAAI,gBAAgB,IACnD,gBAAgB,IAAI,iBAAiB;EAC3C;EAEA,cAAW;AACT,QAAI;AACJ,QAAI,KAAK,aAAa,OAAO;AAC3B,sBAAgB;eACP,KAAK,kBAAkB;AAChC,YAAM,cAAc,KAAK,mBACpB,KAAK,oBACD,2FACA,4DACL;AACJ,sBAAgB;;;;wBAIE,WAAW;;WAExB;AACL,sBAAgB;;AAGlB,QAAI,cAAc;AAClB,QAAI,KAAK,aAAa,OAAO;AAC3B,oBAAc;;AAGhB,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;YAUb,KAAK,mBACD;;oCAGA,qBACI,KAAK,aAAa,QAAQ,QAAQ,yBAAyB,GAAG;;;;;;;;;;;;;;;;;gBAiB9D,aAAa;;;;YAKrB,KAAK,mBAAmB,6CACA,2BAA2B,WAAW,IAAI;;;;AAItE,WAAO;EACT;;AAGI,IAAO,gBAAP,MAAoB;EAexB,YACI,UAAmC,UACnC,mBAAmB,OAAO,mBAAmB,OAC7C,oBAAoB,OAAK;AAb7B,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WACI;AACJ,SAAA,gBAA0C,CAAC,KAAK,GAAG,CAAC;AAEpD,SAAA,OAAO;AASL,QAAI,aAAa,SAAS,kBAAkB;AAC1C,YAAM,IAAI,MAAM,4CAA4C;;AAG9D,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,WAAW;AAChB,SAAK,mBAAmB;AACxB,SAAK,mBAAmB;AACxB,SAAK,oBAAoB;AACzB,SAAK,YAAY,UAAU,QAAQ,IAAI,gBAAgB,IACnD,gBAAgB,IAAI,iBAAiB;EAC3C;EAEA,cAAW;AACT,QAAI;AACJ,QAAI,KAAK,aAAa,OAAO;AAC3B,sBAAgB;eACP,KAAK,kBAAkB;AAChC,YAAM,cAAc,KAAK,mBACpB,KAAK,oBACD,oHACA,sFACL;AACJ,sBAAgB;;;;wBAIE,WAAW;;WAExB;AACL,sBAAgB;;AAGlB,QAAI,cAAc;AAClB,QAAI,KAAK,aAAa,OAAO;AAC3B,oBAAc;;AAGhB,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;YAYb,KAAK,mBACD;;oCAGA,qBACI,KAAK,aAAa,QAAQ,QAAQ,yBAAyB,GAAG;;;;;;;;;;;;;;;;;;;;;;kBAsB5D,aAAa;;;;;YAMvB,KAAK,mBAAmB,6CACA,2BAA2B,WAAW,IAAI;;;;AAItE,WAAO;EACT;;;;AC9NI,SAAU,IACZ,MAAkE;AAEpE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,kBAAkB,SAAQ,IAAI;AAErC,SAAO,OAAO,GAAG,kBAAkB,UAAU,OAAO,OAAO;AAC7D;AAEO,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACbR,SAAU,KACZ,MAAoE;AAEtE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,UAAU,KAAI,IAAI;AAEzB,SAAO,OAAO,GAAG,MAAM,UAAU,QAAQ,OAAO;AAClD;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACPR,SAAU,SACZ,GAAe,UAAmC,UAClD,SAAsB;AACxB,MAAI,SAAS,gBAAgB,KAAK,SAAS,iBAAiB,KACxD,aAAK,YAAY,SAAS,SAAS,SAAS,QAAQ,GAAG;AACzD,WAAO,SAAS,EAAC,QAAQ,EAAC,EAAC,GAAG,QAAO,CAAC;;AAGxC,MAAI,SAAS,gBAAgB,SAAS,WAClC,SAAS,iBAAiB,SAAS,YAAY,SAAS,cAAc,KACtE,SAAS,QAAQ,SAAS,SAAS;AACrC,UAAM,SAAS,EAAE,MAAM;AACvB,UAAM,WAAW,QAAQ;MACvB,QAAQ,EAAC,EAAC;MACV;MACA,OAAO;QACL,OAAO;UACL,EAAE,MAAM,SAAS,CAAC,IAAI,EAAE,MAAM,SAAS,CAAC;UACxC,EAAE,MAAM,SAAS,CAAC;;;;KAGvB;AACD,QAAI;AACJ,QAAI,aAAa,OAAO;AACtB,gBAAU,KACN,EAAC,QAAQ,EAAC,GAAG,SAAQ,GAAG,SAAS,OAAO,EAAC,MAAM,GAAG,UAAU,MAAK,EAAC,CAAC;WAClE;AACL,mBAAK,OAAO,aAAa,OAAO,MAAM,qBAAqB,QAAQ,EAAE;AACrE,gBAAU,IAAI;QACZ,QAAQ,EAAC,GAAG,SAAQ;QACpB;QACA,OAAO,EAAC,kBAAkB,GAAG,UAAU,MAAK;OAC7C;;AAGH,UAAM,SAAS,QACX,EAAC,QAAQ,EAAC,GAAG,QAAO,GAAG,SAAS,OAAO,EAAC,OAAO,SAAS,SAAQ,EAAC,CAAC;AACtE,YAAQ,YAAY,SAAS,MAAM;AACnC,YAAQ,YAAY,QAAQ,MAAM;AAClC,WAAO;;AAGT,MAAI;AACJ,QAAM,aACF,CAAC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC,CAAC;AACzE,MAAI,SAAS,iBAAiB,KAAK,SAAS,gBAAgB,GAAG;AAC7D,cAAU,IAAI,mCAAmC,QAAQ;SACpD;AACL,QAAI,aAAa,OAAO;AACtB,gBAAU,IAAI,cAAc,UAAU,KAAK;WACtC;AACL,mBAAK,OAAO,aAAa,OAAO,MAAM,qBAAqB,QAAQ,EAAE;AACrE,gBAAU,IAAI,cAAc,UAAU,KAAK;;AAG7C,eAAW,KACP,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI,EAAC,GAAG;MACpE,MAAM;MACN,MAAM,CAAC,SAAS,gBAAgB,SAAS,aAAa;OAExD,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,UAAU,SAAS,OAAO,EAAC,GAAG;MAC5D,MAAM;MACN,MAAM,CAAC,SAAS,uBAAuB,SAAS,oBAAoB;KACrE;;AAGP,SAAO,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,OAAO,UAAU;AACnE;;;AC1EM,SAAU,QACZ,MAA0E;AAE5E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,YAAY,SAAS,KAAK,gBAAe,IAAI;AACpD,QAAM,YAAY;AAClB,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OAA2C,YAAY,SACzD,WAAW,KAAK,eAAe;AAEnC,SAAO,SAAS,GAAG,UAAU,OAAO,OAAO;AAC7C;AAEO,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACjBR,SAAU,UAAU,MAIzB;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,YAAY,SAAS,KAAK,YAAY,gBAAe,IAAI;AAChE,QAAM,YAAsC,CAAC,GAAG,GAAG,CAAC;AAEpD,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OAAmD,YAAY,SACjE,WAAW,KAAK,iBAAiB,UAAU;AAC/C,QAAM,iBAAiB,IAAI,cAAc,UAAU,KAAK;AACxD,QAAM,aAAa;IACjB;MACE,MAAM;MACN,MAAM,CAAC,SAAS,aAAa,SAAS,cAAc,SAAS,WAAW;;IAE1E;MACE,MAAM;MACN,MACI,CAAC,SAAS,QAAQ,OAAO,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI;;IAE1E;MACE,MAAM;MACN,MAAM,CAAC,SAAS,SAAS,SAAS,UAAU,SAAS,OAAO;;IAE9D;MACE,MAAM;MACN,MAAM;QACJ,SAAS;QAAsB,SAAS;QACxC,SAAS;;;;AAIf,SAAO,QAAQ,iBAAiB,gBAAgB,CAAC,CAAC,GAAG,EAAE,OAAO,UAAU;AAC1E;AAEO,IAAM,kBAAgC;EAC3C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC1CR,IAAO,2BAAP,MAA+B;EAYnC,YAAY,UAAiC;AAP7C,SAAA,gBAAgB,CAAC,IAAI;AACrB,SAAA,WACI;;AAEJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAE5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AAEzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAsCjB,WAAO;EACT;;AAGI,IAAO,2BAAP,MAA+B;EAWnC,YAAY,UAAiC;AAN7C,SAAA,gBAAgB,CAAC,IAAI;AACrB,SAAA,WAAW;;AAEX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAE5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AAEzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgDjB,WAAO;EACT;;;;AC3II,SAAU,cAAc,MAI7B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,IAAI,MAAK,IAAI;AACpB,QAAM,IAAI;AACV,QAAM,EAAC,YAAY,SAAS,KAAK,gBAAe,IAAI;AAEpD,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OAAmD,YAAY,SACjE,GAAmB,KAAK,eAAe;AAC3C,QAAM,UAAU,IAAI,yBAAyB,QAAQ;AACrD,QAAM,gBACF,KAAK,SAAS,cAAc,SAAS,eAAe,SAAS;AACjE,QAAM,cAAc;IAClB;MACE,MAAM;MACN,MAAM,CAAC,SAAS,aAAa,SAAS,cAAc,SAAS,WAAW;;IAE1E;MACE,MAAM;MACN,MAAM;QACJ,SAAS,uBAAuB,IAAI,SAAS,QAAQ;QACrD,SAAS,wBAAwB,IAAI,SAAS,QAAQ;QACtD,SAAS,uBAAuB,IAAI,SAAS,QAAQ;;;IAGzD;MACE,MAAM;MACN,MAAM;QACJ,SAAS;QAAsB,SAAS;QACxC,SAAS;;;IAGb,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,WAAW,MAAM,CAAC,aAAa,EAAC;;AAEzC,SAAO,QAAQ,iBAAiB,SAAS,CAAC,EAAE,GAAG,EAAE,OAAO,WAAW;AACrE;AAEO,IAAM,sBAAoC;EAC/C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC9CR,SAAU,YAAY,MAI3B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,IAAI,MAAK,IAAI;AACpB,QAAM,IAAI;AACV,mBAAiB,CAAC,IAAI,KAAK,GAAG,aAAa;AAC3C,QAAM,EAAC,YAAY,SAAS,IAAG,IAAI;AAEnC,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OAA2C,YAAY,SACzD,GAAmB,GAAG;AAC1B,QAAM,UAAU,IAAI,yBAAyB,QAAQ;AACrD,QAAM,gBAAgB,KAAK,SAAS,eAAe,SAAS;AAC5D,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IAAG;MACpE,MAAM;MACN,MAAM;QACJ,SAAS,wBAAwB,IAAI,SAAS,QAAQ;QACtD,SAAS,uBAAuB,IAAI,SAAS,QAAQ;;;IAGzD,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,gBAAgB,SAAS,aAAa,EAAC;IAAG;MACxE,MAAM;MACN,MAAM,CAAC,SAAS,uBAAuB,SAAS,oBAAoB;;IAEtE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,WAAW,MAAM,CAAC,aAAa,EAAC;;AAEzC,SAAO,QAAQ,iBAAiB,SAAS,CAAC,EAAE,GAAG,EAAE,OAAO,WAAW;AACrE;AAEO,IAAM,oBAAkC;EAC7C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACvCR,SAAU,YAAY,MAI3B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,EAAC,IAAI;AACf,QAAM,EAAC,YAAY,WAAU,IAAI;AAEjC,SAAO,gBAAgB,EAAC,GAAG,GAAG,YAAY,YAAY,QAAO,CAAC;AAChE;AAEO,IAAM,oBAAkC;EAC7C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACjBR,IAAO,eAAP,MAAmB;EAavB,YAAY,OAAiB,UAAkB;AAZ/C,SAAA,gBAAgB,CAAC,QAAQ;AAOzB,SAAA,gBAAgB;AAChB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAEnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,OAAO,SAAS;AACrB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,CAAC,KAAK,eAAe,GAAG,CAAC,CAAC;AAE9B,SAAK,QAAQ;AACb,SAAK,WAAW,WAAW,kBAAkB,MAAM,MAAM,CAAC;AAC1D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,QAAQ,kBAAkB,KAAK,IAAI;AACzC,UAAM,eAAe,UAAU,KAAK,IAAI;AACxC,QAAI;AACJ,QAAI,KAAK,MAAM,WAAW,GAAG;AAC3B,iBAAW,KAAK,YAAY,IAAI,CAAC,GAAG,MAAK;AACvC,eAAO;MACT,CAAC;WACI;AACL,iBAAW,KAAK,YAAY,IAAI,CAAC,GAAG,MAAK;AACvC,eAAO,aAAa,OAAO,CAAC,CAAC,qBACzB,aAAa,CAAC,CAAC,aAAa,OAAO,CAAC,CAAC;MAC3C,CAAC;;AAGH,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;4BAEO,KAAK;;YAErB,SAAS,KAAK,IAAI,CAAC;8CACe,YAAY;;;;AAItD,WAAO;EACT;;AAGF,IAAM,SAAS,CAAC,KAAK,KAAK,KAAK,KAAK,KAAK,GAAG;AAE5C,SAAS,UAAU,MAAY;AAC7B,MAAI,SAAS,GAAG;AACd,WAAO;aACE,QAAQ,GAAG;AACpB,WAAO,OAAO,MAAM,GAAG,IAAI,EAAE,IAAI,WAAS,aAAa,KAAK,EAAE,EAAE,KAAK,GAAG;SACnE;AACL,UAAM,MAAM,oBAAoB,IAAI,uBAAuB;;AAE/D;;;AC9DM,SAAU,MACZ,MAAsE;AAExE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,OAAO,KAAI,IAAI;AAEtB,QAAM,CAAC,QAAQ,KAAK,IAAI,mBAAW,iBAAiB,GAAG,OAAO,IAAI;AAClE,qBAAW,kBAAkB,GAAG,QAAQ,KAAK;AAE7C,MAAI,QAAQ,mBAAmB,CAAC,CAAC,CAAC,KAAK,EAAE,UAAU,UAAU;AAC3D,UAAM,cAAc,QAAQ,UAAU,IAAI,EAAE,MAAM;AAClD,UAAM,YAAY,aACd,YAAY,QAAsB,QAAQ,OAAO,EAAE,OAAO,EAAE,KAAK;AACrE,WAAO,QAAQ,eAAe,OAAO,EAAE,OAAO,SAAS;;AAGzD,MAAI,aAAK,cAAc,KAAK,MAAM,GAAG;AACnC,WAAO,QAAQ,eAAe,OAAO,EAAE,OAAO,CAAA,CAAE;;AAIlD,QAAM,UAAU,IAAI,aAAa,QAAQ,KAAK;AAC9C,QAAM,cAAc,CAAC,EAAC,MAAM,SAAS,MAAM,OAAM,CAAC;AAClD,SAAO,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,OAAO,WAAW;AACpE;AAEO,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC5BP,IAAM,iBAAiB,CAAC,SAId;AACf,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,YAAY,MAAK,IAAI;AAE5B,eAAK,OACD,EAAE,MAAM,UAAU,GAClB,MAAM,uEACe;AACzB,QAAMC,QAAO,WAAW,OAAO,CAAC,GAAG,MAAM,IAAI,CAAC;AAE9C,QAAM,WAAW,qBAAa,YAAY,EAAE,OAAO,YAAYA,KAAI;AACnE,QAAM,WAAW,qBAAa,YAAY,SAAS,QAAQ,WAAW,MAAM;AAC5E,QAAM,mBACF,qBAAa,oBAAoB,EAAE,OAAO,YAAYA,KAAI;AAC9D,QAAM,mBACF,qBAAa,oBAAoB,OAAO,WAAW,MAAM;AAC7D,QAAM,YACF,qBAAa,aAAa,kBAAkB,OAAO,WAAW,MAAM;AAExE,QAAM,YAAY,CAAA;AAElB,QAAM,uBACF,QAAQ,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AAC5D,QAAM,yBAAyB,UAC3B,EAAC,QAAQ,EAAC,GAAG,qBAAoB,GAAG,SAAS,OAAO,EAAC,MAAM,SAAQ,EAAC,CAAC;AACzE,QAAM,wBAAwB,QAAQ;IACpC,QAAQ,EAAC,GAAG,uBAAsB;IAClC;IACA,OAAO,EAAC,OAAO,iBAAgB;GAChC;AACD,QAAM,SAAS,MAAM;IACnB,QAAQ,EAAC,GAAG,sBAAqB;IACjC;IACA,OAAO,EAAC,OAAO,kBAAkB,MAAM,UAAS;GACjD;AAED,YAAU,KAAK,oBAAoB;AACnC,YAAU,KAAK,sBAAsB;AACrC,YAAU,KAAK,qBAAqB;AAEpC,YAAU,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAEpD,SAAO;AACT;AAEO,IAAM,uBAAqC;EAChD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACzDd,IAAM,eAAe;;MAEf,iBAAiB,kBAAkB,SAAS,SAAS,CAAC;;;AAI5D,IAAM,qBAAqB;;;;;AAMrB,IAAO,kBAAP,MAAsB;EAa1B,YACI,OAAkC,YAClC,eAAe,OAAK;AAdxB,SAAA,cAAwB,CAAA;AAIxB,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,SAAS;AACT,SAAA,aAAa;AACb,SAAA,eAAe;AAMb,SAAK,cAAc;AACnB,SAAK,OAAO,MAAM;AAClB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,eAAe;AACpB,QAAI,cAAc;AAChB,WAAK,SAAS;;AAEhB,SAAK,aAAa;AAClB,QAAI,KAAK,YAAY;AACnB,WAAK,cAAc,KAAK,GAAG;;AAE7B,SAAK,YACD,YAAY,KAAK,UAAU,IAAI,KAAK,YAAY,IAAI,KAAK,IAAI;EACnE;EAEA,cAAW;AACT,UAAM,WAAW;MACf,KAAK,eAAe,qBAAqB,YAAY;IACvD,oBAAK,OAAO,CAAC;MAET,KAAK,SAAS,IACV;;;sBAII,KAAK,eAAe,IACC,KAAK,aAAa,gBAAgB,IAAK;;;SAIhE;;;;sBAKI,KAAK,eACD,IACC,KAAK,aAAa,6BAA6B,IAAK;;;MAGnE;;;AAGF,WAAO;EACT;;;;ACxEI,SAAU,SACZ,MAC0E;AAE5E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,QAAO,IAAI;AACrB,QAAM,EAAC,KAAI,IAAI;AAEf,QAAM,QAAQ,aAAK,cAAc,EAAE,KAAK;AACxC,QAAM,cAAc,aAAK,cAAc,QAAQ,KAAK;AACpD,QAAM,aAAa,cAAc;AACjC,QAAM,aAAuB,CAAC,IAAI;AAClC,QAAM,QAAQ,QAAQ;AAEtB,QAAM,SAAS,KAAK,EAAC,SAAS,OAAO,EAAC,OAAO,YAAY,OAAO,GAAG,MAAK,EAAC,CAAC;AAC1E,QAAM,UAAU,IAAI,gBAAgB,CAAC,KAAK,GAAG,UAAU;AACvD,QAAM,cAAc,CAAC,EAAC,MAAM,SAAS,MAAM,CAAC,IAAI,EAAC,CAAC;AAClD,QAAM,iBAA+B,aAAa,CAAC,GAAG,OAAO,IAAI,CAAC,CAAC;AACnE,QAAM,MAAM,QAAQ,iBAChB,SAAS,gBAAgB,OAAO,aAAa,MAAM;AAEvD,SAAO;AACT;AAEO,IAAM,iBAA+B;EAC1C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC/BR,IAAO,uBAAP,MAA2B;EAU/B,YAAY,OAAa;AATzB,SAAA,cAAwB,CAAA;AAIxB,SAAA,gBAAgB,CAAC,MAAM,IAAI;AAC3B,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,CAAC,KAAK;AACzB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;IACjB,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;AAyBb,WAAO;EACT;;;;AC7CI,SAAU,cAAc,MAG7B;AACC,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,IAAI,GAAE,IAAI;AAEjB,MAAI,QAAQ,mBAAmB,CAAC,IAAI,EAAE,CAAC,GAAG;AACxC,UAAM,eAAe,QAAQ,UAAU,IAAI,GAAG,MAAM;AACpD,UAAM,eAAe,QAAQ,UAAU,IAAI,GAAG,MAAM;AACpD,UAAM,SAAS,aAAa;AAC5B,UAAM,SAAS,aAAa;AAC5B,UAAM,iBAAiB,qBAAa,2BAChC,MAAM,KAAK,MAAM,GAAG,MAAM,KAAK,MAAM,CAAC;AAC1C,WAAO,QAAQ,eACX,CAAC,eAAe,MAAM,GAAG,SAAS,WAAW,KAAK,cAAc,CAAC;;AAGvE,QAAM,SAAS,aAAK,cAAc,GAAG,KAAK;AAC1C,QAAM,SAAS,aAAK,cAAc,GAAG,KAAK;AAC1C,QAAM,aAAa,KAAK,IAAI,QAAQ,MAAM;AAE1C,QAAM,UAAU,IAAI,qBAAqB,UAAU;AACnD,QAAM,cACF,CAAC,EAAC,MAAM,SAAS,MAAM,CAAC,MAAM,EAAC,GAAG,EAAC,MAAM,SAAS,MAAM,CAAC,MAAM,EAAC,CAAC;AACrE,SAAO,QAAQ,iBAAiB,SAAS,CAAC,IAAI,EAAE,GAAG,SAAS,WAAW;AACzE;AAEO,IAAM,sBAAoC;EAC/C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC9BP,IAAM,WAAW,iBAAiB;EACvC,QAAQ,aAAa;EACrB,OAAO;EACP,eAAe;CAChB;AAEM,IAAM,iBAA+B;EAC1C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACVR,SAAU,KAAK,MAAkD;AAErE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,MAAK,IAAI;AAChB,QAAM,YAAY,QAAQ,UAAU,IAAI,MAAM,MAAM;AAEpD,SAAO,SAAS,EAAC,QAAQ,EAAC,GAAG,UAAU,mBAAmB,KAAI,GAAG,QAAO,CAAC;AAC3E;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACZR,SAAU,IAAI,OAAmB,SAAsB;AAC3D,QAAM,UAAU,IAAI,eAAe,MAAM,OAAO,YAAY,MAAM;AAClE,QAAM,SAAS,QAAQ,iBAAiB,SAAS,CAAC,KAAK,GAAG,OAAO;AACjE,SAAO,EAAC,QAAQ,OAAO,QAAQ,OAAO,OAAO,OAAO,OAAO,OAAO,MAAK;AACzE;;;ACGM,SAAU,KACZ,MAAoE;AAEtE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,MAAK,IAAI;AAGhB,MAAI,UAAU,aAAa;AACzB,QAAI,EAAE,UAAU,aAAa;AAC3B,aAAO,SAAS,EAAC,QAAQ,EAAC,EAAC,GAAG,QAAO,CAAC;;AAIxC,UAAM,cAAiB,MAAM,EAAE,KAAK;AACpC,UAAM,SAAS,KAAK,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,UAAS,EAAC,CAAC;AAErE,UAAM,SACF,QAAQ,EAAC,QAAQ,EAAC,MAAM,QAAQ,MAAM,YAAW,GAAG,QAAO,CAAC;AAEhE,gBAAY,QAAO;AACnB,YAAQ,YAAY,OAAO,MAAM;AAEjC,WAAO;;AAIT,MAAI,EAAE,UAAU,aAAa;AAC3B,UAAM,WAAW,KAAK,EAAC,QAAQ,EAAC,OAAO,EAAC,GAAG,QAAO,CAAC;AACnD,UAAM,SAAS,KAAK,EAAC,QAAQ,EAAC,GAAG,SAAQ,GAAG,SAAS,OAAO,EAAC,MAAK,EAAC,CAAC;AACpE,YAAQ,YAAY,SAAS,MAAM;AACnC,WAAO;;AAGT,MAAI,CAAC,aAAK,gBAAgB,EAAE,OAAO,KAAK,GAAG;AAGzC,UAAM,SAAS,SAAS,EAAC,QAAQ,EAAC,EAAC,GAAG,QAAO,CAAC;AAC9C,WAAO,EAAC,QAAQ,OAAO,QAAQ,OAAO,OAAO,OAAO,MAAK;;AAG3D,MAAI,QAAQ,mBAAmB,CAAC,CAAC,CAAC,GAAG;AACnC,UAAM,SAAS,QAAQ,UAAU,IAAI,EAAE,MAAM,EAAE;AAC/C,UAAM,CAAC,aAAa,YAAY,UAAU,IACtC,YAAY,QAAQ,EAAE,OAAO,EAAE,OAAO,KAAK;AAC/C,WAAO,QAAQ,eAAe,aAAa,YAAY,UAAU;;AAGnE,MAAI,UAAU,SAAS;AACrB,WAAO,IAAI,GAAG,OAAO;;AAGvB,MAAI,UAAU,QAAQ;AACpB,UAAM,kBAAkB,QAAQ,eAC5B,CAAA,GAAI,QAAQ,aAAK,uBAAuB,QAAQ,CAAC,CAAC;AAEtD,UAAM,eAA6B,EAAC,GAAG,GAAG,GAAG,gBAAe;AAE5D,UAAM,SAAS,SAAS,EAAC,QAAQ,cAAc,QAAO,CAAC;AACvD,YAAQ,YAAY,gBAAgB,MAAM;AAC1C,WAAO;;AAGT,QAAM,IAAI,MAAM,iCAAiC,EAAE,KAAK,OAAO,KAAK,EAAE;AACxE;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC5EP,IAAM,OACT,gBAAgB,EAAC,QAAQ,YAAY,MAAM,eAAe,YAAW,CAAC;AAEnE,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACRR,IAAO,kBAAP,MAAsB;EAY1B,YAAY,aAAqB;AATjC,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AAGX,SAAA,gBAAgB;AAChB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,kBAAkB;AAClB,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,CAAC,KAAK,eAAe,GAAG,CAAC,CAAC;AAC9B,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;AAUjB,WAAO;EACT;;;;AClCI,IAAO,cAAP,MAAkB;EAYtB,YAAY,aAAqB;AATjC,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AAGX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAGnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;AAWjB,WAAO;EACT;;;;AC/BI,SAAU,YAAY,MAI3B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,cAAc,aAAY,IAAI;AAErC,MAAI;AACJ,QAAM,cAAc;IAClB,EAAC,MAAM,WAAW,MAAM,CAAC,YAAY,EAAC;IACtC,EAAC,MAAM,WAAW,MAAM,CAAC,YAAY,EAAC;;AAExC,MAAI,aAAK,cAAc,EAAE,KAAK,IAAI,MAAM,GAAG;AACzC,cAAU,IAAI,gBAAgB,EAAE,KAAK;SAChC;AACL,cAAU,IAAI,YAAY,EAAE,KAAK;;AAEnC,SAAO,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,OAAO,WAAW;AACpE;AAEO,IAAM,oBAAkC;EAC7C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC7BR,IAAO,oBAAP,MAAwB;EAS5B,YAAY,OAAe;AAR3B,SAAA,cAAwB,CAAA;AAIxB,SAAA,gBAAgB,CAAC,QAAQ,MAAM;AAC/B,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;MACf,oBAAK,OAAO,CAAC;;;;;;;;;;;;AAYf,WAAO;EACT;;;;AC5BF,SAAS,+BACL,eAA2B,aAAuB;AACpD,SAAO;IACL,QAAQ,YAAY;IACpB,OAAO,YAAY;IACnB,OAAO,cAAc;;AAEzB;AAEM,SAAU,WACZ,MAAwD;AAC1D,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,EAAC,IAAI;AAEZ,QAAM,QAAQ,QAAQ,UAAU,IAAI,EAAE,MAAM;AAE5C,QAAM,UAAU,IAAI,kBAAkB,EAAE,KAAK;AAC7C,QAAM,gBAAgB;IACpB,+BAA+B,GAAG,MAAM,mBAAmB,IAAI;IAC/D,+BAA+B,GAAG,MAAM,mBAAmB,IAAI;;AAGjE,SAAO,QAAQ,iBACX,SAAS,eAAe,cAAc,CAAC,EAAE,KAAK;AACpD;AAEO,IAAM,mBAAiC;EAC5C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACjCR,IAAO,gBAAP,MAAoB;EAYxB,YAAY,QAA+B;AAN3C,SAAA,WAAW;AACX,SAAA,gBAAgB;AAChB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAIL,SAAK,cACD,qBAAa;MAAgB;MAAQ;;IAAY;AACrD,SAAK,gBAAgB,OAAO,IAAI,CAAC,GAAG,MAAM,IAAI,CAAC,EAAE;AACjD,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,CAAC,KAAK,eAAe,GAAG,CAAC,CAAC;AAE9B,SAAK,eAAe,OAAO,SAAS;AACpC,aAAS,IAAI,GAAG,IAAI,KAAK,cAAc,KAAK;AAC1C,WAAK,YAAY,SAAS,CAAC;;AAE7B,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAqB,CAAA;AAC3B,QAAI,KAAK,eAAe,GAAG;AACzB,eAAS,KACL,qFAAqF;AACzF,eAAS,IAAI,GAAG,IAAI,KAAK,cAAc,KAAK;AAC1C,iBAAS,KACL,gCAAgC,CAAC,CAAC,CAAC,gDAE/B,CAAC,4BAA4B,IAAI,CAAC,OAAO;;AAEnD,YAAM,YAAY,KAAK;AACvB,YAAM,iBAAiB,KAAK,eAAe;AAC3C,eAAS,KAAK,oDACV,SAAS,4BAA4B,cAAc,OAAO;WACzD;AACL,eAAS,KAAK,uDAAuD;;AAGvE,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;6BACQ,KAAK,aAAa;oCACX,KAAK,aAAa;;;;;;cAMxC,SAAS,KAAK,YAAY,CAAC;;;;;AAKrC,WAAO;EACT;;;;AC7DI,SAAU,KAAK,MAAkD;AAErE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,MAAK,IAAI;AAChB,QAAM,YAAY,QAAQ,UAAU,IAAI,MAAM,MAAM;AAEpD,SAAO,SAAS,EAAC,QAAQ,EAAC,GAAG,UAAU,mBAAmB,KAAI,GAAG,QAAO,CAAC;AAC3E;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNR,SAAU,WACZ,QAAsB,MAAc,SAAsB;AAC5D,QAAM,QAAQ,OAAO,CAAC,EAAE;AACxB,MAAI,UAAU,aAAa;AACzB,UAAM,QAAQ,OAAO,IAAI,CAAC,MAAM,KAAK,EAAC,QAAQ,EAAC,OAAO,EAAC,GAAG,QAAO,CAAC,CAAC;AACnE,UAAM,QAAQ,OAAO,IAAI,CAAC,MAAM,KAAK,EAAC,QAAQ,EAAC,OAAO,EAAC,GAAG,QAAO,CAAC,CAAC;AAEnE,UAAM,eAAe,WAAW,OAAO,MAAM,OAAO;AACpD,UAAM,eAAe,WAAW,OAAO,MAAM,OAAO;AAEpD,UAAM,SACF,QAAQ,EAAC,QAAQ,EAAC,MAAM,cAAc,MAAM,aAAY,GAAG,QAAO,CAAC;AAEvE,UAAM,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAChD,UAAM,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAChD,YAAQ,YAAY,aAAa,MAAM;AACvC,YAAQ,YAAY,aAAa,MAAM;AAEvC,WAAO;;AAGT,MAAI,WAAW,QAAQ,mBAAmB,MAAM;AAQhD,MAAI,UAAU,UAAU;AACtB,eAAW;;AAGb,MAAI,UAAU;AAQZ,UAAMC,aAAY,OAAO,IAAI,OAAI;AAC/B,YAAM,YAAY,aAAK,cAAc,EAAE,MAAM,MAAM,IAAI,CAAC;AACxD,YAAM,QAAQ,CAAC,IAAI,SAAS;AAC5B,aAAO,QAAQ,EAAC,QAAQ,EAAC,GAAG,EAAC,GAAG,SAAS,OAAO,EAAC,MAAK,EAAC,CAAC;IAC1D,CAAC;AAED,UAAM,kBAAkBA,WAAU,IAAI,OAAI;AACxC,aAAO,EAAC,MAAM,QAAQ,SAAS,EAAE,MAAM,GAAG,OAAO,EAAE,MAAK;IAC1D,CAAC;AAGD,UAAMC,YACF,qBAAa;MAAgBD,WAAU,IAAI,OAAK,EAAE,KAAK;MAAG;;IAAY;AAC1E,UAAM,eAAeA,WAAU,CAAC,EAAE,MAAM,CAAC,MAAM;AAC/C,UAAM,UACF,cAAc,iBAAiBC,WAAU,OAAO,YAAY;AAEhE,UAAM,gBACF,qBAAa,gBAAgB,OAAO,IAAI,OAAK,EAAE,KAAK,GAAG,IAAI;AAE/D,UAAM,UAAU,QAAQ,eAAe,eAAe,OAAO,OAAO;AAEpE,IAAAD,WAAU,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAEpD,WAAO;;AAKT,QAAM,cAAc,QAAQ,OAAO,OAAO,kCAAkC;AAC5E,MAAI,OAAO,SAAS,aAAa;AAC/B,UAAM,gBAAgB,CAAA;AACtB,aAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK,aAAa;AACnD,YAAM,WAAW,OAAO,MAAM,GAAG,IAAI,WAAW;AAChD,oBAAc,KAAK,WAAW,UAAU,MAAM,OAAO,CAAC;;AAExD,UAAM,SAAS,WAAW,eAAe,MAAM,OAAO;AAEtD,eAAW,KAAK,eAAe;AAC7B,cAAQ,YAAY,EAAE,MAAM;;AAG9B,WAAO;;AAGT,QAAM,EAAC,WAAW,SAAQ,IAAI,iBAAiB,QAAQ,MAAM,OAAO;AACpE,QAAM,SAAU,UAAW,IAAI,OAAK,EAAE,KAAyB;AAC/D,QAAM,UAAU,IAAI,cAAc,MAAM;AAExC,QAAM,cAAqD,CAAA;AAC3D,QAAM,UAAoB,IAAI,MAAM,OAAO,SAAS,CAAC;AACrD,MAAI,QAAQ,SAAS,GAAG;AACtB,YAAQ,CAAC,IAAI,OAAO,CAAC,EAAE,CAAC;AACxB,gBAAY,KAAK,EAAC,MAAM,SAAS,MAAM,CAAC,QAAQ,CAAC,CAAC,EAAC,CAAC;AACpD,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,cAAQ,CAAC,IAAI,QAAQ,IAAI,CAAC,IAAI,OAAO,CAAC,EAAE,CAAC;AACzC,kBAAY,KAAK,EAAC,MAAM,SAAS,MAAM,CAAC,QAAQ,CAAC,CAAC,EAAC,CAAC;;;AAIxD,QAAM,MAAM,QAAQ,iBAChB,SAAS,WAAW,UAAU,CAAC,EAAE,OAAO,WAAW;AACvD,YAAU,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAEpD,QAAM,iBACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,IAAG,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AACjE,UAAQ,YAAY,IAAI,MAAM;AAC9B,SAAO;AACT;AAEA,SAAS,iBACL,QAAsB,MAAc,SAAsB;AAC5D,QAAM,WAAW,qBAAa,gBAAgB,OAAO,IAAI,OAAK,EAAE,KAAK,GAAG,IAAI;AAC5E,QAAM,YAAY,OAAO,IAAI,OAAK,QAAQ;IACX,QAAQ,EAAC,GAAG,EAAC;IACb;IACA,OAAO;MACL,OAAO;QACL,aAAK,cAAc,EAAE,MAAM,MAAM,GAAG,IAAI,CAAC;QACzC,aAAK,cAAc,EAAE,MAAM,MAAM,IAAI,CAAC;;;GAG3C,CAAC;AAE/B,SAAO,EAAC,WAAW,SAAQ;AAC7B;;;AClIM,SAAU,OACZ,MAAwE;AAE1E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,KAAI,IAAI;AAEf,QAAM,QAAQ,aAAK,eAAe,MAAM,OAAO,CAAC,EAAE,KAAK,EAAE,CAAC;AAE1D,QAAM,SAAS,OAAO,IAAI,OAAK,EAAE,KAAK;AACtC,uBAAa,uBAAuB,QAAQ,KAAK;AAEjD,QAAM,WACF,qBAAa,gBAAgB,OAAO,IAAI,OAAK,EAAE,KAAK,GAAG,KAAK;AAChE,MAAI,aAAK,cAAc,QAAQ,MAAM,GAAG;AACtC,WAAO,QAAQ,eAAe,UAAU,OAAO,CAAC,EAAE,OAAO,CAAA,CAAE;;AAI7D,QAAM,UAAU,OAAO,OAAO,OAAK,aAAK,cAAc,EAAE,KAAK,IAAI,CAAC;AAClE,MAAI,QAAQ,WAAW,GAAG;AACxB,WAAO,SAAS,EAAC,QAAQ,EAAC,GAAG,QAAQ,CAAC,EAAC,GAAG,QAAO,CAAC;;AAGpD,SAAO,WAAW,SAAS,OAAO,OAAO;AAC3C;AAEO,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC7Bd,SAAS,oBACL,gBAAyB,WAAoB,WAC7C,UAAmB,UAAU,OAC7B,aAAsC,MACtC,4BAA4B,OAAO,oBAAoB,GACvD,oBAAoB,GAAG,mBAAmB,GAAC;AAC7C,QAAM,cAAc,CAACE,sBAA4B;AAC/C,YAAQA,mBAAkB;MACxB,KAAK;AACH,eAAO;MACT,KAAK;AACH,eAAO;MACT,KAAK;AACH,eAAO;MACT;AACE,cAAM,IAAI,MACN,oBAAoBA,iBAAgB,oBAAoB;;EAElE;AACA,QAAM,cAAc,CAACA,sBAA4B;AAC/C,YAAQA,mBAAkB;MACxB,KAAK;AACH,eAAO;MACT,KAAK;AACH,eAAO;MACT;AACE,cAAM,IAAI,MACN,oBAAoBA,iBAAgB,oBAAoB;;EAElE;AACA,QAAM,gBAAgB,iBAAiB;;UAGA;;;AAIvC,QAAM,kBAAkB,iBAAiB;;;;;;UAOA;;;;;;;AAQzC,QAAM,SAAS,iBAAiB,uBAAuB;AACvD,QAAM,SAAS,iBAAiB,uBAAuB;AACvD,QAAM,MAAM,iBAAiB,QAAQ;AACrC,QAAM,MAAM,iBAAiB,QAAQ;AACrC,QAAM,eAAe;;uBAGjB,iBAAiB,yBAAyB,sBAAsB;qBACjD,GAAG;qBACH,GAAG;;mBAEL,GAAG;mBACH,GAAG;;;kBAGJ,GAAG;sBACC,YAAY,iBAAiB,CAAC;;;gCAGpB,MAAM,2BAA2B,MAAM;UAC7D,aAAa;;UAEb,YAAY,iBAAiB,CAAC;;;AAItC,QAAM,UAAU,iBAAkB,aAAa,WAAW;QACpD,YAAY,KACwC;;UAElD,YAAY;;eAEP,YAAY,iBAAiB,CAAC,WACT,YAAY,YAAY;QACpD,YAAY,KACwC;;UAElD,YAAY;;eAEP,YAAY,iBAAiB,CAAC;AAE3C,QAAM,UAAU,GAAG,YAAY,iBAAiB,CAAC;AAEjD,QAAM,UAAU,YAAY,gBAAgB;AAC5C,QAAM,QAAQ,iBAAiB,YAAY,iBAAiB,IAC7B,YAAY,iBAAiB;AAC5D,QAAM,QAAQ,iBAAiB,YAAY,iBAAiB,IAC7B,YAAY,iBAAiB;AAC5D,QAAM,WAAW;QAEb,oBACI,YAAY,2BAA2B,qBAAqB,GAAG,CAAC,CAAC;yDAClB,KAAK;UACpD,iBAAiB,UAAU,OAAO;;;yDAGa,KAAK;UACpD,iBAAiB,UAAU,OAAO;;;gEAGoB,OAAO;;;;yBAKjE,iBAAiB,yBAAyB,sBAAsB;UAC5D,eAAe;UACf,sBAAsB,SAAS,UAAU,CAAC;;;;AAIlD,SAAO;AACT;AAEM,IAAO,kBAAP,MAAsB;EA0B1B,YACI,UAAmC,WAAmB,WACtD,UAAkB,UAAU,OAC5B,aAAsC,MACtC,4BAA4B,OAAO,4BAA4B,OAAK;AAzBxE,SAAA,gBAAgB,CAAC,KAAK,GAAG;AAEzB,SAAA,WACI;AAuBF,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,SAAS,eAAe;AAC9C,SAAK,WACE,SAAS,aAAa,MAAM,KAAK,SAAS,aAAa,MAAM,MAC9D,KAAK,kBACL,SAAS,WAAW,MAAM,KAAK,CAAC,KAAK,mBACvC,SAAS,cAAc,MAAM;AACjC,SAAK,iBAAiB,KAAK,iBAAiB,EAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC,EAAC,IAC1B,EAAC,GAAG,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,EAAC;AACtE,SAAK,gBAAgB,8BACjB,KAAK,gBAAgB,KAAK,aAAa,KAAK,MAAM;AACtD,SAAK,oBAAoB,8BACrB,KAAK,gBAAgB,KAAK,aAAa,KAAK,MAAM;AAEtD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,KAAK,iBAAiB;AAE1B,QAAI,KAAK,QAAQ;AACf,WAAK,kBAAkB;AACvB,UAAI,KAAK,kBAAkB,SAAS,aAAa,MAAM,GAAG;AACxD,aAAK,mBAAmB;AACxB,aAAK,qBAAqB,CAAC,GAAG,CAAC;aAC1B;AACL,aAAK,mBAAmB;AACxB,aAAK,qBAAqB,CAAC,GAAG,CAAC;;AAGjC,UAAI,SAAS;AACX,aAAK,cAAc,KAAK,MAAM;AAC9B,aAAK,mBAAmB,KAAK,CAAC;;AAGhC,UAAI,2BAA2B;AAC7B,aAAK,cAAc,KAAK,wBAAwB;AAChD,aAAK,mBAAmB,KAAK,CAAC;;WAE3B;AACL,WAAK,mBAAmB,KAAK,kBAAkB,CAAC;AAChD,UAAI,SAAS;AACX,aAAK,cAAc,KAAK,MAAM;;AAGhC,UAAI,2BAA2B;AAC7B,aAAK,cAAc,KAAK,wBAAwB;;;AAIpD,SAAK,4BAA4B;AACjC,SAAK,UAAU;AACf,SAAK,aAAa;AAClB,SAAK,4BAA4B;AAEjC,SAAK,aAAa,KAAK,cAAc,CAAC,IAAI,KAAK,kBAAkB,CAAC;AAClE,SAAK,aAAa,KAAK,cAAc,CAAC,IAAI,KAAK,kBAAkB,CAAC;AAClE,SAAK,YAAY,KAAK,IAClB,KAAK,cAAc,CAAC,IAAI,KAAK,kBAAkB,KAAK,cAAc,CAAC,CAAC;AAExE,SAAK,YAAY,YAAY,KAAK,eAAe;AACjD,SAAK,YAAY,YAAY,KAAK,eAAe;AACjD,SAAK,WAAW,WAAW,KAAK,cAAc;AAE9C,SAAK,YAAY,YAAY,KAAK,iBAAiB,IAAI,KAAK,UAAU,KAClE,KAAK,SAAS,IAAI,KAAK,SAAS,IAAI,KAAK,QAAQ,IAAI,KAAK,MAAM,IAChE,KAAK,gBAAgB,IAAI,KAAK,cAAc,IAC5C,KAAK,yBAAyB;EACpC;EAEA,cAAW;AACT,UAAM,eAAe,KAAK,SACtB,2BACI,KAAK,mBAAmB,KAAK,eAAe,CAAC,KAAK,gBAClD,KAAK,SAAS,IAClB,uBACI,KAAK,mBAAmB,KAAK,eAAe,CAAC,KAAK,gBAClD,KAAK,WAAW,OAAO,MAAM,KAAK,yBAAyB;AACnE,UAAM,eACF,KAAK,SAAS,CAAC,KAAK,kBAAkB,GAAG,CAAC,IAAI,CAAC,GAAG,GAAG,CAAC;AAC1D,UAAM,WAAW;MAEb,oBACI,KAAK,gBAAgB,KAAK,WAAW,KAAK,WAAW,KAAK,UAC1D,KAAK,SAAS,KAAK,YAAY,KAAK,2BACpC,aAAa,CAAC,GAAG,aAAa,CAAC,GAAG,aAAa,CAAC,CAAC,CAAC;MACxD,YAAY;;AAEd,WAAO;EACT;;;;ACrPI,IAAO,qBAAP,MAAyB;EAc7B,YACI,UAAmC,UAAU,OAC7C,aAAsC,MACtC,4BAA4B,OAAK;AAZrC,SAAA,gBAAgB,CAAC,KAAK,GAAG;AACzB,SAAA,WACI;AACJ,SAAA,gBAA0C,CAAC,GAAG,GAAG,CAAC;AAUhD,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,SAAS,eAAe;AAC9C,SAAK,iBAAiB,KAAK,iBAAiB,EAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,EAAC,IAC1B,EAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,EAAC;AACtE,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,UAAU;AACf,SAAK,aAAa;AAClB,SAAK,4BAA4B;AAEjC,QAAI,SAAS;AACX,WAAK,cAAc,KAAK,MAAM;;AAGhC,QAAI,2BAA2B;AAC7B,WAAK,cAAc,KAAK,wBAAwB;;AAGlD,SAAK,YAAY,eAAe,KAAK,UAAU,IAAI,KAAK,cAAc;EACxE;EAEA,cAAW;AACT,UAAM,WAAW;SAEb,oBACI,KAAK,YAAY,KAAK,2BAA2B,OAAO,CAAC,CAAC;;;;;;;;;;;;;;;;;;wBAmB9D,KAAK,iBAAiB,sCACA,mCAAmC;;;aAGpD,sBAAsB,KAAK,SAAS,KAAK,UAAU,CAAC;;;;SAIxD,oBAAK,OAAO,CAAC;;;4BAGM,KAAK,iBAAiB,eAAe,YAAY;wBACrD,KAAK,iBAAiB,eAAe,YAAY;wBACjD,KAAK,iBAAiB,eAAe,YAAY;;;;;;iDAOjE,KAAK,iBAAiB,wBACA,qBAAqB;iBAE3C,KAAK,iBAAiB,kDACA,+CAA+C;;;;;;;;;AASzE,WAAO;EACT;;;;ACnGI,IAAO,gBAAP,MAAoB;EAaxB,YAAY,aAAuB,gBAAuB;AAZ1D,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WACI;;AAMJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAEnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,iBAAiB;AACtB,SAAK,YAAY,UAAU,KAAK,cAAc;EAChD;EAEA,cAAW;AACT,UAAM,SAAS,KAAK,iBAAiB,IAAI;AACzC,UAAM,SAAS,KAAK,iBAAiB,IAAI;AAEzC,UAAM,MAAM,KAAK,iBAAiB,cAAc;AAChD,UAAM,MAAM,KAAK,iBAAiB,cAAc;AAChD,UAAM,cAAc,KAAK,iBAAiB,gCACA;AAE1C,UAAM,WAAW;MACf,oBAAK,OAAO,CAAC;;;;oBAIC,GAAG;oBACH,GAAG;;;;oCAIa,MAAM;;;;;;sCAMJ,MAAM;sBACtB,WAAW;;;;;;;AAO7B,WAAO;EACT;;;;AC/BF,SAAS,uBACL,OAAiB,gBAAuB;AAC1C,QAAM,SAAS,MAAM;AACrB,MAAI,UAAU,GAAG;AACf,WAAO,iBACH;MACE,GAAG,MAAM,MAAM,GAAG,EAAE;MACpB,MAAM,SAAS,CAAC,IAAI,MAAM,SAAS,CAAC;MACpC,MAAM,SAAS,CAAC;;QAElB;MACE,GAAG,MAAM,MAAM,GAAG,EAAE;MAAe,MAAM,SAAS,CAAC;MACnD,MAAM,SAAS,CAAC,IAAI,MAAM,SAAS,CAAC;;;aAEjC,CAAC,kBAAkB,WAAW,KAAK,MAAM,CAAC,IAAI,GAAG;AAC1D,WAAO,CAAC,MAAM,CAAC,GAAG,CAAC;SACd;AACL,WAAO;;AAEX;AAKA,SAAS,eAAe,EACtB,GACA,QACA,UACA,SACA,OAAO,MACP,yBAAyB,MACzB,iBAAiB,GACjB,aAAa,KAAI,GACJ;AACb,QAAM,iBAAiB,SAAS,eAAe;AAC/C,QAAM,aAAa,iBAAiB,QAAQ;AAC5C,QAAM,aAAa;AAEnB,QAAM,WAAW,kBACb,SAAS,iBAAiB,SAAS,YACnC,SAAS,gBAAgB,SAAS,WAClC,SAAS,QAAQ,SAAS;AAC9B,QAAM,gBAA8B,CAAA;AACpC,MAAI;AACJ,MAAI;AAEJ,MAAI,UAAU;AACZ,UAAM,YACF,SAAS,WAAW,SAAS,UAAU,SAAS;AACpD,gBAAY,QAAQ;MAClB,QAAQ,EAAC,EAAC;MACV;MACA,OAAO,EAAC,OAAO,CAAC,GAAG,SAAS,WAAW,SAAS,EAAC;KAClD;AACD,qBAAiB,QAAQ;MACvB,QAAQ,EAAC,GAAG,OAAM;MAClB;MACA,OAAO,EAAC,OAAO,CAAC,GAAG,WAAW,SAAS,WAAW,EAAC;KACpD;SACI;AACL,gBAAY,QAAQ;MAClB,QAAQ,EAAC,EAAC;MACV;MACA,OAAO;QACL,OAAO,iBACH;UACE,SAAS;UAAW,SAAS,WAAW,SAAS;UACjD,SAAS;YAEX;UACE,SAAS;UAAW,SAAS;UAC7B,SAAS,WAAW,SAAS;;;KAGtC;AACD,qBAAiB,QAAQ;MACvB,QAAQ,EAAC,GAAG,OAAM;MAClB;MACA,OAAO,EAAC,OAAO,CAAC,GAAG,SAAS,YAAY,SAAS,WAAW,EAAC;KAC9D;;AAEH,gBAAc,KAAK,SAAS;AAC5B,gBAAc,KAAK,cAAc;AAEjC,MAAI,0BAA0B,MAAM;AAClC,UAAM,cACF,uBAAuB,uBAAuB,OAAO,cAAc;AACvE,QAAI,eAAe,MAAM;AACvB,+BAAyB,QAAQ;QAC/B,QAAQ,EAAC,GAAG,uBAAsB;QAClC;QACA,OAAO,EAAC,OAAO,YAAW;OAC3B;AACD,oBAAc,KAAK,sBAAsB;;;AAI7C,MAAI,QAAQ,MAAM;AAChB,UAAM,cAAc,uBAAuB,KAAK,OAAO,cAAc;AACrE,QAAI,eAAe,MAAM;AACvB,aAAO,QAAQ,EAAC,QAAQ,EAAC,GAAG,KAAI,GAAG,SAAS,OAAO,EAAC,OAAO,YAAW,EAAC,CAAC;AACxE,oBAAc,KAAK,IAAI;;;AAI3B,QAAM,SAAS,gBAAgB;IAC7B,GAAG,iBAAiB,YAAY;IAChC,GAAG,iBAAiB,iBAAiB;IACrC;IACA;IACA;IACA;IACA;IACA;IACA;GACD;AACD,QAAM,MAAM,QACR,EAAC,QAAQ,EAAC,GAAG,OAAM,GAAG,SAAS,OAAO,EAAC,OAAO,SAAS,SAAQ,EAAC,CAAC;AACrE,gBAAc,KAAK,MAAM;AAEzB,aAAW,KAAK,eAAe;AAC7B,YAAQ,YAAY,EAAE,MAAM;;AAG9B,SAAO;AACT;AAIA,SAAS,iBAAiB,EACxB,GACA,QACA,UACA,SACA,OAAO,MACP,yBAAyB,MACzB,iBAAiB,GACjB,aAAa,KAAI,GACJ;AAOb,QAAM,EACJ,aACA,cACA,YACA,aACA,cACA,SACA,UACA,WACA,eACA,gBACA,WAAU,IACR;AAEJ,QAAM,iBAAiB,eAAe;AAEtC,QAAM,YAAY,cAAc,eAAe;AAC/C,QAAM,UAAU,YAAY;AAC5B,QAAM,aAAa,iBAAiB,CAAC,SAAS,WAAW,SAAS,SAAS,IACvC,CAAC,SAAS,WAAW,WAAW,OAAO;AAE3E,QAAM,gBAAgB,IAAI,cAAc,YAAY,cAAc;AAClE,QAAM,aAAa;IACjB,EAAC,MAAM,SAAS,MAAM,CAAC,QAAQ,KAAK,QAAQ,IAAI,EAAC;IACjD,EAAC,MAAM,SAAS,MAAM,CAAC,cAAc,WAAW,EAAC;IACjD,EAAC,MAAM,SAAS,MAAM,CAAC,gBAAgB,aAAa,EAAC;IACrD,EAAC,MAAM,SAAS,MAAM,CAAC,QAAQ,EAAC;IAChC,EAAC,MAAM,SAAS,MAAM,CAAC,aAAa,WAAW,EAAC;IAChD,EAAC,MAAM,SAAS,MAAM,CAAC,UAAU,EAAC;;AAEpC,QAAM,QACF,QAAQ,iBAAiB,eAAe,CAAC,CAAC,GAAG,EAAE,OAAO,UAAU;AAEpE,QAAM,gBAA8B,CAAA;AACpC,gBAAc,KAAK,KAAK;AAExB,QAAM,iBAAiB,QACnB,EAAC,QAAQ,EAAC,GAAG,OAAM,GAAG,SAAS,OAAO,EAAC,OAAO,CAAC,GAAG,WAAW,EAAE,EAAC,EAAC,CAAC;AACtE,gBAAc,KAAK,cAAc;AAEjC,MAAI,0BAA0B,MAAM;AAClC,UAAM,cACF,uBAAuB,uBAAuB,OAAO,cAAc;AACvE,QAAI,eAAe,MAAM;AACvB,+BAAyB,QAAQ;QAC/B,QAAQ,EAAC,GAAG,uBAAsB;QAClC;QACA,OAAO,EAAC,OAAO,YAAW;OAC3B;AACD,oBAAc,KAAK,sBAAsB;;;AAI7C,MAAI,QAAQ,MAAM;AAChB,UAAM,cAAc,uBAAuB,KAAK,OAAO,cAAc;AACrE,QAAI,eAAe,MAAM;AACvB,aAAO,QAAQ,EAAC,QAAQ,EAAC,GAAG,KAAI,GAAG,SAAS,OAAO,EAAC,OAAO,YAAW,EAAC,CAAC;AACxE,oBAAc,KAAK,IAAI;;;AAI3B,QAAM,aAAa,iBAAiB,QAAQ;AAC5C,QAAM,aAAa;AACnB,QAAM,SAAS,gBAAgB;IAC7B,GAAG,iBAAiB,QAAQ;IAC5B,GAAG,iBAAiB,iBAAiB;IACrC;IACA;IACA;IACA;IACA;IACA;IACA;GACD;AACD,QAAM,MAAM,QACR,EAAC,QAAQ,EAAC,GAAG,OAAM,GAAG,SAAS,OAAO,EAAC,OAAO,SAAS,SAAQ,EAAC,CAAC;AACrE,gBAAc,KAAK,MAAM;AACzB,aAAW,KAAK,eAAe;AAC7B,YAAQ,YAAY,EAAE,MAAM;;AAG9B,SAAO;AACT;AAEM,SAAU,WAAW,EACzB,GACA,QACA,UACA,SACA,OAAO,MACP,yBAAyB,MACzB,iBAAiB,GACjB,aAAa,KAAI,GACJ;AACb,QAAM,UAAU,QAAQ;AACxB,QAAM,4BAA4B,0BAA0B;AAC5D,QAAM,iBAAiB,SAAS,eAAe;AAC/C,QAAM,WAAW,kBACb,SAAS,iBAAiB,SAAS,YACnC,SAAS,gBAAgB,SAAS,WAClC,SAAS,QAAQ,SAAS;AAC9B,QAAM,iBAAiB,IAAG,EAAG,QAAQ,+BAA+B;AAEpE,MAAI,CAAC,mBACA,YACC,SAAS,iBAAiB,KAAK,SAAS,gBAAgB,KACxD,SAAS,mBAAmB,KAAK,SAAS,kBAAkB,KAC5D,SAAS,iBAAiB,KAAK,SAAS,gBAAgB,MACvD,SAAS,QAAQ,SAAS,UAC1B,SAAS,QAAQ,SAAS,WAAY;AAC3C,WAAO,eAAe;MACpB;MACA;MACA;MACA;MACA;MACA;MACA;MACA;KACD;;AAGH,QAAM,qBACF,IAAG,EAAG,UAAU,oDAAoD;AACxE,QAAM,gCAAgC,qBAAqB,KACvD,qBACA,QAAQ;AACZ,QAAM,oBAAoB,SAAS,YAC/B,KAAK,KAAM,SAAS,YAAY,SAAS,WAAY,EAAE,IACvD,KAAK,KAAK,SAAS,cAAc,EAAE;AACvC,MAAI,IAAG,EAAG,QAAQ,oCAAoC,KAClD,qBAAqB,+BAA+B;AACtD,WAAO,iBAAiB;MACtB;MACA;MACA;MACA;MACA;MACA;MACA;MACA;KACD;;AAGH,MAAI;AACJ,QAAM,UAAU,CAAC,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI;AAC5D,QAAM,aAAa;IACjB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,GAAG,OAAO,EAAC;IAClC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,gBAAgB,SAAS,aAAa,EAAC;;AAEzE,MAAI,gBAAgB;AAClB,cAAU,IAAI,mBACV,UAAU,SAAS,YAAY,yBAAyB;SACvD;AACL,UAAM,YAAY,iBAAiB,SAAS,YAAY,SAAS,WAC9B,SAAS;AAC5C,UAAM,YAAY,iBAAiB,SAAS,cACT,SAAS,YAAY,SAAS;AACjE,UAAM,WACF,SAAS,eAAe,SAAS,cAAc,SAAS;AAC5D,eAAW,KACP,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,EAAC,GAAG,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,EAAC,GACrE,EAAC,MAAM,SAAS,MAAM,CAAC,QAAQ,EAAC,CAAC;AAGrC,UAAM,4BAA4B,QAAQ,YAAY,QAAO;AAC7D,cAAU,IAAI,gBACV,UAAU,WAAW,WAAW,UAAU,SAAS,YACnD,2BAA2B,yBAAyB;;AAG1D,QAAM,gBAA8B,CAAA;AACpC,QAAM,WAAyB,CAAC,GAAG,MAAM;AACzC,MAAI,SAAS;AACX,QAAI,CAAC,kBAAkB,KAAK,MAAM,WAAW,GAAG;AAC9C,aAAO,QACH,EAAC,QAAQ,EAAC,GAAG,KAAI,GAAG,SAAS,OAAO,EAAC,OAAO,CAAC,KAAK,MAAM,CAAC,GAAG,GAAG,CAAC,EAAC,EAAC,CAAC;AACvE,oBAAc,KAAK,IAAI;;AAEzB,aAAS,KAAK,IAAI;;AAEpB,MAAI,2BAA2B;AAC7B,QAAI,CAAC,kBAAkB,uBAAuB,MAAM,WAAW,GAAG;AAChE,+BAAyB,QAAQ;QAC/B,QAAQ,EAAC,GAAG,uBAAsB;QAClC;QACA,OAAO,EAAC,OAAO,CAAC,uBAAuB,MAAM,CAAC,GAAG,GAAG,CAAC,EAAC;OACvD;AACD,oBAAc,KAAK,sBAAsB;;AAE3C,aAAS,KAAK,sBAAsB;;AAEtC,MAAI,eAAe,aAAa;AAC9B,eAAW,KAAK,EAAC,MAAM,WAAW,MAAM,CAAC,cAAc,EAAC,CAAC;AACzD,YAAQ,YAAY;;AAEtB,QAAM,MAAM,QAAQ,iBAAiB,SAAS,UAAU,EAAE,OAAO,UAAU;AAC3E,aAAW,KAAK,eAAe;AAC7B,YAAQ,YAAY,EAAE,MAAM;;AAE9B,SAAO;AACT;;;AClXM,SAAU,OACZ,MAAwE;AAC1E,QAAM,EAAC,QAAQ,OAAO,QAAO,IAAI;AACjC,QAAM,EAAC,GAAG,OAAM,IAAI;AACpB,QAAM,EAAC,SAAS,KAAK,YAAY,WAAW,gBAAe,IAAI;AAC/D,QAAM,cAAc,qBAAa,wBAAwB,UAAU;AACnE,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OACF,OAAO,OAA2C,SAAS,WAAW,KACtE,iBAAiB,OAAuB,WAAW;AACvD,SAAO,WAAW,EAAC,GAAG,QAAQ,UAAU,QAAO,CAAC;AAClD;AAEO,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AClBR,IAAO,wBAAP,MAA4B;EAehC,YAAY,UAAiC;AAd7C,SAAA,gBAAgB,CAAC,MAAM,GAAG;AAC1B,SAAA,WACI;AAKJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAEnD,SAAA,OAAO;AACP,SAAA,SAAS;AACT,SAAA,gBAAgB;AAId,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,SAAS,eAAe;AAC9C,SAAK,SAAS,KAAK,kBAAkB,SAAS,cAAc,MAAM,KAC9D,SAAS,aAAa,MAAM;AAChC,QAAI,KAAK,QAAQ;AAEf,WAAK,gBAAgB;AACrB,WAAK,kBAAkB;AACvB,WAAK,gBAAgB,CAAC,GAAG,GAAG,CAAC;AAC7B,WAAK,iBAAiB,EAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,EAAC;AAChD,WAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,CAAC,GAAG,KAAK,eAAe,CAAC,CAAC;WACzB;AACL,WAAK,OAAO;AACZ,WAAK,gBAAgB;AACrB,WAAK,gBAAgB,CAAC,IAAI,GAAG,CAAC;AAC9B,WAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,WAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;;AAE/D,SAAK,YAAY,kBAAkB,KAAK,cAAc,IAAI,KAAK,MAAM,IACjE,KAAK,aAAa;EACxB;EAEA,cAAW;AACT,UAAM,SAAS,KAAK,iBAAiB,IAAI;AACzC,UAAM,SAAS,KAAK,iBAAiB,IAAI;AACzC,UAAM,aAAa,KAAK,iBAAiB,IAAI;AAE7C,UAAM,cAAc;MAClB,oBAAI,CAAE;;;kCAGsB,KAAK,aAAa;;;;;;;sCAOd,KAAK,aAAa;4BAC5B,KAAK,aAAa;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;4BAgFlB,KAAK,aAAa;;;;;;;;AAQ1C,WAAO,KAAK,SACR;MACF,WAAW;QAET;MACF,oBAAK,OAAO,CAAC;;;;0BAIO,UAAU;;0CAEM,MAAM,aACpC,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;6BA2BN,KAAK,iBAAiB,iCACA,8BAA8B;;;;;;;;;;EAU9D;;AAGI,IAAO,yBAAP,MAA6B;EAYjC,YAAY,UAAiC;AAX7C,SAAA,gBAAgB,CAAC,KAAK,IAAI;AAC1B,SAAA,WACI;AAKJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAEnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,iBAAiB,SAAS,eAAe;AAC9C,SAAK,YAAY,mBAAmB,KAAK,cAAc;EACzD;EAEA,cAAW;AACT,WAAO;MACL,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;oBAyBC,KAAK,cAAc;;;;;;;;;;;;;;;;EAgBrC;;AAGI,IAAO,yBAAP,MAA6B;EAYjC,YAAY,UAAiC;AAX7C,SAAA,gBAAgB,CAAC,KAAK,IAAI;AAC1B,SAAA,WACI;;AAMJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,WAAO;MACL,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAwCjB;;AAGI,IAAO,wBAAP,MAA4B;EAWhC,YAAY,UAAiC;AAV7C,SAAA,gBAAgB,CAAC,MAAM,GAAG;AAC1B,SAAA,WAAW;;AAMX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,WAAO;MACL,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAqDjB;;;;ACpZI,SAAU,qBAAqB,MAIpC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,GAAE,IAAI;AAChB,QAAM,EAAC,SAAS,KAAK,YAAY,iBAAiB,YAAW,IAAI;AAEjE,QAAM,cAAc,qBAAa,wBAAwB,UAAU;AACnE,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OAA2C,aAAa,SAC1D,GAAmB,KAAK,iBAAiB,OACzC,WAAW;AAEf,QAAM,UAAU,IAAI,uBAAuB,QAAQ;AACnD,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,OAAO,EAAC;;AAE1C,SAAO,QAAQ,iBAAiB,SAAS,CAAC,GAAG,EAAE,GAAG,EAAE,OAAO,WAAW;AACxE;AAEO,IAAM,6BAA2C;EACtD,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC9Bd,SAAS,6BAA6B,mBAAmB,GAAC;AACxD,QAAM,cAAc,CAACC,sBAA4B;AAC/C,YAAQA,mBAAkB;MACxB,KAAK;AACH,eAAO;MACT,KAAK;AACH,eAAO;;;;;;;;;;MAUT;AACE,cAAM,IAAI,MACN,oBAAoBA,iBAAgB,oBAAoB;;EAElE;AAEA,QAAM,eAAe;;;;;;;;;iBASN,YAAY,gBAAgB,CAAC;;;iBAG7B,YAAY,gBAAgB,CAAC;;;;;;;8DAQxC,gBAAgB;AAEpB,QAAM,UAAU;UACR,YAAY;;eAEP,YAAY,gBAAgB,CAAC;AAE1C,QAAM,WAAW;qDAEb,YAAY,gBAAgB,CAAC;MAC7B,OAAO;;;qDAIP,YAAY,gBAAgB,CAAC;;;;;;;;;QAS3B,YAAY,gBAAgB,CAAC;;aAExB,YAAY,gBAAgB,CAAC;;;+DAIpC,YAAY,gBAAgB,CAAC;;;;;;;;iEAS7B,gBAAgB;;;AAGpB,SAAO;AACT;AAEM,IAAO,0BAAP,MAA8B;EAclC,YAAY,UAAiC;AAT7C,SAAA,gBAAgB,CAAC,KAAK,GAAG;AAEzB,SAAA,WACI;AAOF,SAAK,cAAc,SAAS;AAE5B,iBAAK,OACD,SAAS,eAAe,gBACxB,MAAM,6BAA6B;AACvC,SAAK,SACD,SAAS,aAAa,MAAM,KAAK,SAAS,cAAc,MAAM;AAClE,SAAK,iBAAiB,EAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC,EAAC;AAChD,SAAK,gBAAgB,8BACjB,KAAK,gBAAgB,KAAK,aAAa,KAAK,MAAM;AACtD,SAAK,oBAAoB,8BACrB,KAAK,gBAAgB,KAAK,aAAa,KAAK,MAAM;AAEtD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,KAAK,iBAAiB;AAE1B,QAAI,KAAK,QAAQ;AACf,WAAK,kBAAkB;AACvB,WAAK,qBAAqB,CAAC,GAAG,CAAC;;AAGjC,SAAK,YACD,oBAAoB,KAAK,MAAM,IAAI,KAAK,iBAAiB;EAC/D;EAEA,cAAW;AACT,UAAM,eAAe,KAAK,SACtB,2BAA2B,KAAK,mBAAmB,KAAK,aAAa,IACrE,uBAAuB,KAAK,mBAAmB,KAAK,aAAa;AACrE,UAAM,WAAW;MACf,6BAA6B,KAAK,SAAS,IAAI,CAAC,CAAC;MACjD,YAAY;;AAEd,WAAO;EACT;;;;ACxII,SAAU,oBAAoB,MAInC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,IAAI,OAAM,IAAI;AACrB,QAAM,EAAC,YAAY,SAAS,KAAK,YAAY,gBAAe,IAAI;AAEhE,QAAM,cAAc,qBAAa,wBAAwB,UAAU;AACnE,QAAM,WAAW,qBAAa,kBAC1B,YAAY,OAAO,OAA2C,SAC9D,GAAmB,KAAK,iBAAiB,OAAO,WAAW;AAE/D,QAAM,aAAa;IACjB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE;MACE,MAAM;MACN,MAAM;QACJ,SAAS,eAAe,IAAI,SAAS,QAAQ;QAC7C,SAAS,cAAc,IAAI,SAAS,QAAQ;;;IAGhD,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE;MACE,MAAM;MACN,MAAM;QACJ,SAAS;QAAW,SAAS;QAAW,SAAS;QACjD,SAAS;;;;AAIf,MAAI;AAEJ,MAAI,IAAG,EAAG,QAAQ,mCAAmC,KACjD,SAAS,eAAe,gBAAgB;AAC1C,cAAU,IAAI,sBAAsB,QAAQ;SACvC;AACL,cAAU,IAAI,wBAAwB,QAAQ;AAC9C,UAAM,YAAY,SAAS,WAAW,SAAS;AAC/C,UAAM,YAAY,SAAS;AAC3B,UAAM,WACF,SAAS,eAAe,SAAS,cAAc,SAAS;AAC5D,eAAW,KACP,EAAC,MAAM,UAAU,MAAM,CAAC,SAAS,EAAC,GAClC,EAAC,MAAM,UAAU,MAAM,CAAC,SAAS,EAAC,GAClC,EAAC,MAAM,UAAU,MAAM,CAAC,QAAQ,EAAC,CAAC;;AAExC,SAAO,QAAQ,iBAAiB,SAAS,CAAC,IAAI,MAAM,GAAG,WAAW,UAAU;AAC9E;AAEO,IAAM,4BAA0C;EACrD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACvDR,IAAO,qBAAP,MAAyB;EAW7B,YAAY,UAAiC;AAN7C,SAAA,gBAAgB,CAAC,KAAK,GAAG;AACzB,SAAA,WACI;AACJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;MACf,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkFf,WAAO;EACT;;;;ACzGI,SAAU,OACZ,MAAwE;AAC1E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,OAAM,IAAI;AACpB,QAAM,EAAC,SAAS,KAAK,UAAS,IAAI;AAElC,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OACF,OAAO,OAAmD,SAC1D,WAAW,GAAG;AAElB,QAAM,UACF,CAAC,SAAS,QAAQ,OAAO,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI;AACxE,QAAM,aAAa;IACjB;MACE,MAAM;MACN,MAAM,CAAC,SAAS,aAAa,SAAS,cAAc,SAAS,WAAW;;IAE1E,EAAC,MAAM,SAAS,MAAM,CAAC,GAAG,OAAO,EAAC;IAAG;MACnC,MAAM;MACN,MAAM,CAAC,SAAS,aAAa,SAAS,cAAc,SAAS,WAAW;;IAE1E;MACE,MAAM;MACN,MAAM;QACJ,SAAS;QAAe,SAAS;QAAgB,SAAS;;;;AAIhE,QAAM,UAAU,IAAI,mBAAmB,QAAQ;AAC/C,QAAM,QAAQ,WAAW,EAAE,OAAO,OAAO,KAAK;AAC9C,SAAO,QAAQ,iBAAiB,SAAS,CAAC,GAAG,MAAM,GAAG,OAAO,UAAU;AACzE;AAEO,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACrCR,SAAU,uBAAuB,MAItC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,GAAE,IAAI;AAChB,QAAM,EAAC,SAAS,KAAK,YAAW,IAAI;AAEpC,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OAAmD,aAAa,SAClE,GAAmB,GAAG;AAE1B,QAAM,UAAU,IAAI,uBAAuB,QAAQ;AACnD,QAAM,cAAc;IAClB;MACE,MAAM;MACN,MACI,CAAC,SAAS,QAAQ,OAAO,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI;;IAE1E;MACE,MAAM;MACN,MAAM,CAAC,SAAS,aAAa,SAAS,cAAc,SAAS,WAAW;;IAE1E,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,OAAO,EAAC;IACxC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,OAAO,EAAC;;AAE1C,SAAO,QAAQ,iBAAiB,SAAS,CAAC,GAAG,EAAE,GAAG,GAAG,OAAO,WAAW;AACzE;AAEO,IAAM,+BAA6C;EACxD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACtCR,SAAU,sBAAsB,MAIrC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,IAAI,OAAM,IAAI;AACrB,QAAM,EAAC,SAAS,KAAK,WAAU,IAAI;AAEnC,QAAM,WAAW,qBAAa,kBAC1B,YAAY,OAAO,OACnB,SAAS,GAAmB,GAAG;AAEnC,QAAM,UAAU,IAAI,sBAAsB,QAAQ;AAClD,QAAM,cAAc;IAClB;MACE,MAAM;MACN,MAAM,CAAC,SAAS,aAAa,SAAS,cAAc,SAAS,WAAW;;IAE1E;MACE,MAAM;MACN,MAAM;QACJ,SAAS,cAAc,IAAI,SAAS,QAAQ;QAC5C,SAAS,eAAe,IAAI,SAAS,QAAQ;QAC7C,SAAS,cAAc,IAAI,SAAS,QAAQ;;;IAGhD;MACE,MAAM;MACN,MAAM,CAAC,SAAS,aAAa,SAAS,cAAc,SAAS,WAAW;;IAE1E,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,WAAW,EAAC;;AAG9C,SAAO,QAAQ,iBAAiB,SAAS,CAAC,IAAI,MAAM,GAAG,GAAG,OAAO,WAAW;AAC9E;AAEO,IAAM,8BAA4C;EACvD,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC1CP,IAAM,MAAM,gBAAgB,EAAC,QAAQ,YAAY,IAAG,CAAC;AAErD,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,OAAO,gBAAgB,EAAC,QAAQ,YAAY,KAAI,CAAC;AAEvD,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACRR,IAAO,uBAAP,MAA2B;EAa/B,YACI,UAAkB,UAA4B,UAC9C,QAA4B;AAVhC,SAAA,gBAAgB,CAAC,SAAS,SAAS,QAAQ;AAC3C,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAInD,SAAA,OAAO;AAKL,UAAM,CAAC,QAAQ,IAAM;AACrB,SAAK,cAAc,CAAC,UAAU,SAAS,CAAC,GAAG,SAAS,CAAC,GAAG,QAAQ;AAChE,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,WAAW,WAAW,aAAa,IAAI;AAC5C,SAAK,wBAAwB,KAAK,YAAY,CAAC,IAAI;AACnD,SAAK,uBAAuB,KAAK,YAAY,CAAC,IAAI;AAClD,SAAK,YAAY,iBAAiB,KAAK,QAAQ,IAC3C,KAAK,qBAAqB,IAAI,KAAK,oBAAoB;EAC7D;EAEA,cAAW;AACT,UAAM,CAAC,kBAAkB,eAAe,IACpC,CAAC,mCAAmC,iCAAiC;AAEzE,UAAM,CAAC,aAAa,aAAa,GAAG,IAAI,KAAK,wBACzC;MACE,IAAI,gBAAgB;MACpB;MACA,MAAM,gBAAgB;QAExB;MACE;MACA;MACA,mBAAmB,gBAAgB;;AAEzC,UAAM,CAAC,YAAY,YAAY,GAAG,IAAI,KAAK,uBACvC;MACE,IAAI,eAAe;MACnB;MACA,MAAM,eAAe;QAEvB;MACE;MACA;MACA,mBAAmB,eAAe;;AAMxC,UAAM,WAAW;MACf,oBAAK,OAAO,CAAC;;;iCAGc,WAAW;gCACZ,UAAU;;;;;;;;;;;;;;;6BAeb,WAAW;4BACZ,UAAU;qBACjB,GAAG;mCACW,gBAAgB;;;;qBAI9B,GAAG;mCACW,eAAe;;;;;aAKrC,KAAK,QAAQ;;;;;;;;;;;;;;;;;;;;;;;;AAwBtB,WAAO;EACT;;;;ACnHK,IAAM,gBAAgB,CAAC,SAIb;AACf,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,OAAO,OAAO,OAAM,IAAI;AAC/B,QAAM,EAAC,UAAU,QAAQ,mBAAkB,IAAI;AAE/C,QAAM,UAAU,IAAI,qBAChB,MAAM,MAAM,CAAC,GAAG,MAAM,OAA2B,UAAU,MAAM;AACrE,QAAM,cAAc,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,kBAAkB,EAAC,CAAC;AAClE,SAAO,QAAQ,iBACX,SAAS,CAAC,OAAO,OAAO,MAAM,GAAG,WAAW,WAAW;AAC7D;AAEO,IAAM,sBAAoC;EAC/C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACrBd,IAAY;CAAZ,SAAYC,YAAS;AACnB,EAAAA,WAAA,MAAA,IAAA;AACA,EAAAA,WAAA,KAAA,IAAA;AACF,GAHY,cAAA,YAAS,CAAA,EAAA;AAKf,IAAO,aAAP,MAAiB;EAcrB,YACI,IAAe,OAAiB,WAAoBC,UAAgB;AAVxE,SAAA,gBAAgB,CAAC,GAAG;AAGpB,SAAA,WAAW;AACX,SAAA,OAAO;AAOL,SAAK,gBAAgB,CAAC,KAAK,GAAG,CAAC;AAC/B,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,YAAY;AACjB,SAAK,UAAUA;AACf,SAAK,KAAK;AACV,SAAK,YAAY,OAAO,KAAK,EAAE,IAAI,KAAK,SAAS,IAAI,KAAK,OAAO;EACnE;EAEA,cAAW;AACT,UAAM,OAAO,KAAK,YAAY;AAC9B,UAAM,UAAU,KAAK,OAAO,UAAU,OAAO,QAAQ;AACrD,UAAM,MAAM,KAAK,YAAY,UACA,QAAQC,WAAU,MAAM,UAAU,KAAK,EAAE,CAAC;AACvE,UAAM,SAAS,KAAK,YAAY,KAAK,YAAY,SAAS,CAAC;AAC3D,QAAI,YAAY;AAChB,QAAI,YAAY;AAIhB,QAAI,KAAK,WAAW;AAClB,kBAAY,KAAK,UAAU,UAAU,SAAS,CAAC,KAAK;AACpD,kBAAY,KAAK,UAAU,YAAY;WAClC;AACL,kBAAY,KAAK,UAAU,gBAAgB,MAAM,KAAK;AACtD,kBAAa,KAAK,UAAU,eAAe;;AAE7C,WAAO;QACH,oBAAK,OAAO,CAAC;;;;qBAIA,cAAc,MAAM,UAAU,KAAK,EAAE,CAAC;qBACtC,GAAG;;eAET,SAAS;uBACD,SAAS;aACnB,cAAc,MAAM,UAAU,KAAK,EAAE,CAAC;iBAClC,KAAK,EAAE,UAAUA,WAAU,MAAM,UAAU,KAAK,EAAE,CAAC;;;;;;EAMlE;;AAGF,SAASA,WAAU,MAAc,MAAc,IAAa;AAC1D,MAAI,SAAS,GAAG;AACd,WAAO,GAAG,IAAI;aACL,SAAS,GAAG;AACrB,WAAO,GAAG,IAAI,OAAO,IAAI;aAChB,SAAS,GAAG;AACrB,WAAO,GAAG,IAAI,OAAO,IAAI,OAAO,IAAI;aAC3B,SAAS,GAAG;AACrB,WAAO,GAAG,IAAI,OAAO,IAAI,OAAO,IAAI,OAAO,IAAI;SAC1C;AACL,UAAM,MAAM,cAAc,EAAE,aAAa,IAAI,uBAAuB;;AAExE;AAEA,SAAS,cAAc,MAAc,MAAc,IAAa;AAC9D,MAAI,SAAS,GAAG;AACd,WAAO,GAAG,IAAI;aACL,SAAS,GAAG;AACrB,WAAO,GAAG,IAAI;aACL,SAAS,GAAG;AACrB,WAAO,GAAG,IAAI;aACL,SAAS,GAAG;AACrB,WAAO,GAAG,IAAI;SACT;AACL,UAAM,MAAM,cAAc,EAAE,aAAa,IAAI,uBAAuB;;AAExE;;;AC3FM,SAAU,QACZ,IAAe,GAAe,SAAwB,MACtD,WAAoBC,UAAgB;AACtC,QAAM,QAAQ,EAAE,MAAM;AACtB,QAAM,cAAc,qBAAa,mBAAmB,CAAC,IAAI,GAAG,KAAK;AACjE,MAAI,YAAY;AAChB,MAAI,eAAe,MAAM;AACvB,gBAAY,UAAU,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,MAAM,YAAW,EAAC,CAAC;;AAE1E,QAAM,eAAe,qBAAa,iBAAiB,GAAG,KAAK,EAAE,CAAC;AAE9D,MAAI,iBAAiB,QAAQ,GAAG;AAC9B,UAAM,IAAI,MACN,oDACI,EAAE,MAAM,SAAS,CAAC,iBACN,IAAI,EAAE;;AAE5B,QAAM,OAAO,UAAU,MAAM,YAAY;AACzC,MAAI,SAAS,SAAS,EAAC,QAAQ,EAAC,GAAG,UAAS,GAAG,QAAO,CAAC;AAMvD,WAAS,IAAI,GAAG,KAAK,KAAK,KAAK,KAAK,KAAK,IAAI,CAAC,IAAI,GAAG,KAAK;AACxD,UAAM,UAAU,IAAI,WAAW,IAAI,UAAU,OAAO,OAAOA,QAAO;AAClE,UAAM,aAAa;AACnB,UAAM,cAAc,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,CAAC,EAAC,CAAC;AACjD,aACI,QAAQ,iBAAiB,SAAS,CAAC,MAAM,GAAG,OAAO,OAAO,WAAW;AACzE,YAAQ,YAAY,WAAW,MAAM;;AAIvC,MAAI,WAAW;AACb,UAAM,UAAU,IAAI,WAAW,IAAI,UAAU,OAAO,WAAWA,QAAO;AACtE,UAAM,aAAa;AACnB,UAAM,cAAc,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,CAAC,EAAC,CAAC;AACjD,aACI,QAAQ,iBAAiB,SAAS,CAAC,MAAM,GAAG,OAAO,OAAO,WAAW;AACzE,YAAQ,YAAY,WAAW,MAAM;;AAGvC,MAAI,eAAe,MAAM;AACvB,UAAM,qBAAqB,qBAAa,uBAAuB,WAAW;AAC1E,UAAM,0BAA0B,UAC5B,EAAC,QAAQ,EAAC,GAAG,OAAM,GAAG,SAAS,OAAO,EAAC,MAAM,mBAAkB,EAAC,CAAC;AAErE,YAAQ,YAAY,OAAO,MAAM;AACjC,YAAQ,YAAY,UAAU,MAAM;AAEpC,WAAO;;AAGT,SAAO;AACT;;;ACzDM,SAAU,QACZ,MAA0E;AAE5E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,MAAM,WAAW,SAAAC,SAAO,IAAI;AACnC,SAAO,QAAQ,UAAU,MAAM,GAAG,SAAS,MAAM,WAAWA,QAAO;AACrE;AAEO,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACZR,SAAU,OACZ,MAAwE;AAE1E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,MAAM,WAAW,SAAAC,SAAO,IAAI;AACnC,SAAO,QAAQ,UAAU,KAAK,GAAG,SAAS,MAAM,WAAWA,QAAO;AACpE;AAEO,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACXR,SAAU,cAAc,MAI7B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,QAAO,IAAI;AACrB,QAAM,EAAC,MAAM,aAAY,IAAI;AAE7B,QAAM,WAAW,EAAE,MAAM,WAAW;AACpC,QAAM,cAAc,aAAK,cAAc,QAAQ,KAAK;AACpD,QAAM,aAAa,cAAc;AACjC,QAAM,QAAQ,QAAQ;AACtB,QAAM,QACF,WAAW,CAAC,EAAE,MAAM,CAAC,CAAC,IAAI,CAAC,EAAE,MAAM,CAAC,GAAG,EAAE,MAAM,CAAC,CAAC;AACrD,QAAM,aACF,WAAW,CAAC,IAAI,IAAI,CAAC,EAAE,MAAM,CAAC,GAAG,IAAI;AAEzC,QAAM,SAAS,KAAK,EAAC,SAAS,OAAO,EAAC,OAAO,YAAY,OAAO,GAAG,MAAK,EAAC,CAAC;AAC1E,QAAM,UAAU,IAAI,gBAAgB,OAAO,YAAY,YAAY;AACnE,QAAM,cAAc,CAAC,EAAC,MAAM,SAAS,MAAM,CAAC,IAAI,EAAC,CAAC;AAClD,QAAM,iBAA+B,aAAa,CAAC,GAAG,OAAO,IAAI,CAAC,CAAC;AACnE,QAAM,MAAM,QAAQ,iBAChB,SAAS,gBAAgB,OAAO,aAAa,MAAM;AAEvD,SAAO;AACT;AAEO,IAAM,sBAAoC;EAC/C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACnCR,IAAO,sBAAP,MAA0B;EAW9B,YAAY,aAAuB,YAAyB;AAV5D,SAAA,gBAAgB,CAAC,GAAG;AAMpB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AACP,SAAA,WAAW;AAGT,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,YAAY,gBAAgB,UAAU;AAC3C,SAAK,aAAa;EACpB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;oBAID,KAAK,qBAAoB,CAAE;oBAC3B,KAAK,oBAAmB,CAAE;oBAC1B,KAAK,oBAAmB,CAAE;;;;;;;cAOhC,KAAK,mBAAkB,CAAE;;;sBAGjB,KAAK,uBAAsB,CAAE;;;;AAI/C,WAAO;EACT;EAEQ,uBAAoB;AAC1B,QAAI,KAAK,eAAe,QAAQ;AAC9B,aAAO;WACF;AACL,aAAO;;EAEX;EAEQ,sBAAmB;AACzB,QAAI,KAAK,eAAe,QAAQ;AAC9B,aAAO;WACF;AACL,aAAO;;EAEX;EAEQ,sBAAmB;AACzB,QAAI,KAAK,eAAe,QAAQ;AAC9B,aAAO;WACF;AACL,aAAO;;EAEX;EAEQ,qBAAkB;AACxB,QAAI,KAAK,eAAe,QAAQ;AAC9B,aAAO;WACF;AACL,aAAO;;EAEX;EAEQ,yBAAsB;AAC5B,QAAI,KAAK,eAAe,QAAQ;AAC9B,aAAO;WACF;AACL,aAAO;;EAEX;;;;ACjFI,SAAU,aAAa,MAI5B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,WAAW,WAAU,IAAI;AAEhC,QAAM,YAAY,EAAE,MAAM,CAAC;AAC3B,QAAM,cAAe,eAAe,SAAU,EAAE,MAAM,CAAC,IAAI,EAAE,MAAM,CAAC;AACpE,QAAM,aAAc,eAAe,SAAU,EAAE,MAAM,CAAC,IAAI,EAAE,MAAM,CAAC;AACnE,QAAM,aAAc,eAAe,SAAU,EAAE,MAAM,CAAC,IAAI,EAAE,MAAM,CAAC;AAEnE,QAAM,eAAe,cAAc;AACnC,QAAM,cAAc,aAAa;AACjC,QAAM,cAAc,cAAc,YAAY;AAE9C,QAAM,cAAe,eAAe,SAChC,CAAC,WAAW,cAAc,aAAa,WAAW,IAClD,CAAC,WAAW,aAAa,cAAc,WAAW;AAEtD,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,EAAC;;AAGnC,QAAM,UAAU,IAAI,oBAAoB,aAAa,UAAU;AAC/D,SAAO,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,OAAO,WAAW;AACpE;AAEO,IAAM,qBAAmC;EAC9C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AChCR,IAAO,mCAAP,MAAuC;EAc3C,YACI,aAAuB,cAAsB,aAC7C,UAAU,OAAO,aAAsC,MACvD,qBAAqB,OAAK;AAZ9B,SAAA,gBAAgB,CAAC,KAAK,GAAG;AACzB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,IAAI,CAAC;AAWlD,SAAK,cAAc;AACnB,SAAK,iBAAiB,EAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,EAAC;AAChD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,QAAI,SAAS;AACX,WAAK,cAAc,KAAK,MAAM;;AAEhC,QAAI,oBAAoB;AACtB,WAAK,cAAc,KAAK,wBAAwB;;AAGlD,SAAK,UAAU;AACf,SAAK,aAAa;AAClB,SAAK,qBAAqB;AAC1B,SAAK,eAAe;AACpB,SAAK,cAAc;AACnB,SAAK,YAAY,iBAAiB,KAAK,UAAU,IAAI,KAAK,YAAY,IAClE,KAAK,WAAW;EACtB;EAEA,cAAW;AACT,UAAM,aAAa,KAAK,cAAc,KAAK;AAC3C,UAAM,oBACF,KAAK,cAAc,CAAC,IAAI,KAAK,cAAc,CAAC,IAAI,KAAK,cAAc,CAAC;AACxE,UAAM,cAAc,KAAK,cAAc,CAAC,IAAI,KAAK,eAAe;AAChE,UAAM,aAAa,KAAK,cAAc,CAAC,IAAI,KAAK,cAAc;AAE9D,UAAM,WAAW;QACb,oBAAoB,KAAK,YAAY,KAAK,oBAAoB,OAAO,CAAC,CAAC;;kDAE7B,UAAU,MAAM,WAAW;kDAC3B,KAAK,WAAW,MAC1D,KAAK,YAAY;;;;;;;;;;QAUjB,oBAAI,CAAE;;;;;;;;;;;;;;;mDAgBN,WAAW,2BAA2B,KAAK,cAAc,CAAC,CAAC;qDAE3D,UAAU,2BAA2B,KAAK,cAAc,CAAC,CAAC;;;;;;;;;UAU1D,aAAa,oBACT,gBAAgB,UAAU,MAC1B,kBAAkB,UAAU,uBACxB,iBAAiB,GAAG;;;gCAGJ,KAAK,WAAW;gCAChB,KAAK,WAAW;;;;;;;gCAOhB,KAAK,YAAY;kCACf,KAAK,WAAW;;;;;;UAMxC,sBAAsB,KAAK,SAAS,KAAK,UAAU,CAAC;;;;;;AAM1D,WAAO;EACT;;;;ACtHI,IAAO,6BAAP,MAAiC;EAgBrC,YACI,UAAmC,UAAU,OAC7C,aAAsC,MAAM,qBAAqB,OAAK;AAb1E,SAAA,gBAAgB,CAAC,KAAK,GAAG;AACzB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,gBAAgB;AAKhB,SAAA,kBAAkB;AAMhB,SAAK,cAAc,SAAS;AAC5B,SAAK,eAAe,KAAK,KAAK,KAAK,YAAY,CAAC,IAAI,KAAK,aAAa,IAClE,KAAK;AACT,UAAM,qBAAqB;MACzB,KAAK,YAAY,CAAC;MAAG,KAAK,YAAY,CAAC;MAAG,KAAK;MAC/C,KAAK,YAAY,CAAC;;AAEpB,SAAK,iBAAiB,mBAAmB,kBAAkB;AAE3D,SAAK,WAAW,gBACZ,KAAK,gBAAgB,oBAAoB,KAAK,eAC9C,CAAC,KAAK,kBAAkB,KAAK,eAAe,GAAG,CAAC,CAAC;AAErD,iBAAK,OACD,SAAS,eAAe,gBACxB,MAAM,6BAA6B;AAEvC,QAAI,SAAS;AACX,WAAK,cAAc,KAAK,MAAM;;AAEhC,QAAI,oBAAoB;AACtB,WAAK,cAAc,KAAK,wBAAwB;;AAGlD,SAAK,WAAW;AAChB,SAAK,UAAU;AACf,SAAK,aAAa;AAClB,SAAK,qBAAqB;AAE1B,SAAK,YACD,iBAAiB,UAAU,IAAI,KAAK,SAAS,YAAY,IACrD,KAAK,SAAS,WAAW,IAAI,KAAK,SAAS,YAAY,IACvD,KAAK,SAAS,WAAW,IAAI,KAAK,aAAa;EACzD;EAEA,cAAW;AACT,UAAM,WAAW,KAAK,gBAAgB,KAAK,KAAK,SAAS,cACrD,KAAK,SAAS;AAClB,UAAM,eAAe,KAAK,SAAS;AACnC,UAAM,cAAc,KAAK,SAAS;AAElC,UAAM,WAAW;QACb,oBAAoB,KAAK,YAAY,KAAK,oBAAoB,MAAM,CAAC,CAAC;;;;;;;;;QAStE,oBAAK,OAAO,CAAC;8CACyB,KAAK,eAAe;sCAC5B,KAAK,eAAe;;+CAEX,KAAK,aAAa;sCAC3B,KAAK,aAAa;;;;;sDAKF,YAAY,KAC1D,WAAW;;;;uCAIoB,OAAO;yCACL,KAAK,aAAa;8BAC7B,KAAK,aAAa;;;;;gCAKhB,KAAK,SAAS,YAAY;;;kCAGxB,OAAO;;;oCAGL,KAAK,SAAS,WAAW;;oCAEzB,KAAK,aAAa;6CAE9C,WAAW;;;;;;8BAMW,KAAK,aAAa;;;;cAIlC,sBAAsB,KAAK,SAAS,KAAK,UAAU,CAAC;;;;;;AAM9D,WAAO;EACT;;;;ACtHI,IAAO,yBAAP,MAA6B;EAiBjC,YACI,UAAmC,UAAU,OAC7C,aAAsC,MAAM,qBAAqB,OAAK;AAd1E,SAAA,gBAAgB,CAAC,KAAK,GAAG;AACzB,SAAA,WAAW;;AAGX,SAAA,gBAA0C,CAAC,KAAK,GAAG,CAAC;AAMpD,SAAA,OAAO;AAKL,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,iBAAiB,SAAS,eAAe;AAE9C,QAAI,SAAS;AACX,WAAK,cAAc,KAAK,MAAM;;AAEhC,QAAI,oBAAoB;AACtB,WAAK,cAAc,KAAK,wBAAwB;;AAGlD,SAAK,WAAW;AAChB,SAAK,UAAU;AACf,SAAK,aAAa;AAClB,SAAK,qBAAqB;AAC1B,SAAK,YAAY,aAAa,KAAK,UAAU,IAAI,KAAK,cAAc;EACtE;EAEA,cAAW;AACT,UAAM,cAAc,KAAK,iBAAiB,6BACA;AAE1C,UAAM,WAAW;QACb,oBAAoB,KAAK,YAAY,KAAK,oBAAoB,OAAO,CAAC,CAAC;;QAEvE,oBAAK,OAAO,CAAC;;;;6CAKb,KAAK,iBAAiB,OAAO,IAAI;4BACb,KAAK,iBAAiB,IAAI,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;+BA4BxB,WAAW;;;;;;;;;;;;;;;;;;;;+BAoBX,WAAW;;;;;;cAM5B,sBAAsB,KAAK,SAAS,KAAK,UAAU,CAAC;;;;;AAK9D,WAAO;EACT;;;;AChHI,SAAU,sBAAsB,MAIrC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,OAAM,IAAI;AACpB,QAAM,EAAC,SAAS,KAAK,YAAY,WAAW,gBAAe,IAAI;AAC/D,QAAM,cAAc,qBAAa,wBAAwB,UAAU;AACnE,MAAI,aAAa;AACjB,MAAI,cAAc,MAAM;AACtB,iBAAa,CAAC,GAAG,CAAC;;AAGpB,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OACF,OAAO,OAA2C,SAAS,YAC3D,KAAK,iBAAiB,MAAsB,WAAW;AAC3D,QAAM,aAAa;IACjB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,UAAU,SAAS,OAAO,EAAC;;AAG7D,QAAM,iBAAiB,SAAS,eAAe;AAC/C,MAAI;AAEJ,MAAI,CAAC,kBAAkB,SAAS,WAAW,MAAM,SAAS,UAAU,MAChE,SAAS,iBAAiB,KAAK,SAAS,gBAAgB,KACxD,SAAS,kBAAkB,KAAK,SAAS,mBAAmB,KAC5D,SAAS,eAAe,SAAS,aAAa;AAChD,cAAU,IAAI,iCACV,SAAS,UAAU,SAAS,cAAc,SAAS,WAAW;aAEhE,kBAAkB,SAAS,YAAY,KAAK,SAAS,WAAW,KAChE,SAAS,eAAe,KACxB,SAAS,eAAe,SAAS,eACjC,SAAS,mBAAmB,KAAK,SAAS,kBAAkB,KAC5D,SAAS,aAAa,MAAM,GAAG;AACjC,cAAU,IAAI,2BAA2B,QAAQ;AACjD,eAAW,KAAK,EAAC,MAAM,SAAS,MAAM,CAAC,QAAQ,YAAY,EAAC,CAAC;SACxD;AACL,cAAU,IAAI,uBAAuB,QAAQ;AAC7C,eAAW,KACP,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,YAAY,EAAC,GAC7C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,WAAW,EAAC,GAC5C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC,GAAG;MACpE,MAAM;MACN,MAAM,CAAC,SAAS,gBAAgB,SAAS,aAAa;KACvD;;AAGP,SAAO,QAAQ,iBAAiB,SAAS,CAAC,GAAG,MAAM,GAAG,EAAE,OAAO,UAAU;AAC3E;AAEO,IAAM,8BAA4C;EACvD,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC5DR,IAAO,kCAAP,MAAsC;EAY1C,YAAY,UAAiC;AAP7C,SAAA,gBAAgB,CAAC,KAAK,IAAI;AAC1B,SAAA,WACI;;AAEJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAE5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AAEzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmCjB,WAAO;EACT;;AAGI,IAAO,iCAAP,MAAqC;EAWzC,YAAY,UAAiC;AAN7C,SAAA,gBAAgB,CAAC,MAAM,GAAG;AAC1B,SAAA,WAAW;;AAEX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAE5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AAEzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0CjB,WAAO;EACT;;;;AClII,SAAU,oCAAoC,MAInD;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,GAAE,IAAI;AAChB,QAAM,EAAC,SAAS,WAAW,KAAK,iBAAiB,YAAW,IAAI;AAEhE,QAAM,WAAW,qBAAa;IAC1B,EAAE;IAA2C;IAAa;IAC1D;IAAW;IAAK;IAAiB;;EAAoB;AAEzD,QAAM,UAAU,IAAI,gCAAgC,QAAQ;AAC5D,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,OAAO,EAAC;IACxC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,UAAU,EAAC;;AAEpE,SAAO,QAAQ,iBAAiB,SAAS,CAAC,GAAG,EAAE,GAAG,WAAW,WAAW;AAC1E;AAEO,IAAM,4CAA0D;EACrE,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC/BR,SAAU,mCAAmC,MAIlD;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,IAAI,OAAM,IAAI;AACrB,QAAM,EAAC,SAAS,WAAW,KAAK,iBAAiB,WAAU,IAAI;AAE/D,QAAM,WAAW,qBAAa;IAC1B;IAAY,OAAO;IAA2C;IAC9D;IAAW;IAAK;IAAiB;;EAAoB;AAEzD,QAAM,UAAU,IAAI,+BAA+B,QAAQ;AAC3D,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IAAG;MACpE,MAAM;MACN,MAAM;QACJ,SAAS,eAAe,IAAI,SAAS,QAAQ;QAC7C,SAAS,cAAc,IAAI,SAAS,QAAQ;;;IAGhD,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,UAAU,EAAC;;AAEpE,SAAO,QAAQ,iBAAiB,SAAS,CAAC,IAAI,MAAM,GAAG,GAAG,OAAO,WAAW;AAC9E;AAEO,IAAM,2CAAyD;EACpE,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACnCR,IAAO,cAAP,MAAkB;EAStB,YAAY,MAAY;AAJxB,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,CAAC,MAAM,IAAI;AAC9B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;AAQjB,WAAO;EACT;;;;AC1BI,SAAU,KAAK,MAAkD;AAErE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,EAAC,IAAI;AAEZ,QAAM,WAAW,CAAC,GAAG,EAAE,OAAO,GAAG,EAAE,KAAK;AACxC,QAAM,QAAQ,aAAK,cAAc,EAAE,KAAK;AAExC,QAAM,OAAO,QAAQ,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,CAAC,KAAK,EAAC,EAAC,CAAC;AAEpE,QAAM,UAAU,IAAI,YAAY,KAAK;AACrC,QAAM,MAAM,QAAQ,iBAAiB,SAAS,CAAC,IAAI,GAAG,KAAK,KAAK;AAEhE,QAAM,MAAM,QAAQ,EAAC,QAAQ,EAAC,GAAG,IAAG,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AAEzE,UAAQ,YAAY,KAAK,MAAM;AAC/B,UAAQ,YAAY,IAAI,MAAM;AAE9B,SAAO;AACT;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACzBR,IAAO,oBAAP,MAAwB;EAW5B,YAAY,UAAiC;AAN7C,SAAA,gBAAgB,CAAC,KAAK,GAAG;AACzB,SAAA,WACI;AACJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;SACZ,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgClB,WAAO;EACT;;;;ACvDI,SAAU,WAAW,MAI1B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,OAAM,IAAI;AACpB,QAAM,EAAC,SAAS,KAAK,UAAS,IAAI;AAElC,QAAM,WAAW,qBAAa,sBAC1B,EAAE,OACF,OAAO,OAAmC,SAAS,KACnD,QAAyB,SAAS;AACtC,QAAM,UAAU,CAAC,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI;AAC5D,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,GAAG,OAAO,EAAC;IAClC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,gBAAgB,SAAS,aAAa,EAAC;;AAGzE,QAAM,UAAU,IAAI,kBAAkB,QAAQ;AAC9C,QAAM,MACF,QAAQ,iBAAiB,SAAS,CAAC,GAAG,MAAM,GAAG,EAAE,OAAO,WAAW;AAEvE,SAAO;AACT;AAEO,IAAM,mBAAiC;EAC5C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC9BR,IAAO,iCAAP,MAAqC;EAYzC,YAAY,UAAmC,aAAqB;AAPpE,SAAA,gBAAgB,CAAC,KAAK,KAAK,IAAI;AAC/B,SAAA,WACI;AACJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,SAAS;AAIP,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,mBAAmB,SAAS,QAAQ;AAC1D,SAAK,WAAW,gBACZ,KAAK,gBAAgB,SAAS,UAAU,KAAK,aAAa;AAE9D,QAAI,gBAAgB,aAAa,gBAAgB,SAAS;AACxD,YAAM,IAAI,MAAM;oCACc,WAAW,QAAQ;;AAEnD,SAAK,OAAO;AACZ,SAAK,YAAY;EACnB;EAEA,cAAW;AAGT,UAAM,WAAW;SACZ,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;aAwCd,iBACI,wBAAwB,SAAS,KAAK,IAA2B,CAAC;;;;AAI1E,WAAO;EACT;;AAGI,IAAO,kCAAP,MAAsC;EAY1C,YACI,UAAmC,OACnC,aAAqB;AATzB,SAAA,gBAAgB,CAAC,KAAK,KAAK,IAAI;AAC/B,SAAA,WACI;AACJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,SAAS;AAMP,SAAK,cAAc,SAAS;AAC5B,SAAK,iBAAiB,mBAAmB,SAAS,QAAQ;AAC1D,SAAK,WAAW,gBACZ,KAAK,gBAAgB,SAAS,UAAU,KAAK,aAAa;AAE9D,QAAI,gBAAgB,aAAa,gBAAgB,SAAS;AACxD,YAAM,IAAI,MAAM;oCACc,WAAW,QAAQ;;AAEnD,SAAK,OAAO;AACZ,SAAK,YAAY;EACnB;EAEA,cAAW;AAGT,UAAM,WAAW;SACZ,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;aAuCd,iBACI,wBAAwB,SAAS,KAAK,IAA2B,CAAC;;;;AAI1E,WAAO;EACT;;;;AC5JI,SAAU,yBAAyB,MAIxC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,QAAQ,GAAE,IAAI;AACxB,QAAM,EAAC,SAAS,KAAK,UAAS,IAAI;AAElC,QAAM,WAAW,qBAAa,sBAC1B,EAAE,OACF,OAAO,OAAmC,SAAS,KACnD,QAAyB,SAAS;AAEtC,QAAM,QAAQ,OAAO;AACrB,QAAM,UACF,IAAI,gCAAgC,UAAU,OAAO,OAAO,KAAK;AACrE,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,gBAAgB,SAAS,aAAa,EAAC;IACvE,EAAC,MAAM,SAAS,MAAM,CAAC,aAAK,cAAc,SAAS,QAAQ,CAAC,EAAC;;AAE/D,QAAM,SAAS,KAAK,EAAC,SAAS,OAAO,EAAC,OAAO,OAAO,OAAO,OAAO,GAAG,MAAK,EAAC,CAAC;AAC5E,SAAO,QAAQ,iBACX,SAAS,CAAC,GAAG,QAAQ,EAAE,GAAG,OAAO,aAAa,MAAM;AAC1D;AAEO,IAAM,iCAA+C;EAC1D,YAAY;EACZ,aAAa;EACb,YAAY;;;;AChCR,SAAU,wBAAwB,MAIvC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,QAAQ,GAAE,IAAI;AACxB,QAAM,EAAC,SAAS,KAAK,UAAS,IAAI;AAElC,QAAM,WAAW,qBAAa,sBAC1B,EAAE,OACF,OAAO,OAAmC,SAAS,KACnD,QAAyB,SAAS;AAEtC,QAAM,QAAQ,EAAE;AAChB,QAAM,UAAU,IAAI,+BAA+B,UAAU,KAAK;AAClE,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,gBAAgB,SAAS,aAAa,EAAC;IACvE,EAAC,MAAM,SAAS,MAAM,CAAC,aAAK,cAAc,SAAS,QAAQ,CAAC,EAAC;;AAE/D,QAAM,SACF,KAAK,EAAC,SAAS,OAAO,EAAC,OAAO,SAAS,SAAS,OAAO,GAAG,MAAK,EAAC,CAAC;AACrE,SAAO,QAAQ,iBACX,SAAS,CAAC,GAAG,QAAQ,EAAE,GAAG,OAAO,aAAa,MAAM;AAC1D;AAEO,IAAM,gCAA8C;EACzD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACjCR,IAAO,cAAP,MAAkB;EAatB,YACI,UAAoB,MAAgB,eAA+B;AAbvE,SAAA,gBAAgB,CAAC,OAAO;AACxB,SAAA,WAAW;AAKX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAGnD,SAAA,eAAe,aAAa;AAC5B,SAAA,OAAO;AAIL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,OAAO;AACZ,SAAK,gBAAgB;AACrB,SAAK,YAAY,QAAQ,IAAI,IAAI,aAAa;EAChD;EAEA,cAAW;AACT,QAAI;AACJ,UAAM,QAAQ,KAAK,SAAS,YAAY,UAAU;AAClD,sBAAkB;;oBAEF,KAAK;oBACL,KAAK;oBACL,KAAK;;oBAEL,KAAK;;AAGrB,UAAM,WAAW;iEAEb,KAAK,aAAa;SACjB,oBAAK,OAAO,CAAC;;;;;eAKP,eAAe;;;;;;;;;;AAU1B,WAAO;EACT;;;;ACtDI,SAAU,KACZ,MAAoE;AAEtE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,MAAK,IAAI;AAChB,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,CAAC,QAAQ,KAAK,IAAI,MAAM,MAAM,MAAM,GAAG,CAAC;AAC9C,QAAM,EAAC,aAAY,IAAI,WAAW,CAAA;AAClC,QAAM,SAAQ,iBAAY,QAAZ,iBAAY,SAAA,SAAZ,aAAe,UAAS;AAKtC,QAAM,SAAS,QAAQ,OAAO,SAAS,IAAI,oBAAoB,IAC3D,eACA;AACJ,QAAM,WAAW,CAAC,QAAQ,KAAK;AAC/B,QAAM,UAAU,IAAI,YAAY,UAAU,MAAM,OAAO,MAAM;AAC7D,SAAO,QAAQ;AACf,SAAO,SAAS;AAChB,QAAM,cAAc;AACpB,MAAI,aAAa,OAAO,WAAW,WAAW;AAC9C,MAAI;AACJ,MAAI,CAAC,YAAY;AACf,mBAAe,IAAI,gBAAgB,OAAO,MAAM;AAChD,iBAAa,aAAa,WAAW,WAAW;;AAElD,QAAM,cAAc,MAAM,MAAM,WAAW,IAAI,MAAM,MAAM,CAAC,IAAI;AAChE,aAAW,UAAU;IACnB,QAAQ,QAAQ;IAChB;IACA,OAAO,gBAAgB;IACvB,WAAW;GACZ;AAED,QAAM,cAAc;AACpB,QAAM,SAAS,QAAQ,eAAe,UAAU,WAAW;AAC3D,QAAM,OAAO,QAAQ,UAAU,IAAI,OAAO,MAAM;AAChD,OAAK,WAAW,WAAW,kBAAiB;AAC5C,OAAK,WAAW;AAEhB,QAAM,cACF,CAAC,EAAC,MAAM,UAAU,MAAM,CAAC,WAAW,EAAC,GAAG,EAAC,MAAM,WAAW,MAAM,CAAC,KAAK,EAAC,CAAC;AAC5E,UAAQ,iBAAiB,SAAS,CAAC,KAAK,GAAG,aAAa,aAAa,MAAM;AAE3E,MAAI,cAAc;AAChB,UAAM,kBAAkB,OAAO,WAAW,IAAI;AAC9C,QAAI,CAAC,iBAAiB;AACpB,YAAM,IAAI,MACN,2EAA2E;;AAEjF,oBAAgB,UAAU,cAAc,GAAG,CAAC;;AAE9C,UAAQ,YAAY,OAAO,MAAM;AACjC,SAAO;AACT;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC5DP,IAAM,qBAAqB,iBAAiB;EACjD,QAAQ,aAAa;EACrB,eAAe;EACf,iBAAiB;CAClB;AAEM,IAAM,iBAA+B;EAC1C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACVR,SAAU,IACZ,MAAkE;AAEpE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,MAAM,SAAQ,IAAI;AAEzB,SAAO,OAAO,GAAG,MAAM,UAAU,OAAO,OAAO;AACjD;AAEO,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACTR,SAAU,OACZ,MAAwE;AAE1E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,SAAQ,IAAI;AACnB,QAAM,UAAU;AAEhB,QAAM,EAAC,SAAS,YAAY,OAAM,IAC9B,qBAAa,qBAAqB,UAAU,QAAQ,MAAM;AAC9D,uBAAa,oBAAoB,QAAQ,QAAQ,QAAQ,OAAO;AAChE,QAAM,EAAC,MAAM,MAAK,IAAI,qBAAa,qBAAqB,YAAY,MAAM;AAE1E,QAAM,SAAS,MAAM;AACrB,MAAI,MAAuB;AAC3B,MAAI,mBAAmB,QAAQ;AAC/B,QAAM,mBAAiC,CAAA;AACvC,WAAS,IAAI,GAAG,IAAI,QAAQ,EAAE,GAAG;AAC/B,eAAW,UAAU,MAAM,CAAC,GAAG;AAC7B,YAAM,EAAC,oBAAoB,MAAM,YAAY,aAAY,IACrD,qBAAa,qBAAqB,kBAAkB,OAAO,MAAM,CAAC;AACtE,UAAI;AACJ,UAAI,qBAAa,sBAAsB,IAAI,GAAG;AAC5C,YAAI,QAAQ,MAAM;aACb;AACL,YAAI,UAAU,EAAC,QAAQ,EAAC,GAAG,QAAQ,MAAM,EAAC,GAAG,SAAS,OAAO,EAAC,KAAI,EAAC,CAAC;AACpE,yBAAiB,KAAK,CAAC;;AAEzB,YAAM,cAAwB,EAAE,MAAM,MAAK;AAC3C,eAAS,IAAI,GAAG,IAAI,aAAa,QAAQ,EAAE,GAAG;AAC5C,oBAAY,OAAO,aAAa,CAAC,GAAG,GAAG,CAAC;;AAG1C,UAAI,CAAC,aAAK,YAAY,EAAE,OAAO,WAAW,GAAG;AAC3C,YAAI,QAAQ,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,YAAW,EAAC,CAAC;AAC/D,yBAAiB,KAAK,CAAC;;AAEzB,UAAI,QAAQ,MAAM;AAChB,cAAM;aACD;AAEL,cACI,mBAAmB,EAAC,QAAQ,EAAC,GAAG,GAAG,GAAG,IAAG,GAAG,QAAO,CAAC;AACxD,yBAAiB,KAAK,GAAG;;;AAG7B,QAAI,IAAI,SAAS,GAAG;AAClB,UAAI,KAAK,CAAC,KAAK,GAAG;AAChB,cAAM,IAAI;UACR,QAAQ,EAAC,GAAG,IAAG;UACf;UACA,OAAO;YACL,MAAM,KAAK,CAAC,KAAK,QAAQ,SAAS;YAClC,UAAU;;SAEb;AACD,yBAAiB,KAAK,GAAG;;AAE3B;;;AAKJ,aAAW,cAAc,kBAAkB;AACzC,QAAI,eAAe,KAAK;AACtB;;AAEF,YAAQ,YAAY,WAAW,MAAM;;AAGvC,SAAO;AACT;AAEO,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AChFP,IAAM,MAAM,gBAAgB,EAAC,QAAQ,YAAY,IAAG,CAAC;AAErD,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACHP,IAAM,UACT,CAAC,SAAqE;AACpE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,IAAI,EAAC,IAAI;AAEhB,QAAM,UACF,IAAI,gBAAgB,aAAa,SAAS,GAAG,OAAO,EAAE,KAAK;AAC/D,SAAO,QAAQ,iBAAiB,SAAS,CAAC,IAAI,CAAC,GAAG,GAAG,KAAK;AAC5D;AAEG,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACbP,IAAM,QAAQ,iBACjB,EAAC,QAAQ,aAAa,OAAO,OAAO,QAAQ,eAAe,aAAQ,CAAC;AAEjE,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNP,IAAM,MAAM,gBAAgB,EAAC,QAAQ,YAAY,IAAG,CAAC;AAErD,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNP,IAAM,MAAM,gBAAgB;EACjC,QAAQ,YAAY;EACpB,eAAe;EACf,OAAO;CACR;AAEM,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACTR,SAAU,WAAW,MAI1B;AACC,QAAM,EAAC,QAAQ,OAAO,QAAO,IAAI;AACjC,QAAM,EAAC,IAAG,IAAI;AACd,QAAM,EAAC,MAAK,IAAI;AAEhB,QAAM,YAAY,MAAM,MAAM;AAC9B,QAAM,WAAW,MAAM,MAAM,MAAK;AAClC,MAAI,OAAO;AACX,MAAI,MAAM,GAAG;AAEX,iBAAK,OACD,EAAE,YAAY,MAAM,KACpB,MAAM,iCAAiC,EAAG,YAAY,EAAE,KACpD,SAAS,GAAG;AACpB,WAAO,YAAY,MAAM;;AAE3B,WAAS,OAAO,MAAM,GAAG,CAAC;AAE1B,SAAO,QAAQ,EAAC,QAAQ,EAAC,GAAG,MAAK,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AACxE;AAEO,IAAM,mBAAiC;EAC5C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC5BP,IAAM,QACT,gBAAgB,EAAC,QAAQ,YAAY,OAAO,eAAe,aAAY,CAAC;AAErE,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACRR,IAAO,aAAP,MAAiB;EAWrB,YAAY,WAA0B,OAAuB;AAV7D,SAAA,gBAA0B,CAAC,QAAQ,MAAM;AACzC,SAAA,cAAwB,CAAA;AAIxB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAIL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;AACjB,SAAK,YAAY,OAAO,SAAS;EACnC;EAEA,cAAW;AACT,UAAM,WAAW,KAAK,cAAc,SAChC,sCACA;AACJ,UAAM,WAAW;;QAEb,QAAQ;;;;;;;;;;;;;;;;;;;;;;;;;MAyBV,oBAAK,OAAO,CAAC;;;;;;;AAOf,WAAO;EACT;;;;ACvDI,SAAU,QACZ,GAAe,SAAkB,SAAsB;AACzD,QAAM,QAAQ,QAAQ,UAAU,IAAI,EAAE,MAAM;AAE5C,QAAM,YAAY,aAAK,cAAc,EAAE,KAAK;AAE5C,QAAM,qBAAqB,EAAE,MAAM,EAAE,MAAM,SAAS,CAAC;AACrD,QAAM,QAAQ,YAAY;AAE1B,QAAM,YAAY,CAAA;AAClB,QAAM,UAAU,QACZ,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,CAAC,OAAO,kBAAkB,EAAC,EAAC,CAAC;AACvE,YAAU,KAAK,OAAO;AAEtB,QAAM,SAAS,QAAQ;AACvB,QAAM,cAAc,IAAI,WAAW,QAAQ,MAAM;AACjD,QAAM,cAAc,IAAI,WAAW,QAAQ,MAAM;AAEjD,QAAM,SAAS;IACb;MACE,QAAQ,MAAM,mBAAmB,KAAK;MACtC,OAAO,MAAM,mBAAmB,KAAK;MACrC,OAAO;;IAET;MACE,QAAQ,MAAM,mBAAmB,KAAK;MACtC,OAAO,MAAM,mBAAmB,KAAK;MACrC,OAAO;;;AAIX,QAAM,qBAAqB,UAAU,IAAM,KAAK,KAAK,KAAO,KAAK;AACjE,QAAM,cAAc,UAAU,OAAO,CAAC,IAAI;AAC1C,QAAM,cAAc;IAClB,EAAC,MAAM,WAAW,MAAM,CAAC,kBAAkB,EAAC;IAC5C,EAAC,MAAM,WAAW,MAAM,CAAC,WAAW,EAAC;;AAGvC,QAAM,WACF,QAAQ,iBAAiB,aAAa,QAAQ,WAAW,WAAW;AACxE,YAAU,KAAK,QAAQ;AACvB,QAAM,WACF,QAAQ,iBAAiB,aAAa,QAAQ,WAAW,WAAW;AACxE,YAAU,KAAK,QAAQ;AAEvB,QAAM,gBACF,QAAQ,EAAC,QAAQ,EAAC,MAAM,UAAU,MAAM,SAAQ,GAAG,QAAO,CAAC;AAC/D,YAAU,KAAK,aAAa;AAE5B,QAAM,wBACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,cAAa,GAAG,SAAS,OAAO,EAAC,OAAO,EAAE,MAAK,EAAC,CAAC;AAE1E,YAAU,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAEpD,SAAO;AACT;;;ACzDM,SAAU,IAAI,MAAiD;AAEnE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,MAAK,IAAI;AAEhB,SAAO,QAAQ,OAAO,OAAqB,OAAO;AACpD;AAEO,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACdR,IAAO,uBAAP,MAA2B;EAS/B,YAAY,YAA4C;AARxD,SAAA,cAAwB,CAAA;AAIxB,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;AASjB,WAAO;EACT;;;;AC1BK,IAAM,sBAAoC;EAC7C,YAAY;EACZ,aAAa;EACb,YAAY,CAAC,EAAC,QAAQ,QAAO,MAAK;AAChC,UAAM,EAAC,MAAK,IAAI;AAChB,UAAM,gBAAgB;AAEtB,UAAM,UAAU,IAAI,qBAAsB,MAAmB,KAAK;AAClE,UAAM,SACF,cAAc,iBAAiB,SAAS,CAAC,KAAK,GAAG,MAAM,KAAK;AAChE,WAAO;EACX;;;;ACXK,IAAM,QACT,gBAAgB,EAAC,QAAQ,YAAY,OAAO,eAAe,aAAY,CAAC;AAErE,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNP,IAAM,WAAW,iBAAiB;EACvC,QAAQ,aAAa;EACrB,eAAe;EACf,OAAO;CACR;AAEM,IAAM,iBAA+B;EAC1C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACZR,IAAO,oBAAP,MAAwB;EAW5B,YAAY,aAAuB,aAAqB,cAAc,OAAK;AAR3E,SAAA,eAAe,aAAa;AAC5B,SAAA,cAAwB,CAAC,CAAC;AAG1B,SAAA,gBAA0B,CAAA;AAC1B,SAAA,gBACI,CAAC,KAAK,GAAG,CAAC;AAGZ,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,CAAC,aAAa,GAAG,CAAC,CAAC;AAEvB,SAAK,cAAc;AACnB,SAAK,YAAY,cAAc,KAAK,WAAW;EACjD;EAEA,cAAW;AACT,UAAM,cAAc,KAAK,cACrB,4CACA;AACJ,UAAM,cACF,KAAK,cAAc,qBAAqB;AAC5C,WAAO;uCAC4B,WAAW;QAC1C,oBAAK,OAAO,CAAC;;;;yBAII,WAAW;;;;;;;EAOlC;;;;ACrCK,IAAM,mBAAiC;EAC5C,YAAY;EACZ,aAAa;EACb,YAAY;;AAGd,IAAI;AACJ,IAAI,qBAAqB,IAAG,EAAG,QAAQ,uCAAuC;AAExE,SAAU,WAAW,MAI1B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,MAAI,EAAC,OAAM,IAAI;AACf,QAAM,EAAC,YAAW,IAAI;AAEtB,MAAI,UAAU,MAAM;AAClB,UAAM,IAAI,MAAM,0DAA0D;;AAG5E,QAAM,UAAU,OAAQ,qBAAsB,eAC1C,kBAAkB;AACtB,QAAM,UAAU,OAAQ,qBAAsB,eAC1C,kBAAkB;AACtB,QAAM,WAAY,OAAQ,sBAAuB,eAC/B,kBAAkB,qBAC/B,OAAQ,oBAAqB,eAC7B,kBAAkB;AACvB,QAAM,gBACF,OAAQ,gBAAiB,eAAe,kBAAkB;AAE9D,QAAM,CAAC,OAAO,MAAM,IAAI,UACpB;IACG,OAA4B;IAC5B,OAA4B;MAE/B,CAAC,OAAO,OAAO,OAAO,MAAM;AAChC,QAAM,cAAc,CAAC,QAAQ,OAAO,WAAW;AAE/C,QAAM,cACF,IAAG,EAAG,QAAQ,gCAAgC,KAAK;AACvD,QAAM,iBAAiB,WAAW;AAClC,MAAI,iBAAiB,YAAY,gBAAgB;AAC/C,QAAI;AACJ,QAAI,aAAa;AACf,iBAAW,QAAQ,OAAO,sBACtB,EAAC,QAAQ,OAA0B,CAAC;WACnC;AACL,UAAI,gBAAgB;AAClB,cAAM,wBACF,IAAG,EAAG,QAAQ,uCAAuC;AACzD,YAAI,uBAAuB,QACvB,0BAA0B,oBAAoB;AAChD,+BAAqB;AACrB,gCAAsB,SAAS,cAAc,QAAQ,EAAE,WACnD,MAAM,EAAC,mBAAkB,CAAC;;AAEhC,4BAAoB,OAAO,QAAQ;AACnC,4BAAoB,OAAO,SAAS;AACpC,4BAAoB,UAChB,QAA+C,GAAG,GAAG,OAAO,MAAM;AACtE,iBAAS,oBAAoB;;AAG/B,YAAM,QAAQ,gBAAgB,WAC1B,gBAAgB,oBAAoB,gBAAgB;AACxD,YAAM,SAAS;AACf,YAAM,UAAU,QAAQ,eAAe,eACnC,YAAY,CAAC,GAAG,YAAY,CAAC,GAAG,QAAQ,KAAK;AACjD,cAAQ,MAAM,2BACV,EAAC,QAAQ,OAAyC,GAAG,EAAC,QAAO,GAC7D,CAAC,YAAY,CAAC,GAAG,YAAY,CAAC,CAAC,CAAC;AACpC,iBAAW;;AAGb,UAAM,OAAO,aAAK,cAAc,WAAW;AAC3C,UAAM,UAAU,aAAK,eAAe,WAAW;AAC/C,UAAM,UACF,IAAI,kBAAkB,aAAa,aAAa,WAAW;AAE/D,UAAM,cAAc;MAClB,EAAC,MAAM,UAAU,MAAM,CAAC,IAAI,EAAC;MAAG,EAAC,MAAM,UAAU,MAAM,CAAC,WAAW,EAAC;MACpE,EAAC,MAAM,UAAU,MAAM,CAAC,GAAG,OAAO,EAAC;;AAErC,UAAM,QAAQ,QAAQ,eAAe,CAAC,QAAQ,KAAK,GAAG,OAAO;AAC7D,UAAM,OAAO,QAAQ,UAAU,IAAI,MAAM,MAAM;AAC/C,SAAK,WAAW;AAEhB,UAAM,SACF,QAAQ,iBAAiB,SAAS,CAAC,KAAK,GAAG,SAAS,WAAW;AACnE,YAAQ,YAAY,MAAM,MAAM;AAChC,WAAO;;AAKT,QAAM,YAAa,OAA8C;AACjE,MAAI,aAAa;AACjB,MAAI,eAAe,QAAQ,gBAAgB,GAAG;AAC5C,iBAAa,IAAI,WAAW,OAAO,QAAQ,OAAO,SAAS,WAAW;AAEtE,UAAM,aAAa,UAAU;AAC7B,QAAI,IAAI;AACR,aAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,UAAI,IAAI,IAAI,aAAa;AACvB,mBAAW,GAAG,IAAI,UAAU,CAAC;;;;AAKnC,QAAM,SACF,QAAQ,eAAe,aAAa,SAAS,IAAI,WAAW,UAAU,CAAC;AAC3E,UAAQ,YAAY,OAAO,MAAM;AACjC,SAAO;AACT;;;ACvHM,IAAO,mBAAP,MAAuB;EAc3B,YACI,QAAkB,WAAqB,eACvC,aAA4B,YAAyB;AAVzD,SAAA,WAAW;AAEX,SAAA,gBAA0C,CAAC,KAAK,GAAG,CAAC;AAIpD,SAAA,OAAO;AAKL,SAAK,gBAAgB,CAAC,KAAK,QAAQ,UAAU;AAC7C,yBAAa,2BAA2B,QAAQ,SAAS;AACzD,yBAAa,2BAA2B,QAAQ,aAAa;AAC7D,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,QAAI,eAAe,MAAM;AACvB,2BAAa,2BAA2B,QAAQ,WAAW;AAC3D,WAAK,cAAc,KAAK,QAAQ;;AAElC,QAAI,cAAc,MAAM;AACtB,2BAAa,2BAA2B,QAAQ,UAAU;AAC1D,WAAK,cAAc,KAAK,OAAO;;AAEjC,SAAK,cAAc;AACnB,SAAK,aAAa;AAClB,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,QAAI,gBAAgB;AACpB,QAAI,KAAK,eAAe,MAAM;AAC5B,sBAAgB;;AAGlB,QAAI,eAAe;AACnB,QAAI,KAAK,cAAc,MAAM;AAC3B,qBAAe;;AAGjB,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;8BAMS,aAAa;6BACd,YAAY;;;;;;AAMrC,WAAO;EACT;;;;AC9DK,IAAM,uBAAqC;EAChD,YAAY;EACZ,aAAa;EACb,YAAY,CAAC,EAAC,QAAQ,OAAO,QAAO,MAAK;AACvC,UAAM,EAAC,GAAG,OAAO,QAAQ,MAAAC,OAAM,SAAQ,IAAI;AAC3C,UAAM,EAAC,gBAAe,IAAI;AAC1B,UAAM,gBAAgB;AACtB,UAAM,kBAAkB,CAAC,GAAaA,OAAgB,QAAkB;AACxE,QAAI,cAAc;AAClB,QAAI,UAAU,MAAM;AAClB,oBAAc,OAAO;AACrB,sBAAgB,KAAK,MAAgB;;AAEvC,QAAI,aAAa;AACjB,QAAI,SAAS,MAAM;AACjB,mBAAa,MAAM;AACnB,sBAAgB,KAAK,KAAe;;AAEtC,UAAM,UAAU,IAAI,iBAChB,EAAE,OAAOA,MAAK,OAAO,SAAS,OAAO,aAAa,UAAU;AAChE,UAAM,cAAc,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,eAAe,EAAC,CAAC;AAC/D,WAAO,cAAc,iBACjB,SAAS,iBAAiB,EAAE,OAAO,WAAW;EACpD;;;;ACvBI,SAAU,YAAY,MAI3B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,QAAQ,MAAM,uBAAsB,IAAI;AAClD,QAAM,EACJ,SACA,KACA,YACA,WACA,iBACA,YACA,eAAc,IACZ;AAEJ,QAAM,cAAc,qBAAa,wBAAwB,UAAU;AACnE,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OACF,OAAO,OAA2C,SAAS,WAAW,KACtE,iBAAiB,OAAuB,WAAW;AAEvD,SAAO,WAAW;IAChB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;GACD;AACH;AAEO,IAAM,oBAAkC;EAC7C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACtCR,SAAU,qBAAqB,MAIpC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,QAAQ,MAAM,uBAAsB,IAAI;AAClD,QAAM,EAAC,SAAS,KAAK,WAAW,iBAAiB,YAAY,eAAc,IACvE;AAEJ,MAAI,aAAa;AACjB,MAAI,cAAc,MAAM;AACtB,iBAAa,CAAC,GAAG,CAAC;;AAGpB,eAAK,OACD,qBAAa,+BAA+B,SAAS,UAAU,GAC/D,MAAM,gFACgB,OAAO,mBAAmB,UAAU,GAAG;AAEjE,QAAM,WAAW,qBAAa;IAC1B,EAAE;IACF,OAAO;IAA2C;IAAS;IAC3D;IAAK;IAAiB;;EAAoB;AAE9C,QAAM,gBAA8B,CAAC,GAAG,MAAM;AAE9C,QAAM,UAAU,QAAQ;AACxB,QAAM,4BAA4B,0BAA0B;AAE5D,MAAI,SAAS;AACX,kBAAc,KAAK,IAAI;;AAEzB,MAAI,2BAA2B;AAC7B,kBAAc,KAAK,sBAAsB;;AAG3C,QAAM,aAAa;IACjB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,UAAU,SAAS,OAAO,EAAC;;AAG7D,MAAI;AACJ,MAAI,SAAS,YAAY,KAAK,SAAS,WAAW,KAC9C,SAAS,eAAe,KACxB,SAAS,eAAe,SAAS,eACjC,SAAS,mBAAmB,KAAK,SAAS,kBAAkB,KAC5D,SAAS,aAAa,MAAM,GAAG;AACjC,cAAU,IAAI,2BACV,UAAU,SAAS,YAAY,yBAAyB;AAC5D,eAAW,KAAK,EAAC,MAAM,SAAS,MAAM,CAAC,QAAQ,YAAY,EAAC,CAAC;SACxD;AACL,cAAU,IAAI,uBACV,UAAU,SAAS,YAAY,yBAAyB;AAC5D,eAAW,KACP,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,YAAY,EAAC,GAC7C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,WAAW,EAAC,GAC5C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC,GAAG;MACpE,MAAM;MACN,MAAM,CAAC,SAAS,gBAAgB,SAAS,aAAa;KACvD;;AAEP,MAAI,eAAe,aAAa;AAC9B,eAAW,KAAK,EAAC,MAAM,WAAW,MAAM,CAAC,cAAc,EAAC,CAAC;AACzD,YAAQ,YAAY;;AAEtB,QAAM,SACF,QAAQ,iBAAiB,SAAS,eAAe,WAAW,UAAU;AAE1E,SAAO;AACT;AAEO,IAAM,6BAA2C;EACtD,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC9ER,IAAO,kBAAP,MAAsB;EAU1B,YAAY,UAAkB,OAAe;AAL7C,SAAA,gBAA0B,CAAC,KAAK,SAAS;AAEzC,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,YAAY,YAAY,QAAQ;AACrC,SAAK,WAAW;AAChB,SAAK,WAAW,6BAA6B,kBAAkB,QAAQ,CAAC;EAC1E;EAEA,cAAW;AACT,QAAI;AACJ,QAAI,KAAK,WAAW,GAAG;AACrB,qBAAe;WACV;AACL,qBAAe;;AAEjB,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;8BAMS,YAAY;;;;;;;;AAQtC,WAAO;EACT;;;;ACtCI,SAAU,SACZ,MAAsD;AACxD,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,QAAQ,QAAO,IAAI;AAE1B,QAAM,eAAe,QAAQ;AAC7B,QAAM,YAAY,aAAa,aAAa,SAAS,CAAC;AACtD,QAAM,aAAa,aAAK,cAAc,OAAO,KAAK;AAElD,QAAM,CAAC,aAAa,WAAW,WAAW,OAAO,IAC7C,qBAAa,mBAAmB,QAAQ,OAAO;AAEnD,QAAM,iBAAiB,QACnB,EAAC,QAAQ,EAAC,GAAG,QAAO,GAAG,SAAS,OAAO,EAAC,OAAO,CAAC,WAAW,SAAS,EAAC,EAAC,CAAC;AAC3E,QAAM,WAAW,QAAQ;IACvB,QAAQ,EAAC,GAAG,OAAM;IAClB;IACA,OAAO,EAAC,OAAO,CAAE,aAAK,cAAc,OAAO,KAAK,IAAI,WAAY,SAAS,EAAC;GAC3E;AACD,MAAI,QAAQ,mBAAmB,CAAC,QAAQ,OAAO,CAAC,KAC5C,OAAO,UAAU,UAAU;AAC7B,UAAM,cAAc,QAAQ,SAAS,QAAQ,MAAM;AACnD,UAAM,YAAY,QAAQ,WAA4B,MAAM;AAC5D,UAAM,WAAW,gBACb,aAAa,WAAW,OAAO,OAAO,WAAW,WAAW,WAC5D,SAAS,OAAO,OAAO,UAAU;AAErC,WAAO,QAAQ,eAAe,aAAa,OAAO,OAAO,SAAS,MAAM;;AAE1E,QAAM,UAAU,IAAI,gBAAgB,WAAW,CAAC,WAAW,SAAS,CAAC;AACrE,QAAM,cACF,CAAC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,EAAC,GAAG,EAAC,MAAM,SAAS,MAAM,QAAO,CAAC;AACvE,QAAM,MAAM,QAAQ,iBAChB,SAAS,CAAC,UAAU,cAAc,GAAG,SAAS,OAAO,WAAW;AAEpE,QAAM,WACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,IAAG,GAAG,SAAS,OAAO,EAAC,OAAO,YAAW,EAAC,CAAC;AAEpE,UAAQ,YAAY,eAAe,MAAM;AACzC,UAAQ,YAAY,SAAS,MAAM;AACnC,UAAQ,YAAY,IAAI,MAAM;AAE9B,SAAO;AACT;AAEO,IAAM,iBAA+B;EAC1C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACrDR,IAAO,gBAAP,MAAoB;EAUxB,YAAY,QAAkB,aAAqB;AALnD,SAAA,gBAA0B,CAAC,KAAK,SAAS;AACzC,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAEnD,SAAA,OAAO;AAGL,SAAK,cAAc,OAAO,MAAK;AAC/B,SAAK,SAAS;AACd,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,eAAe,gBAAgB,KAAK,MAAM;AAChD,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;oDAK+B,YAAY;;;;AAI5D,WAAO;EACT;;AAIF,SAAS,gBAAgB,QAAgB;AACvC,QAAM,gBAAgB,CAAC,WAAW,WAAW,WAAW,SAAS;AACjE,QAAM,eAAe,CAAA;AACrB,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,QAAI,MAAM,GAAG;AACX,mBAAa,KAAK,QAAQ;WACrB;AACL,mBAAa,KAAK,GAAG,cAAc,CAAC,CAAC,EAAE;;;AAG3C,SAAO,aAAa,KAAI;AAC1B;;;AC3CM,SAAU,SACZ,MAC0E;AAE5E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,QAAO,IAAI;AACrB,QAAM,EAAC,MAAM,UAAS,IAAI;AAI1B,QAAM,aAAa,aAAK,eAAe,MAAM,EAAE,KAAK,EAAE,CAAC;AAEvD,QAAM,YAAY,qBAAa,aAAa,yBACxC,GAAG,SAAS,YAAY,SAAS;AAErC,QAAM,cAAc,aAAK,cAAc,QAAQ,KAAK;AAEpD,QAAM,YAAY,CAAA;AAElB,QAAM,WAAW,QAAQ;IACvB,QAAQ,EAAC,EAAC;IACV;IACA,OAAO;MACL,OAAO;QACL,UAAU;QAAW,UAAU;QAAW,UAAU;QACpD,UAAU;;;GAGf;AAED,QAAM,eAAe,QAAQ;IAC3B,QAAQ,EAAC,GAAG,QAAO;IACnB;IACA,OAAO,EAAC,OAAO,CAAC,UAAU,WAAW,cAAc,UAAU,SAAS,EAAC;GACxE;AAED,YAAU,KAAK,QAAQ;AACvB,YAAU,KAAK,YAAY;AAE3B,QAAM,qBAAqB;IACzB,UAAU;IAAW,UAAU;IAAW,cAAc,UAAU;IAClE,UAAU;;AAGZ,MAAI,QAAQ,mBAAmB,CAAC,GAAG,OAAO,CAAC,GAAG;AAC5C,UAAM,oBAAoB,QAAQ,UAAU,IAAI,aAAa,MAAM;AACnE,UAAM,gBAAgB,kBAAkB;AACxC,UAAM,gBACF,OAAO,aAAa,OAAO,aAAa,OAAO,aAAa;AAEhE,UAAM,qBAAqB,QAAQ,UAAU,IAAI,SAAS,MAAM;AAChE,UAAM,UAAU,mBAAmB;AACnC,UAAM,UACF,OAAO,SAAS,OAAO,SAAS,OAAO,OAAO;AAClD,UAAM,SAAS,gBAAgB,SAAS,eAAe,kBAAkB;AAEzE,cAAU,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAEpD,WAAO,QAAQ,eACX,UAAU,aAAa,OAAO,OAAO,OAAO,MAAoB;;AAGtE,QAAM,UAAU,IAAI,cAAc,SAAS,OAAO,kBAAkB;AACpE,QAAM,MAAM,QAAQ,iBAChB,SAAS,CAAC,UAAU,YAAY,GAAG,SAAS,KAAK;AACrD,YAAU,KAAK,GAAG;AAElB,QAAM,WAAW,QACb,EAAC,QAAQ,EAAC,GAAG,IAAG,GAAG,SAAS,OAAO,EAAC,OAAO,UAAU,YAAW,EAAC,CAAC;AACtE,YAAU,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AACpD,SAAO;AACT;AAEO,IAAM,iBAA+B;EAC1C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC9EP,IAAM,UAAU,iBAAiB;EACtC,QAAQ,aAAa;EACrB,eAAe;EACf,OAAO;CACR;AAEM,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACTP,IAAM,eAAe,iBAAiB;EAC3C,QAAQ,aAAa;EACrB,OAAO;EACP,eAAe;CAChB;AAEM,IAAM,qBAAmC;EAC9C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACTR,SAAU,KAAK,MAAkD;AAErE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,MAAK,IAAI;AAEhB,SAAO,QAAQ,OAAO,MAAoB,OAAO;AACnD;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACXP,IAAM,WACT,gBAAgB,EAAC,QAAQ,YAAY,WAAW,OAAO,OAAM,CAAC;AAE3D,IAAM,iBAA+B;EAC1C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNP,IAAM,QACT,gBAAgB,EAAC,QAAQ,YAAY,QAAQ,OAAO,OAAM,CAAC;AAExD,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACRP,IAAM,QACT,gBAAgB,EAAC,QAAQ,YAAY,QAAQ,OAAO,OAAM,CAAC;AAExD,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACJR,SAAU,UAAU,MAIzB;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,MAAK,IAAI;AAChB,QAAM,cAAc,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,KAAK,EAAC,CAAC;AACrD,QAAM,UACF,IAAI,eAAe,EAAE,OAAO,YAAY,WAAW,cAAc;AACrE,SAAO,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,WAAW,WAAW;AACtE;AAEO,IAAM,kBAAgC;EAC3C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACjBP,IAAM,OAAO,iBAChB,EAAC,QAAQ,aAAa,MAAM,OAAO,QAAQ,eAAe,YAAO,CAAC;AAE/D,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNP,IAAM,YAAY,iBAAiB;EACxC,QAAQ,aAAa;EACrB,OAAO;EACP,eAAe;CAChB;AAEM,IAAM,kBAAgC;EAC3C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACZR,IAAO,kBAAP,MAAsB;EAU1B,YAAY,OAAa;AATzB,SAAA,gBAA0B,CAAA;AAC1B,SAAA,cAAwB,CAAA;AAIxB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,CAAC,KAAK;AACzB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;AAMjB,WAAO;EACT;;;;AC1BI,SAAU,SAAS,MAAoD;AAE3E,QAAM,EAAC,SAAS,MAAK,IAAI;AACzB,QAAM,EAAC,OAAO,MAAM,IAAG,IAAI;AAC3B,QAAMC,SAAQ,OAAO,UAAU,MAAM;AAErC,QAAM,UAAU,IAAI,gBAAgB,GAAG;AACvC,QAAM,cACF,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,KAAK,EAAC,GAAG,EAAC,MAAM,WAAW,MAAM,CAACA,KAAI,EAAC,CAAC;AACtE,SAAO,QAAQ,iBAAiB,SAAS,CAAA,GAAI,WAAW,WAAW;AACrE;AAEO,IAAM,iBAA+B;EAC1C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACfP,IAAM,MACT,gBAAgB,EAAC,QAAQ,YAAY,KAAK,eAAe,WAAU,CAAC;AAEjE,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,QAAQ,gBAAgB,EAAC,QAAQ,YAAY,MAAK,CAAC;AAEzD,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNP,IAAM,aACT,iBAAiB,EAAC,QAAQ,aAAa,aAAa,OAAO,OAAM,CAAC;AAE/D,IAAM,mBAAiC;EAC5C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,aAAa,gBAAgB,EAAC,QAAQ,YAAY,YAAW,CAAC;AAEpE,IAAM,mBAAiC;EAC5C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNP,IAAM,YAAY,iBAAiB,EAAC,QAAQ,aAAa,WAAU,CAAC;AAEpE,IAAM,kBAAgC;EAC3C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNd,IAAM,qBAAqB;;;;;;;;;;;AAYrB,IAAO,aAAP,MAAiB;EAUrB,YAAY,QAAgB;AAT5B,SAAA,cAAwB,CAAA;AAIxB,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;MACf,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;UAiBT,kBAAkB;;;;;;AAMxB,WAAO;EACT;;AAGI,IAAO,mBAAP,MAAuB;EAW3B,YAAY,QAAkB,QAAc;AAV5C,SAAA,cAAwB,CAAA;AAIxB,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,KAAK,GAAG,CAAC;AACpD,SAAA,iBAAiB;AAIf,iBAAK,OACD,UAAU,KAAK,gBACf,MAAM,wCACF,KAAK,cAAc,uBAAuB,MAAM,EAAE;AAE1D,SAAK,cAAc;AAInB,SAAK,uBAAuB,KAAK,cAAc,CAAC,IAAI,IAAI,KAAK;AAC7D,SAAK,iBAAiB,EAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,EAAC;AAChD,SAAK,WAAW,gBAAgB,KAAK,gBAAgB,KAAK,aAAa;MACrE,KAAK;MAAsB,KAAK,cAAc,CAAC;MAAG,KAAK,cAAc,CAAC;KACvE;AACD,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;wCACmB,KAAK,cAAc,CAAC,CAAC;mCAC1B,KAAK,oBAAoB;6BAC/B,KAAK,cAAc;;MAE1C,oBAAI,CAAE;;;;;;;;;;;;;;;;;;;;;;;UAuBF,kBAAkB;;;;;AAKxB,WAAO;EACT;;;;AC1HI,SAAU,IACZ,MAAkE;AAEpE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,aAAa,MAAM,OAAO,KAAI,IAAI;AAOzC,MAAI;AACJ,MAAI,cAAc,IAAI;AACpB,cAAU,IAAI,WAAW,EAAE,KAAK;SAC3B;AACL,cAAU,IAAI,iBAAiB,EAAE,OAAO,WAAW;;AAErD,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,WAAW,EAAC;IAAG,EAAC,MAAM,WAAW,MAAM,CAAC,IAAI,EAAC;IACpE,EAAC,MAAM,WAAW,MAAM,CAAC,KAAK,EAAC;IAAG,EAAC,MAAM,WAAW,MAAM,CAAC,IAAI,EAAC;;AAElE,QAAM,MAAM,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,OAAO,WAAW;AAEvE,SAAO;AACT;AAEO,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AChCR,IAAO,iBAAP,MAAqB;EAUzB,YAAY,YAAoB;AAThC,SAAA,cAAwB,CAAA;AAIxB,SAAA,gBAAgB,CAAC,cAAc,eAAe,IAAI;AAClD,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;MACf,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkDf,WAAO;EACT;;;;ACrEI,SAAU,QACZ,MAA0E;AAE5E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,GAAG,GAAE,IAAI;AACnB,QAAM,EAAC,aAAa,MAAM,OAAO,KAAI,IAAI;AAEzC,QAAM,UAAU,IAAI,eAAe,EAAE,KAAK;AAC1C,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,WAAW,EAAC;IAAG,EAAC,MAAM,WAAW,MAAM,CAAC,IAAI,EAAC;IACpE,EAAC,MAAM,WAAW,MAAM,CAAC,KAAK,EAAC;IAAG,EAAC,MAAM,WAAW,MAAM,CAAC,IAAI,EAAC;;AAElE,QAAM,MACF,QAAQ,iBAAiB,SAAS,CAAC,GAAG,GAAG,EAAE,GAAG,EAAE,OAAO,WAAW;AAEtE,SAAO;AACT;AAEO,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACpBP,IAAM,UAAU,iBAAiB;EACtC,QAAQ,aAAa;EACrB,eAAe;CAChB;AAEM,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACVR,SAAU,QACZ,MAA0E;AAE5E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,YAAY,SAAS,KAAK,gBAAe,IAAI;AACpD,QAAM,YAAY;AAClB,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OAA2C,YAAY,SACzD,WAAW,KAAK,eAAe;AAEnC,SAAO,SAAS,GAAG,UAAU,OAAO,OAAO;AAC7C;AAEO,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACjBR,SAAU,UAAU,MAIzB;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,YAAY,SAAS,KAAK,YAAY,gBAAe,IAAI;AAChE,QAAM,YAAsC,CAAC,GAAG,GAAG,CAAC;AAEpD,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OAAmD,YAAY,SACjE,WAAW,KAAK,iBAAiB,UAAU;AAC/C,QAAM,iBAAiB,IAAI,cAAc,UAAU,KAAK;AACxD,QAAM,aAAa;IACjB;MACE,MAAM;MACN,MAAM,CAAC,SAAS,aAAa,SAAS,cAAc,SAAS,WAAW;;IAE1E;MACE,MAAM;MACN,MACI,CAAC,SAAS,QAAQ,OAAO,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI;;IAE1E;MACE,MAAM;MACN,MAAM,CAAC,SAAS,SAAS,SAAS,UAAU,SAAS,OAAO;;IAE9D;MACE,MAAM;MACN,MAAM;QACJ,SAAS;QAAsB,SAAS;QACxC,SAAS;;;;AAIf,SAAO,QAAQ,iBAAiB,gBAAgB,CAAC,CAAC,GAAG,EAAE,OAAO,UAAU;AAC1E;AAEO,IAAM,kBAAgC;EAC3C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC1CR,IAAO,2BAAP,MAA+B;EAYnC,YAAY,UAAiC;AAP7C,SAAA,gBAAgB,CAAC,MAAM,QAAQ;AAC/B,SAAA,WACI;;AAEJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAE5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AAEzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4CjB,WAAO;EACT;;AAGI,IAAO,2BAAP,MAA+B;EAWnC,YAAY,UAAiC;AAN7C,SAAA,gBAAgB,CAAC,MAAM,QAAQ;AAC/B,SAAA,WAAW;;AAEX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;AAE5B,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AAEzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAyDjB,WAAO;EACT;;;;ACzJI,SAAU,cAAc,MAI7B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,IAAI,MAAK,IAAI;AACpB,QAAM,IAAI;AACV,QAAM,EAAC,YAAY,SAAS,KAAK,gBAAe,IAAI;AACpD,QAAM,YAAsC,CAAC,GAAG,GAAG,CAAC;AAEpD,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OAAmD,YAAY,SACjE,WAAW,KAAK,eAAe;AAEnC,QAAM,4BACF,IAAI;IAAc;IAAU;IAAO;;EAAwB;AAC/D,MAAI,cAAc;IAChB;MACE,MAAM;MACN,MAAM,CAAC,SAAS,aAAa,SAAS,cAAc,SAAS,WAAW;;IAE1E;MACE,MAAM;MACN,MACI,CAAC,SAAS,QAAQ,OAAO,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI;;IAE1E;MACE,MAAM;MACN,MAAM,CAAC,SAAS,SAAS,SAAS,UAAU,SAAS,OAAO;;IAE9D;MACE,MAAM;MACN,MAAM;QACJ,SAAS;QAAsB,SAAS;QACxC,SAAS;;;;AAIf,QAAM,qBAAqB,QAAQ,iBAC/B,2BAA2B,CAAC,CAAC,GAAG,SAAS,WAAW;AAExD,QAAM,2BAA2B,IAAI,yBAAyB,QAAQ;AACtE,gBAAc;IACZ;MACE,MAAM;MACN,MAAM,CAAC,SAAS,aAAa,SAAS,cAAc,SAAS,WAAW;;IAE1E;MACE,MAAM;MACN,MAAM;QACJ,SAAS,uBAAuB,IAAI,SAAS,QAAQ;QACrD,SAAS,wBAAwB,IAAI,SAAS,QAAQ;QACtD,SAAS,uBAAuB,IAAI,SAAS,QAAQ;;;IAGzD;MACE,MAAM;MACN,MAAM;QACJ,SAAS;QAAsB,SAAS;QACxC,SAAS;;;IAGb,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;IACzC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;;AAE3C,QAAM,SAAS,QAAQ,iBACnB,0BAA0B,CAAC,IAAI,kBAAkB,GAAG,EAAE,OAAO,WAAW;AAC5E,UAAQ,YAAY,mBAAmB,MAAM;AAE7C,SAAO;AACT;AAEO,IAAM,sBAAoC;EAC/C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC5ER,SAAU,YAAY,MAI3B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,IAAI,OAAO,OAAM,IAAI;AAC5B,QAAM,IAAI;AACV,mBAAiB,CAAC,OAAO,MAAM,GAAG,aAAa;AAC/C,QAAM,EAAC,YAAY,SAAS,KAAK,gBAAe,IAAI;AAEpD,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OAA2C,YAAY,SACzD,GAAmB,KAAK,eAAe;AAE3C,QAAM,0BAA0B,IAAI,cAAc,UAAU,OAAO,IAAI;AACvE,MAAI,cAAc;IAChB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,gBAAgB,SAAS,aAAa,EAAC;IACvE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,UAAU,SAAS,OAAO,EAAC;IAAG;MAC5D,MAAM;MACN,MAAM,CAAC,SAAS,uBAAuB,SAAS,oBAAoB;;;AAGxE,QAAM,mBAAmB,QAAQ,iBAC7B,yBAAyB,CAAC,CAAC,GAAG,SAAS,WAAW;AAEtD,QAAM,yBAAyB,IAAI,yBAAyB,QAAQ;AACpE,gBAAc;IACZ,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IAAG;MACpE,MAAM;MACN,MAAM;QACJ,SAAS,wBAAwB,IAAI,SAAS,QAAQ;QACtD,SAAS,uBAAuB,IAAI,SAAS,QAAQ;;;IAGzD,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,gBAAgB,SAAS,aAAa,EAAC;IAAG;MACxE,MAAM;MACN,MAAM,CAAC,SAAS,uBAAuB,SAAS,oBAAoB;;IAEtE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,SAAS,EAAC;IAC1C,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,EAAC;;AAE3C,QAAM,SAAS,QAAQ,iBACnB,wBAAwB,CAAC,IAAI,gBAAgB,GAAG,EAAE,OAAO,WAAW;AACxE,UAAQ,YAAY,iBAAiB,MAAM;AAE3C,SAAO;AACT;AAEO,IAAM,oBAAkC;EAC7C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACvDR,SAAU,kBAAkB,MAIjC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,YAAY,SAAS,KAAK,oBAAmB,IAAI;AACxD,QAAM,EAAC,EAAC,IAAI;AAEZ,eAAK,OACD,EAAE,MAAM,WAAW,GACnB,MAAM,uDACF,EAAE,MAAM,MAAM,GAAG;AACzB,QAAM,YAA8B,CAAC,GAAG,CAAC;AACzC,eAAK,OACD,qBAAa,+BAA+B,SAAS,SAAS,GAC9D,MAAM,wEACa,OAAO,mBAAmB,SAAS,GAAG;AAE7D,QAAM,WAAW,qBAAa,kBAC1B,EAAE,OAA2C,YAAY,SACzD,WAAW,GAAG;AAElB,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,cAAc,SAAS,WAAW,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,QAAQ,KAAK,SAAS,QAAQ,IAAI,EAAC;IACnE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,gBAAgB,SAAS,aAAa,EAAC;IACvE,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,UAAU,SAAS,OAAO,EAAC;IAAG;MAC5D,MAAM;MACN,MAAM,CAAC,SAAS,uBAAuB,SAAS,oBAAoB;;;AAGxE,MAAI,UAAU,IAAI,cAAc,UAAU,OAAO,KAAK;AACtD,QAAM,aACF,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,OAAO,WAAW;AAE/D,YAAU,IAAI,cAAc,UAAU,OAAO,MAAM,MAAM,mBAAmB;AAC5E,QAAM,cACF,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,SAAS,WAAW;AAC/D,SAAO,CAAC,YAAY,WAAW;AACjC;AAEO,IAAM,0BAAwC;EACnD,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC9CR,SAAU,IACZ,MAAkE;AAEpE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,MAAM,SAAQ,IAAI;AAEzB,SAAO,OAAO,GAAG,MAAM,UAAU,OAAO,OAAO;AACjD;AAEO,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACZP,IAAM,UAAU,iBAAiB;EACtC,QAAQ,aAAa;EACrB,eAAe;CAChB;AAEM,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACXR,IAAO,mBAAP,MAAuB;EAY3B,YACI,QAAkB,UAClB,MAA2B;AAX/B,SAAA,WAAW;AAGX,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAGnD,SAAA,OAAO;AAKL,SAAK,cAAc,SAAS;MACxB,CAAC,GAAG,MAAM,EAAE,CAAC,IAAoB,OAAO,CAAC,IAAI,EAAE,CAAC;;IAAgB;AACpE,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,SAAS;AACd,aAAS,IAAI,CAAC,GAAG,MAAK;AACpB,WAAK,YAAY,OAAO,CAAC;IAC3B,CAAC;AACD,SAAK,SAAS,SAAS,YAAY,IAAI;AACvC,SAAK,YAAY,aAAa,IAAI;EACpC;EAEA,cAAW;AACT,UAAM,OAAO,KAAK,OAAO;AAEzB,UAAM,QAAQ,KAAK,OAAO,IAAI,CAAC,GAAG,MAAM,eAAe,CAAC,KAAK,EAAE,KAAK,GAAG;AACvE,UAAM,MAAM,KAAK,OACA,IACG,CAAC,GAAG,MAAM,eAAe,CAAC,wBACtB,OAAO,IAAI,IAAI,CAAC,MAAM,EAAE,EAAE,EACjC,KAAK,GAAG;AAEzB,UAAM,cAAc,SAAS,IAAI,UAAU;AAC3C,UAAM,YAAY,SAAS,IAAI,QAAQ;AACvC,UAAM,aAAa,SAAS,IAAI,SAAS;AACzC,UAAM,QAAQ,kBAAkB,IAAI;AACpC,UAAM,iBAAiB,OAAO,IAC1B,CAAC,aAAa,aAAa,aAAa,WAAW,EAAE,MAAM,GAAG,IAAI,IAClE;AAEJ,WAAO;QACH,oBAAK,OAAO,CAAC;;wBAEG,KAAK,IAAI,KAAK;sBAChB,KAAK,IAAI,GAAG;;gCAEF,IAAI;kBAClB,UAAU,MAAM,WAAW;gBAC7B,UAAU,MAAM,WAAW,UAAU,UAAU,MACvD,KAAK,MAAM;wBACK,UAAU,OAAO,SAAS;gBAClC,UAAU,OAAO,SAAS,eAAe,UAAU,MAC3D,KAAK,MAAM;;;;yCAIsB,cAAc;;;;EAIrD;;;;AChEK,IAAM,kBAAgC;EAC3C,YAAY;EACZ,aAAa;EACb,YAAY,CAAC,EAAC,QAAQ,OAAO,QAAO,MAAK;AACvC,UAAM,EAAC,EAAC,IAAI;AACZ,UAAM,EAAC,UAAU,KAAI,IAAI;AACzB,UAAM,gBAAgB;AAEtB,UAAM,cAAc,SAAS,IAAI,OAAI;AACnC,aAAO,EAAC,MAAM,SAAS,MAAM,CAAC,EAAE,CAAC,GAAG,EAAE,CAAC,CAAC,EAAC;IAC3C,CAAC;AACD,UAAM,UAAU,IAAI,iBAAiB,EAAE,OAAO,UAAU,IAAI;AAC5D,UAAM,SACF,cAAc,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,OAAO,WAAW;AAErE,WAAO;EACT;;;;ACjBK,IAAM,MAAM,iBAAiB,EAAC,QAAQ,aAAa,IAAG,CAAC;AAEvD,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACPR,IAAO,qBAAP,MAAyB;EAU7B,YAAY,WAAmB,YAAkB;AATjD,SAAA,gBAA0B,CAAC,OAAO;AAClC,SAAA,cAAwB,CAAA;AAIxB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,CAAC,WAAW,UAAU;AACzC,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;;;;;;;;;;;MAWf,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;AAuBf,WAAO;EACT;;;;ACvDI,IAAO,iBAAP,MAAqB;EAQzB,YAAY,aAAqB;AAPjC,SAAA,gBAAgB,CAAC,QAAQ;AAQvB,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,CAAC,KAAK,YAAY,CAAC,GAAG,GAAG,CAAC;AAC1C,QAAI,KAAK,YAAY,CAAC,KAAK,MAAM;AAC/B,WAAK,gBAAgB,CAAC,KAAK,GAAG,CAAC;WAC1B;AACL,WAAK,gBAAgB,CAAC,IAAI,GAAG,CAAC;;AAEhC,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;sCACiB,KAAK,cAAc,CAAC,CAAC;;;wBAGnC,KAAK,cAAc,CAAC,CAAC;MACvC,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAuDf,WAAO;EACT;;;;AC9EI,SAAU,QACZ,MAA0E;AAE5E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,OAAM,IAAI;AACjB,QAAM,EAAC,IAAG,IAAI;AAEd,QAAM,iBAAiB,QAAQ;IAC7B,QAAQ,EAAC,GAAG,OAAM;IAClB;IACA,OAAO;MACL,OAAO;QACL,aAAK,cAAc,OAAO,KAAK,IAAI,OAAO,MAAM,GAAG;QAAG,OAAO,MAAM,GAAG;;;GAG3E;AACD,QAAM,UAAU,IAAI,eAAe,eAAe,KAAK;AACvD,QAAM,MAAM,QAAQ,iBAAiB,SAAS,CAAC,cAAc,GAAG,OAAO,KAAK;AAC5E,QAAM,cACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,IAAG,GAAG,SAAS,OAAO,EAAC,OAAO,OAAO,MAAK,EAAC,CAAC;AACrE,UAAQ,YAAY,eAAe,MAAM;AACzC,UAAQ,YAAY,IAAI,MAAM;AAC9B,SAAO;AACT;AAEO,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC5BR,SAAU,YAAY,MAI3B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,OAAM,IAAI;AACjB,QAAM,EAAC,YAAY,MAAM,WAAU,IAAI;AAEvC,QAAM,QAAQ,aACV,SACA,QACI,EAAC,QAAQ,EAAC,OAAM,GAAG,SAAS,OAAO,EAAC,KAAK,OAAO,MAAM,SAAS,EAAC,EAAC,CAAC;AAC1E,QAAM,YAAY,MAAM,MAAM,CAAC;AAC/B,QAAM,cAAc,MAAM,MAAM,CAAC;AACjC,QAAM,UAAU,IAAI,mBAAmB,WAAW,UAAU;AAC5D,QAAM,cACF,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,IAAI,EAAC,GAAG,EAAC,MAAM,SAAS,MAAM,CAAC,WAAW,EAAC,CAAC;AAC1E,QAAM,MAAM,QAAQ,iBAAiB,SAAS,CAAC,KAAK,GAAG,SAAS,WAAW;AAC3E,MAAI,CAAC,YAAY;AACf,YAAQ,YAAY,MAAM,MAAM;;AAElC,SAAO;AACT;AAEO,IAAM,oBAAkC;EAC7C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACzBR,SAAU,IAAI,MAAiD;AAEnE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,EAAC,IAAI;AAEZ,MAAI,QAAQ,mBAAmB,CAAC,CAAC,CAAC,GAAG;AACnC,UAAM,QAAQ,QAAQ,UAAU,IAAI,EAAE,MAAM;AAC5C,UAAM,CAAC,WAAW,QAAQ,IACtB,WAAW,MAAM,QAAsB,EAAE,OAAO,EAAE,KAAK;AAC3D,WAAO,QAAQ,eAAe,UAAU,EAAE,OAAO,SAAS;;AAG5D,QAAM,UAAU,IAAI,eAAe,EAAE,OAAO,YAAY,GAAG;AAE3D,SAAO,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,KAAK;AACvD;AAEO,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC3BR,SAAU,oBAAoB,MAInC;AACC,UAAQ,KACJ,gGAC0C;AAE9C,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,OAAO,OAAM,IAAI;AACxB,QAAM,EAAC,eAAe,cAAc,eAAc,IAAI;AAEtD,QAAM,YAAY,QAAQ,SAAS,MAAM,MAAM;AAC/C,QAAM,aAAa,QAAQ,SAAS,OAAO,MAAM;AAEjD,QAAM,EAAC,gBAAe,IAAI,qBAAa,wBACnC,WAAW,YAAY,eAAe,cAAc,cAAc;AAEtE,SAAO,QAAQ,eACX,CAAC,gBAAgB,MAAM,GAAG,SAAS,IAAI,WAAW,eAAe,CAAC;AACxE;AAEO,IAAM,4BAA0C;EACrD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACzBR,SAAU,oBAAoB,MAInC;AACC,UAAQ,KACJ,gGAC0C;AAE9C,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,OAAO,OAAM,IAAI;AACxB,QAAM,EAAC,eAAe,cAAc,gBAAgB,aAAY,IAAI;AAEpE,QAAM,YAAY,QAAQ,SAAS,MAAM,MAAM;AAC/C,QAAM,aAAa,QAAQ,SAAS,OAAO,MAAM;AAEjD,QAAM,mBAAmB;AACzB,QAAM,kBAAkB;AACxB,QAAM,oBAAoB;AAC1B,QAAM,kBAAkB;AAExB,QAAM,EAAC,iBAAiB,eAAc,IAClC,qBAAa,wBACT,WAAW,YAAY,kBAAkB,iBACzC,mBAAmB,eAAe;AAE1C,SAAO;IACL,QAAQ,eACJ,CAAC,gBAAgB,MAAM,GAAG,SAAS,IAAI,WAAW,eAAe,CAAC;IACtE,QAAQ,eACJ,CAAC,eAAe,MAAM,GAAG,WAAW,IAAI,aAAa,cAAc,CAAC;;AAE5E;AAEO,IAAM,4BAA0C;EACrD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACtCR,IAAO,gBAAP,MAAoB;EAUxB,YAAY,YAAoB,OAAa;AAL7C,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc,CAAC,YAAY,KAAK;AACrC,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;AASjB,WAAO;EACT;;;;AC3BI,SAAU,OACZ,MAAwE;AAE1E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,QAAO,IAAI;AAClB,QAAM,EAAC,OAAO,OAAO,SAAS,SAAQ,IAAI;AAE1C,QAAM,cAAc,aAAK,cAAc,QAAQ,KAAK;AACpD,QAAM,UAAU,IAAI,cAAc,aAAa,KAAK;AACpD,QAAM,WACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,QAAO,GAAG,SAAS,OAAO,EAAC,OAAO,CAAC,WAAW,EAAC,EAAC,CAAC;AAE1E,QAAM,cACF,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,OAAO,EAAC,GAAG,EAAC,MAAM,WAAW,MAAM,CAAC,QAAQ,EAAC,CAAC;AAC5E,QAAM,SACF,QAAQ,iBAAiB,SAAS,CAAC,QAAQ,GAAG,OAAO,WAAW;AACpE,UAAQ,YAAY,SAAS,MAAM;AAEnC,QAAM,WAAW,CAAC,GAAG,QAAQ,OAAO,KAAK;AACzC,QAAM,MAAM,QAAQ,EAAC,QAAQ,EAAC,GAAG,OAAM,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AAC5E,UAAQ,YAAY,OAAO,MAAM;AAEjC,SAAO;AACT;AAEO,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACzBR,SAAU,UACZ,MAAuD;AACzD,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,EAAC,IAAI;AACZ,MAAI,EAAE,UAAU,aAAa;AAC3B,UAAM,WAAW,KAAK,EAAC,QAAQ,EAAC,OAAO,EAAC,GAAG,QAAO,CAAC;AACnD,UAAM,IAAI,UAAU,EAAC,QAAQ,EAAC,GAAG,SAAQ,GAAG,QAAO,CAAC;AACpD,UAAM,WAAW,KAAK,EAAC,QAAQ,EAAC,OAAO,EAAC,GAAG,QAAO,CAAC;AACnD,UAAM,IAAI,UAAU,EAAC,QAAQ,EAAC,GAAG,SAAQ,GAAG,QAAO,CAAC;AAEpD,UAAM,SAAS,QAAQ,EAAC,QAAQ,EAAC,MAAM,GAAG,MAAM,EAAC,GAAG,QAAO,CAAC;AAE5D,YAAQ,YAAY,SAAS,MAAM;AACnC,YAAQ,YAAY,EAAE,MAAM;AAC5B,YAAQ,YAAY,SAAS,MAAM;AACnC,YAAQ,YAAY,EAAE,MAAM;AAE5B,WAAO;SACF;AACL,WAAO,KAAK;MACV,OAAO;QACL,OAAO,EAAE;QACT,OAAO,EAAE;QACT,OAAO,EAAE,UAAU,WAAW,KAAK;;MAErC;KACD;;AAEL;AAEO,IAAM,kBAAgC;EAC3C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AChCR,SAAU,SACZ,MAAsD;AACxD,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,EAAC,IAAI;AAEZ,MAAI,EAAE,UAAU,UAAU;AACxB,UAAM,IAAI,MAAM,8CAA8C;aACrD,EAAE,UAAU,aAAa;AAClC,UAAM,WAAW,KAAK,EAAC,QAAQ,EAAC,OAAO,EAAC,GAAG,QAAO,CAAC;AACnD,UAAM,IAAI,SAAS,EAAC,QAAQ,EAAC,GAAG,SAAQ,GAAG,QAAO,CAAC;AACnD,UAAM,WAAW,KAAK,EAAC,QAAQ,EAAC,OAAO,EAAC,GAAG,QAAO,CAAC;AACnD,UAAM,IAAI,UAAU,EAAC,QAAQ,EAAC,GAAG,SAAQ,GAAG,QAAO,CAAC;AAEpD,UAAM,SAAS,QAAQ,EAAC,QAAQ,EAAC,MAAM,GAAG,MAAM,EAAC,GAAG,QAAO,CAAC;AAE5D,YAAQ,YAAY,SAAS,MAAM;AACnC,YAAQ,YAAY,EAAE,MAAM;AAC5B,YAAQ,YAAY,SAAS,MAAM;AACnC,YAAQ,YAAY,EAAE,MAAM;AAE5B,WAAO;SACF;AACL,WAAO,KAAK,EAAC,OAAO,EAAC,OAAO,EAAE,OAAO,OAAO,EAAE,OAAO,OAAO,EAAC,GAAG,QAAO,CAAC;;AAE5E;AAEO,IAAM,iBAA+B;EAC1C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACjCR,SAAU,KACZ,MAAoE;AAEtE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,KAAI,IAAI;AAEf,MAAI,OAAO,WAAW,GAAG;AACvB,WAAO,WACH,EAAC,QAAQ,EAAC,OAAO,OAAO,CAAC,EAAC,GAAG,SAAS,OAAO,EAAC,KAAK,KAAI,EAAC,CAAC;;AAG/D,QAAM,QAAQ,OAAO,CAAC,EAAE;AACxB,QAAM,QAAQ,OAAO,CAAC,EAAE;AAExB,SAAO,QAAQ,OAAI;AACjB,iBAAK,kBACD,OAAO,EAAE,OACT,uDAAuD;AAC3D,iBAAK,OACD,UAAU,EAAE,OACZ,MAAM,uDAAuD;EACnE,CAAC;AAED,QAAM,0BAAwC,CAAA;AAC9C,QAAM,kBAAkB,OAAO,IAAI,OAAI;AACrC,UAAM,YACF,WAAW,EAAC,QAAQ,EAAC,OAAO,EAAC,GAAG,SAAS,OAAO,EAAC,KAAK,KAAI,EAAC,CAAC;AAChE,4BAAwB,KAAK,SAAS;AACtC,WAAO;EACT,CAAC;AAED,QAAM,SAAS,OAAO,EAAC,QAAQ,iBAAiB,SAAS,OAAO,EAAC,KAAI,EAAC,CAAC;AAEvE,0BAAwB,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAElE,SAAO;AACT;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC5CR,SAAU,UAAU,OAAiB,WAAW,OAAK;AACzD,QAAM,OAAO,MAAM;AACnB,QAAM,OAAO,kBAAkB,IAAI;AACnC,QAAM,QAAQ,MAAM,IAAI,CAAC,GAAG,MAAM,eAAe,CAAC,KAAK,EAAE,KAAK,GAAG;AACjE,QAAM,MAAM,MACK,IACG,CAAC,GAAG,MAAM,eAAe,CAAC,wBACtB,OAAO,IAAI,IAAI,CAAC,MAAM,EAAE,EAAE,EACjC,KAAK,GAAG;AACzB,QAAM,aAAa,OAAO,IAAI,GAAG,IAAI,IAAI,KAAK,MAAM,GAAG,KAAK;AAC5D,QAAM,WAAW,OAAO,IAAI,GAAG,IAAI,IAAI,GAAG,MAAM,GAAG,GAAG;AAEtD,QAAM,mBACF,OAAO,IAAI,8BAA8B;AAC7C,QAAM,oBACF,OAAO,IAAI,6BAA6B;AAE5C,QAAM,iBAAiB,OAAO,IAC1B,CAAC,aAAa,aAAa,aAAa,WAAW,EAAE,MAAM,GAAG,IAAI,IAClE;AACJ,SAAO;sBACa,UAAU;oBACZ,QAAQ;cACd,gBAAgB,OAAO,iBAAiB;oCAClB,WAAW,IAAM,wBAAwB;;;yCAGpC,cAAc;;;AAGvD;AAEM,IAAO,aAAP,MAAiB;EAWrB,YAAY,QAAkB,UAAiC;AAN/D,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAEnD,SAAA,OAAO;AAGL,SAAK,cAAc,SAAS;MACxB,CAAC,GAAG,MAAM,EAAE,CAAC,IAAoB,OAAO,CAAC,IAAI,EAAE,CAAC;;IAAgB;AACpE,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,aAAS,IAAI,CAAC,GAAG,MAAK;AACpB,WAAK,YAAY,OAAO,CAAC;IAC3B,CAAC;AACD,SAAK,SAAS;AACd,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;YAGT,UAAU,KAAK,MAAM,CAAC;;;;AAI9B,WAAO;EACT;;;;AC9DK,IAAM,QACT,CAAC,SAEyC;AACxC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,UAAU,cAAa,IAAI;AAClC,MAAI,SAAS,MAAM,OAAK,aAAK,YAAY,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG;AACpD,WAAO,SAAS,EAAC,QAAQ,EAAC,EAAC,GAAG,QAAO,CAAC;;AAExC,MAAI,aAAK,cAAc,EAAE,KAAK,MAAM,GAAG;AAGrC,UAAM,cAAc,SAAS;MACzB,CAAC,GAAG,MACA,EAAE,CAAC,IAAoB,EAAE,MAAM,CAAC,IAAI,EAAE,CAAC;;IAAgB;AAC/D,WAAO,KAAK;MACV;MACA,OAAO,EAAC,OAAO,aAAa,OAAO,eAAe,OAAO,EAAE,MAAK;KACjE;;AAEH,QAAM,cAAc,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,aAAa,EAAC,CAAC;AAC7D,WAAS,IAAI,OAAK,YAAY,KAAK,EAAC,MAAM,SAAS,MAAM,CAAC,EAAE,CAAC,GAAG,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;AACvE,QAAM,UAAU,IAAI,WAAW,EAAE,OAAO,QAAQ;AAChD,SAAO,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,OAAO,WAAW;AACpE;AAEG,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AChCP,IAAM,MAAM,iBAAiB;EAClC,QAAQ,aAAa;CACtB;AAEM,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLR,SAAU,MAAM,MAAmD;AAEvE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,GAAG,MAAK,IAAI;AAEnB,QAAM,UAAU,IAAI,gBAAgB,aAAa,OAAO,EAAE,OAAO,MAAM,KAAK;AAC5E,SAAO,QAAQ,iBAAiB,SAAS,CAAC,GAAG,KAAK,GAAG,SAAS;AAChE;AAEO,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACdR,SAAU,KACZ,MAAoE;AAEtE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,MAAM,SAAQ,IAAI;AAEzB,SAAO,OAAO,GAAG,MAAM,UAAU,QAAQ,OAAO;AAClD;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACbP,IAAM,QACT,CAAC,SAAiE;AAChE,QAAM,EAAC,SAAS,MAAK,IAAI;AACzB,QAAM,EAAC,OAAO,MAAM,MAAAC,OAAM,MAAK,IAAI;AACnC,QAAM,SAAS,aAAa,OAAO,MAAMA,OAAM,KAAK;AACpD,SAAO,QAAQ,eAAe,CAAC,OAAO,MAAM,GAAG,OAAO,MAAM;AAC9D;AAEG,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACXP,IAAM,UAAU,iBAAiB,EAAC,QAAQ,aAAa,IAAG,CAAC;AAE3D,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNP,IAAM,aAAa,gBAAgB,EAAC,QAAQ,YAAY,WAAU,CAAC;AAEnE,IAAM,mBAAiC;EAC5C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,OAAO,gBAAgB,EAAC,QAAQ,YAAY,KAAI,CAAC;AAEvD,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,QAAQ,gBAAgB,EAAC,QAAQ,YAAY,MAAK,CAAC;AAEzD,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNR,IAAO,wBAAP,MAA4B;EAUhC,YACI,YAA8C,WAC9C,UAAgB;AAPpB,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAKL,SAAK,cAAc,CAAC,WAAW,CAAC,GAAG,WAAW,UAAU,WAAW,CAAC,CAAC;AAErE,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AAEzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2CjB,WAAO;EACT;;;;ACnEI,SAAU,eAAe,MAI9B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,OAAM,IAAI;AACjB,QAAM,EAAC,cAAc,MAAM,iBAAgB,IAAI;AAE/C,QAAM,CAAC,WAAW,QAAQ,IAAI;AAC9B,QAAM,eAAe,gBAAgB,YAAY,IAAI,IAAM;AAC3D,QAAM,cAAc,gBAAgB,WAAW,IAAI,IAAM;AACzD,QAAM,wBAAwB,mBAAmB,MAAM;AACvD,QAAM,cAAc;IAClB,EAAC,MAAM,WAAW,MAAM,CAAC,cAAc,WAAW,EAAC;IACnD,EAAC,MAAM,WAAW,MAAM,CAAC,qBAAqB,EAAC;;AAGjD,QAAM,UAAU,IAAI,sBAChB,OAAO,OAA2C,WAAW,QAAQ;AAEzE,SAAO,QAAQ,iBAAiB,SAAS,CAAC,MAAM,GAAG,WAAW,WAAW;AAC3E;AAEO,IAAM,uBAAqC;EAChD,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC7BR,IAAO,gCAAP,MAAoC;EAaxC,YACI,YAA8C,cAAqB;AATvE,SAAA,gBAAgB,CAAC,IAAI;AACrB,SAAA,WACI;;AAEJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAEnD,SAAA,OAAO;AAIL,SAAK,cAAc;AAEnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,eAAe;AACpB,SAAK,YAAY,0BAA0B,YAAY;EACzD;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0EjB,WAAO;EACT;;;;ACpGI,SAAU,mBAAmB,MAIlC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,QAAQ,GAAE,IAAI;AACrB,QAAM,EAAC,aAAY,IAAI;AAEvB,QAAM,CAAC,EAAE,SAAS,MAAM,IACpB,OAAO;AACX,QAAM,CAAC,EAAE,SAAS,MAAM,IAAI,GAAG;AAE/B,QAAM,iBAAmC;IACtC,gBAAgB,UAAU,IAAK,UAAU,IAAI;IAC7C,gBAAgB,SAAS,IAAK,SAAS,IAAI;;AAG9C,QAAM,iBAAmC;IACtC,gBAAgB,UAAU,IAAK,UAAU,IAAI;IAC7C,gBAAgB,SAAS,IAAK,SAAS,IAAI;;AAG9C,QAAM,cAAc,eAAe,CAAC,IAAI,eAAe,CAAC;AACxD,QAAM,aAAa,eAAe,CAAC,IAAI,eAAe,CAAC;AAEvD,QAAM,iBAAiB,IAAI;AAC3B,QAAM,gBAAgB,IAAI;AAI1B,QAAM,YAAa,KAAK,KAAK,cAAc,IAAI,IAAK;AACpD,QAAM,WAAY,KAAK,KAAK,aAAa,IAAI,IAAK;AAElD,QAAM,UAAU,IAAI,8BAChB,OAAO,OAA2C,YAAY;AAClE,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,eAAc;IACpC,EAAC,MAAM,SAAS,MAAM,eAAc;IACpC,EAAC,MAAM,WAAW,MAAM,CAAC,WAAW,EAAC;IACrC,EAAC,MAAM,WAAW,MAAM,CAAC,UAAU,EAAC;IACpC,EAAC,MAAM,WAAW,MAAM,CAAC,cAAc,EAAC;IACxC,EAAC,MAAM,WAAW,MAAM,CAAC,aAAa,EAAC;IACvC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,EAAC;IAAG,EAAC,MAAM,SAAS,MAAM,CAAC,QAAQ,EAAC;;AAEtE,SAAO,QAAQ,iBAAiB,SAAS,CAAC,EAAE,GAAG,GAAG,OAAO,WAAW;AACtE;AAEO,IAAM,2BAAyC;EACpD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACrDR,IAAO,+BAAP,MAAmC;EAWvC,YACI,YAA8C,WAC9C,UAAkB,kBAAyB;AAR/C,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAEnD,SAAA,OAAO;AAKL,SAAK,cAAc,CAAC,WAAW,CAAC,GAAG,WAAW,UAAU,WAAW,CAAC,CAAC;AAErE,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AAEzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,mBAAmB;AACxB,SAAK,YAAY,iBAAiB,gBAAgB;EACpD;EAEA,cAAW;AACT,QAAI;AACJ,QAAI,KAAK,kBAAkB;AACzB,0BACI;WAEC;AACL,0BAAoB;;AAGtB,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;oCAmBe,iBAAiB;;;;;;;;;;;;AAYjD,WAAO;EACT;;;;AClEI,SAAU,sBAAsB,MAIrC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,OAAM,IAAI;AACjB,QAAM,EAAC,cAAc,kBAAkB,KAAI,IAAI;AAE/C,QAAM,CAAC,WAAW,QAAQ,IAAI;AAC9B,QAAM,eAAe,gBAAgB,YAAY,IAAI,IAAM;AAC3D,QAAM,cAAc,gBAAgB,WAAW,IAAI,IAAM;AAEzD,QAAM,YAAY,eAAe,MAAM;AACvC,QAAM,cAAc;IAClB,EAAC,MAAM,WAAW,MAAM,CAAC,cAAc,WAAW,EAAC;IACnD,EAAC,MAAM,WAAW,MAAM,CAAC,SAAS,EAAC;;AAGrC,QAAM,UAAU,IAAI,6BAChB,OAAO,OAA2C,WAAW,UAC7D,gBAAgB;AACpB,SAAO,QAAQ,iBAAiB,SAAS,CAAC,MAAM,GAAG,OAAO,OAAO,WAAW;AAC9E;AAEO,IAAM,8BAA4C;EACvD,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC9BR,IAAO,sCAAP,MAA0C;EAa9C,YACI,YAA8C,cAAqB;AATvE,SAAA,gBAAgB,CAAC,IAAI;AACrB,SAAA,WACI;;AAEJ,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAEnD,SAAA,OAAO;AAIL,SAAK,cAAc;AAEnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,eAAe;AACpB,SAAK,YAAY,gCAAgC,YAAY;EAC/D;EAEA,cAAW;AACT,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;oBA2Cb,KAAK,eAAe,+BACA,sBAAsB;;;;oBAK1C,KAAK,eAAe,+BACA,sBAAsB;;;;;;;;;;;;;AAa9C,WAAO;EACT;;;;ACzFI,SAAU,0BAA0B,MAIzC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,QAAQ,GAAE,IAAI;AACrB,QAAM,EAAC,aAAY,IAAI;AAEvB,QAAM,CAAC,EAAE,SAAS,MAAM,IAAI,OAAO;AACnC,QAAM,CAAC,EAAE,SAAS,MAAM,IAAI,GAAG;AAE/B,QAAM,iBAAmC;IACtC,gBAAgB,UAAU,IAAK,UAAU,IAAI;IAC7C,gBAAgB,SAAS,IAAK,SAAS,IAAI;;AAG9C,QAAM,iBAAmC;IACtC,gBAAgB,UAAU,IAAK,UAAU,IAAI;IAC7C,gBAAgB,SAAS,IAAK,SAAS,IAAI;;AAG9C,QAAM,cAAc,eAAe,CAAC,IAAI,eAAe,CAAC;AACxD,QAAM,aAAa,eAAe,CAAC,IAAI,eAAe,CAAC;AAEvD,QAAM,iBAAiB,IAAI;AAC3B,QAAM,gBAAgB,IAAI;AAI1B,QAAM,YAAa,KAAK,KAAK,cAAc,IAAI,IAAK;AACpD,QAAM,WAAY,KAAK,KAAK,aAAa,IAAI,IAAK;AAElD,QAAM,UAAU,IAAI,oCAChB,OAAO,OAA2C,YAAY;AAClE,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,eAAc;IACpC,EAAC,MAAM,SAAS,MAAM,eAAc;IACpC,EAAC,MAAM,WAAW,MAAM,CAAC,cAAc,EAAC;IACxC,EAAC,MAAM,WAAW,MAAM,CAAC,aAAa,EAAC;IACvC,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,EAAC;IAAG,EAAC,MAAM,SAAS,MAAM,CAAC,QAAQ,EAAC;;AAEtE,SAAO,QAAQ,iBAAiB,SAAS,CAAC,EAAE,GAAG,GAAG,OAAO,WAAW;AACtE;AAEO,IAAM,kCAAgD;EAC3D,YAAY;EACZ,aAAa;EACb,YAAY;;;;AClDR,IAAO,iBAAP,MAAqB;EAUzB,YAAY,QAAwC;AALpD,SAAA,gBAAgB,CAAC,GAAG;AAEpB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,WAAW;AAChB,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,uBAAuB;;;;;;;;;;;;;;;;;;;;;AAqB7B,UAAM,WAAW;QACb,oBAAoB;QACpB,oBAAK,OAAO,CAAC;;;;;;;;;AASjB,WAAO;EACT;;;;AChDI,SAAU,QACZ,MAA0E;AAE5E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,KAAI,IAAI;AAEf,QAAM,QAAQ,EAAE,MAAM;AACtB,MAAI,UAAU,GAAG;AACf,WAAO,SAAS,EAAC,QAAQ,EAAC,EAAC,GAAG,QAAO,CAAC;;AAGxC,QAAM,SAAS,EAAE;AACjB,QAAM,WAA6C,CAAC,GAAG,GAAG,GAAG,CAAC;AAC9D,SAAO,QAAQ,CAAC,GAAG,MAAK;AACtB,UAAM,QAAQ,IAAI,IAAI;AACtB,aAAS,KAAK,IAAI;EACpB,CAAC;AAED,QAAM,OAAO,aAAK,eAAe,MAAM,EAAE,KAAK;AAC9C,QAAM,SAA2C,CAAC,GAAG,GAAG,GAAG,CAAC;AAC5D,OAAK,QAAQ,QAAK;AAChB,UAAM,QAAQ,KAAK,IAAI;AACvB,WAAO,KAAK,IAAI;EAClB,CAAC;AACD,QAAM,cAAc,CAAC,EAAC,MAAM,SAAS,MAAM,OAAM,CAAC;AAElD,QAAM,YAAY,QAAQ,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AAE1E,QAAM,UAAU,IAAI,eAAe,QAAQ;AAC3C,QAAM,SAAS,QAAQ,iBACnB,SAAS,CAAC,SAAS,GAAG,UAAU,OAAO,WAAW;AACtD,UAAQ,YAAY,UAAU,MAAM;AAEpC,QAAM,SACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,OAAM,GAAG,SAAS,OAAO,EAAC,OAAO,OAAM,EAAC,CAAC;AAClE,UAAQ,YAAY,OAAO,MAAM;AAEjC,SAAO;AACT;AAEO,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACjDR,IAAO,gBAAP,MAAoB;EAWxB,YACI,YACA,WAA0C;AAZ9C,SAAA,cAAwB,CAAA;AAIxB,SAAA,gBAAgB,CAAC,GAAG;AAEpB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAEnD,SAAA,OAAO;AAKL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,WAAW;;AAEhB,SAAK,YAAY;AACjB,SAAK,cAAc;AAEnB,QAAI,OAAO,cAAc,UAAU;AACjC,WAAK,YAAY;AACjB,WAAK,cAAc;AACnB,WAAK,aAAa;WACb;AACL,WAAK,YAAY;AACjB,WAAK,cAAc;AACnB,WAAK,aAAa;;EAEtB;EAEA,cAAW;AACT,UAAM,WAAW;UACX,oBAAK,OAAO,CAAC;;;;;;;;;;;cAWT,KAAK,WAAW;;;;;;;;;AAS1B,WAAO;EACT;;;;ACtDK,IAAM,yBAAuC;EAChD,YAAY;EACZ,aAAa;EACb,YAAY,CAAC,EAAC,QAAQ,OAAO,QAAO,MAAK;AACvC,UAAM,EAAC,MAAK,IAAI;AAChB,UAAM,EAAC,SAAS,WAAW,OAAM,IAC7B;AACJ,UAAM,gBAAgB;AAEtB,UAAM,UAAU,IAAI,cAAe,MAAmB,OAAO,SAAS;AACtE,UAAM,CAAC,SAAS,OAAO,IACnB,qBAAa,eAAe,QAAQ,MAAM,MAAM,CAAC,GAAG,MAAM,MAAM,CAAC,CAAC;AACtE,UAAM,cAAc;MACd,EAAC,MAAM,WAAW,MAAM,CAAC,OAAO,EAAC;MACjC,EAAC,MAAM,WAAW,MAAM,CAAC,OAAO,EAAC;MACjC,EAAC,MAAM,WAAW,MAAM,CAAC,KAAK,IAAI,OAAO,CAAC,EAAC;MAC3C,EAAC,MAAM,WAAW,MAAM,CAAC,KAAK,IAAI,OAAO,CAAC,EAAC;;AAGjD,QAAI,OAAO,cAAc,UAAU;AACjC,kBAAY,KACR,EAAC,MAAM,WAAW,MAAM,CAAC,OAAO,WAAW,UAAU,QAAQ,CAAC,CAAC,CAAC,EAAC,CAAC;WACjE;AACL,kBAAY,KAAK,EAAC,MAAM,WAAW,MAAM,UAAS,CAAC;;AAGrD,UAAM,SAAS,cAAc,iBACzB,SAAS,CAAC,KAAK,GAAG,MAAM,OAAO,WAAW;AAC9C,WAAO;EACV;;;;AC7BI,IAAM,QAAQ,gBAAgB,EAAC,QAAQ,YAAY,MAAK,CAAC;AAEzD,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNP,IAAM,QACT,gBAAgB,EAAC,QAAQ,YAAY,OAAO,eAAe,aAAY,CAAC;AAErE,IAAM,cAA4B;EACvC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLR,IAAO,iBAAP,MAAqB;EAezB,YACI,eAAyB,UAAkB,aAC3C,aAAqB,SAAmB,OACxC,aAAuB,iBAAiB,MAAI;AAjBhD,SAAA,gBAAgB,CAAC,WAAW,SAAS;AAOrC,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAInD,SAAA,SAAS;AAOP,SAAK,cAAc;AACnB,SAAK,OAAO;AACZ,SAAK,iBAAiB;AACtB,SAAK,iBAAiB,mBAAmB,aAAa;AAEtD,SAAK,WACD,gBAAgB,KAAK,gBAAgB,eAAe,KAAK,aAAa;AAC1E,SAAK,yBAAyB,WAAW;AACzC,SAAK,YACD,WAAW,WAAW,IAAI,WAAW,IAAI,KAAK,sBAAsB,IAChE,WAAW,IAAI,cAAc,IAAI,QAAQ,MAAM;AACvD,UAAM,cAAc,kBAAkB,QAAQ,MAAM;AACpD,SAAK,WACD,4BAA4B,WAAW;AAC3C,SAAK,cAAc;AACnB,SAAK,cAAc;EACrB;EAEA,cAAW;AACT,QAAI,gBAAgB;AACpB,QAAI,KAAK,gBAAgB,GAAG;AAC1B,sBAAgB;eACP,KAAK,gBAAgB,GAAG;AACjC,sBAAgB;;AAElB,UAAM,iBAAiB,cAAc,aAAa;AAElD,UAAM,eAAe,KAAK,yBAAyB,wBACA;AAEnD,QAAI,kBAAkB;AACtB,QAAI,gCAAgC;AACpC,QAAI,KAAK,eAAe,EAAE,WAAW,GAAG;AACtC,wBAAkB;AAClB,sCAAgC;;;;;eAKvB,KAAK,eAAe,EAAE,WAAW,GAAG;AAC7C,wBAAkB;AAClB,sCAAgC;;;;;;;;;;;;;AAalC,UAAM,gBACF,MAAM,KAAK,EAAC,QAAQ,KAAK,YAAW,GAAG,CAAC,GAAG,QAAQ,UAAU,GAAG,GAAG;AACvE,UAAM,iBAAiB,cAAc,cAAc,KAAK,IAAI,CAAC;AAE7D,UAAM,WAAW;MACf,6BAA6B;QAC3B,oBAAK,OAAO,CAAC;;;;;0CAKqB,cAAc;8DACM,YAAY;;;gBAG1D,kBAAkB,KAAK,IAAI,CAAC,IAAI,cAAc;qDACT,eAAe;;YAG5D,KAAK,iBACD,iBACI,sBAAsB,eACtB,KAAK,IAA2B,IACpC,6DAA6D;;;AAGrE,WAAO;EACT;;;;AClGI,SAAU,UAAU,MAIzB;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,SAAS,QAAO,IAAI;AAC3B,QAAM,EAAC,MAAK,IAAI;AAEhB,QAAM,EAAC,WAAW,YAAY,WAAW,SAAS,WAAU,IACxD,qBAAa,gBAAgB,SAAS,SAAS,KAAK;AAExD,QAAM,eAAe,CAAC,aAAa,WAAW,SAAS;AAEvD,MAAI,eAAe,GAAG;AACpB,WAAO,QAAQ,eAAe,OAAO,QAAQ,KAAK;;AAGpD,QAAM,iBAAiB,QACnB,EAAC,QAAQ,EAAC,GAAG,QAAO,GAAG,SAAS,OAAO,EAAC,OAAO,CAAC,YAAY,SAAS,EAAC,EAAC,CAAC;AAC5E,QAAM,WAAW,QACb,EAAC,QAAQ,EAAC,GAAG,QAAO,GAAG,SAAS,OAAO,EAAC,OAAO,CAAC,YAAY,SAAS,EAAC,EAAC,CAAC;AAE5E,QAAM,OAAO,SAAS;AACtB,QAAM,SACF,KAAK,EAAC,SAAS,OAAO,EAAC,OAAO,cAAc,OAAO,GAAG,OAAO,KAAI,EAAC,CAAC;AACvE,QAAM,OAAO,aAAK,cAAc,SAAS,KAAK;AAC9C,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,EAAC;IAAG,EAAC,MAAM,SAAS,MAAM,QAAO;IACjE,EAAC,MAAM,SAAS,MAAM,CAAC,IAAI,EAAC;;AAE9B,QAAM,UAAU,IAAI,eAChB,SAAS,OAAO,WAAW,eAAe,MAAM,QAChD,SAAS,MAAM,QAAQ,SAAS,cAAc,IAAI;AACtD,QAAM,MAAM,QAAQ,iBAChB,SAAS,CAAC,UAAU,cAAc,GAAG,MAAM,aAAa,MAAM;AAElE,QAAM,WAAW,QAAQ,EAAC,QAAQ,EAAC,GAAG,IAAG,GAAG,SAAS,OAAO,EAAC,MAAK,EAAC,CAAC;AAEpE,UAAQ,YAAY,eAAe,MAAM;AACzC,UAAQ,YAAY,SAAS,MAAM;AACnC,UAAQ,YAAY,IAAI,MAAM;AAE9B,SAAO;AACT;AAEO,IAAM,kBAAgC;EAC3C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACtDR,IAAO,sBAAP,MAA0B;EAW9B,YAAY,aAA+B,MAAoB;AAV/D,SAAA,cAAwB,CAAA;AAIxB,SAAA,gBAAgB,CAAC,kBAAkB,QAAQ;AAC3C,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAIL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,OAAO;AACZ,SAAK,YAAY,iBAAiB,IAAI;EACxC;EAEA,cAAW;AACT,UAAM,kBAAkB,KAAK,SAAS,SAAS,MAAM;AACrD,UAAM,WAAW;;;;;;8CAMyB,eAAe;;;;;;;;;QASrD,oBAAK,OAAO,CAAC;;;;;;;;AASjB,WAAO;EACT;;;;AC9CI,SAAU,aAAa,MAI5B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,gBAAgB,OAAM,IAAI;AACjC,QAAM,EAAC,KAAI,IAAI;AAEf,QAAM,UACF,IAAI,oBAAoB,CAAC,OAAO,MAAM,CAAC,GAAG,OAAO,MAAM,CAAC,CAAC,GAAG,IAAI;AACpE,QAAM,cAAc,CAAC,EAAC,MAAM,SAAS,MAAM,CAAC,eAAe,MAAM,CAAC,CAAC,EAAC,CAAC;AACrE,SAAO,QAAQ,iBACX,SAAS,CAAC,gBAAgB,MAAM,GAAG,SAAS,WAAW;AAC7D;AAEO,IAAM,qBAAmC;EAC9C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACrBR,IAAO,gBAAP,MAAoB;EAWxB,YAAY,OAAe,OAAiB,MAAY;AAVxD,SAAA,gBAAgB,CAAC,KAAK,KAAK,GAAG;AAK9B,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAGnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAE7D,SAAK,QAAQ;AACb,SAAK,OAAO;AACZ,SAAK,YAAY;EACnB;EAEA,cAAW;AAET,QAAI;AACJ,QAAI;AACJ,QAAI,KAAK,OAAO,GAAG;AACjB,YAAM,MAAM,kBAAkB,KAAK,IAAI,uBAAuB;;AAGhE,QAAI,KAAK,SAAS,GAAG;AACnB,iBAAW;AACX,gBAAU;WACL;AACL,YAAM,gBAAgB,CAAC,WAAW,WAAW,WAAW,SAAS;AACjE,YAAM,aAAa,CAAA;AACnB,YAAM,cAAc,CAAA;AACpB,eAAS,IAAI,GAAG,IAAI,KAAK,YAAY,QAAQ,KAAK;AAChD,oBAAY,KAAK,GAAG,cAAc,CAAC,CAAC,EAAE;AACtC,YAAI,IAAI,KAAK,OAAO;AAClB,qBAAW,KAAK,GAAG,cAAc,CAAC,CAAC,EAAE;;;AAGzC,gBAAU,WAAW,KAAI;AACzB,iBAAW,YAAY,KAAI;;AAG7B,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;4BAGO,OAAO;;2CAEQ,QAAQ;;2CAER,QAAQ;;;;;AAK/C,WAAO;EACT;;;;AC3DI,SAAU,OAAO,MAAoD;AAEzE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,WAAW,GAAG,EAAC,IAAI;AAE1B,QAAM,UACF,IAAI,cAAc,UAAU,MAAM,QAAQ,EAAE,OAAO,EAAE,MAAM,MAAM;AACrE,SAAO,QAAQ,iBACX,SAAS,CAAC,WAAW,GAAG,CAAC,GAAG,WAAW,EAAE,OAAO,EAAE,KAAK,CAAC;AAC9D;AAEO,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACbP,IAAM,OAAO,gBAAgB,EAAC,QAAQ,YAAY,KAAI,CAAC;AAEvD,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACPP,IAAM,UAAU,gBAAgB,EAAC,QAAQ,YAAY,QAAO,CAAC;AAE7D,IAAM,gBAA8B;EACzC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACHP,IAAM,OAAO,gBAAgB,EAAC,QAAQ,YAAY,KAAI,CAAC;AAEvD,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,MAAM,gBAAgB,EAAC,QAAQ,YAAY,IAAG,CAAC;AAErD,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,OAAO,gBAAgB,EAAC,QAAQ,YAAY,KAAI,CAAC;AAEvD,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACLP,IAAM,WAAW,gBAAgB,EAAC,QAAQ,YAAY,SAAQ,CAAC;AAE/D,IAAM,iBAA+B;EAC1C,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNR,IAAO,wBAAP,MAA4B;EAahC,YACI,QAAkB,cAClB,UAAmC,sBACnC,QAAkB,gCAAsC;AAf5D,SAAA,gBAAgB,CAAC,GAAG;AACpB,SAAA,cAAwB,CAAA;AAIxB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AAInD,SAAA,OAAO;AAML,UAAM,cAAwB,IAAI,MAAM,qBAAqB,MAAM;AACnE,aAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK;AAC3C,kBAAY,CAAC,IAAI,qBAAqB,OAAO,CAAC,CAAC;;AAEjD,SAAK,cAAc;AACnB,SAAK,SAAS;AACd,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,SAAS;AACd,SAAK,eAAe;AACpB,SAAK,YAAY,0BACb,kBACI,qBAAqB,MAAM,CAAC,2BAChC,kBAAkB,8BAA8B,CAAC;AACrD,aAAS,IAAI,CAAC,GAAG,MAAK;AACpB,WAAK,YAAY,OAAO,CAAC;IAC3B,CAAC;AACD,SAAK,YAAY,kBAAkB,MAAM;EAC3C;EAEA,cAAW;AACT,UAAM,QAAQ,kBAAkB,KAAK,YAAY,MAAM;AACvD,UAAM,WAAW,kBAAkB,KAAK,MAAM;AAE9C,UAAM,WAAW;QACb,0BAA0B,KAAK,cAAc,SAAS,CAAC;QACvD,oBAAK,OAAO,CAAC;;;kDAG6B,KAAK,YAAY,MAAM,KACjE,KAAK,IAAI,QAAQ;;YAEb,UAAU,KAAK,QAAQ,IAAI,CAAC;;;;AAIpC,WAAO;EACT;;;;ACrDK,IAAM,iBAAiB,CAAC,SAId;AACf,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,YAAY,SAAQ,IAAI;AAE/B,eAAK,OACD,EAAE,MAAM,UAAU,GAClB,MAAM,uEACe;AAEzB,QAAMC,QAAO,WAAW,OAAO,CAAC,GAAG,MAAM,IAAI,CAAC;AAE9C,QAAM,mBAA4C,CAAC,CAAC,GAAG,CAAC,CAAC;AACzD,mBAAiB,KAAK,GAAG,QAAmC;AAC5D,WAAS,IAAI,IAAI,WAAW,QAAQ,IAAI,EAAE,MAAM,QAAQ,EAAE,GAAG;AAC3D,qBAAiB,KAAK,CAAC,GAAG,CAAC,CAAC;;AAG9B,QAAM,eAAe,iBAAiB;IAClC,CAAC,GAAG,MAAM,EAAE,CAAC,IAAoB,EAAE,MAAM,CAAC,IAAI,EAAE,CAAC;;EAAgB;AACrE,QAAM,sBACF,qBAAa,YAAY,cAAc,YAAYA,OAAM,KAAK;AAElE,QAAM,oCAAoC,qBAAa,YACnD,oBAAoB,QAAQ,WAAW,QAAQ,KAAK;AAExD,QAAM,eACF,qBAAa,oBAAoB,cAAc,YAAYA,OAAM,KAAK;AAE1E,QAAM,sBAAsB,aAAK,eAAe,YAAY;AAC5D,QAAM,UAAU,IAAI,sBAChB,EAAE,OAAO,cAAc,kBAAkB,qBACzC,mCAAmC,oBAAoB,MAAM;AACjE,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,oBAAmB;IACzC,EAAC,MAAM,SAAS,MAAM,oBAAmB;;AAE3C,mBAAiB,IACb,OAAK,YAAY,KAAK,EAAC,MAAM,SAAS,MAAM,CAAC,EAAE,CAAC,GAAG,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;AAC9D,QAAM,WAAW,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,OAAO,WAAW;AAC5E,QAAM,SACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,SAAQ,GAAG,SAAS,OAAO,EAAC,OAAO,aAAY,EAAC,CAAC;AAC1E,UAAQ,YAAY,SAAS,MAAM;AACnC,SAAO;AACT;AAEO,IAAM,uBAAqC;EAChD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACtDR,IAAO,0BAAP,MAA8B;EAWlC,YAAY,UAAoB,YAAoB,aAAqB;AAVzE,SAAA,gBAAgB,CAAC,SAAS,WAAW,YAAY;AACjD,SAAA,cAAwB,CAAA;AAIxB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,SAAS;AAIP,SAAK,cAAc;AACnB,SAAK,OAAO;AACZ,SAAK,iBAAiB,mBAAmB,CAAC,UAAU,CAAC;AACrD,SAAK,WACD,gBAAgB,KAAK,gBAAgB,CAAC,UAAU,GAAG,KAAK,aAAa;AAEzE,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;MACf,oBAAK,OAAO,CAAC;;;;;;;;;UAUX,iBACI,qBAAqB,SAAS,KAAK,IAA2B,CAAC;;;;AAIvE,WAAO;EACT;;AAGI,IAAO,8BAAP,MAAkC;EAStC,YAAY,UAAkB,iBAAyB;AARvD,SAAA,gBAAgB,CAAC,YAAY;AAC7B,SAAA,cAAwB,CAAA;AAIxB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,SAAS;AAGP,SAAK,cAAc,CAAC,QAAQ;AAC5B,SAAK,iBAAiB,mBAAmB,eAAe;AACxD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,iBAAiB,KAAK,aAAa;AAE5D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;MACf,oBAAK,OAAO,CAAC;;;UAGT,iBAAiB,sBAAsB,KAAK,OAAO,CAAC;;;;AAI1D,WAAO;EACT;;AAGI,IAAO,2BAAP,MAA+B;EAWnC,YAAY,UAAoB,aAAqB;AAVrD,SAAA,gBAAgB,CAAC,cAAc,oBAAoB;AACnD,SAAA,cAAwB,CAAA;AAIxB,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAIL,SAAK,cAAc;AACnB,SAAK,OAAO;AACZ,SAAK,iBAAiB,mBAAmB,QAAQ;AACjD,SAAK,WACD,gBAAgB,KAAK,gBAAgB,UAAU,KAAK,aAAa;AAErE,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;MACf,oBAAK,OAAO,CAAC;;;;;YAMX,KAAK,SAAS,YACV,6DACA,wDAAwD;;;;;AAKhE,WAAO;EACT;;;;AC7GI,SAAU,oBACZ,OAAmB,SAAqB,YACxC,QAAQ,OAAO,SAAsB;AACvC,QAAM,YAAY,aAAK,cAAc,MAAM,KAAK;AAChD,QAAM,cAAc,YAAY,MAAM,MAAM,CAAC;AAC7C,QAAM,QAAQ,MAAM;AAIpB,QAAM,aAAa,aAAK,cAAc,QAAQ,KAAK;AACnD,QAAM,cAAc,QAAQ,SAAS,WAAW,MAAM;AACtD,QAAM,uBACF,aAAa,IAAI,YAAY,aAAa,CAAC,IAAI,IAAI;AACvD,QAAM,aAAa;AAEnB,MAAI;AACJ,QAAM,cAAc,MAAM,MAAM,MAAK;AACrC,cAAY,CAAC,IAAI;AAEjB,QAAM,aAAa,aAAa;AAChC,QAAMC,oBACF,KAAK,EAAC,SAAS,OAAO,EAAC,OAAO,aAAa,OAAO,GAAG,MAAK,EAAC,CAAC;AAChE,YAAU,IAAI,wBAAwB,aAAa,YAAY,KAAK;AACpE,MAAI,cAAc;IAChB,EAAC,MAAM,SAAS,MAAM,CAAC,WAAW,EAAC;IAAG,EAAC,MAAM,SAAS,MAAM,CAAC,UAAU,EAAC;;AAE1E,QAAM,oBAAoB,QAAQ,iBAC9B,SAAS,CAAC,OAAO,SAAS,UAAU,GAAG,OAAO,aAC9CA,iBAAgB;AAEpB,MAAI,OAAO;AACT,WAAO;;AAGT,QAAM,uBACF,KAAK,EAAC,SAAS,OAAO,EAAC,OAAO,CAAC,UAAU,GAAG,OAAO,GAAG,OAAO,QAAO,EAAC,CAAC;AAC1E,YAAU,IAAI,4BAA4B,YAAY,WAAW,KAAK;AACtE,QAAM,wBAAwB,QAAQ,iBAClC,SAAS,CAAC,UAAU,GAAG,SAAS,MAAM,oBAAoB;AAE9D,QAAMC,qBACF,KAAK,EAAC,SAAS,OAAO,EAAC,OAAO,aAAa,OAAO,GAAG,MAAK,EAAC,CAAC;AAChE,YAAU,IAAI,yBAAyB,aAAa,KAAK;AACzD,gBAAc,CAAC,EAAC,MAAM,SAAS,MAAM,CAAC,WAAW,EAAC,CAAC;AACnD,QAAM,qBAAqB,QAAQ,iBAC/B,SAAS,CAAC,mBAAmB,qBAAqB,GAAG,OAAO,aAC5DA,kBAAiB;AAErB,UAAQ,YAAY,kBAAkB,MAAM;AAC5C,UAAQ,YAAY,sBAAsB,MAAM;AAChD,SAAO;AACT;;;ACrDM,SAAU,kBACZ,MAA+D;AAEjE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,MAAM,SAAS,WAAU,IAAI;AAEpC,SAAO,oBAAoB,MAAM,SAAS,YAAY,OAAO,OAAO;AACtE;AAEO,IAAM,0BAAwC;EACnD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACZR,SAAU,iBACZ,MAA8D;AAEhE,QAAM,EAAC,QAAQ,QAAO,IAAI;AAC1B,QAAM,EAAC,MAAM,SAAS,WAAU,IAAI;AAEpC,SAAO,oBAAoB,MAAM,SAAS,YAAY,MAAM,OAAO;AACrE;AAEO,IAAM,yBAAuC;EAClD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACdR,IAAO,cAAP,MAAkB;EAUtB,YAAY,QAAkB,MAAc;AAT5C,SAAA,gBAAgB,CAAC,GAAG;AAKpB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAIL,UAAM,cAAwB,IAAI,MAAM,OAAO,MAAM;AACrD,aAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK;AAC3C,kBAAY,CAAC,IAAI,OAAO,CAAC,IAAI,KAAK,CAAC;;AAErC,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,OAAO,KAAK,YAAY;AAC7B,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,eAAeC,iBAAgB,KAAK,MAAM,WAAW;AAE3D,UAAM,WAAW;QACb,oBAAK,OAAO,CAAC;;;yCAGoB,YAAY;;;;AAIjD,WAAO;EACT;;AAGF,SAASA,iBAAgB,MAAc,gBAAgB,IAAE;AACvD,MAAI,QAAQ,GAAG;AACb,UAAM,MAAM,iBAAiB,IAAI,uBAAuB;;AAE1D,MAAI,SAAS,GAAG;AACd,WAAO,YAAY,aAAa;;AAGlC,QAAM,gBAAgB,CAAC,WAAW,WAAW,WAAW,SAAS;AACjE,QAAM,eAAe,CAAA;AACrB,WAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,iBAAa,KAAK,IAAI,cAAc,CAAC,CAAC,MAAM,aAAa,UAAU,CAAC,IAAI;;AAE1E,SAAO,aAAa,KAAI;AAC1B;;;ACjDM,SAAU,KACZ,QAAsE;AAExE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,KAAI,IAAI;AAGf,MAAI,QAAQ,mBAAmB,CAAC,CAAC,CAAC,KAAK,EAAE,UAAU,YAC/C,EAAE,MAAM,UAAU,GAAG;AAGvB,UAAM,OAAO,QAAQ,SAAS,EAAE,MAAM;AACtC,UAAM,QAAQ,EAAE,UAAU,WACrB,KAAsB,IAAI,OAAK,aAAK,aAAa,CAAC,CAAC,IACpD;AACJ,UAAM,MAAM,OAAO,EAAE,OAAO,EAAE,OAAO,KAAK;AAC1C,UAAM,SAAS,YAAY,KAAK,IAAI;AACpC,WAAO,QAAQ,eAAe,OAAO,OAAO,OAAO,OAAO,OAAO,MAAM;;AAGzE,QAAM,UAAU,IAAI,YAAY,EAAE,OAAO,IAAI;AAC7C,QAAM,SAAS,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,KAAK;AAE7D,SAAO;AACT;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC1BR,SAAU,cAAc,MAI7B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,eAAe,cAAc,aAAY,IAAI;AACpD,QAAM,EAAC,YAAW,IAAI;AAEtB,QAAM,EAAC,WAAW,YAAY,WAAW,SAAS,WAAU,IACxD,qBAAa,gBAAgB,cAAc,eAAe,WAAW;AAEzE,QAAM,iBAAiB;AACvB,MAAI,aAAa,UAAU,UAAU;AACnC,UAAM,aAAa,QAAQ,WAA0B,aAAa;AAClE,UAAM,aAAa,QAAQ,WAA2B,YAAY;AAClE,UAAMC,iBAAgB,aAAK,aACvB,QAAQ,SAAS,aAAa,MAAM,EAAE,CAAC,CAAe;AAC1D,UAAM,SAAS,eACX,YAAY,YAAY,aAAa,YAAY,WAAW,YAC5D,WAAW,SAASA,gBAAe,cAAc;AACrD,WAAO,QAAQ,eAAe,aAAa,OAAO,OAAO,OAAO,MAAM;;AAGxE,QAAM,eAAe,CAAC,aAAa,WAAW,SAAS;AAEvD,QAAM,iBAAiB,QAAQ;IAC7B,QAAQ,EAAC,GAAG,cAAa;IACzB;IACA,OAAO,EAAC,OAAO,CAAC,YAAY,SAAS,EAAC;GACvC;AACD,QAAM,gBAAgB,aAAa,MAAM,SACrC,QAAQ;IACN,QAAQ,EAAC,GAAG,aAAY;IACxB;IACA,OAAO,EAAC,OAAO,CAAC,YAAY,SAAS,EAAC;GACvC,IACD,SAAS,EAAC,QAAQ,EAAC,GAAG,aAAY,GAAG,QAAO,CAAC;AAEjD,QAAM,OAAO,cAAc;AAC3B,QAAM,OACF,QAAQ,eAAe,CAAA,GAAI,MAAM,aAAK,oBAAoB,GAAG,IAAI,CAAC;AAGtE,QAAM,gBAAgB,QAAQ;IAC5B,QAAQ,EAAC,GAAG,aAAY;IACxB;IACA,OAAO,EAAC,OAAO,MAAM,aAAa,MAAM,EAAE,KAAK,CAAC,EAAC;GAClD;AACD,QAAM,eACF,KAAK,EAAC,QAAQ,EAAC,GAAG,cAAa,GAAG,SAAS,OAAO,EAAC,MAAM,aAAY,EAAC,CAAC;AAE3E,QAAM,OAAO,aAAK,cAAc,CAAC,YAAY,SAAS,CAAC;AACvD,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,EAAC;IACjC,EAAC,MAAM,SAAS,MAAM,QAAO;IAC7B,EAAC,MAAM,SAAS,MAAM,CAAC,IAAI,EAAC;;AAG9B,UAAQ,YAAY;IAClB,KAAK;AACH;IACF,KAAK;AACH,UAAI,MAAM;AACR,cAAM,UAAU,IAAI,eAChB,CAAC,YAAY,SAAS,GAAG,WAAW,eAAe,MAAM,QACzD,cAAc,MAAM,QAAQ,SAAS,cAAc,MACnD,cAAc;AAClB,gBAAQ,iBACJ,SAAS,CAAC,eAAe,cAAc,GAAG,MAAM,aAChD,YAAY;;AAElB;IACF;AACE,UAAI,MAAM;AAER,cAAM,UAAU,IAAI,eAChB,CAAC,YAAY,SAAS,GAAG,WAAW,eAAe,MAAM,QACzD,KAAK,MAAM,QAAQ,SAAS,cAAc,MAAM,cAAc;AAClE,gBAAQ,iBACJ,SAAS,CAAC,MAAM,cAAc,GAAG,MAAM,aAAa,YAAY;;AAEtE;AAEE,cAAM,UAAU,IAAI,eAChB,CAAC,YAAY,SAAS,GAAG,WAAW,eAAe,MAAM,QACzD,cAAc,MAAM,QAAQ,SAAS,cAAc,IAAI;AAC3D,gBAAQ,iBACJ,SAAS,CAAC,eAAe,cAAc,GAAG,MAAM,aAChD,YAAY;;;AAItB,QAAM,cAAc,QAChB,EAAC,QAAQ,EAAC,GAAG,aAAY,GAAG,SAAS,OAAO,EAAC,OAAO,YAAW,EAAC,CAAC;AAErE,UAAQ,YAAY,eAAe,MAAM;AACzC,UAAQ,YAAY,cAAc,MAAM;AACxC,UAAQ,YAAY,cAAc,MAAM;AACxC,UAAQ,YAAY,KAAK,MAAM;AAC/B,UAAQ,YAAY,aAAa,MAAM;AACvC,SAAO;AACT;AAEO,IAAM,sBAAoC;EAC/C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AChHR,SAAU,OACZ,MAAwE;AAE1E,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,iBAAiB,KAAI,IAAI;AAEhC,QAAM,QAAQ,aAAK,eAAe,MAAM,EAAE,KAAK,EAAE,CAAC;AAClD,QAAM,aAAa,qBAAa,iBAAiB,GAAG,iBAAiB,KAAK;AAE1E,QAAM,QAAQ,EAAE,MAAM;AACtB,QAAM,QAAQ,IAAI,MAAM,KAAK,EAAE,KAAK,CAAC;AACrC,QAAM,OAAO,EAAE,MAAM,MAAK;AAE1B,SAAO,WAAW,IAAI,OAAI;AACxB,UAAM,YAAY,CAAC,GAAG,IAAI;AAC1B,cAAU,KAAK,IAAI;AACnB,UAAM,SACF,MAAM,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,MAAM,UAAS,EAAC,CAAC;AACjE,UAAM,KAAK,KAAK;AAChB,WAAO;EACT,CAAC;AACH;AAEO,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC5BP,IAAM,OAAO,gBAAgB,EAAC,QAAQ,YAAY,KAAI,CAAC;AAEvD,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACJP,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY,CAAC,EAAC,QAAQ,QAAO,MAAK;AAChC,UAAM,EAAC,EAAC,IAAI;AACZ,UAAM,gBAAgB;AACtB,UAAM,UAAU,IAAI,eAAe,EAAE,OAAO,YAAY,MAAM;AAC9D,WAAO,cAAc,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,KAAK;EAC7D;;;;ACRK,IAAM,oBAAoB,iBAAiB;EAChD,QAAQ,aAAa;CACtB;AAEM,IAAM,0BAAwC;EACnD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNR,SAAU,KACZ,EAAC,QAAQ,OAAO,QAAO,GAC4C;AAErE,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,UACF,IAAI,eAAe,EAAE,OAAO,YAAY,MAAM,kBAAkB;AACpE,QAAM,cAAc,CAAC,EAAC,MAAM,WAAW,MAAM,CAAC,MAAM,KAAK,EAAC,CAAC;AAC3D,SAAO,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,OAAO,WAAW;AACpE;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACjBR,IAAO,sBAAP,MAA0B;EAY9B,YAAY,UAAkB;AAX9B,SAAA,gBAAgB,CAAC,GAAG;AAOpB,SAAA,gBAAgB;AAChB,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,eAC5C,CAAC,KAAK,eAAe,GAAG,CAAC,CAAC;AAE9B,UAAM,QAAQ,kBAAkB,KAAK,YAAY,MAAM;AACvD,SAAK,WAAW,WAAW,KAAK,gBAAgB,KAAK;AACrD,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,OAAO,KAAK,YAAY;AAC9B,QAAI,YAAY;AAChB,QAAI,SAAS,GAAG;AACd,kBAAY;WACP;AACL,UAAI,aAAa;AACjB,kBACI,KAAK,YACA,IAAI,CAAC,GAAG,MAAK;AACZ;AACA,eAAO,KAAK,YAAY,WAAW,IAC/B,6BAA6B,CAAC,sBAAsB,CAAC,MACrD,UAAU,aAAa,CAAC,wBACpB,CAAC,sBAAsB,CAAC;MAClC,CAAC,EACA,KAAK,GAAG;;AAGnB,UAAM,WAAW;SACZ,oBAAK,OAAO,CAAC;;;0CAGoB,SAAS;;;;AAI/C,WAAO;EACT;;;;AC9CI,SAAU,aAAa,MAI5B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EACJ,OACA,KACA,SACA,WACA,SACA,cACA,aACA,eAAc,IACZ;AAEJ,QAAM,EACJ,kBACA,YACA,YACA,WACA,eACA,OAAO,QACP,KAAK,MACL,SAAS,SAAQ,IAEf,mBAAW,UACP,EAAE,OAAO,OAAO,KAAK,SAAS,WAAW,SAAS,cAClD,aAAa,cAAc;AAEnC,MAAI;AAEJ,MAAI,YAAY;AAEd,aAAS,QAAQ,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,WAAU,EAAC,CAAC;aAC1D,aAAa,eAAe;AAErC,iBAAK,OACD,EAAE,MAAM,UAAU,GAClB,MAAM,yCAAyC,EAAE,MAAM,MAAM,EAAE;AAEnE,UAAM,OAAO,mBAAW,gBAAgB,QAAQ,MAAM,QAAQ;AAE9D,UAAM,SAAS,MAAM,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,QAAQ,KAAI,EAAC,CAAC;AACzE,aACI,QAAQ,EAAC,QAAQ,EAAC,GAAG,OAAM,GAAG,SAAS,OAAO,EAAC,OAAO,WAAU,EAAC,CAAC;AACtE,YAAQ,YAAY,OAAO,MAAM;SAC5B;AACL,UAAM,qBAAqB,QAAQ,mBAAmB,CAAC,CAAC,CAAC;AACzD,QAAI,oBAAoB;AACtB,YAAM,SAAS,QAAQ,SAAS,EAAE,MAAM;AACxC,YAAM,OAAO,OAAO,EAAE,OAAO,EAAE,OAAO,MAAM;AAC5C,YAAM,eACF,oBAAoB,kBAAkB,MAAM,UAAU,MAAM;AAChE,eAAS,QAAQ,eAAe,YAAY,EAAE,OAAO,aAAa,MAAM;WACnE;AACL,YAAM,UAAU,IAAI,oBAAoB,gBAAgB;AACxD,YAAM,cACF,CAAC,EAAC,MAAM,SAAS,MAAM,OAAM,GAAG,EAAC,MAAM,SAAS,MAAM,SAAQ,CAAC;AACnE,YAAM,eACF,QAAQ,iBAAiB,SAAS,CAAC,CAAC,GAAG,EAAE,OAAO,WAAW;AAC/D,eAAS,QACL,EAAC,QAAQ,EAAC,GAAG,aAAY,GAAG,SAAS,OAAO,EAAC,OAAO,WAAU,EAAC,CAAC;AACpE,cAAQ,YAAY,aAAa,MAAM;;;AAI3C,SAAO;AACT;AAEO,IAAM,qBAAmC;EAC9C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC/ER,SAAU,aAAa,MAI5B;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EACJ,WACA,aACA,SACA,UACA,UACA,uBAAsB,IACpB;AACJ,QAAM,EAAC,MAAM,WAAU,IAAI;AAC3B,QAAM,QAAQ,QAAQ,SAAS,KAAK,MAAM;AAC1C,QAAM,cAAc,QAAQ,SAAS,WAAW,MAAM;AAEtD,QAAM,CAAC,QAAQ,YAAY,IAAI,oBAC3B,OAAO,aAAa,WAAW,aAAa,SAAS,UAAU,UAC/D,sBAAsB;AAC1B,SAAO;IACL,QAAQ,eAAe,CAAC,OAAO,MAAM,GAAG,UAAU,MAAM;IACxD,QAAQ,eAAe,WAAW,OAAO,SAAS,YAAY;;AAElE;AAEO,IAAM,qBAAmC;EAC9C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC7BP,IAAM,MAAM,iBACf,EAAC,QAAQ,aAAa,KAAK,eAAe,YAAQ,iBAAiB,KAAI,CAAC;AAErE,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACPP,IAAM,MAAM,gBAAgB,EAAC,QAAQ,YAAY,IAAG,CAAC;AAErD,IAAM,YAA0B;EACrC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACNP,IAAM,OAAO,gBAAgB,EAAC,QAAQ,YAAY,KAAI,CAAC;AAEvD,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACDR,SAAU,oBAAoB,MAInC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,QAAQ,SAAS,QAAO,IAAI;AACnC,QAAM,CAAA,IAAK;AAEX,QAAM,EAAC,WAAW,YAAY,WAAW,SAAS,WAAU,IACxD,qBAAa,gBAAgB,SAAS,SAAS,OAAO,KAAK;AAE/D,QAAM,eAAe,CAAC,aAAa,WAAW,SAAS;AAEvD,MAAI,eAAe,GAAG;AACpB,WAAO,QAAQ,eAAe,OAAO,OAAO,QAAQ,KAAK;;AAG3D,QAAM,YAAY,CAAA;AAElB,QAAM,iBAAiB,QACnB,EAAC,QAAQ,EAAC,GAAG,QAAO,GAAG,SAAS,OAAO,EAAC,OAAO,CAAC,YAAY,SAAS,EAAC,EAAC,CAAC;AAC5E,YAAU,KAAK,cAAc;AAC7B,QAAM,WAAW,QACb,EAAC,QAAQ,EAAC,GAAG,QAAO,GAAG,SAAS,OAAO,EAAC,OAAO,CAAC,YAAY,SAAS,EAAC,EAAC,CAAC;AAC5E,YAAU,KAAK,QAAQ;AACvB,QAAM,gBACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,OAAM,GAAG,SAAS,OAAO,EAAC,OAAO,aAAY,EAAC,CAAC;AACxE,YAAU,KAAK,aAAa;AAC5B,QAAM,SAAS,KAAK;IAClB,QAAQ,EAAC,GAAG,cAAa;IACzB;IACA,OAAO,EAAC,MAAM,MAAM,aAAa,MAAM,EAAE,KAAK,CAAC,EAAC;GACjD;AACD,QAAM,UAAU,IAAI,eAChB,CAAC,YAAY,SAAS,GAAG,WAAW,eAAe,MAAM,QACzD,SAAS,MAAM,QAAQ,SAAS,cAAc,OAAO,OAAO,KAAK;AACrE,QAAM,OAAO,aAAK,cAAc,CAAC,YAAY,SAAS,CAAC;AACvD,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,EAAC;IACjC,EAAC,MAAM,SAAS,MAAM,QAAO;IAC7B,EAAC,MAAM,SAAS,MAAM,CAAC,IAAI,EAAC;;AAE9B,QAAM,MAAM,QAAQ,iBAChB,SAAS,CAAC,UAAU,cAAc,GAAG,cAAc,OAAO,aAC1D,MAAM;AACV,YAAU,KAAK,GAAG;AAElB,QAAM,WACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,IAAG,GAAG,SAAS,OAAO,EAAC,OAAO,OAAO,MAAK,EAAC,CAAC;AAErE,YAAU,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AAEpD,SAAO;AACT;AAEO,IAAM,4BAA0C;EACrD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACtDR,IAAO,cAAP,MAAkB;EAUtB,YAAY,OAAe;AAL3B,SAAA,gBAAgB,CAAC,KAAK,SAAS;AAE/B,SAAA,gBAA0C,CAAC,KAAK,GAAG,CAAC;AACpD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,WAAW;;AAEhB,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;UACX,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmEnB,WAAO;EACT;;AAGI,IAAO,eAAP,MAAmB;EAUvB,YAAY,OAAe;AAL3B,SAAA,gBAAgB,CAAC,KAAK,SAAS;AAE/B,SAAA,gBAA0C,CAAC,KAAK,GAAG,CAAC;AACpD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAK7D,SAAK,WAAW;AAChB,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;UACX,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2DnB,WAAO;EACT;;;;ACrLF,SAAS,oCACL,SAAwB,YAAsB;AAChD,MAAI,eAAe,MAAM;AACvB,YAAQ,YAAY,WAAW,MAAM;;AAEzC;AAEA,SAAS,cAAc,KAAW;AAChC,MAAI,OAAO;AACX,SAAO,OAAO,KAAK;AACjB,YAAQ;;AAEV,SAAO;AACT;AAIM,SAAU,KACZ,MAAoE;AAEtE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,EAAC,IAAI;AACZ,QAAM,EAAC,GAAG,OAAM,IAAG;AAEnB,QAAM,SAAS,EAAE;AACjB,QAAM,UAAU,OAAO,OAAO,SAAS,CAAC;AAExC,MAAI,QAAQ,mBAAmB,CAAC,CAAC,CAAC,GAAG;AACnC,UAAM,QAAQ,QAAQ,SAAS,EAAE,MAAM;AACvC,UAAM,CAAC,aAAa,cAAc,IAC9B,YAAY,OAAO,QAAQ,EAAE,OAA0B,GAAG,MAAM;AAEpE,WAAO;MACL,QAAQ,eACJ,YAAY,OAAO,YAAY,OAAO,YAAY,MAAM;MAC5D,QAAQ,eACJ,eAAe,OAAO,eAAe,OAAO,eAAe,MAAM;;;AAIzE,MAAI,MAAM,GAAG;AACX,WAAO,OAAO,SAAS,CAAC,IAAI;AAC5B,WAAO;MACL,QAAQ,eAAe,QAAQ,EAAE,OAAO,CAAA,CAAE;MAC1C,QAAQ,eAAe,QAAQ,SAAS,CAAA,CAAE;;;AAI9C,MAAI,YAAY,GAAmB;AACjC,WAAO;MACL;MAAG,KAAK,EAAC,OAAO,EAAC,OAAO,QAAQ,OAAO,SAAS,OAAO,EAAC,GAAG,QAAO,CAAC;;;AAKvE,QAAM,QAAQ,aAAK,cAAc,MAAM;AACvC,QAAM,QAAQ,QAAQ;AACtB,QAAM,MAAM,QAAQ,EAAC,QAAQ,EAAC,EAAC,GAAG,OAAO,EAAC,OAAO,CAAC,OAAO,OAAO,EAAC,GAAG,QAAO,CAAC;AAE5E,QAAM,QAAQ,cAAc,CAAC;AAC7B,QAAM,cAAc,cAAc,OAAO;AAMzC,MAAI,UAAsB;AAK1B,QAAM,YAAY,MAAM,YAAY,OAAO,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,OAAO;AAErE,QAAM,UAAU,CAAC,KAAa,KAAa,UAAmB;AAC5D,UAAMC,UAAS,UAAS;AACxB,UAAM,UAAU,IAAI,YAAY,KAAK;AACrC,UAAM,YAAY,YAAY,OAAO,IAAI;AACzC,UAAM,kBAAkB;MACpB,EAAC,MAAM,SAAS,MAAM,CAAC,OAAO,EAAC;MAC/B,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,EAAC;MACjC,EAAC,MAAM,WAAW,MAAM,CAAC,OAAO,iBAAiB,EAAC;MAClD,EAAC,MAAM,SAAS,MAAM,CAAC,GAAG,EAAC;MAC3B,EAAC,MAAM,SAAS,MAAM,CAAC,GAAG,EAAC;;AAE/B,UAAMC,eAAc;AACpB,cAAU,QAAQ,iBACd,SAASD,SAAQ,SAAS,eAAe;AAC7C,wCAAoC,SAASC,YAAW;EAC1D;AAGA,WAAS,MAAM,GAAG,MAAM,OAAO,OAAO,GAAG;AACvC,UAAM,MAAM,MAAM;AAClB,aAAS,MAAM,KAAK,OAAO,GAAG,OAAO,GAAG;AACtC,cAAQ,KAAK,KAAK,CAAC,OAAO,WAAW,CAAC;;;AAK1C,WAAS,cAAc,aAAa,cAAc,OAAO,eAAe,GAAG;AACzE,UAAMD,UAAS,UAAS;AACxB,UAAM,eAAe,IAAI,aAAa,CAAC,OAAO,cAAc,CAAC,CAAC;AAC9D,UAAM,YAAY,YAAY,OAAO,IAAI;AACzC,UAAM,mBAAmB;MACrB,EAAC,MAAM,SAAS,MAAM,CAAC,OAAO,EAAC;MAC/B,EAAC,MAAM,SAAS,MAAM,CAAC,SAAS,EAAC;MACjC,EAAC,MAAM,SAAS,MAAM,CAAC,KAAK,EAAC;;AAEjC,UAAMC,eAAc;AACpB,cAAU,QAAQ,iBACd,cAAcD,SAAQ,SAAS,gBAAgB;AACnD,wCAAoC,SAASC,YAAW;AAGxD,UAAM,MAAM,QAAQ;AACpB,UAAM,MAAM,MAAM;AAClB,aAAS,MAAM,KAAK,OAAO,GAAG,OAAO,GAAG;AACtC,cAAQ,KAAK,KAAK,QAAQ,KAAK;;;AAKnC,MAAI,cAAc;AAClB,YAAU,MACN,EAAC,QAAQ,EAAC,GAAG,QAAO,GAAG,SAAS,OAAO,EAAC,OAAO,GAAG,MAAM,CAAC,OAAO,CAAC,EAAC,EAAC,CAAC;AACxE,sCAAoC,SAAS,WAAW;AAGxD,MAAI,SAAS,SACT,EAAC,QAAQ,EAAC,GAAG,KAAK,QAAO,GAAG,SAAS,OAAO,EAAC,MAAM,GAAG,WAAW,EAAC,EAAC,CAAC;AACxE,sCAAoC,SAAS,GAAG;AAIhD,QAAM,WAAW,OAAO,MAAM,GAAG,EAAE;AACnC,WAAS,KAAK,CAAC;AAEf,gBAAc;AACd,YAAU,QAAQ,EAAC,QAAQ,EAAC,GAAG,QAAO,GAAG,OAAO,EAAC,OAAO,SAAQ,GAAG,QAAO,CAAC;AAC3E,sCAAoC,SAAS,WAAW;AAExD,QAAM,aAAa;AACnB,WAAS,QAAQ,EAAC,QAAQ,EAAC,GAAG,OAAM,GAAG,OAAO,EAAC,OAAO,SAAQ,GAAG,QAAO,CAAC;AACzE,sCAAoC,SAAS,UAAU;AAEvD,SAAO,CAAC,QAAQ,OAAO;AACzB;AAEO,IAAM,aAA2B;EACtC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC9JR,IAAO,mBAAP,MAAuB;EAU3B,YAAY,UAA0C;AATtD,SAAA,gBAAgB,CAAC,SAAS,YAAY;AAEtC,SAAA,WAAW;AAIX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,OAAO;AAGL,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,KAAK,WAAW;AACzD,SAAK,WAAW,gBACZ,KAAK,gBAAgB,KAAK,aAAa,KAAK,aAAa;AAC7D,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;YAgET,oBAAK,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAqDrB,WAAO;EACT;;;;ACvII,SAAU,UAAU,MAIzB;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,OAAO,WAAU,IAAI;AAC5B,QAAM,EAAC,eAAe,UAAU,WAAW,YAAW,IAAI;AAE1D,QAAM,CAAC,OAAO,aAAa,YAAY,WAAW,IAAI,MAAM;AAC5D,QAAM,CAAC,WAAW,QAAQ,IACtB,eAAe,OAAO,cAAc,CAAC,aAAa,UAAU;AAChE,QAAM,WACF;IAAC;IAAO;IAAW;IAClB;EAAW;AAEhB,QAAM,UAAU,IAAI,iBAAiB,QAAQ;AAC7C,QAAM,sBAAsB,kBAAkB,YAAY,IAAI;AAC9D,MAAI;AACJ,UAAQ,UAAU;IAChB,KAAK;AACH,mBAAa;AACb;IACF,KAAK;AACH,mBAAa;AACb;IACF,KAAK;AACH,mBAAa;AACb;IACF,KAAK;AACH,mBAAa;AACb;IACF;AACE,mBAAa;AACb;;AAEJ,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,mBAAmB,EAAC;IAC3C,EAAC,MAAM,SAAS,MAAM,CAAC,UAAU,EAAC;IAAG,EAAC,MAAM,WAAW,MAAM,CAAC,SAAS,EAAC;;AAE1E,SAAO,QAAQ,iBACX,SAAS,CAAC,OAAO,UAAU,GAAG,WAAW,WAAW;AAC1D;AAEO,IAAM,kBAAgC;EAC3C,YAAY;EACZ,aAAa;EACb,YAAY;;;;AC7CR,SAAU,OACZ,MACsE;AAExE,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,MAAK,IAAI;AAChB,MAAI,EAAC,KAAI,IAAI;AAEb,MAAI,OAAO,GAAG;AACZ,YAAQ,MAAM,MAAM;;AAGtB,QAAM,IAAI;AACV,QAAM,QAAQ,EAAE,MAAM;AAEtB,QAAM,MAAM,MAAM,MAAM,IAAI;AAC5B,QAAM,WAAqB,IAAI,MAAM,QAAQ,CAAC;AAC9C,MAAI,WAAW;AACf,WAAS,IAAI,GAAG,IAAI,OAAO,KAAK;AAC9B,QAAI,MAAM,MAAM;AACd,eAAS,UAAU,IAAI,EAAE,MAAM,CAAC;;;AAIpC,QAAM,YAAY,CAAA;AAElB,QAAM,QAAQ,IAAI,MAAM,KAAK,EAAE,KAAK,CAAC;AACrC,QAAM,OAAO,EAAE,MAAM,MAAK;AAC1B,OAAK,IAAI,IAAI;AACb,QAAM,MAAoB,IAAI,MAAM,GAAG;AACvC,WAAS,IAAI,GAAG,IAAI,IAAI,QAAQ,KAAK;AACnC,UAAM,IAAI,IAAI;AACd,UAAM,SAAS,MAAM,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,OAAO,KAAI,EAAC,CAAC;AACjE,UAAM,WACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,OAAM,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AACpE,QAAI,CAAC,IAAI;AAET,cAAU,KAAK,MAAM;;AAGvB,YAAU,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AACpD,SAAO;AACT;AAEO,IAAM,eAA6B;EACxC,YAAY;EACZ,aAAa;EACb,YAAY;;;;AChDR,IAAO,4BAAP,MAAgC;EAWpC,YAAY,SAAmB,UAAoB,aAAqB;AAVxE,SAAA,cAAwB,CAAA;AAIxB,SAAA,gBAAgB,CAAC,KAAK,YAAY;AAClC,SAAA,WAAW;AACX,SAAA,gBAA0C,CAAC,IAAI,GAAG,CAAC;AACnD,SAAA,SAAS;AAIP,SAAK,cAAc;AACnB,SAAK,iBAAiB,mBAAmB,OAAO;AAChD,SAAK,WACD,gBAAgB,KAAK,gBAAgB,SAAS,KAAK,aAAa;AACpE,QAAI,gBAAgB,aAAa,gBAAgB,SAAS;AACxD,YAAM,IAAI,MAAM;wCACkB,WAAW,QAAQ;;AAEvD,SAAK,OAAO;AACZ,SAAK,YAAY;EACnB;EAEA,cAAW;AACT,UAAM,WAAW;MACf,oBAAK,OAAO,CAAC;;;;;;;;;;;YAYX,iBACI,sBAAsB,SAAS,KAAK,IAA2B,CAAC;;;;;AAKxE,WAAO;EACT;;;;AC1CI,SAAU,mBAAmB,MAIlC;AACC,QAAM,EAAC,QAAQ,SAAS,MAAK,IAAI;AACjC,QAAM,EAAC,GAAG,WAAU,IAAI;AACxB,QAAM,EAAC,YAAW,IAAI;AAEtB,QAAM,QAAQ,EAAE,MAAM;AAEtB,QAAM,YAAY,CAAA;AAElB,MAAI,OAAO;AACX,QAAM,cAAc,qBAAa,mBAAmB,CAAC,IAAI,GAAG,KAAK;AACjE,MAAI,YAAY;AAChB,MAAI,eAAe,MAAM;AACvB,gBAAY,UAAU,EAAC,QAAQ,EAAC,EAAC,GAAG,SAAS,OAAO,EAAC,MAAM,YAAW,EAAC,CAAC;AACxE,cAAU,KAAK,SAAS;AACxB,WAAO,qBAAa,iBAAiB,GAAG,KAAK,EAAE,CAAC;;AAGlD,QAAM,WAAW,qBAAa,aAAa,gBACvC,UAAU,OAAO,MAAM,WAAW;AACtC,QAAM,SAAS,aAAK,cAAc,CAAC,UAAU,MAAM,IAAI,CAAC,CAAC;AACzD,QAAM,MACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,UAAS,GAAG,SAAS,OAAO,EAAC,OAAO,CAAC,IAAI,MAAM,EAAC,EAAC,CAAC;AAC3E,YAAU,KAAK,GAAG;AAElB,QAAM,QAAQ,EAAE;AAChB,QAAM,QAAQ,CAAC,IAAI,MAAM,CAAC,GAAG,WAAW;AACxC,QAAM,SAAS,KAAK,EAAC,SAAS,OAAO,EAAC,OAAO,OAAO,GAAG,MAAK,EAAC,CAAC;AAC9D,QAAM,UAAU,IAAI,0BAA0B,IAAI,OAAO,OAAO,KAAK;AACrE,QAAM,cAAc;IAClB,EAAC,MAAM,SAAS,MAAM,CAAC,WAAW,EAAC;IACnC,EAAC,MAAM,SAAS,MAAM,CAAC,aAAK,cAAc,IAAI,KAAK,CAAC,EAAC;;AAEvD,QAAM,YAAY,QAAQ,iBACtB,SAAS,CAAC,KAAK,UAAU,GAAG,OAAO,aAAa,MAAM;AAE1D,QAAM,WACF,QAAQ,EAAC,QAAQ,EAAC,GAAG,UAAS,GAAG,SAAS,OAAO,EAAC,OAAO,SAAQ,EAAC,CAAC;AACvE,YAAU,KAAK,SAAS;AACxB,MAAI,SAAS;AACb,MAAI,eAAe,MAAM;AACvB,cAAU,KAAK,QAAQ;AACvB,UAAM,OAAO,qBAAa,uBAAuB,WAAW;AAC5D,aAAS,UAAU,EAAC,QAAQ,EAAC,GAAG,OAAM,GAAG,SAAS,OAAO,EAAC,KAAI,EAAC,CAAC;;AAGlE,YAAU,QAAQ,OAAK,QAAQ,YAAY,EAAE,MAAM,CAAC;AACpD,SAAO;AACT;AAEO,IAAM,2BAAyC;EACpD,YAAY;EACZ,aAAa;EACb,YAAY;;;;ACmGd,IAAM,gBAAgC;EACpC;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;AAGF,WAAW,gBAAgB,eAAe;AACxC,iBAAe,YAAY;;",
  "names": ["buffer", "newTexture", "PixelsOpType", "useGlobalIndex", "coords", "isFlatDispatchLayout", "dtype", "snippet", "MatMulProgramType", "buffer", "width", "height", "offset", "uniformsType", "BinaryOpType", "isNaN", "UnaryOpType", "activationFnSnippet", "transpose", "outReshaped", "real", "imag", "complex", "real", "imag", "program", "inputs", "program", "prod", "tensors2D", "outShape", "innerElementSize", "innerElementSize", "CumOpType", "reverse", "getCoords", "reverse", "reverse", "reverse", "mean", "step", "step", "prod", "sparseSegmentSum", "sparseSegmentMean", "getSourceCoords", "$defaultValue", "inputs", "prevIndices"]
}
